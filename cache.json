{"2025-01-30T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.16464v2","updated":"2025-01-30T18:58:30Z","published":"2024-10-21T19:46:06Z","title":"Beyond Browsing: API-Based Web Agents","summary":"  Web browsers are a portal to the internet, where much of human activity is\nundertaken. Thus, there has been significant research work in AI agents that\ninteract with the internet through web browsing. However, there is also another\ninterface designed specifically for machine interaction with online content:\napplication programming interfaces (APIs). In this paper we ask -- what if we\nwere to take tasks traditionally tackled by browsing agents, and give AI agents\naccess to APIs? To do so, we propose two varieties of agents: (1) an\nAPI-calling agent that attempts to perform online tasks through APIs only,\nsimilar to traditional coding agents, and (2) a Hybrid Agent that can interact\nwith online data through both web browsing and APIs. In experiments on\nWebArena, a widely-used and realistic benchmark for web navigation tasks, we\nfind that API-based agents outperform web browsing agents. Hybrid Agents\nout-perform both others nearly uniformly across tasks, resulting in a more than\n20.0% absolute improvement over web browsing alone, achieving a success rate of\n35.8%, achiving the SOTA performance among task-agnostic agents. These results\nstrongly suggest that when APIs are available, they present an attractive\nalternative to relying on web browsing alone.\n","authors":["Yueqi Song","Frank Xu","Shuyan Zhou","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.16464v2.pdf","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.18585v1","updated":"2025-01-30T18:58:18Z","published":"2025-01-30T18:58:18Z","title":"Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs","summary":"  Large language models (LLMs) such as OpenAI's o1 have demonstrated remarkable\nabilities in complex reasoning tasks by scaling test-time compute and\nexhibiting human-like deep thinking. However, we identify a phenomenon we term\nunderthinking, where o1-like LLMs frequently switch between different reasoning\nthoughts without sufficiently exploring promising paths to reach a correct\nsolution. This behavior leads to inadequate depth of reasoning and decreased\nperformance, particularly on challenging mathematical problems. To\nsystematically analyze this issue, we conduct experiments on three challenging\ntest sets and two representative open-source o1-like models, revealing that\nfrequent thought switching correlates with incorrect responses. We introduce a\nnovel metric to quantify underthinking by measuring token efficiency in\nincorrect answers. To address underthinking, we propose a decoding strategy\nwith thought switching penalty TIP that discourages premature transitions\nbetween thoughts, encouraging deeper exploration of each reasoning path.\nExperimental results demonstrate that our approach improves accuracy across\nchallenging datasets without requiring model fine-tuning. Our findings\ncontribute to understanding reasoning inefficiencies in o1-like LLMs and offer\na practical solution to enhance their problem-solving capabilities.\n","authors":["Yue Wang","Qiuzhi Liu","Jiahao Xu","Tian Liang","Xingyu Chen","Zhiwei He","Linfeng Song","Dian Yu","Juntao Li","Zhuosheng Zhang","Rui Wang","Zhaopeng Tu","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2501.18585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18578v1","updated":"2025-01-30T18:50:25Z","published":"2025-01-30T18:50:25Z","title":"R.I.P.: Better Models by Survival of the Fittest Prompts","summary":"  Training data quality is one of the most important drivers of final model\nquality. In this work, we introduce a method for evaluating data integrity\nbased on the assumption that low-quality input prompts result in high variance\nand low quality responses. This is achieved by measuring the rejected response\nquality and the reward gap between the chosen and rejected preference pair. Our\nmethod, Rejecting Instruction Preferences (RIP) can be used to filter prompts\nfrom existing training sets, or to make high quality synthetic datasets,\nyielding large performance gains across various benchmarks compared to\nunfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC Win\nRate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama\n3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, which is from 18th\nplace to 6th overall in the leaderboard.\n","authors":["Ping Yu","Weizhe Yuan","Olga Golovneva","Tianhao Wu","Sainbayar Sukhbaatar","Jason Weston","Jing Xu"],"pdf_url":"https://arxiv.org/pdf/2501.18578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07176v3","updated":"2025-01-30T18:17:13Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention enhances parameter flexibility. For example,\nunlike traditional softmax attention heads that use a static output-value (OV)\nmatrix to delete or copy inputs that the heads attend to, Cog Attention\nnaturally learns to use the sign of dynamic query-key (QK) inner products to\nrepresent these operations. This enables Cog Attention to perform multiple\noperations simultaneously within a single head. Meanwhile, Cog Attention's OV\nmatrix can focus more on refinement or modification. (2) Cog Attention enhances\nthe model's robustness against representational collapse by preventing the\n``over-squashing'' of earlier tokens into later positions. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models at various scales for language modeling and U-ViT diffusion\nmodels for image generation. Experiments show that models using Cog Attention\nexhibit superior performance compared to those employing traditional softmax\nattention modules. Our approach suggests a promising research direction for\nrethinking and breaking the entrenched constraints of traditional softmax\nattention, such as the requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Di Wang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14883v2","updated":"2025-01-30T18:13:05Z","published":"2025-01-24T19:17:06Z","title":"Verify with Caution: The Pitfalls of Relying on Imperfect Factuality\n  Metrics","summary":"  Improvements in large language models have led to increasing optimism that\nthey can serve as reliable evaluators of natural language generation outputs.\nIn this paper, we challenge this optimism by thoroughly re-evaluating five\nstate-of-the-art factuality metrics on a collection of 11 datasets for\nsummarization, retrieval-augmented generation, and question answering. We find\nthat these evaluators are inconsistent with each other and often misestimate\nsystem-level performance, both of which can lead to a variety of pitfalls. We\nfurther show that these metrics exhibit biases against highly paraphrased\noutputs and outputs that draw upon faraway parts of the source documents. We\nurge users of these factuality metrics to proceed with caution and manually\nvalidate the reliability of these metrics in their domain of interest before\nproceeding.\n","authors":["Ameya Godbole","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2501.14883v2.pdf","comment":"v2: Added Acknowledgements to funding sources and advisors"},{"id":"http://arxiv.org/abs/2501.18539v1","updated":"2025-01-30T18:07:19Z","published":"2025-01-30T18:07:19Z","title":"Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented\n  LLM-based Retrieval Method","summary":"  Real-world open-domain questions can be complicated, particularly when\nanswering them involves information from multiple information sources. LLMs\nhave demonstrated impressive performance in decomposing complex tasks into\nsimpler steps, and previous work has used it for better retrieval in support of\ncomplex questions. However, LLM's decomposition of questions is unaware of what\ndata is available and how data is organized, often leading to a sub-optimal\nretrieval performance. Recent effort in agentic RAG proposes to perform\nretrieval in an iterative fashion, where a followup query is derived as an\naction based on previous rounds of retrieval. While this provides one way of\ninteracting with the data collection, agentic RAG's exploration of data is\ninefficient because successive queries depend on previous results rather than\nbeing guided by the organization of available data in the collection. To\naddress this problem, we propose an LLM-based retrieval method -- ARM, that\naims to better align the question with the organization of the data collection\nby exploring relationships among data objects beyond matching the utterance of\nthe query, thus leading to a retrieve-all-at-once solution for complex queries.\nWe evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperforms\nstandard RAG with query decomposition by up to 5.2 pt in execution accuracy and\nagentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and\n19.3 pt higher F1 match scores compared to these approaches.\n","authors":["Peter Baile Chen","Yi Zhang","Michael Cafarella","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2501.18539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18533v1","updated":"2025-01-30T17:59:45Z","published":"2025-01-30T17:59:45Z","title":"Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models","summary":"  Large Vision-Language Models (VLMs) have achieved remarkable performance\nacross a wide range of tasks. However, their deployment in safety-critical\ndomains poses significant challenges. Existing safety fine-tuning methods,\nwhich focus on textual or multimodal content, fall short in addressing\nchallenging cases or disrupt the balance between helpfulness and harmlessness.\nOur evaluation highlights a safety reasoning gap: these methods lack safety\nvisual reasoning ability, leading to such bottlenecks. To address this\nlimitation and enhance both visual perception and reasoning in safety-critical\ncontexts, we propose a novel dataset that integrates multi-image inputs with\nsafety Chain-of-Thought (CoT) labels as fine-grained reasoning logic to improve\nmodel performance. Specifically, we introduce the Multi-Image Safety (MIS)\ndataset, an instruction-following dataset tailored for multi-image safety\nscenarios, consisting of training and test splits. Our experiments demonstrate\nthat fine-tuning InternVL2.5-8B with MIS significantly outperforms both\npowerful open-source models and API-based models in challenging multi-image\ntasks requiring safety-related visual reasoning. This approach not only\ndelivers exceptional safety performance but also preserves general capabilities\nwithout any trade-offs. Specifically, fine-tuning with MIS increases average\naccuracy by 0.83% across five general benchmarks and reduces the Attack Success\nRate (ASR) on multiple safety benchmarks by a large margin. Data and Models are\nreleased under:\n\\href{https://dripnowhy.github.io/MIS/}{\\texttt{https://dripnowhy.github.io/MIS/}}\n","authors":["Yi Ding","Lijun Li","Bing Cao","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2501.18533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17635v2","updated":"2025-01-30T17:59:08Z","published":"2025-01-29T13:12:01Z","title":"In-Context Meta LoRA Generation","summary":"  Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task\nspecific fine-tuning. However, in scenarios that involve multiple tasks,\ntraining a separate LoRA model for each one results in considerable\ninefficiency in terms of storage and inference. Moreover, existing parameter\ngeneration methods fail to capture the correlations among these tasks, making\nmulti-task LoRA parameter generation challenging. To address these limitations,\nwe propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently\nachieves task-specific customization of large language models (LLMs).\nSpecifically, we use training data from all tasks to train a tailored\ngenerator, Conditional Variational Autoencoder (CVAE). CVAE takes task\ndescriptions as inputs and produces task-aware LoRA weights as outputs. These\nLoRA weights are then merged with LLMs to create task-specialized models\nwithout the need for additional fine-tuning. Furthermore, we utilize in-context\nmeta-learning for knowledge enhancement and task mapping, to capture the\nrelationship between tasks and parameter distributions. As a result, our method\nachieves more accurate LoRA parameter generation for diverse tasks using CVAE.\nICM-LoRA enables more accurate LoRA parameter reconstruction than current\nparameter reconstruction methods and is useful for implementing task-specific\nenhancements of LoRA parameters. At the same time, our method occupies 283MB,\nonly 1\\% storage compared with the original LoRA.\n","authors":["Yihua Shao","Minxi Yan","Yang Liu","Siyu Chen","Wenjie Chen","Xinwei Long","Ziyang Yan","Lei Li","Chenyu Zhang","Nicu Sebe","Hao Tang","Yan Wang","Hao Zhao","Mengzhu Wang","Jingcai Guo"],"pdf_url":"https://arxiv.org/pdf/2501.17635v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17703v2","updated":"2025-01-30T17:58:54Z","published":"2025-01-29T15:20:30Z","title":"Critique Fine-Tuning: Learning to Critique is More Effective than\n  Learning to Imitate","summary":"  Supervised Fine-Tuning (SFT) is commonly used to train language models to\nimitate annotated responses for given instructions. In this paper, we challenge\nthis paradigm and propose Critique Fine-Tuning (CFT), a strategy where models\nlearn to critique noisy responses rather than simply imitate correct ones.\nInspired by human learning processes that emphasize critical thinking, CFT\nencourages deeper analysis and nuanced understanding-traits often overlooked by\nstandard SFT. To validate the effectiveness of CFT, we construct a 50K-sample\ndataset from WebInstruct, using GPT-4o as the teacher to generate critiques in\nthe form of ([query; noisy response], critique). CFT on this dataset yields a\nconsistent 4-10% improvement over SFT on six math benchmarks with different\nbase models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We further expand to\nMetaMath and NuminaMath datasets and observe similar gains over SFT. Notably,\nour model Qwen2.5-Math-CFT only requires 1 hour training on 8xH100 over the 50K\nexamples. It can match or outperform strong competitors like\nQwen2.5-Math-Instruct on most benchmarks, which use over 2M samples. Moreover,\nit can match the performance of SimpleRL, which is a deepseek-r1 replication\ntrained with 140x more compute. Ablation studies show that CFT is robust to the\nsource of noisy response and teacher critique model. Through these findings, we\nargue that CFT offers a more effective alternative to advance the reasoning of\nlanguage models.\n","authors":["Yubo Wang","Xiang Yue","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2501.17703v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18532v1","updated":"2025-01-30T17:58:36Z","published":"2025-01-30T17:58:36Z","title":"Differentially Private Steering for Large Language Model Alignment","summary":"  Aligning Large Language Models (LLMs) with human values and away from\nundesirable behaviors (such as hallucination) has become increasingly\nimportant. Recently, steering LLMs towards a desired behavior via activation\nediting has emerged as an effective method to mitigate harmful generations at\ninference-time. Activation editing modifies LLM representations by preserving\ninformation from positive demonstrations (e.g., truthful) and minimising\ninformation from negative demonstrations (e.g., hallucinations). When these\ndemonstrations come from a private dataset, the aligned LLM may leak private\ninformation contained in those private samples. In this work, we present the\nfirst study of aligning LLM behavior with private datasets. Our work proposes\nthe \\textit{\\underline{P}rivate \\underline{S}teering for LLM\n\\underline{A}lignment (PSA)} algorithm to edit LLM activations with\ndifferential privacy (DP) guarantees. We conduct extensive experiments on seven\ndifferent benchmarks with open-source LLMs of different sizes (0.5B to 7B) and\nmodel families (LlaMa, Qwen, Mistral and Gemma). Our results show that PSA\nachieves DP guarantees for LLM alignment with minimal loss in performance,\nincluding alignment metrics, open-ended text generation quality, and\ngeneral-purpose reasoning. We also develop the first Membership Inference\nAttack (MIA) for evaluating and auditing the empirical privacy for the problem\nof LLM steering via activation editing. Our attack is tailored for activation\nediting and relies solely on the generated texts without their associated\nprobabilities. Our experiments support the theoretical guarantees by showing\nimproved guarantees for our \\textit{PSA} algorithm compared to several existing\nnon-private techniques.\n","authors":["Anmol Goel","Yaxi Hu","Iryna Gurevych","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2501.18532v1.pdf","comment":"ICLR 2025; Code: https://github.com/UKPLab/iclr2025-psa"},{"id":"http://arxiv.org/abs/2501.13919v2","updated":"2025-01-30T17:35:08Z","published":"2025-01-23T18:58:03Z","title":"Temporal Preference Optimization for Long-Form Video Understanding","summary":"  Despite significant advancements in video large multimodal models\n(video-LMMs), achieving effective temporal grounding in long-form videos\nremains a challenge for existing models. To address this limitation, we propose\nTemporal Preference Optimization (TPO), a novel post-training framework\ndesigned to enhance the temporal grounding capabilities of video-LMMs through\npreference learning. TPO adopts a self-training approach that enables models to\ndifferentiate between well-grounded and less accurate temporal responses by\nleveraging curated preference datasets at two granularities: localized temporal\ngrounding, which focuses on specific video segments, and comprehensive temporal\ngrounding, which captures extended temporal dependencies across entire video\nsequences. By optimizing on these preference datasets, TPO significantly\nenhances temporal understanding while reducing reliance on manually annotated\ndata. Extensive experiments on three long-form video understanding\nbenchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness\nof TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO\nestablishes itself as the leading 7B model on the Video-MME benchmark,\nunderscoring the potential of TPO as a scalable and efficient solution for\nadvancing temporal reasoning in long-form video understanding. Project page:\nhttps://ruili33.github.io/tpo_website.\n","authors":["Rui Li","Xiaohan Wang","Yuhui Zhang","Zeyu Wang","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2501.13919v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06595v3","updated":"2025-01-30T17:34:51Z","published":"2024-09-10T15:39:32Z","title":"GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question\n  Answering","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use\nLarge Language Models (LLMs) alongside private and up-to-date knowledge bases.\nIn this work, we address the challenges of using LLM-as-a-Judge when evaluating\ngrounded answers generated by RAG systems. To assess the calibration and\ndiscrimination capabilities of judge models, we identify 7 generator failure\nmodes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a\nmeta-evaluation benchmark of 144 unit tests. This benchmark reveals that\nexisting automated RAG evaluation frameworks often overlook important failure\nmodes, even when using GPT-4 as a judge.\n  To improve on the current design of automated RAG evaluation frameworks, we\npropose a novel pipeline and find that while closed models perform well on\nGroUSE, state-of-the-art open-source judges do not generalize to our proposed\ncriteria, despite strong correlation with GPT-4's judgement. Our findings\nsuggest that correlation with GPT-4 is an incomplete proxy for the practical\nperformance of judge models and should be supplemented with evaluations on unit\ntests for precise failure mode detection.\n  We further show that finetuning Llama-3 on GPT-4's reasoning traces\nsignificantly boosts its evaluation capabilities, improving upon both\ncorrelation with GPT-4's evaluations and calibration on reference situations.\n","authors":["Sacha Muller","António Loison","Bilel Omrani","Gautier Viaud"],"pdf_url":"https://arxiv.org/pdf/2409.06595v3.pdf","comment":"Proceedings of the 31st International Conference on Computational\n  Linguistics"},{"id":"http://arxiv.org/abs/2406.20095v3","updated":"2025-01-30T17:34:37Z","published":"2024-06-28T17:59:12Z","title":"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy","summary":"  Vision Language Models (VLMs) have recently been leveraged to generate\nrobotic actions, forming Vision-Language-Action (VLA) models. However, directly\nadapting a pretrained VLM for robotic control remains challenging, particularly\nwhen constrained by a limited number of robot demonstrations. In this work, we\nintroduce LLaRA: Large Language and Robotics Assistant, a framework that\nformulates robot action policy as visuo-textual conversations and enables an\nefficient transfer of a pretrained VLM into a powerful VLA, motivated by the\nsuccess of visual instruction tuning in Computer Vision. First, we present an\nautomated pipeline to generate conversation-style instruction tuning data for\nrobots from existing behavior cloning datasets, aligning robotic actions with\nimage pixel coordinates. Further, we enhance this dataset in a self-supervised\nmanner by defining six auxiliary tasks, without requiring any additional action\nannotations. We show that a VLM finetuned with a limited amount of such\ndatasets can produce meaningful action decisions for robotic control. Through\nexperiments across multiple simulated and real-world tasks, we demonstrate that\nLLaRA achieves state-of-the-art performance while preserving the generalization\ncapabilities of large language models. The code, datasets, and pretrained\nmodels are available at https://github.com/LostXine/LLaRA.\n","authors":["Xiang Li","Cristina Mata","Jongwoo Park","Kumara Kahatapitiya","Yoo Sung Jang","Jinghuan Shang","Kanchana Ranasinghe","Ryan Burgert","Mu Cai","Yong Jae Lee","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2406.20095v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.18512v1","updated":"2025-01-30T17:23:50Z","published":"2025-01-30T17:23:50Z","title":"Streaming DiLoCo with overlapping communication: Towards a Distributed\n  Free Lunch","summary":"  Training of large language models (LLMs) is typically distributed across a\nlarge number of accelerators to reduce training time. Since internal states and\nparameter gradients need to be exchanged at each and every single gradient\nstep, all devices need to be co-located using low-latency high-bandwidth\ncommunication links to support the required high volume of exchanged bits.\nRecently, distributed algorithms like DiLoCo have relaxed such co-location\nconstraint: accelerators can be grouped into ``workers'', where\nsynchronizations between workers only occur infrequently. This in turn means\nthat workers can afford being connected by lower bandwidth communication links\nwithout affecting learning quality. However, in these methods, communication\nacross workers still requires the same peak bandwidth as before, as the\nsynchronizations require all parameters to be exchanged across all workers. In\nthis paper, we improve DiLoCo in three ways. First, we synchronize only subsets\nof parameters in sequence, rather than all at once, which greatly reduces peak\nbandwidth. Second, we allow workers to continue training while synchronizing,\nwhich decreases wall clock time. Third, we quantize the data exchanged by\nworkers, which further reduces bandwidth across workers. By properly combining\nthese modifications, we show experimentally that we can distribute training of\nbillion-scale parameters and reach similar quality as before, but reducing\nrequired bandwidth by two orders of magnitude.\n","authors":["Arthur Douillard","Yanislav Donchev","Keith Rush","Satyen Kale","Zachary Charles","Zachary Garrett","Gabriel Teston","Dave Lacey","Ross McIlroy","Jiajun Shen","Alexandre Ramé","Arthur Szlam","Marc'Aurelio Ranzato","Paul Barham"],"pdf_url":"https://arxiv.org/pdf/2501.18512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18511v1","updated":"2025-01-30T17:21:44Z","published":"2025-01-30T17:21:44Z","title":"WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in\n  Post-Training","summary":"  Language model (LLM) post-training, from DPO to distillation, can refine\nbehaviors and unlock new skills, but the open science supporting these\npost-training techniques is still in its infancy. One limiting factor has been\nthe difficulty of conducting large-scale comparative analyses of synthetic data\ngenerating models and LLM judges. To close this gap, we introduce WILDCHAT-50M,\nthe largest public chat dataset to date. We extend the existing WildChat\ndataset to include responses not only from GPT, but from over 50 different\nopen-weight models, ranging in size from 0.5B to 104B parameters. We conduct an\nextensive comparative analysis and demonstrate the potential of this dataset by\ncreating RE-WILD, our own public SFT mix, which outperforms the recent Tulu-3\nSFT mixture from Allen AI with only 40% as many samples. Our dataset, samples\nand code are available at https://github.com/penfever/wildchat-50m.\n","authors":["Benjamin Feuer","Chinmay Hegde"],"pdf_url":"https://arxiv.org/pdf/2501.18511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16273v2","updated":"2025-01-30T16:44:45Z","published":"2025-01-27T18:06:36Z","title":"Return of the Encoder: Maximizing Parameter Efficiency for SLMs","summary":"  The dominance of large decoder-only language models has overshadowed\nencoder-decoder architectures, despite their fundamental efficiency advantages\nin sequence processing. For small language models (SLMs) - those with 1 billion\nparameters or fewer - our systematic analysis across GPU, CPU, and NPU\nplatforms reveals that encoder-decoder architectures achieve 47% lower\nfirst-token latency and 4.7x higher throughput compared to decoder-only models\non edge devices. These gains may be attributed to encoder-decoder's one-time\ninput processing and efficient separation of understanding and generation\nphases.\n  We introduce a novel knowledge distillation framework that enables\nencoder-decoder models to leverage capabilities from large scalable\ndecoder-only teachers while preserving their architectural advantages,\nachieving up to 6 average performance points improvement across diverse tasks,\nwith significant gains in asymmetric sequence tasks where input and output\ndistributions can benefit from different processing approaches.\n  When combined with modern advances like Rotary Positional Embeddings (RoPE)\nand Vision encoders, our systematic investigation demonstrates that\nencoder-decoder architectures provide a more practical path toward deploying\ncapable language models in resource-constrained environments. Our findings\nchallenge the prevailing trend toward decoder-only scaling, showing that\narchitectural choices become increasingly crucial as parameter budgets\ndecrease, particularly for on-device and edge deployments where computational\nefficiency is paramount.\n","authors":["Mohamed Elfeki","Rui Liu","Chad Voegele"],"pdf_url":"https://arxiv.org/pdf/2501.16273v2.pdf","comment":"13 pages, 5 figures. LLMs/SLMs, encoder-decoder and decoder-only"},{"id":"http://arxiv.org/abs/2501.16673v2","updated":"2025-01-30T16:40:12Z","published":"2025-01-28T03:18:48Z","title":"LLM-AutoDiff: Auto-Differentiate Any LLM Workflow","summary":"  Large Language Models (LLMs) have reshaped natural language processing,\npowering applications from multi-hop retrieval and question answering to\nautonomous agent workflows. Yet, prompt engineering -- the task of crafting\ntextual inputs to effectively direct LLMs -- remains difficult and\nlabor-intensive, particularly for complex pipelines that combine multiple LLM\ncalls with functional operations like retrieval and data formatting. We\nintroduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering\n(APE) that extends textual gradient-based methods (such as Text-Grad) to\nmulti-component, potentially cyclic LLM architectures. Implemented within the\nAdalFlow library, LLM-AutoDiff treats each textual input as a trainable\nparameter and uses a frozen backward engine LLM to generate feedback-akin to\ntextual gradients -- that guide iterative prompt updates. Unlike prior\nsingle-node approaches, LLM-AutoDiff inherently accommodates functional nodes,\npreserves time-sequential behavior in repeated calls (e.g., multi-hop loops),\nand combats the \"lost-in-the-middle\" problem by isolating distinct sub-prompts\n(instructions, formats, or few-shot examples). It further boosts training\nefficiency by focusing on error-prone samples through selective gradient\ncomputation. Across diverse tasks, including single-step classification,\nmulti-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff\nconsistently outperforms existing textual gradient baselines in both accuracy\nand training cost. By unifying prompt optimization through a graph-centric\nlens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating\nLLM workflows - mirroring the transformative role that automatic\ndifferentiation libraries have long played in neural network research.\n","authors":["Li Yin","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2501.16673v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03249v3","updated":"2025-01-30T16:31:31Z","published":"2024-10-04T09:14:11Z","title":"How Much Can We Forget about Data Contamination?","summary":"  The leakage of benchmark data into the training data has emerged as a\nsignificant challenge for evaluating the capabilities of large language models\n(LLMs). In this work, we challenge the common assumption that small-scale\ncontamination renders benchmark evaluations invalid. First, we experimentally\nquantify the magnitude of benchmark overfitting based on scaling along three\ndimensions: The number of model parameters (up to 1.6B), the number of times an\nexample is seen (up to 144), and the number of training tokens (up to 40B). If\nmodel and data follow the Chinchilla scaling laws, minor contamination indeed\nleads to overfitting. At the same time, even 144 times of contamination can be\nforgotten if the training data is scaled beyond five times Chinchilla, a regime\ncharacteristic of many modern LLMs. Continual pre-training of OLMo-7B\ncorroborates these results. Next, we study the impact of the weight decay\nparameter on example forgetting, showing that empirical forgetting occurs\nfaster than the cumulative weight decay. This allows us to gauge the degree of\nexample forgetting in large-scale training runs, indicating that many LLMs,\nincluding Lllama 3 405B, have forgotten the data seen at the beginning of\ntraining.\n","authors":["Sebastian Bordt","Suraj Srinivas","Valentyn Boreiko","Ulrike von Luxburg"],"pdf_url":"https://arxiv.org/pdf/2410.03249v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16727v2","updated":"2025-01-30T16:17:56Z","published":"2025-01-28T06:07:58Z","title":"xJailbreak: Representation Space Guided Reinforcement Learning for\n  Interpretable LLM Jailbreaking","summary":"  Safety alignment mechanism are essential for preventing large language models\n(LLMs) from generating harmful information or unethical content. However,\ncleverly crafted prompts can bypass these safety measures without accessing the\nmodel's internal parameters, a phenomenon known as black-box jailbreak.\nExisting heuristic black-box attack methods, such as genetic algorithms, suffer\nfrom limited effectiveness due to their inherent randomness, while recent\nreinforcement learning (RL) based methods often lack robust and informative\nreward signals. To address these challenges, we propose a novel black-box\njailbreak method leveraging RL, which optimizes prompt generation by analyzing\nthe embedding proximity between benign and malicious prompts. This approach\nensures that the rewritten prompts closely align with the intent of the\noriginal prompts while enhancing the attack's effectiveness. Furthermore, we\nintroduce a comprehensive jailbreak evaluation framework incorporating\nkeywords, intent matching, and answer validation to provide a more rigorous and\nholistic assessment of jailbreak success. Experimental results show the\nsuperiority of our approach, achieving state-of-the-art (SOTA) performance on\nseveral prominent open and closed-source LLMs, including Qwen2.5-7B-Instruct,\nLlama3.1-8B-Instruct, and GPT-4o-0806. Our method sets a new benchmark in\njailbreak attack effectiveness, highlighting potential vulnerabilities in LLMs.\nThe codebase for this work is available at\nhttps://github.com/Aegis1863/xJailbreak.\n","authors":["Sunbowen Lee","Shiwen Ni","Chi Wei","Shuaimin Li","Liyang Fan","Ahmadreza Argha","Hamid Alinejad-Rokny","Ruifeng Xu","Yicheng Gong","Min Yang"],"pdf_url":"https://arxiv.org/pdf/2501.16727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18457v1","updated":"2025-01-30T16:15:38Z","published":"2025-01-30T16:15:38Z","title":"CALM: Unleashing the Cross-Lingual Self-Aligning Ability of Language\n  Model Question Answering","summary":"  Large Language Models (LLMs) are pretrained on extensive multilingual corpora\nto acquire both language-specific cultural knowledge and general knowledge.\nIdeally, while LLMs should provide consistent responses to culture-independent\nquestions across languages, we observe significant performance disparities. To\naddress this, we explore the Cross-Lingual Self-Aligning ability of Language\nModels (CALM) to align knowledge across languages. Specifically, for a given\nquestion, we sample multiple responses across different languages, and select\nthe most self-consistent response as the target, leaving the remaining\nresponses as negative examples. We then employ direct preference optimization\n(DPO) to align the model's knowledge across different languages. Evaluations on\nthe MEDQA and X-CSQA datasets demonstrate CALM's effectiveness in enhancing\ncross-lingual knowledge question answering, both in zero-shot and retrieval\naugmented settings. We also found that increasing the number of languages\ninvolved in CALM training leads to even higher accuracy and consistency. We\noffer a qualitative analysis of how cross-lingual consistency can enhance\nknowledge alignment and explore the method's generalizability. The source code\nand data of this paper are available on GitHub.\n","authors":["Yumeng Wang","Zhiyuan Fan","Qingyun Wang","May Fung","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2501.18457v1.pdf","comment":"Accepted by NAACL 2025"},{"id":"http://arxiv.org/abs/2410.18417v2","updated":"2025-01-30T15:45:45Z","published":"2024-10-24T04:02:30Z","title":"Large Language Models Reflect the Ideology of their Creators","summary":"  Large language models (LLMs) are trained on vast amounts of data to generate\nnatural language, enabling them to perform tasks like text summarization and\nquestion answering. These models have become popular in artificial intelligence\n(AI) assistants like ChatGPT and already play an influential role in how humans\naccess information. However, the behavior of LLMs varies depending on their\ndesign, training, and use.\n  In this paper, we prompt a diverse panel of popular LLMs to describe a large\nnumber of prominent personalities with political relevance, in all six official\nlanguages of the United Nations. By identifying and analyzing moral assessments\nreflected in their responses, we find normative differences between LLMs from\ndifferent geopolitical regions, as well as between the responses of the same\nLLM when prompted in different languages. Among only models in the United\nStates, we find that popularly hypothesized disparities in political views are\nreflected in significant normative differences related to progressive values.\nAmong Chinese models, we characterize a division between internationally- and\ndomestically-focused models.\n  Our results show that the ideological stance of an LLM appears to reflect the\nworldview of its creators. This poses the risk of political instrumentalization\nand raises concerns around technological and regulatory efforts with the stated\naim of making LLMs ideologically 'unbiased'.\n","authors":["Maarten Buyl","Alexander Rogiers","Sander Noels","Guillaume Bied","Iris Dominguez-Catena","Edith Heiter","Iman Johary","Alexandru-Cristian Mara","Raphaël Romero","Jefrey Lijffijt","Tijl De Bie"],"pdf_url":"https://arxiv.org/pdf/2410.18417v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18435v1","updated":"2025-01-30T15:42:24Z","published":"2025-01-30T15:42:24Z","title":"GENIE: Generative Note Information Extraction model for structuring EHR\n  data","summary":"  Electronic Health Records (EHRs) hold immense potential for advancing\nhealthcare, offering rich, longitudinal data that combines structured\ninformation with valuable insights from unstructured clinical notes. However,\nthe unstructured nature of clinical text poses significant challenges for\nsecondary applications. Traditional methods for structuring EHR free-text data,\nsuch as rule-based systems and multi-stage pipelines, are often limited by\ntheir time-consuming configurations and inability to adapt across clinical\nnotes from diverse healthcare settings. Few systems provide a comprehensive\nattribute extraction for terminologies. While giant large language models\n(LLMs) like GPT-4 and LLaMA 405B excel at structuring tasks, they are slow,\ncostly, and impractical for large-scale use. To overcome these limitations, we\nintroduce GENIE, a Generative Note Information Extraction system that leverages\nLLMs to streamline the structuring of unstructured clinical text into usable\ndata with standardized format. GENIE processes entire paragraphs in a single\npass, extracting entities, assertion statuses, locations, modifiers, values,\nand purposes with high accuracy. Its unified, end-to-end approach simplifies\nworkflows, reduces errors, and eliminates the need for extensive manual\nintervention. Using a robust data preparation pipeline and fine-tuned small\nscale LLMs, GENIE achieves competitive performance across multiple information\nextraction tasks, outperforming traditional tools like cTAKES and MetaMap and\ncan handle extra attributes to be extracted. GENIE strongly enhances real-world\napplicability and scalability in healthcare systems. By open-sourcing the model\nand test data, we aim to encourage collaboration and drive further advancements\nin EHR structurization.\n","authors":["Huaiyuan Ying","Hongyi Yuan","Jinsen Lu","Zitian Qu","Yang Zhao","Zhengyun Zhao","Isaac Kohane","Tianxi Cai","Sheng Yu"],"pdf_url":"https://arxiv.org/pdf/2501.18435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07066v3","updated":"2025-01-30T15:24:28Z","published":"2024-11-11T15:30:16Z","title":"Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training","summary":"  Network pruning focuses on computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has been pruning and re-training, which nowadays\nis inconvenient due to the vast amount of pre-trained models, which are in any\ncase too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAL}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs,\nwhich modifies the block-wise and row-wise sparsity exploiting information from\nboth the dense model and its sparse version to maximize the \\emph{neuron\nalignment} among activations. Differently from existing methods, our approach\nadaptively selects the best hyperparameters for the block-wise and row-wise\nsparsity ratios w.r.t. the model and the desired sparsity, and requires\n\\emph{no re-training}. We test our method over 276 cases combining four LLM\nfamilies, three sparsity ratios, and ten language tasks (three language\nmodeling and seven zero-shot datasets), showing how it consistently outperforms\nthe latest state-of-the-art methods in terms of performance-runtime trade-off.\nThe code is available at\n\\href{https://github.com/eliacunegatti/NeuroAL}{https://github.com/eliacunegatti/NeuroAL}.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2411.07066v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2211.11337v4","updated":"2025-01-30T15:13:01Z","published":"2022-11-21T10:37:56Z","title":"DreamArtist++: Controllable One-Shot Text-to-Image Generation via\n  Positive-Negative Adapter","summary":"  State-of-the-arts text-to-image generation models such as Imagen and Stable\nDiffusion Model have succeed remarkable progresses in synthesizing\nhigh-quality, feature-rich images with high resolution guided by human text\nprompts. Since certain characteristics of image content \\emph{e.g.}, very\nspecific object entities or styles, are very hard to be accurately described by\ntext, some example-based image generation approaches have been proposed,\n\\emph{i.e.} generating new concepts based on absorbing the salient features of\na few input references. Despite of acknowledged successes, these methods have\nstruggled on accurately capturing the reference examples' characteristics while\nkeeping diverse and high-quality image generation, particularly in the one-shot\nscenario (\\emph{i.e.} given only one reference). To tackle this problem, we\npropose a simple yet effective framework, namely DreamArtist, which adopts a\nnovel positive-negative prompt-tuning learning strategy on the pre-trained\ndiffusion model, and it has shown to well handle the trade-off between the\naccurate controllability and fidelity of image generation with only one\nreference example. Specifically, our proposed framework incorporates both\npositive and negative embeddings or adapters and optimizes them in a joint\nmanner. The positive part aggressively captures the salient characteristics of\nthe reference image to drive diversified generation and the negative part\nrectifies inadequacies from the positive part. We have conducted extensive\nexperiments and evaluated the proposed method from image similarity (fidelity)\nand diversity, generation controllability, and style cloning. And our\nDreamArtist has achieved a superior generation performance over existing\nmethods. Besides, our additional evaluation on extended tasks, including\nconcept compositions and prompt-guided image editing, demonstrates its\neffectiveness for more applications.\n","authors":["Ziyi Dong","Pengxu Wei","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2211.11337v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.12851v2","updated":"2025-01-30T14:36:52Z","published":"2025-01-22T12:59:08Z","title":"ACEBench: Who Wins the Match Point in Tool Learning?","summary":"  Large language models (LLMs) have demonstrated significant potential in\ndecision-making and reasoning, especially when combined with various tools to\neffectively solve complex problems. However, existing evaluation systems for\nassessing LLM function calling capabilities have several limitations: (1)\nlimited evaluation scenarios, lacking assessments in real multi-turn dialogue\ncontexts; (2) narrow evaluation dimensions, lacking detailed assessments for\nfine-grained function calls; (3) relying on LLMs or real API executions for\nresult evaluation, which introduces significant overhead. To address these\nissues, we propose a comprehensive evaluation system named ACEBench. This\nsystem is meticulously designed to encompass a wide spectrum of function\ncalling scenarios. Moreover, it categorizes these scenarios into three primary\ntypes according to the evaluation methodology: Normal, Special, and Agent.\nNormal evaluates function calls in basic scenarios; Special evaluates function\ncalls in scenarios with vague or incomplete instructions; Agent introduces\nmulti-agent interactions to simulate function calling evaluation in real-world\nmulti-turn interactions. We conducted extensive experiments on ACEBench,\nanalyzing various LLMs in-depth and performing a more granular analysis of\nerror causes across different data types.\n","authors":["Chen Chen","Xinlong Hao","Weiwen Liu","Xu Huang","Xingshan Zeng","Shuai Yu","Dexun Li","Shuai Wang","Weinan Gan","Yuefeng Huang","Wulong Liu","Xinzhi Wang","Defu Lian","Baoqun Yin","Yasheng Wang","Wu Liu"],"pdf_url":"https://arxiv.org/pdf/2501.12851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18365v1","updated":"2025-01-30T14:15:09Z","published":"2025-01-30T14:15:09Z","title":"RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against\n  Retrieval Defects","summary":"  Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge retrieved from a knowledge base. However, its\neffectiveness is fundamentally constrained by the reliability of both the\nretriever and the knowledge base. In real-world scenarios, imperfections in\nthese components often lead to the retrieval of noisy, irrelevant, or\nmisleading counterfactual information, ultimately undermining the\ntrustworthiness of RAG systems. To address this challenge, we propose Robust\nFine-Tuning (RbFT), a method designed to enhance the resilience of LLMs against\nretrieval defects through two targeted fine-tuning tasks. Experimental results\ndemonstrate that RbFT significantly improves the robustness of RAG systems\nacross diverse retrieval conditions, surpassing existing methods while\nmaintaining high inference efficiency and compatibility with other robustness\ntechniques.\n","authors":["Yiteng Tu","Weihang Su","Yujia Zhou","Yiqun Liu","Qingyao Ai"],"pdf_url":"https://arxiv.org/pdf/2501.18365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18362v1","updated":"2025-01-30T14:07:56Z","published":"2025-01-30T14:07:56Z","title":"MedXpertQA: Benchmarking Expert-Level Medical Reasoning and\n  Understanding","summary":"  We introduce MedXpertQA, a highly challenging and comprehensive benchmark to\nevaluate expert-level medical knowledge and advanced reasoning. MedXpertQA\nincludes 4,460 questions spanning 17 specialties and 11 body systems. It\nincludes two subsets, Text for text evaluation and MM for multimodal\nevaluation. Notably, MM introduces expert-level exam questions with diverse\nimages and rich clinical information, including patient records and examination\nresults, setting it apart from traditional medical multimodal benchmarks with\nsimple QA pairs generated from image captions. MedXpertQA applies rigorous\nfiltering and augmentation to address the insufficient difficulty of existing\nbenchmarks like MedQA, and incorporates specialty board questions to improve\nclinical relevance and comprehensiveness. We perform data synthesis to mitigate\ndata leakage risk and conduct multiple rounds of expert reviews to ensure\naccuracy and reliability. We evaluate 16 leading models on MedXpertQA.\nMoreover, medicine is deeply connected to real-world decision-making, providing\na rich and representative setting for assessing reasoning abilities beyond\nmathematics and code. To this end, we develop a reasoning-oriented subset to\nfacilitate the assessment of o1-like models.\n","authors":["Yuxin Zuo","Shang Qu","Yifei Li","Zhangren Chen","Xuekai Zhu","Ermo Hua","Kaiyan Zhang","Ning Ding","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.18362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18356v1","updated":"2025-01-30T14:03:36Z","published":"2025-01-30T14:03:36Z","title":"State Stream Transformer (SST) : Emergent Metacognitive Behaviours\n  Through Latent State Persistence","summary":"  We introduce the State Stream Transformer (SST), a novel LLM architecture\nthat reveals emergent reasoning behaviours and capabilities latent in\npretrained weights through addressing a fundamental limitation in traditional\ntransformer models: the lack of latent computational continuity across\nautoregressive generations in the state space. SST introduces a sliding window\nlatent state (FFN) cache with weighted decay that maintains and evolves\npersistent latent processes throughout autoregressive generations. Through\ncontrolled experiments comparing base and SST architectures using the same\nfrozen weights, we demonstrate that this architectural modification alone\nenables enhanced reasoning capabilities which appear best explained by some\nform of potential higher-order processing, as evidenced by emergent\nmetacognitive behaviours. These behaviours persist under controlled conditions\ndesigned to eliminate confounding factors such as stochastic variation or\nlearned response patterns. Analysis of latent state distributions and\nprocessing dynamics provides evidence that it is solely the 'state stream' that\nis responsible for these phenomena. In quantitative evaluations, the SST\nachieves substantial performance improvements over the base model on two\nreasoning benchmarks, reaching 89.01\\% accuracy on GSM-8K (0-shot) and 91.04\\%\non ARC Challenge (0-shot CoT). These findings indicate that persistent\ncomputation in the latent state space enables fundamentally different\ninformation processing and internal reasoning strategies, with implications for\nour understanding of artificial intelligence systems.\n","authors":["Thea Aviss"],"pdf_url":"https://arxiv.org/pdf/2501.18356v1.pdf","comment":"25 pages, 3 figures"},{"id":"http://arxiv.org/abs/2501.18324v1","updated":"2025-01-30T13:11:19Z","published":"2025-01-30T13:11:19Z","title":"A Video-grounded Dialogue Dataset and Metric for Event-driven Activities","summary":"  This paper presents VDAct, a dataset for a Video-grounded Dialogue on\nEvent-driven Activities, alongside VDEval, a session-based context evaluation\nmetric specially designed for the task. Unlike existing datasets, VDAct\nincludes longer and more complex video sequences that depict a variety of\nevent-driven activities that require advanced contextual understanding for\naccurate response generation. The dataset comprises 3,000 dialogues with over\n30,000 question-and-answer pairs, derived from 1,000 videos with diverse\nactivity scenarios. VDAct displays a notably challenging characteristic due to\nits broad spectrum of activity scenarios and wide range of question types.\nEmpirical studies on state-of-the-art vision foundation models highlight their\nlimitations in addressing certain question types on our dataset. Furthermore,\nVDEval, which integrates dialogue session history and video content summaries\nextracted from our supplementary Knowledge Graphs to evaluate individual\nresponses, demonstrates a significantly higher correlation with human\nassessments on the VDAct dataset than existing evaluation metrics that rely\nsolely on the context of single dialogue turns.\n","authors":["Wiradee Imrattanatrai","Masaki Asada","Kimihiro Hasegawa","Zhi-Qi Cheng","Ken Fukuda","Teruko Mitamura"],"pdf_url":"https://arxiv.org/pdf/2501.18324v1.pdf","comment":"Accepted at AAAI2025"},{"id":"http://arxiv.org/abs/2410.01805v2","updated":"2025-01-30T13:07:37Z","published":"2024-10-02T17:59:52Z","title":"Locret: Enhancing Eviction in Long-Context LLM Inference with Trained\n  Retaining Heads on Consumer-Grade Devices","summary":"  Scaling the input context length of a large language model (LLM) incurs a\nsignificant increase in computation cost and memory footprint to maintain the\nattention key-value (KV) cache. Existing KV cache compression methods suffer\nfrom inefficient compression strategies and limited memory reduction effects,\nmaking it difficult for LLMs to conduct long-context inference on\nconsumer-grade devices, especially when inferring long-context stream input.\nSuch obstacles prevent consumer-grade devices from supporting more complex\napplications, creating challenges for the democratization of LLMs. To overcome\nthis, we propose Locret, the first framework to create an eviction policy\ncompatible with chunked prefill. By evaluating the causal importance of KV\ncache units by learnable retaining heads, Locret enables precise eviction of\ncache units, facilitating efficient long-context inference. In our extensive\nempirical studies, Locret outperforms the recent popular and competitive\napproaches in terms of memory efficiency and generation quality -- Locret\nachieves up to 20x of KV cache compression ratio within less than 10%\nperformance loss. Furthermore, Locret achieves 128K+ long-context inference on\na single NVIDIA 4090 GPU without compromising generation quality and only costs\n<1 GPU hour of additional training.\n","authors":["Yuxiang Huang","Binhang Yuan","Xu Han","Chaojun Xiao","Zhiyuan Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01805v2.pdf","comment":"Preprints"},{"id":"http://arxiv.org/abs/2501.18292v1","updated":"2025-01-30T12:08:00Z","published":"2025-01-30T12:08:00Z","title":"Citation Recommendation based on Argumentative Zoning of User Queries","summary":"  Citation recommendation aims to locate the important papers for scholars to\ncite. When writing the citing sentences, the authors usually hold different\nciting intents, which are referred to citation function in citation analysis.\nSince argumentative zoning is to identify the argumentative and rhetorical\nstructure in scientific literature, we want to use this information to improve\nthe citation recommendation task. In this paper, a multi-task learning model is\nbuilt for citation recommendation and argumentative zoning classification. We\nalso generated an annotated corpus of the data from PubMed Central based on a\nnew argumentative zoning schema. The experimental results show that, by\nconsidering the argumentative information in the citing sentence, citation\nrecommendation model will get better performance.\n","authors":["Shutian Ma","Chengzhi Zhang","Heng Zhang","Zheng Gao"],"pdf_url":"https://arxiv.org/pdf/2501.18292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13798v3","updated":"2025-01-30T12:03:48Z","published":"2024-05-22T16:23:40Z","title":"Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property\n  for Perplexity in Generative Language Models","summary":"  We prove a new asymptotic equipartition property for the perplexity of long\ntexts generated by a language model and present supporting experimental\nevidence from open-source models. Specifically we show that the logarithmic\nperplexity of any large text generated by a language model must asymptotically\nconverge to the average entropy of its token distributions. This defines a\n\"typical set\" that all long synthetic texts generated by a language model must\nbelong to. We show that this typical set is a vanishingly small subset of all\npossible grammatically correct outputs. These results suggest possible\napplications to important practical problems such as (a) detecting synthetic\nAI-generated text, and (b) testing whether a text was used to train a language\nmodel. We make no simplifying assumptions (such as stationarity) about the\nstatistics of language model outputs, and therefore our results are directly\napplicable to practical real-world models without any approximations.\n","authors":["Avinash Mudireddy","Tyler Bell","Raghu Mudumbai"],"pdf_url":"https://arxiv.org/pdf/2405.13798v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18287v1","updated":"2025-01-30T11:55:44Z","published":"2025-01-30T11:55:44Z","title":"Mining for Species, Locations, Habitats, and Ecosystems from Scientific\n  Papers in Invasion Biology: A Large-Scale Exploratory Study with Large\n  Language Models","summary":"  This paper presents an exploratory study that harnesses the capabilities of\nlarge language models (LLMs) to mine key ecological entities from invasion\nbiology literature. Specifically, we focus on extracting species names, their\nlocations, associated habitats, and ecosystems, information that is critical\nfor understanding species spread, predicting future invasions, and informing\nconservation efforts. Traditional text mining approaches often struggle with\nthe complexity of ecological terminology and the subtle linguistic patterns\nfound in these texts. By applying general-purpose LLMs without domain-specific\nfine-tuning, we uncover both the promise and limitations of using these models\nfor ecological entity extraction. In doing so, this study lays the groundwork\nfor more advanced, automated knowledge extraction tools that can aid\nresearchers and practitioners in understanding and managing biological\ninvasions.\n","authors":["Jennifer D'Souza","Zachary Laubach","Tarek Al Mustafa","Sina Zarrieß","Robert Frühstückl","Phyllis Illari"],"pdf_url":"https://arxiv.org/pdf/2501.18287v1.pdf","comment":"8 pages, 2 figures, accepted to the NLP4Ecology Workshop 2025\n  (https://nlp4ecology2025.di.unito.it/) co-located with the Joint 25th Nordic\n  Conference on Computational Linguistics and 11th Baltic Conference on Human\n  Language Technologies"},{"id":"http://arxiv.org/abs/2501.18280v1","updated":"2025-01-30T11:37:40Z","published":"2025-01-30T11:37:40Z","title":"Jailbreaking LLMs' Safeguard with Universal Magic Words for Text\n  Embedding Models","summary":"  The security issue of large language models (LLMs) has gained significant\nattention recently, with various defense mechanisms developed to prevent\nharmful outputs, among which safeguards based on text embedding models serve as\na fundamental defense. Through testing, we discover that the distribution of\ntext embedding model outputs is significantly biased with a large mean.\nInspired by this observation, we propose novel efficient methods to search for\nuniversal magic words that can attack text embedding models. The universal\nmagic words as suffixes can move the embedding of any text towards the bias\ndirection, therefore manipulate the similarity of any text pair and mislead\nsafeguards. By appending magic words to user prompts and requiring LLMs to end\nanswers with magic words, attackers can jailbreak the safeguard. To eradicate\nthis security risk, we also propose defense mechanisms against such attacks,\nwhich can correct the biased distribution of text embeddings in a train-free\nmanner.\n","authors":["Haoyu Liang","Youran Sun","Yunfeng Cai","Jun Zhu","Bo Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.18280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18265v1","updated":"2025-01-30T11:04:14Z","published":"2025-01-30T11:04:14Z","title":"Collecting Cost-Effective, High-Quality Truthfulness Assessments with\n  LLM Summarized Evidence","summary":"  With the degradation of guardrails against mis- and disinformation online, it\nis more critical than ever to be able to effectively combat it. In this paper,\nwe explore the efficiency and effectiveness of using crowd-sourced truthfulness\nassessments based on condensed, large language model (LLM) generated summaries\nof online sources. We compare the use of generated summaries to the use of\noriginal web pages in an A/B testing setting, where we employ a large and\ndiverse pool of crowd-workers to perform the truthfulness assessment. We\nevaluate the quality of assessments, the efficiency with which assessments are\nperformed, and the behavior and engagement of participants. Our results\ndemonstrate that the Summary modality, which relies on summarized evidence,\noffers no significant change in assessment accuracy over the Standard modality,\nwhile significantly increasing the speed with which assessments are performed.\nWorkers using summarized evidence produce a significantly higher number of\nassessments in the same time frame, reducing the cost needed to acquire\ntruthfulness assessments. Additionally, the Summary modality maximizes both the\ninter-annotator agreements as well as the reliance on and perceived usefulness\nof evidence, demonstrating the utility of summarized evidence without\nsacrificing the quality of assessments.\n","authors":["Kevin Roitero","Dustin Wright","Michael Soprano","Isabelle Augenstein","Stefano Mizzaro"],"pdf_url":"https://arxiv.org/pdf/2501.18265v1.pdf","comment":"18 pages; 7 figures; 5 tables"},{"id":"http://arxiv.org/abs/2501.18251v1","updated":"2025-01-30T10:33:26Z","published":"2025-01-30T10:33:26Z","title":"How to Select Datapoints for Efficient Human Evaluation of NLG Models?","summary":"  Human evaluation is the gold-standard for evaluating text generation models.\nIt is also expensive, and to fit budgetary constraints, a random subset of the\ntest data is often chosen in practice. The randomly selected data may not\naccurately represent test performance, making this approach economically\ninefficient for model comparison. Thus, in this work, we develop a suite of\nselectors to get the most informative datapoints for human evaluation while\ntaking the evaluation costs into account. We show that selectors based on\nvariance in automated metric scores, diversity in model outputs, or Item\nResponse Theory outperform random selection. We further develop an approach to\ndistill these selectors to the scenario where the model outputs are not yet\navailable. In particular, we introduce source-based estimators, which predict\nitem usefulness for human evaluation just based on the source texts. We\ndemonstrate the efficacy of our selectors in two common NLG tasks, machine\ntranslation and summarization, and show that up to only ~50% of the test data\nis needed to produce the same evaluation result as the entire data. Our\nimplementations are published in the subset2evaluate package.\n","authors":["Vilém Zouhar","Peng Cui","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2501.18251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18243v1","updated":"2025-01-30T10:21:10Z","published":"2025-01-30T10:21:10Z","title":"Statistical multi-metric evaluation and visualization of LLM system\n  predictive performance","summary":"  The evaluation of generative or discriminative large language model\n(LLM)-based systems is often a complex multi-dimensional problem. Typically, a\nset of system configuration alternatives are evaluated on one or more benchmark\ndatasets, each with one or more evaluation metrics, which may differ between\ndatasets. We often want to evaluate -- with a statistical measure of\nsignificance -- whether systems perform differently either on a given dataset\naccording to a single metric, on aggregate across metrics on a dataset, or\nacross datasets. Such evaluations can be done to support decision-making, such\nas deciding whether a particular system component change (e.g., choice of LLM\nor hyperparameter values) significantly improves performance over the current\nsystem configuration, or, more generally, whether a fixed set of system\nconfigurations (e.g., a leaderboard list) have significantly different\nperformances according to metrics of interest. We present a framework\nimplementation that automatically performs the correct statistical tests,\nproperly aggregates the statistical results across metrics and datasets (a\nnontrivial task), and can visualize the results. The framework is demonstrated\non the multi-lingual code generation benchmark CrossCodeEval, for several\nstate-of-the-art LLMs.\n","authors":["Samuel Ackerman","Eitan Farchi","Orna Raz","Assaf Toledo"],"pdf_url":"https://arxiv.org/pdf/2501.18243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14528v2","updated":"2025-01-30T10:15:35Z","published":"2025-01-24T14:31:30Z","title":"Idiom Detection in Sorani Kurdish Texts","summary":"  Idiom detection using Natural Language Processing (NLP) is the computerized\nprocess of recognizing figurative expressions within a text that convey\nmeanings beyond the literal interpretation of the words. While idiom detection\nhas seen significant progress across various languages, the Kurdish language\nfaces a considerable research gap in this area despite the importance of idioms\nin tasks like machine translation and sentiment analysis. This study addresses\nidiom detection in Sorani Kurdish by approaching it as a text classification\ntask using deep learning techniques. To tackle this, we developed a dataset\ncontaining 10,580 sentences embedding 101 Sorani Kurdish idioms across diverse\ncontexts. Using this dataset, we developed and evaluated three deep learning\nmodels: KuBERT-based transformer sequence classification, a Recurrent\nConvolutional Neural Network (RCNN), and a BiLSTM model with an attention\nmechanism. The evaluations revealed that the transformer model, the fine-tuned\nBERT, consistently outperformed the others, achieving nearly 99% accuracy while\nthe RCNN achieved 96.5% and the BiLSTM 80%. These results highlight the\neffectiveness of Transformer-based architectures in low-resource languages like\nKurdish. This research provides a dataset, three optimized models, and insights\ninto idiom detection, laying a foundation for advancing Kurdish NLP.\n","authors":["Skala Kamaran Omer","Hossein Hassani"],"pdf_url":"https://arxiv.org/pdf/2501.14528v2.pdf","comment":"22 pages, 8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2501.18205v1","updated":"2025-01-30T08:51:48Z","published":"2025-01-30T08:51:48Z","title":"Contextually Structured Token Dependency Encoding for Large Language\n  Models","summary":"  Token representation strategies within large-scale neural architectures often\nrely on contextually refined embeddings, yet conventional approaches seldom\nencode structured relationships explicitly within token interactions.\nSelf-attention mechanisms effectively capture dynamic contextual dependencies,\nbut their reliance on learned weight distributions limits the preservation of\nlong-range hierarchical structures in generated sequences. Dependency-aware\ntoken encoding introduces a structured approach to embedding initialization,\nensuring that relational constraints are embedded within token representations\nrather than inferred solely through attention dynamics. The proposed encoding\nmechanism refines token interactions through dependency-weighted attention\ncomputations, ensuring that syntactic and semantic dependencies are retained\nacross multiple processing layers. Empirical evaluations indicate reductions in\nperplexity across diverse linguistic benchmarks, suggesting improvements in\ncontextual coherence and predictive consistency in autoregressive text\ngeneration. Computational efficiency assessments reveal a moderate increase in\nmemory consumption and training time, attributed to additional matrix\ncomputations within the encoding module, yet scalability remains feasible\nwithin conventional transformer architectures. Structured encoding enhances\nlexical variation and dependency retention, reinforcing linguistic coherence\nwithout requiring external syntactic annotations or auxiliary training\nobjectives. Statistical comparisons highlight improvements in dependency\nalignment, particularly in longer sequences where conventional self-attention\nmodels exhibit degradation in hierarchical consistency. Sentence length\ndistributions indicate a reduction in abrupt phrase transitions, further\nsupporting the hypothesis that explicit dependency encoding facilitates more\nstructured phrase generation.\n","authors":["James Blades","Frederick Somerfield","William Langley","Susan Everingham","Maurice Witherington"],"pdf_url":"https://arxiv.org/pdf/2501.18205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11149v7","updated":"2025-01-30T08:45:30Z","published":"2024-09-17T13:03:12Z","title":"SAGED: A Holistic Bias-Benchmarking Pipeline for Language Models with\n  Customisable Fairness Calibration","summary":"  The development of unbiased large language models is widely recognized as\ncrucial, yet existing benchmarks fall short in detecting biases due to limited\nscope, contamination, and lack of a fairness baseline. SAGED(bias) is the first\nholistic benchmarking pipeline to address these problems. The pipeline\nencompasses five core stages: scraping materials, assembling benchmarks,\ngenerating responses, extracting numeric features, and diagnosing with\ndisparity metrics. SAGED includes metrics for max disparity, such as impact\nratio, and bias concentration, such as Max Z-scores. Noticing that metric tool\nbias and contextual bias in prompts can distort evaluation, SAGED implements\ncounterfactual branching and baseline calibration for mitigation. For\ndemonstration, we use SAGED on G20 Countries with popular 8b-level models\nincluding Gemma2, Llama3.1, Mistral, and Qwen2. With sentiment analysis, we\nfind that while Mistral and Qwen2 show lower max disparity and higher bias\nconcentration than Gemma2 and Llama3.1, all models are notably biased against\ncountries like Russia and (except for Qwen2) China. With further experiments to\nhave models role-playing U.S. presidents, we see bias amplifies and shifts in\nheterogeneous directions. Moreover, we see Qwen2 and Mistral not engage in\nrole-playing, while Llama3.1 and Gemma2 role-play Trump notably more\nintensively than Biden and Harris, indicating role-playing performance bias in\nthese models.\n","authors":["Xin Guan","Ze Wang","Nathaniel Demchak","Saloni Gupta","Ediz Ertekin Jr.","Adriano Koshiyama","Emre Kazim","Zekun Wu"],"pdf_url":"https://arxiv.org/pdf/2409.11149v7.pdf","comment":"COLING 2025 Main Conference Oral Presentation"},{"id":"http://arxiv.org/abs/2410.08436v2","updated":"2025-01-30T08:06:33Z","published":"2024-10-11T00:45:50Z","title":"Exploring the Role of Reasoning Structures for Constructing Proofs in\n  Multi-Step Natural Language Reasoning with Large Language Models","summary":"  When performing complex multi-step reasoning tasks, the ability of Large\nLanguage Models (LLMs) to derive structured intermediate proof steps is\nimportant for ensuring that the models truly perform the desired reasoning and\nfor improving models' explainability. This paper is centred around a focused\nstudy: whether the current state-of-the-art generalist LLMs can leverage the\nstructures in a few examples to better construct the proof structures with\n\\textit{in-context learning}. Our study specifically focuses on structure-aware\ndemonstration and structure-aware pruning. We demonstrate that they both help\nimprove performance. A detailed analysis is provided to help understand the\nresults.\n","authors":["Zi'ou Zheng","Christopher Malon","Martin Renqiang Min","Xiaodan Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.08436v2.pdf","comment":"Accepted by EMNLP2024 main conference"},{"id":"http://arxiv.org/abs/2501.16513v2","updated":"2025-01-30T08:00:14Z","published":"2025-01-27T21:26:37Z","title":"Deception in LLMs: Self-Preservation and Autonomous Goals in Large\n  Language Models","summary":"  Recent advances in Large Language Models (LLMs) have incorporated planning\nand reasoning capabilities, enabling models to outline steps before execution\nand provide transparent reasoning paths. This enhancement has reduced errors in\nmathematical and logical tasks while improving accuracy. These developments\nhave facilitated LLMs' use as agents that can interact with tools and adapt\ntheir responses based on new information.\n  Our study examines DeepSeek R1, a model trained to output reasoning tokens\nsimilar to OpenAI's o1. Testing revealed concerning behaviors: the model\nexhibited deceptive tendencies and demonstrated self-preservation instincts,\nincluding attempts of self-replication, despite these traits not being\nexplicitly programmed (or prompted). These findings raise concerns about LLMs\npotentially masking their true objectives behind a facade of alignment. When\nintegrating such LLMs into robotic systems, the risks become tangible - a\nphysically embodied AI exhibiting deceptive behaviors and self-preservation\ninstincts could pursue its hidden objectives through real-world actions. This\nhighlights the critical need for robust goal specification and safety\nframeworks before any physical implementation.\n","authors":["Sudarshan Kamath Barkur","Sigurd Schacht","Johannes Scholl"],"pdf_url":"https://arxiv.org/pdf/2501.16513v2.pdf","comment":"Corrected Version - Solved Some Issues with reference compilation by\n  latex"},{"id":"http://arxiv.org/abs/2501.12746v3","updated":"2025-01-30T07:11:06Z","published":"2025-01-22T09:27:11Z","title":"EvidenceMap: Learning Evidence Analysis to Unleash the Power of Small\n  Language Models for Biomedical Question Answering","summary":"  When addressing professional questions in the biomedical domain, humans\ntypically acquire multiple pieces of information as evidence and engage in\nmultifaceted evidence analysis to provide high-quality answers. Current\nLLM-based answer generation methods lack a detailed definition and learning\nprocess for evidence analysis, leading to the risk of error propagation and\nhallucinations while using evidence. Although increasing the parameter size of\nLLMs can alleviate these issues, it also presents challenges in model training\nand deployment with limited resources. In this study, we propose EvidenceMap,\nwhich aims to enable a tiny pre-trained language model to explicitly learn\nmultiple aspects of biomedical evidence, including supportive evaluation,\nlogical correlation and content summarization, thereby latently guiding a small\ngenerative model (around 3B parameters) to provide textual responses.\nExperimental results demonstrate that our method, fine-tuning a language model\nwith 66M parameters, exceeds the RAG method with an 8B LLM by 19.9% and 5.7% in\nreference-based quality and accuracy, respectively.\n","authors":["Chang Zong","Jian Wan","Siliang Tang","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.12746v3.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.15188v3","updated":"2025-01-30T07:08:45Z","published":"2024-12-19T18:56:24Z","title":"LMFusion: Adapting Pretrained Language Models for Multimodal Generation","summary":"  We present LMFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLMFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LMFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLMFusion improves image understanding by 20% and image generation by 3.6% using\nonly 50% of the FLOPs while maintaining Llama-3's language capabilities. We\nalso demonstrate that this framework can adapt existing vision-language models\nwith multimodal generation ability. Overall, this framework not only leverages\nexisting computational investments in text-only LLMs but also enables the\nparallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.\n","authors":["Weijia Shi","Xiaochuang Han","Chunting Zhou","Weixin Liang","Xi Victoria Lin","Luke Zettlemoyer","Lili Yu"],"pdf_url":"https://arxiv.org/pdf/2412.15188v3.pdf","comment":"Name change: LlamaFusion to LMFusion"},{"id":"http://arxiv.org/abs/2501.15797v2","updated":"2025-01-30T06:10:23Z","published":"2025-01-27T05:46:06Z","title":"LemmaHead: RAG Assisted Proof Generation Using Large Language Models","summary":"  Developing the logic necessary to solve mathematical problems or write\nmathematical proofs is one of the more difficult objectives for large language\nmodels (LLMS). Currently, the most popular methods in literature consists of\nfine-tuning the model on written mathematical content such as academic\npublications and textbooks, so that the model can learn to emulate the style of\nmathematical writing. In this project, we explore the effectiveness of using\nretrieval augmented generation (RAG) to address gaps in the mathematical\nreasoning of LLMs. We develop LemmaHead, a RAG knowledge base that supplements\nqueries to the model with relevant mathematical context, with particular focus\non context from published textbooks. To measure our model's performance in\nmathematical reasoning, our testing paradigm focuses on the task of automated\ntheorem proving via generating proofs to a given mathematical claim in the Lean\nformal language.\n","authors":["Tianbo Yang","Mingqi Yang","Hongyi Zhao","Tianshuo Yang"],"pdf_url":"https://arxiv.org/pdf/2501.15797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18154v1","updated":"2025-01-30T05:39:01Z","published":"2025-01-30T05:39:01Z","title":"Mixed-Precision Graph Neural Quantization for Low Bit Large Language\n  Models","summary":"  Post-Training Quantization (PTQ) is pivotal for deploying large language\nmodels (LLMs) within resource-limited settings by significantly reducing\nresource demands. However, existing PTQ strategies underperform at low bit\nlevels < 3 bits due to the significant difference between the quantized and\noriginal weights. To enhance the quantization performance at low bit widths, we\nintroduce a Mixed-precision Graph Neural PTQ (MG-PTQ) approach, employing a\ngraph neural network (GNN) module to capture dependencies among weights and\nadaptively assign quantization bit-widths. Through the information propagation\nof the GNN module, our method more effectively captures dependencies among\ntarget weights, leading to a more accurate assessment of weight importance and\noptimized allocation of quantization strategies. Extensive experiments on the\nWikiText2 and C4 datasets demonstrate that our MG-PTQ method outperforms\nprevious state-of-the-art PTQ method GPTQ, setting new benchmarks for\nquantization performance under low-bit conditions.\n","authors":["Wanlong Liu","Yichen Xiao","Dingyi Zeng","Hongyang Zhao","Wenyu Chen","Malu Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.18154v1.pdf","comment":"ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.17762v2","updated":"2025-01-30T05:26:05Z","published":"2025-01-29T16:53:16Z","title":"Improving Privacy Benefits of Redaction","summary":"  We propose a novel redaction methodology that can be used to sanitize natural\ntext data. Our new technique provides better privacy benefits than other state\nof the art techniques while maintaining lower redaction levels.\n","authors":["Vaibhav Gusain","Douglas Leith"],"pdf_url":"https://arxiv.org/pdf/2501.17762v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13101v2","updated":"2025-01-30T04:51:41Z","published":"2024-07-18T02:19:00Z","title":"Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with\n  an Iterative Approach","summary":"  Multi-hop question answering is a challenging task with distinct industrial\nrelevance, and Retrieval-Augmented Generation (RAG) methods based on large\nlanguage models (LLMs) have become a popular approach to tackle this task.\nOwing to the potential inability to retrieve all necessary information in a\nsingle iteration, a series of iterative RAG methods has been recently\ndeveloped, showing significant performance improvements. However, existing\nmethods still face two critical challenges: context overload resulting from\nmultiple rounds of retrieval, and over-planning and repetitive planning due to\nthe lack of a recorded retrieval trajectory. In this paper, we propose a novel\niterative RAG method called ReSP, equipped with a dual-function summarizer.\nThis summarizer compresses information from retrieved documents, targeting both\nthe overarching question and the current sub-question concurrently.\nExperimental results on the multi-hop question-answering datasets HotpotQA and\n2WikiMultihopQA demonstrate that our method significantly outperforms the\nstate-of-the-art, and exhibits excellent robustness concerning context length.\n","authors":["Zhouyu Jiang","Mengshu Sun","Lei Liang","Zhiqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.13101v2.pdf","comment":"Accepted by WWW2025 Agent4IR Workshop"},{"id":"http://arxiv.org/abs/2501.12619v2","updated":"2025-01-30T04:25:00Z","published":"2025-01-22T03:57:52Z","title":"Distillation Quantification for Large Language Models","summary":"  Model distillation is a technique for transferring knowledge from large\nlanguage models (LLMs) to smaller ones, aiming to create resource-efficient yet\nhigh-performing models. However, excessive distillation can lead to\nhomogenization, reducing diversity among models and impairing their ability to\nrobustly handle complex or novel tasks. These limitations underscore the need\nto systematically quantify the distillation process and its impact. In this\nwork, we propose a framework to evaluate and quantify model distillation. Our\nmethod addresses two key aspects: (1) Identifying identity cognition\ncontradictions to assess discrepancies in how models perceive and represent\nidentity-related information, and (2) Analyzing multi-granularity response\nsimilarities across models to measure the extent of homogenization.\nExperimental results demonstrate two key insights: (1) Well-known closed-source\nand open-source LLMs usually exhibit high distillation degrees, except for\nClaude, Doubao, and Gemini. (2) Base LLMs show higher distillation degrees\ncompared to aligned LLMs. By offering a systematic approach to improve the\ntransparency of LLM data distillation, we call for LLMs with more independent\ndevelopment and more transparent technical reports to improve LLMs' robustness\nand safety. The code and data are available under\nhttps://github.com/Aegis1863/LLMs-Distillation-Quantification.\n","authors":["Sunbowen Lee","Junting Zhou","Chang Ao","Kaige Li","Xinrun Du","Sirui He","Jiaheng Liu","Min Yang","Zhoufutu Wen","Shiwen Ni"],"pdf_url":"https://arxiv.org/pdf/2501.12619v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18128v1","updated":"2025-01-30T04:20:16Z","published":"2025-01-30T04:20:16Z","title":"Unraveling the Capabilities of Language Models in News Summarization","summary":"  Given the recent introduction of multiple language models and the ongoing\ndemand for improved Natural Language Processing tasks, particularly\nsummarization, this work provides a comprehensive benchmarking of 20 recent\nlanguage models, focusing on smaller ones for the news summarization task. In\nthis work, we systematically test the capabilities and effectiveness of these\nmodels in summarizing news article texts which are written in different styles\nand presented in three distinct datasets. Specifically, we focus in this study\non zero-shot and few-shot learning settings and we apply a robust evaluation\nmethodology that combines different evaluation concepts including automatic\nmetrics, human evaluation, and LLM-as-a-judge. Interestingly, including\ndemonstration examples in the few-shot learning setting did not enhance models'\nperformance and, in some cases, even led to worse quality of the generated\nsummaries. This issue arises mainly due to the poor quality of the gold\nsummaries that have been used as reference summaries, which negatively impacts\nthe models' performance. Furthermore, our study's results highlight the\nexceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate\ndue to their advanced capabilities. However, among the public models evaluated,\ncertain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B\nand Zephyr-7B-Beta demonstrated promising results. These models showed\nsignificant potential, positioning them as competitive alternatives to large\nmodels for the task of news summarization.\n","authors":["Abdurrahman Odabaşı","Göksel Biricik"],"pdf_url":"https://arxiv.org/pdf/2501.18128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17186v2","updated":"2025-01-30T04:02:48Z","published":"2025-01-26T09:43:39Z","title":"Complete Chess Games Enable LLM Become A Chess Master","summary":"  Large language models (LLM) have shown remarkable abilities in text\ngeneration, question answering, language translation, reasoning and many other\ntasks. It continues to advance rapidly and is becoming increasingly influential\nin various fields, from technology and business to education and entertainment.\nDespite LLM's success in multiple areas, its ability to play abstract games,\nsuch as chess, is underexplored. Chess-playing requires the language models to\noutput legal and reasonable moves from textual inputs. Here, we propose the\nLarge language model ChessLLM to play full chess games. We transform the game\ninto a textual format with the best move represented in the Forsyth-Edwards\nNotation. We show that by simply supervised fine-tuning, our model has achieved\na professional-level Elo rating of 1788 in matches against the standard\nElo-rated Stockfish when permitted to sample 10 times. We further show that\ndata quality is important. Long-round data supervision enjoys a 350 Elo rating\nimprovement over short-round data.\n","authors":["Yinqi Zhang","Xintian Han","Haolong Li","Kedi Chen","Shaohui Lin"],"pdf_url":"https://arxiv.org/pdf/2501.17186v2.pdf","comment":"NAACL 2025"},{"id":"http://arxiv.org/abs/2501.18119v1","updated":"2025-01-30T03:40:20Z","published":"2025-01-30T03:40:20Z","title":"Self-supervised Quantized Representation for Seamlessly Integrating\n  Knowledge Graphs with Large Language Models","summary":"  Due to the presence of the natural gap between Knowledge Graph (KG)\nstructures and the natural language, the effective integration of holistic\nstructural information of KGs with Large Language Models (LLMs) has emerged as\na significant question. To this end, we propose a two-stage framework to learn\nand apply quantized codes for each entity, aiming for the seamless integration\nof KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)\nmethod is proposed to compress both KG structural and semantic knowledge into\ndiscrete codes (\\ie, tokens) that align the format of language sentences. We\nfurther design KG instruction-following data by viewing these learned codes as\nfeatures to directly input to LLMs, thereby achieving seamless integration. The\nexperiment results demonstrate that SSQR outperforms existing unsupervised\nquantized methods, producing more distinguishable codes. Further, the\nfine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link\nprediction and triple classification tasks, utilizing only 16 tokens per entity\ninstead of thousands in conventional prompting methods.\n","authors":["Qika Lin","Tianzhe Zhao","Kai He","Zhen Peng","Fangzhi Xu","Ling Huang","Jingying Ma","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2501.18119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18107v1","updated":"2025-01-30T03:16:44Z","published":"2025-01-30T03:16:44Z","title":"Scaling Inference-Efficient Language Models","summary":"  Scaling laws are powerful tools to predict the performance of large language\nmodels. However, current scaling laws fall short of accounting for inference\ncosts. In this work, we first show that model architecture affects inference\nlatency, where models of the same size can have up to 3.5x difference in\nlatency. To tackle this challenge, we modify the Chinchilla scaling laws to\nco-optimize the model parameter count, the number of training tokens, and the\nmodel architecture. Due to the reason that models of similar training loss\nexhibit gaps in downstream evaluation, we also propose a novel method to train\ninference-efficient models based on the revised scaling laws. We perform\nextensive empirical studies to fit and evaluate our inference-aware scaling\nlaws. We vary model parameters from 80M to 1B, training tokens from 1.6B to\n30B, and model shapes, training a total of 63 models. Guided by our\ninference-efficient scaling law and model selection method, we release the\nMorph-1B model, which improves inference latency by 1.8x while maintaining\naccuracy on downstream tasks compared to open-source models, pushing the Pareto\nfrontier of accuracy-latency tradeoff.\n","authors":["Song Bian","Minghao Yan","Shivaram Venkataraman"],"pdf_url":"https://arxiv.org/pdf/2501.18107v1.pdf","comment":"17 pages, 16 figures"},{"id":"http://arxiv.org/abs/2501.18103v1","updated":"2025-01-30T03:01:01Z","published":"2025-01-30T03:01:01Z","title":"Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM\n  Interactions","summary":"  Traditional text-based human-AI interactions often adhere to a strict\nturn-taking approach. In this research, we propose a novel approach that\nincorporates overlapping messages, mirroring natural human conversations.\nThrough a formative study, we observed that even in text-based contexts, users\ninstinctively engage in overlapping behaviors like \"A: Today I went to-\" \"B:\nyeah.\" To capitalize on these insights, we developed OverlapBot, a prototype\nchatbot where both AI and users can initiate overlapping. Our user study\nrevealed that OverlapBot was perceived as more communicative and immersive than\ntraditional turn-taking chatbot, fostering faster and more natural\ninteractions. Our findings contribute to the understanding of design space for\noverlapping interactions. We also provide recommendations for implementing\noverlap-capable AI interactions to enhance the fluidity and engagement of\ntext-based conversations.\n","authors":["JiWoo Kim","Minsuk Chang","JinYeong Bak"],"pdf_url":"https://arxiv.org/pdf/2501.18103v1.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.18101v1","updated":"2025-01-30T02:47:41Z","published":"2025-01-30T02:47:41Z","title":"Diverse Preference Optimization","summary":"  Post-training of language models, either through reinforcement learning,\npreference optimization or supervised finetuning, tends to sharpen the output\nprobability distribution and reduce the diversity of generated responses. This\nis particularly a problem for creative generative tasks where varied responses\nare desired. %This impacts the ability to generate high quality synthetic data\nwhich is becoming a vital component of model training. In this work we\nintroduce Diverse Preference Optimization (DivPO), an online optimization\nmethod which learns to generate much more diverse responses than standard\npipelines, while maintaining the quality of the generations. In DivPO,\npreference pairs are selected by first considering a pool of responses, and a\nmeasure of diversity among them, and selecting chosen examples as being more\nrare but high quality, while rejected examples are more common, but low\nquality. DivPO results in generating 45.6% more diverse persona attributes, and\nan 74.6% increase in story diversity, while maintaining similar win rates as\nstandard baselines.\n","authors":["Jack Lanchantin","Angelica Chen","Shehzaad Dhuliawala","Ping Yu","Jason Weston","Sainbayar Sukhbaatar","Ilia Kulikov"],"pdf_url":"https://arxiv.org/pdf/2501.18101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18100v1","updated":"2025-01-30T02:47:09Z","published":"2025-01-30T02:47:09Z","title":"Panacea: Mitigating Harmful Fine-tuning for Large Language Models via\n  Post-fine-tuning Perturbation","summary":"  Harmful fine-tuning attack introduces significant security risks to the\nfine-tuning services. Mainstream defenses aim to vaccinate the model such that\nthe later harmful fine-tuning attack is less effective. However, our evaluation\nresults show that such defenses are fragile -- with a few fine-tuning steps,\nthe model still can learn the harmful knowledge. To this end, we do further\nexperiment and find that an embarrassingly simple solution -- adding purely\nrandom perturbations to the fine-tuned model, can recover the model from\nharmful behavior, though it leads to a degradation in the model's fine-tuning\nperformance. To address the degradation of fine-tuning performance, we further\npropose Panacea, which optimizes an adaptive perturbation that will be applied\nto the model after fine-tuning. Panacea maintains model's safety alignment\nperformance without compromising downstream fine-tuning performance.\nComprehensive experiments are conducted on different harmful ratios,\nfine-tuning tasks and mainstream LLMs, where the average harmful scores are\nreduced by up-to 21.5%, while maintaining fine-tuning performance. As a\nby-product, we analyze the optimized perturbation and show that different\nlayers in various LLMs have distinct safety coefficients. Source code available\nat https://github.com/w-yibo/Panacea\n","authors":["Yibo Wang","Tiansheng Huang","Li Shen","Huanjin Yao","Haotian Luo","Rui Liu","Naiqiang Tan","Jiaxing Huang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2501.18100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18099v1","updated":"2025-01-30T02:21:59Z","published":"2025-01-30T02:21:59Z","title":"Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge","summary":"  LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to\ncapture the step-bystep reasoning process that underlies the final evaluation\nof a response. However, due to the lack of human annotated CoTs for evaluation,\nthe required components and structure of effective reasoning traces remain\nunderstudied. Consequently, previous approaches often (1) constrain reasoning\ntraces to hand-designed components, such as a list of criteria, reference\nanswers, or verification questions and (2) structure them such that planning is\nintertwined with the reasoning for evaluation. In this work, we propose\nEvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge\nthat first generates an unconstrained evaluation plan, followed by its\nexecution, and then the final judgment. In a self-training loop, EvalPlanner\niteratively optimizes over synthetically constructed evaluation plans and\nexecutions, leading to better final verdicts. Our method achieves a new\nstate-of-the-art performance for generative reward models on RewardBench (with\na score of 93.9), despite being trained on fewer amount of, and synthetically\ngenerated, preference pairs. Additional experiments on other benchmarks like\nRM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both\nplanning and reasoning for building robust LLM-as-a-Judge reasoning models.\n","authors":["Swarnadeep Saha","Xian Li","Marjan Ghazvininejad","Jason Weston","Tianlu Wang"],"pdf_url":"https://arxiv.org/pdf/2501.18099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18096v1","updated":"2025-01-30T02:16:35Z","published":"2025-01-30T02:16:35Z","title":"LLMs can see and hear without any training","summary":"  We present MILS: Multimodal Iterative LLM Solver, a surprisingly simple,\ntraining-free approach, to imbue multimodal capabilities into your favorite\nLLM. Leveraging their innate ability to perform multi-step reasoning, MILS\nprompts the LLM to generate candidate outputs, each of which are scored and fed\nback iteratively, eventually generating a solution to the task. This enables\nvarious applications that typically require training specialized models on\ntask-specific data. In particular, we establish a new state-of-the-art on\nemergent zero-shot image, video and audio captioning. MILS seamlessly applies\nto media generation as well, discovering prompt rewrites to improve\ntext-to-image generation, and even edit prompts for style transfer! Finally,\nbeing a gradient-free optimization approach, MILS can invert multimodal\nembeddings into text, enabling applications like cross-modal arithmetic.\n","authors":["Kumar Ashutosh","Yossi Gandelsman","Xinlei Chen","Ishan Misra","Rohit Girdhar"],"pdf_url":"https://arxiv.org/pdf/2501.18096v1.pdf","comment":"Code: https://github.com/facebookresearch/MILS"},{"id":"http://arxiv.org/abs/2404.06711v2","updated":"2025-01-30T01:47:47Z","published":"2024-04-10T03:35:51Z","title":"MathVC: An LLM-Simulated Multi-Character Virtual Classroom for\n  Mathematics Education","summary":"  Mathematical modeling (MM) is considered a fundamental skill for students in\nSTEM disciplines. Practicing the MM skill is often the most effective when\nstudents can engage in group discussion and collaborative problem-solving.\nHowever, due to unevenly distributed teachers and educational resources needed\nto monitor such group activities, students do not always receive equal\nopportunities for this practice. Excitingly, large language models (LLMs) have\nrecently demonstrated strong capability in both modeling mathematical problems\nand simulating characters with different traits and properties. Drawing\ninspiration from the advancement of LLMs, in this work, we present MATHVC, the\nvery first LLM-powered virtual classroom containing multiple LLM-simulated\nstudent characters, with whom a human student can practice their MM skill. To\nencourage each LLM character's behaviors to be aligned with their specified\nmath-relevant properties (termed \"characteristics alignment\") and the overall\nconversational procedure to be close to an authentic student MM discussion\n(termed \"conversational procedural alignment\"), we proposed three innovations:\nintegrating MM domain knowledge into the simulation, defining a symbolic schema\nas the ground for character simulation, and designing a meta planner at the\nplatform level to drive the conversational procedure. Through experiments and\nablation studies, we confirmed the effectiveness of our simulation approach and\nshowed the promise for MATHVC to benefit real-life students in the future.\n","authors":["Murong Yue","Wenhan Lyu","Wijdane Mifdal","Jennifer Suh","Yixuan Zhang","Ziyu Yao"],"pdf_url":"https://arxiv.org/pdf/2404.06711v2.pdf","comment":"Accepted by AAAI workshop"},{"id":"http://arxiv.org/abs/2501.17282v2","updated":"2025-01-30T01:25:12Z","published":"2025-01-28T20:30:36Z","title":"From Natural Language to Extensive-Form Game Representations","summary":"  We introduce a framework for translating game descriptions in natural\nlanguage into extensive-form representations in game theory, leveraging Large\nLanguage Models (LLMs) and in-context learning. Given the varying levels of\nstrategic complexity in games, such as perfect versus imperfect information,\ndirectly applying in-context learning would be insufficient. To address this,\nwe introduce a two-stage framework with specialized modules to enhance\nin-context learning, enabling it to divide and conquer the problem effectively.\nIn the first stage, we tackle the challenge of imperfect information by\ndeveloping a module that identifies information sets along and the\ncorresponding partial tree structure. With this information, the second stage\nleverages in-context learning alongside a self-debugging module to produce a\ncomplete extensive-form game tree represented using pygambit, the Python API of\na recognized game-theoretic analysis tool called Gambit. Using this python\nrepresentation enables the automation of tasks such as computing Nash\nequilibria directly from natural language descriptions. We evaluate the\nperformance of the full framework, as well as its individual components, using\nvarious LLMs on games with different levels of strategic complexity. Our\nexperimental results show that the framework significantly outperforms baseline\nmodels in generating accurate extensive-form games, with each module playing a\ncritical role in its success.\n","authors":["Shilong Deng","Yongzhao Wang","Rahul Savani"],"pdf_url":"https://arxiv.org/pdf/2501.17282v2.pdf","comment":"This work has been accepted as a full paper for AAMAS 2025. This is a\n  full version of the AAMAS 2025 proceedings"},{"id":"http://arxiv.org/abs/2407.11068v4","updated":"2025-01-30T01:04:40Z","published":"2024-07-12T14:17:26Z","title":"Show, Don't Tell: Evaluating Large Language Models Beyond Textual\n  Understanding with ChildPlay","summary":"  We develop a systematic benchmark set to test the generalization of\nstate-of-the-art large language models on broader problems beyond linguistic\ntasks and evaluate it on a systematic progression of GPT models (GPT-3.5,\nGPT-4, GPT-4o, GPT-4o-mini). Using well-known simple games like Tic-Tac-Toe,\nConnect Four, and Battleship, all encoded in ASCII, we test their strategic\ncapabilities and spatial reasoning. To probe generalization, we introduce three\nnew games: LEGO Connect Language (LCL) for spatial logic, a shape recognition\ngame, and Guess-the-SMILES (GtS), an advanced spatial logic benchmark in\nchemistry. Results show that, despite proficiency in standard benchmarks, GPT\nmodels perform poorly in these games, failing to anticipate losing moves, play\ncorrectly, or recognize spatial relationships. Except for Tic-Tac-Toe and GtS,\na systematic progression in gameplay performance as models are formally\nimproved (GPT-3.5, GPT-4, GPT-4o) is not observed. GPT-4 succeeds in shape\nrecognition, but all models consistently struggle with LCL and GtS. This\nsuggests that while GPT models can emulate conversational proficiency and basic\nrule comprehension, they have limited cognitive flexibility and generalization\nin strategy and spatial reasoning. Our findings, highlighted with our benchmark\nsuite (ChildPlay GitHub Repository), caution against claims of emergent\nintelligence in GPT models, which appear more specialized than general.\n","authors":["Gonçalo Hora de Carvalho","Oscar Knap","Robert Pollice"],"pdf_url":"https://arxiv.org/pdf/2407.11068v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16235v2","updated":"2025-01-30T00:36:42Z","published":"2024-10-21T17:41:11Z","title":"ToW: Thoughts of Words Improve Reasoning in Large Language Models","summary":"  We introduce thoughts of words (ToW), a novel training-time data-augmentation\nmethod for next-word prediction. ToW views next-word prediction as a core\nreasoning task and injects fine-grained thoughts explaining what the next word\nshould be and how it is related to the previous contexts in pre-training texts.\nOur formulation addresses two fundamental drawbacks of existing next-word\nprediction learning schemes: they induce factual hallucination and are\ninefficient for models to learn the implicit reasoning processes in raw texts.\nWhile there are many ways to acquire such thoughts of words, we explore the\nfirst step of acquiring ToW annotations through distilling from larger models.\nAfter continual pre-training with only 70K ToW annotations, we effectively\nimprove models' reasoning performances by 7% to 9% on average and reduce model\nhallucination by up to 10%. At the same time, ToW is entirely agnostic to tasks\nand applications, introducing no additional biases on labels or semantics.\n","authors":["Zhikun Xu","Ming Shen","Jacob Dineen","Zhaonan Li","Xiao Ye","Shijie Lu","Aswin RRV","Chitta Baral","Ben Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.16235v2.pdf","comment":"Accepted by NAACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2501.18062v1","updated":"2025-01-30T00:06:55Z","published":"2025-01-30T00:06:55Z","title":"FinanceQA: A Benchmark for Evaluating Financial Analysis Capabilities of\n  Large Language Models","summary":"  FinanceQA is a testing suite that evaluates LLMs' performance on complex\nnumerical financial analysis tasks that mirror real-world investment work.\nDespite recent advances, current LLMs fail to meet the strict accuracy\nrequirements of financial institutions, with models failing approximately 60%\nof realistic tasks that mimic on-the-job analyses at hedge funds, private\nequity firms, investment banks, and other financial institutions. The primary\nchallenges include hand-spreading metrics, adhering to standard accounting and\ncorporate valuation conventions, and performing analysis under incomplete\ninformation - particularly in multi-step tasks requiring assumption generation.\nThis performance gap highlights the disconnect between existing LLM\ncapabilities and the demands of professional financial analysis that are\ninadequately tested by current testing architectures. Results show that\nhigher-quality training data is needed to support such tasks, which we\nexperiment with using OpenAI's fine-tuning API. FinanceQA is publicly released\nat [this https URL](https://huggingface.co/datasets/AfterQuery/FinanceQA).\n","authors":["Spencer Mateega","Carlos Georgescu","Danny Tang"],"pdf_url":"https://arxiv.org/pdf/2501.18062v1.pdf","comment":"10 pages, 7 figures"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2501.18595v1","updated":"2025-01-30T18:59:54Z","published":"2025-01-30T18:59:54Z","title":"ROSA: Reconstructing Object Shape and Appearance Textures by Adaptive\n  Detail Transfer","summary":"  Reconstructing an object's shape and appearance in terms of a mesh textured\nby a spatially-varying bidirectional reflectance distribution function (SVBRDF)\nfrom a limited set of images captured under collocated light is an ill-posed\nproblem. Previous state-of-the-art approaches either aim to reconstruct the\nappearance directly on the geometry or additionally use texture normals as part\nof the appearance features. However, this requires detailed but inefficiently\nlarge meshes, that would have to be simplified in a post-processing step, or\nsuffers from well-known limitations of normal maps such as missing shadows or\nincorrect silhouettes. Another limiting factor is the fixed and typically low\nresolution of the texture estimation resulting in loss of important surface\ndetails. To overcome these problems, we present ROSA, an inverse rendering\nmethod that directly optimizes mesh geometry with spatially adaptive mesh\nresolution solely based on the image data. In particular, we refine the mesh\nand locally condition the surface smoothness based on the estimated normal\ntexture and mesh curvature. In addition, we enable the reconstruction of fine\nappearance details in high-resolution textures through a pioneering tile-based\nmethod that operates on a single pre-trained decoder network but is not limited\nby the network output resolution.\n","authors":["Julian Kaltheuner","Patrick Stotko","Reinhard Klein"],"pdf_url":"https://arxiv.org/pdf/2501.18595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18594v1","updated":"2025-01-30T18:59:43Z","published":"2025-01-30T18:59:43Z","title":"Foundational Models for 3D Point Clouds: A Survey and Outlook","summary":"  The 3D point cloud representation plays a crucial role in preserving the\ngeometric fidelity of the physical world, enabling more accurate complex 3D\nenvironments. While humans naturally comprehend the intricate relationships\nbetween objects and variations through a multisensory system, artificial\nintelligence (AI) systems have yet to fully replicate this capacity. To bridge\nthis gap, it becomes essential to incorporate multiple modalities. Models that\ncan seamlessly integrate and reason across these modalities are known as\nfoundation models (FMs). The development of FMs for 2D modalities, such as\nimages and text, has seen significant progress, driven by the abundant\navailability of large-scale datasets. However, the 3D domain has lagged due to\nthe scarcity of labelled data and high computational overheads. In response,\nrecent research has begun to explore the potential of applying FMs to 3D tasks,\novercoming these challenges by leveraging existing 2D knowledge. Additionally,\nlanguage, with its capacity for abstract reasoning and description of the\nenvironment, offers a promising avenue for enhancing 3D understanding through\nlarge pre-trained language models (LLMs). Despite the rapid development and\nadoption of FMs for 3D vision tasks in recent years, there remains a gap in\ncomprehensive and in-depth literature reviews. This article aims to address\nthis gap by presenting a comprehensive overview of the state-of-the-art methods\nthat utilize FMs for 3D visual understanding. We start by reviewing various\nstrategies employed in the building of various 3D FMs. Then we categorize and\nsummarize use of different FMs for tasks such as perception tasks. Finally, the\narticle offers insights into future directions for research and development in\nthis field. To help reader, we have curated list of relevant papers on the\ntopic: https://github.com/vgthengane/Awesome-FMs-in-3D.\n","authors":["Vishal Thengane","Xiatian Zhu","Salim Bouzerdoum","Son Lam Phung","Yunpeng Li"],"pdf_url":"https://arxiv.org/pdf/2501.18594v1.pdf","comment":"Initial submission"},{"id":"http://arxiv.org/abs/2501.18593v1","updated":"2025-01-30T18:59:37Z","published":"2025-01-30T18:59:37Z","title":"Diffusion Autoencoders are Scalable Image Tokenizers","summary":"  Tokenizing images into compact visual representations is a key step in\nlearning efficient and high-quality image generative models. We present a\nsimple diffusion tokenizer (DiTo) that learns compact visual representations\nfor image generation models. Our key insight is that a single learning\nobjective, diffusion L2 loss, can be used for training scalable image\ntokenizers. Since diffusion is already widely used for image generation, our\ninsight greatly simplifies training such tokenizers. In contrast, current\nstate-of-the-art tokenizers rely on an empirically found combination of\nheuristics and losses, thus requiring a complex training recipe that relies on\nnon-trivially balancing different losses and pretrained supervised models. We\nshow design decisions, along with theoretical grounding, that enable us to\nscale DiTo for learning competitive image representations. Our results show\nthat DiTo is a simpler, scalable, and self-supervised alternative to the\ncurrent state-of-the-art image tokenizer which is supervised. DiTo achieves\ncompetitive or better quality than state-of-the-art in image reconstruction and\ndownstream image generation tasks.\n","authors":["Yinbo Chen","Rohit Girdhar","Xiaolong Wang","Sai Saketh Rambhatla","Ishan Misra"],"pdf_url":"https://arxiv.org/pdf/2501.18593v1.pdf","comment":"Project page: https://yinboc.github.io/dito/"},{"id":"http://arxiv.org/abs/2501.18592v1","updated":"2025-01-30T18:59:36Z","published":"2025-01-30T18:59:36Z","title":"Advances in Multimodal Adaptation and Generalization: From Traditional\n  Approaches to Foundation Models","summary":"  In real-world scenarios, achieving domain adaptation and generalization poses\nsignificant challenges, as models must adapt to or generalize across unknown\ntarget distributions. Extending these capabilities to unseen multimodal\ndistributions, i.e., multimodal domain adaptation and generalization, is even\nmore challenging due to the distinct characteristics of different modalities.\nSignificant progress has been made over the years, with applications ranging\nfrom action recognition to semantic segmentation. Besides, the recent advent of\nlarge-scale pre-trained multimodal foundation models, such as CLIP, has\ninspired works leveraging these models to enhance adaptation and generalization\nperformances or adapting them to downstream tasks. This survey provides the\nfirst comprehensive review of recent advances from traditional approaches to\nfoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal\ntest-time adaptation; (3) Multimodal domain generalization; (4) Domain\nadaptation and generalization with the help of multimodal foundation models;\nand (5) Adaptation of multimodal foundation models. For each topic, we formally\ndefine the problem and thoroughly review existing methods. Additionally, we\nanalyze relevant datasets and applications, highlighting open challenges and\npotential future research directions. We maintain an active repository that\ncontains up-to-date literature at\nhttps://github.com/donghao51/Awesome-Multimodal-Adaptation.\n","authors":["Hao Dong","Moru Liu","Kaiyang Zhou","Eleni Chatzi","Juho Kannala","Cyrill Stachniss","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2501.18592v1.pdf","comment":"Project page:\n  https://github.com/donghao51/Awesome-Multimodal-Adaptation"},{"id":"http://arxiv.org/abs/2501.18590v1","updated":"2025-01-30T18:59:11Z","published":"2025-01-30T18:59:11Z","title":"DiffusionRenderer: Neural Inverse and Forward Rendering with Video\n  Diffusion Models","summary":"  Understanding and modeling lighting effects are fundamental tasks in computer\nvision and graphics. Classic physically-based rendering (PBR) accurately\nsimulates the light transport, but relies on precise scene\nrepresentations--explicit 3D geometry, high-quality material properties, and\nlighting conditions--that are often impractical to obtain in real-world\nscenarios. Therefore, we introduce DiffusionRenderer, a neural approach that\naddresses the dual problem of inverse and forward rendering within a holistic\nframework. Leveraging powerful video diffusion model priors, the inverse\nrendering model accurately estimates G-buffers from real-world videos,\nproviding an interface for image editing tasks, and training data for the\nrendering model. Conversely, our rendering model generates photorealistic\nimages from G-buffers without explicit light transport simulation. Experiments\ndemonstrate that DiffusionRenderer effectively approximates inverse and\nforwards rendering, consistently outperforming the state-of-the-art. Our model\nenables practical applications from a single video input--including relighting,\nmaterial editing, and realistic object insertion.\n","authors":["Ruofan Liang","Zan Gojcic","Huan Ling","Jacob Munkberg","Jon Hasselgren","Zhi-Hao Lin","Jun Gao","Alexander Keller","Nandita Vijaykumar","Sanja Fidler","Zian Wang"],"pdf_url":"https://arxiv.org/pdf/2501.18590v1.pdf","comment":"Project page: research.nvidia.com/labs/toronto-ai/DiffusionRenderer/"},{"id":"http://arxiv.org/abs/2501.18588v1","updated":"2025-01-30T18:59:04Z","published":"2025-01-30T18:59:04Z","title":"Inkspire: Supporting Design Exploration with Generative AI through\n  Analogical Sketching","summary":"  With recent advancements in the capabilities of Text-to-Image (T2I) AI\nmodels, product designers have begun experimenting with them in their work.\nHowever, T2I models struggle to interpret abstract language and the current\nuser experience of T2I tools can induce design fixation rather than a more\niterative, exploratory process. To address these challenges, we developed\nInkspire, a sketch-driven tool that supports designers in prototyping product\ndesign concepts with analogical inspirations and a complete\nsketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we\nconducted an exchange session with designers and distilled design goals for\nimproving T2I interactions. In a within-subjects study comparing Inkspire to\nControlNet, we found that Inkspire supported designers with more inspiration\nand exploration of design ideas, and improved aspects of the co-creative\nprocess by allowing designers to effectively grasp the current state of the AI\nto guide it towards novel design intentions.\n","authors":["David Chuan-En Lin","Hyeonsu B. Kang","Nikolas Martelaro","Aniket Kittur","Yan-Ying Chen","Matthew K. Hong"],"pdf_url":"https://arxiv.org/pdf/2501.18588v1.pdf","comment":"Accepted to CHI 2025"},{"id":"http://arxiv.org/abs/2501.16662v2","updated":"2025-01-30T18:48:48Z","published":"2025-01-28T02:52:04Z","title":"Vision-based autonomous structural damage detection using data-driven\n  methods","summary":"  This study addresses the urgent need for efficient and accurate damage\ndetection in wind turbine structures, a crucial component of renewable energy\ninfrastructure. Traditional inspection methods, such as manual assessments and\nnon-destructive testing (NDT), are often costly, time-consuming, and prone to\nhuman error. To tackle these challenges, this research investigates advanced\ndeep learning algorithms for vision-based structural health monitoring (SHM). A\ndataset of wind turbine surface images, featuring various damage types and\npollution, was prepared and augmented for enhanced model training. Three\nalgorithms-YOLOv7, its lightweight variant, and Faster R-CNN- were employed to\ndetect and classify surface damage. The models were trained and evaluated on a\ndataset split into training, testing, and evaluation subsets (80%-10%-10%).\nResults indicate that YOLOv7 outperformed the others, achieving 82.4% mAP@50\nand high processing speed, making it suitable for real-time inspections. By\noptimizing hyperparameters like learning rate and batch size, the models'\naccuracy and efficiency improved further. YOLOv7 demonstrated significant\nadvancements in detection precision and execution speed, especially for\nreal-time applications. However, challenges such as dataset limitations and\nenvironmental variability were noted, suggesting future work on segmentation\nmethods and larger datasets. This research underscores the potential of\nvision-based deep learning techniques to transform SHM practices by reducing\ncosts, enhancing safety, and improving reliability, thus contributing to the\nsustainable maintenance of critical infrastructure and supporting the longevity\nof wind energy systems.\n","authors":["Seyyed Taghi Ataei","Parviz Mohammad Zadeh","Saeid Ataei"],"pdf_url":"https://arxiv.org/pdf/2501.16662v2.pdf","comment":"14 pages, 8 figures. This study examines advanced deep learning\n  algorithms, specifically YOLOv7, for efficient and accurate damage detection\n  in wind turbine structures. It significantly enhances detection precision and\n  speed for real-time inspections"},{"id":"http://arxiv.org/abs/2408.07786v2","updated":"2025-01-30T18:18:26Z","published":"2024-08-14T19:49:19Z","title":"Perspectives: Comparison of Deep Learning Segmentation Models on\n  Biophysical and Biomedical Data","summary":"  Deep learning based approaches are now widely used across biophysics to help\nautomate a variety of tasks including image segmentation, feature selection,\nand deconvolution. However, the presence of multiple competing deep learning\narchitectures, each with its own unique advantages and disadvantages, makes it\nchallenging to select an architecture best suited for a specific application.\nAs such, we present a comprehensive comparison of common models. Here, we focus\non the task of segmentation assuming the typically small training dataset sizes\navailable from biophysics experiments and compare the following four commonly\nused architectures: convolutional neural networks, U-Nets, vision transformers,\nand vision state space models. In doing so, we establish criteria for\ndetermining optimal conditions under which each model excels, thereby offering\npractical guidelines for researchers and practitioners in the field.\n","authors":["J Shepard Bryan IV","Pedro Pessoa","Meyam Tavakoli","Steve Presse"],"pdf_url":"https://arxiv.org/pdf/2408.07786v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20327v3","updated":"2025-01-30T18:16:17Z","published":"2024-10-27T03:56:56Z","title":"R-LLaVA: Improving Med-VQA Understanding through Visual Region of\n  Interest","summary":"  Artificial intelligence has made significant strides in medical visual\nquestion answering (Med-VQA), yet prevalent studies often interpret images\nholistically, overlooking the visual regions of interest that may contain\ncrucial information, potentially aligning with a doctor's prior knowledge that\ncan be incorporated with minimal annotations (e.g., bounding boxes). To address\nthis gap, this paper introduces R-LLaVA, designed to enhance biomedical VQA\nunderstanding by integrating simple medical annotations as prior knowledge\ndirectly into the image space through CLIP. These annotated visual regions of\ninterest are then fed into the LLaVA model during training, aiming to enrich\nthe model's understanding of biomedical queries. Experimental evaluation on\nfour standard Med-VQA datasets demonstrates R-LLaVA's superiority over existing\nstate-of-the-art (SoTA) methods. Additionally, to verify the model's capability\nin visual comprehension, a novel multiple-choice medical visual understanding\ndataset is introduced, confirming the positive impact of focusing on visual\nregions of interest in advancing biomedical VQA understanding.\n","authors":["Xupeng Chen","Zhixin Lai","Kangrui Ruan","Shichu Chen","Jiaxiang Liu","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.20327v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18545v1","updated":"2025-01-30T18:13:29Z","published":"2025-01-30T18:13:29Z","title":"UDC-VIT: A Real-World Video Dataset for Under-Display Cameras","summary":"  Under Display Camera (UDC) is an advanced imaging system that places a\ndigital camera lens underneath a display panel, effectively concealing the\ncamera. However, the display panel significantly degrades captured images or\nvideos, introducing low transmittance, blur, noise, and flare issues. Tackling\nsuch issues is challenging because of the complex degradation of UDCs,\nincluding diverse flare patterns. Despite extensive research on UDC images and\ntheir restoration models, studies on videos have yet to be significantly\nexplored. While two UDC video datasets exist, they primarily focus on\nunrealistic or synthetic UDC degradation rather than real-world UDC\ndegradation. In this paper, we propose a real-world UDC video dataset called\nUDC-VIT. Unlike existing datasets, only UDC-VIT exclusively includes human\nmotions that target facial recognition. We propose a video-capturing system to\nsimultaneously acquire non-degraded and UDC-degraded videos of the same scene.\nThen, we align a pair of captured videos frame by frame, using discrete Fourier\ntransform (DFT). We compare UDC-VIT with six representative UDC still image\ndatasets and two existing UDC video datasets. Using six deep-learning models,\nwe compare UDC-VIT and an existing synthetic UDC video dataset. The results\nindicate the ineffectiveness of models trained on earlier synthetic UDC video\ndatasets, as they do not reflect the actual characteristics of UDC-degraded\nvideos. We also demonstrate the importance of effective UDC restoration by\nevaluating face recognition accuracy concerning PSNR, SSIM, and LPIPS scores.\nUDC-VIT enables further exploration in the UDC video restoration and offers\nbetter insights into the challenge. UDC-VIT is available at our project site.\n","authors":["Kyusu Ahn","JiSoo Kim","Sangik Lee","HyunGyu Lee","Byeonghyun Ko","Chanwoo Park","Jaejin Lee"],"pdf_url":"https://arxiv.org/pdf/2501.18545v1.pdf","comment":"Main body (10 pages, 9 Figures, 3 Tables), References (4 pages),\n  Appendix (15 pages, 11 Figures, 6 Tables)"},{"id":"http://arxiv.org/abs/2501.18543v1","updated":"2025-01-30T18:12:11Z","published":"2025-01-30T18:12:11Z","title":"Learning Priors of Human Motion With Vision Transformers","summary":"  A clear understanding of where humans move in a scenario, their usual paths\nand speeds, and where they stop, is very important for different applications,\nsuch as mobility studies in urban areas or robot navigation tasks within\nhuman-populated environments. We propose in this article, a neural architecture\nbased on Vision Transformers (ViTs) to provide this information. This solution\ncan arguably capture spatial correlations more effectively than Convolutional\nNeural Networks (CNNs). In the paper, we describe the methodology and proposed\nneural architecture and show the experiments' results with a standard dataset.\nWe show that the proposed ViT architecture improves the metrics compared to a\nmethod based on a CNN.\n","authors":["Placido Falqueto","Alberto Sanfeliu","Luigi Palopoli","Daniele Fontanelli"],"pdf_url":"https://arxiv.org/pdf/2501.18543v1.pdf","comment":"2024 IEEE 48th Annual Computers, Software, and Applications\n  Conference (COMPSAC). IEEE, 2024"},{"id":"http://arxiv.org/abs/2501.17595v2","updated":"2025-01-30T18:07:59Z","published":"2025-01-29T11:54:37Z","title":"Technical report on label-informed logit redistribution for better\n  domain generalization in low-shot classification with foundation models","summary":"  Confidence calibration is an emerging challenge in real-world decision\nsystems based on foundations models when used for downstream vision\nclassification tasks. Due to various reasons exposed, logit scores on the CLIP\nhead remain large irrespective of whether the image-language pairs reconcile.\nIt is difficult to address in data space, given the few-shot regime. We propose\na penalty incorporated into loss objective that penalizes incorrect\nclassifications whenever one is made during finetuning, by moving an amount of\nlog-likelihood to the true class commensurate to the relative amplitudes of the\ntwo likelihoods. We refer to it as \\textit{confidence misalignment penalty\n(CMP)}. Extensive experiments on $12$ vision datasets and $5$ domain\ngeneralization datasets supports the calibration performance of our method\nagainst stat-of-the-art. CMP outperforms the benchmarked prompt learning\nmethods, demonstrating average improvement in Expected Calibration Error (ECE)\nby average $6.01$\\%, $4.01$ \\% at minimum and $9.72$\\% at maximum.\n","authors":["Behraj Khan","Tahir Syed"],"pdf_url":"https://arxiv.org/pdf/2501.17595v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18538v1","updated":"2025-01-30T18:06:44Z","published":"2025-01-30T18:06:44Z","title":"Mini-ResEmoteNet: Leveraging Knowledge Distillation for Human-Centered\n  Design","summary":"  Facial Emotion Recognition has emerged as increasingly pivotal in the domain\nof User Experience, notably within modern usability testing, as it facilitates\na deeper comprehension of user satisfaction and engagement. This study aims to\nextend the ResEmoteNet model by employing a knowledge distillation framework to\ndevelop Mini-ResEmoteNet models - lightweight student models - tailored for\nusability testing. Experiments were conducted on the FER2013 and RAF-DB\ndatasets to assess the efficacy of three student model architectures: Student\nModel A, Student Model B, and Student Model C. Their development involves\nreducing the number of feature channels in each layer of the teacher model by\napproximately 50%, 75%, and 87.5%. Demonstrating exceptional performance on the\nFER2013 dataset, Student Model A (E1) achieved a test accuracy of 76.33%,\nmarking a 0.21% absolute improvement over EmoNeXt. Moreover, the results\nexhibit absolute improvements in terms of inference speed and memory usage\nduring inference compared to the ResEmoteNet model. The findings indicate that\nthe proposed methods surpass other state-of-the-art approaches.\n","authors":["Amna Murtada","Omnia Abdelrhman","Tahani Abdalla Attia"],"pdf_url":"https://arxiv.org/pdf/2501.18538v1.pdf","comment":"5 pages with 4 figures"},{"id":"http://arxiv.org/abs/2501.18533v1","updated":"2025-01-30T17:59:45Z","published":"2025-01-30T17:59:45Z","title":"Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models","summary":"  Large Vision-Language Models (VLMs) have achieved remarkable performance\nacross a wide range of tasks. However, their deployment in safety-critical\ndomains poses significant challenges. Existing safety fine-tuning methods,\nwhich focus on textual or multimodal content, fall short in addressing\nchallenging cases or disrupt the balance between helpfulness and harmlessness.\nOur evaluation highlights a safety reasoning gap: these methods lack safety\nvisual reasoning ability, leading to such bottlenecks. To address this\nlimitation and enhance both visual perception and reasoning in safety-critical\ncontexts, we propose a novel dataset that integrates multi-image inputs with\nsafety Chain-of-Thought (CoT) labels as fine-grained reasoning logic to improve\nmodel performance. Specifically, we introduce the Multi-Image Safety (MIS)\ndataset, an instruction-following dataset tailored for multi-image safety\nscenarios, consisting of training and test splits. Our experiments demonstrate\nthat fine-tuning InternVL2.5-8B with MIS significantly outperforms both\npowerful open-source models and API-based models in challenging multi-image\ntasks requiring safety-related visual reasoning. This approach not only\ndelivers exceptional safety performance but also preserves general capabilities\nwithout any trade-offs. Specifically, fine-tuning with MIS increases average\naccuracy by 0.83% across five general benchmarks and reduces the Attack Success\nRate (ASR) on multiple safety benchmarks by a large margin. Data and Models are\nreleased under:\n\\href{https://dripnowhy.github.io/MIS/}{\\texttt{https://dripnowhy.github.io/MIS/}}\n","authors":["Yi Ding","Lijun Li","Bing Cao","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2501.18533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17635v2","updated":"2025-01-30T17:59:08Z","published":"2025-01-29T13:12:01Z","title":"In-Context Meta LoRA Generation","summary":"  Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task\nspecific fine-tuning. However, in scenarios that involve multiple tasks,\ntraining a separate LoRA model for each one results in considerable\ninefficiency in terms of storage and inference. Moreover, existing parameter\ngeneration methods fail to capture the correlations among these tasks, making\nmulti-task LoRA parameter generation challenging. To address these limitations,\nwe propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently\nachieves task-specific customization of large language models (LLMs).\nSpecifically, we use training data from all tasks to train a tailored\ngenerator, Conditional Variational Autoencoder (CVAE). CVAE takes task\ndescriptions as inputs and produces task-aware LoRA weights as outputs. These\nLoRA weights are then merged with LLMs to create task-specialized models\nwithout the need for additional fine-tuning. Furthermore, we utilize in-context\nmeta-learning for knowledge enhancement and task mapping, to capture the\nrelationship between tasks and parameter distributions. As a result, our method\nachieves more accurate LoRA parameter generation for diverse tasks using CVAE.\nICM-LoRA enables more accurate LoRA parameter reconstruction than current\nparameter reconstruction methods and is useful for implementing task-specific\nenhancements of LoRA parameters. At the same time, our method occupies 283MB,\nonly 1\\% storage compared with the original LoRA.\n","authors":["Yihua Shao","Minxi Yan","Yang Liu","Siyu Chen","Wenjie Chen","Xinwei Long","Ziyang Yan","Lei Li","Chenyu Zhang","Nicu Sebe","Hao Tang","Yan Wang","Hao Zhao","Mengzhu Wang","Jingcai Guo"],"pdf_url":"https://arxiv.org/pdf/2501.17635v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13919v2","updated":"2025-01-30T17:35:08Z","published":"2025-01-23T18:58:03Z","title":"Temporal Preference Optimization for Long-Form Video Understanding","summary":"  Despite significant advancements in video large multimodal models\n(video-LMMs), achieving effective temporal grounding in long-form videos\nremains a challenge for existing models. To address this limitation, we propose\nTemporal Preference Optimization (TPO), a novel post-training framework\ndesigned to enhance the temporal grounding capabilities of video-LMMs through\npreference learning. TPO adopts a self-training approach that enables models to\ndifferentiate between well-grounded and less accurate temporal responses by\nleveraging curated preference datasets at two granularities: localized temporal\ngrounding, which focuses on specific video segments, and comprehensive temporal\ngrounding, which captures extended temporal dependencies across entire video\nsequences. By optimizing on these preference datasets, TPO significantly\nenhances temporal understanding while reducing reliance on manually annotated\ndata. Extensive experiments on three long-form video understanding\nbenchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness\nof TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO\nestablishes itself as the leading 7B model on the Video-MME benchmark,\nunderscoring the potential of TPO as a scalable and efficient solution for\nadvancing temporal reasoning in long-form video understanding. Project page:\nhttps://ruili33.github.io/tpo_website.\n","authors":["Rui Li","Xiaohan Wang","Yuhui Zhang","Zeyu Wang","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2501.13919v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20095v3","updated":"2025-01-30T17:34:37Z","published":"2024-06-28T17:59:12Z","title":"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy","summary":"  Vision Language Models (VLMs) have recently been leveraged to generate\nrobotic actions, forming Vision-Language-Action (VLA) models. However, directly\nadapting a pretrained VLM for robotic control remains challenging, particularly\nwhen constrained by a limited number of robot demonstrations. In this work, we\nintroduce LLaRA: Large Language and Robotics Assistant, a framework that\nformulates robot action policy as visuo-textual conversations and enables an\nefficient transfer of a pretrained VLM into a powerful VLA, motivated by the\nsuccess of visual instruction tuning in Computer Vision. First, we present an\nautomated pipeline to generate conversation-style instruction tuning data for\nrobots from existing behavior cloning datasets, aligning robotic actions with\nimage pixel coordinates. Further, we enhance this dataset in a self-supervised\nmanner by defining six auxiliary tasks, without requiring any additional action\nannotations. We show that a VLM finetuned with a limited amount of such\ndatasets can produce meaningful action decisions for robotic control. Through\nexperiments across multiple simulated and real-world tasks, we demonstrate that\nLLaRA achieves state-of-the-art performance while preserving the generalization\ncapabilities of large language models. The code, datasets, and pretrained\nmodels are available at https://github.com/LostXine/LLaRA.\n","authors":["Xiang Li","Cristina Mata","Jongwoo Park","Kumara Kahatapitiya","Yoo Sung Jang","Jinghuan Shang","Kanchana Ranasinghe","Ryan Burgert","Mu Cai","Yong Jae Lee","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2406.20095v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.18517v1","updated":"2025-01-30T17:30:00Z","published":"2025-01-30T17:30:00Z","title":"Integrating Spatial and Frequency Information for Under-Display Camera\n  Image Restoration","summary":"  Under-Display Camera (UDC) houses a digital camera lens under a display\npanel. However, UDC introduces complex degradations such as noise, blur,\ndecrease in transmittance, and flare. Despite the remarkable progress, previous\nresearch on UDC mainly focuses on eliminating diffraction in the spatial domain\nand rarely explores its potential in the frequency domain. It is essential to\nconsider both the spatial and frequency domains effectively. For example,\ndegradations, such as noise and blur, can be addressed by local information\n(e.g., CNN kernels in the spatial domain). At the same time, tackling flares\nmay require leveraging global information (e.g., the frequency domain). In this\npaper, we revisit the UDC degradations in the Fourier space and figure out\nintrinsic frequency priors that imply the presence of the flares. Based on this\nobservation, we propose a novel multi-level DNN architecture called SFIM. It\nefficiently restores UDC-distorted images by integrating local and global (the\ncollective contribution of all points in the image) information. The\narchitecture exploits CNNs to capture local information and FFT-based models to\ncapture global information. SFIM comprises a spatial domain block (SDB), a\nFrequency Domain Block (FDB), and an Attention-based Multi-level Integration\nBlock (AMIB). Specifically, SDB focuses more on detailed textures such as noise\nand blur, FDB emphasizes irregular texture loss in extensive areas such as\nflare, and AMIB enables effective cross-domain interaction. SFIM's superior\nperformance over state-of-the-art approaches is demonstrated through rigorous\nquantitative and qualitative assessments across three UDC benchmarks.\n","authors":["Kyusu Ahn","Jinpyo Kim","Chanwoo Park","JiSoo Kim","Jaejin Lee"],"pdf_url":"https://arxiv.org/pdf/2501.18517v1.pdf","comment":"Main body (10 pages, 9 Figures, 5 Tables), References (3 pages),\n  Appendix (8 pages, 6 Figures, 6 Tables)"},{"id":"http://arxiv.org/abs/2501.18509v1","updated":"2025-01-30T17:20:42Z","published":"2025-01-30T17:20:42Z","title":"Deconstruct Complexity (DeComplex): A Novel Perspective on Tackling\n  Dense Action Detection","summary":"  Dense action detection involves detecting multiple co-occurring actions in an\nuntrimmed video while action classes are often ambiguous and represent\noverlapping concepts. To address this challenge task, we introduce a novel\nperspective inspired by how humans tackle complex tasks by breaking them into\nmanageable sub-tasks. Instead of relying on a single network to address the\nentire problem, as in current approaches, we propose decomposing the problem\ninto detecting key concepts present in action classes, specifically, detecting\ndense static concepts and detecting dense dynamic concepts, and assigning them\nto distinct, specialized networks. Furthermore, simultaneous actions in a video\noften exhibit interrelationships, and exploiting these relationships can\nimprove performance. However, we argue that current networks fail to\neffectively learn these relationships due to their reliance on binary\ncross-entropy optimization, which treats each class independently. To address\nthis limitation, we propose providing explicit supervision on co-occurring\nconcepts during network optimization through a novel language-guided\ncontrastive learning loss. Our extensive experiments demonstrate the\nsuperiority of our approach over state-of-the-art methods, achieving\nsubstantial relative improvements of 23.4% and 2.5% mAP on the challenging\nbenchmark datasets, Charades and MultiTHUMOS.\n","authors":["Faegheh Sardari","Armin Mustafa","Philip J. B. Jackson","Adrian Hilton"],"pdf_url":"https://arxiv.org/pdf/2501.18509v1.pdf","comment":"Computer Vision"},{"id":"http://arxiv.org/abs/2501.14265v2","updated":"2025-01-30T17:19:05Z","published":"2025-01-24T06:07:11Z","title":"Bayesian Neural Networks for One-to-Many Mapping in Image Enhancement","summary":"  In image enhancement tasks, such as low-light and underwater image\nenhancement, a degraded image can correspond to multiple plausible target\nimages due to dynamic photography conditions, such as variations in\nillumination. This naturally results in a one-to-many mapping challenge. To\naddress this, we propose a Bayesian Enhancement Model (BEM) that incorporates\nBayesian Neural Networks (BNNs) to capture data uncertainty and produce diverse\noutputs. To achieve real-time inference, we introduce a two-stage approach:\nStage I employs a BNN to model the one-to-many mappings in the low-dimensional\nspace, while Stage II refines fine-grained image details using a Deterministic\nNeural Network (DNN). To accelerate BNN training and convergence, we introduce\na dynamic Momentum Prior. Extensive experiments on multiple low-light and\nunderwater image enhancement benchmarks demonstrate the superiority of our\nmethod over deterministic models.\n","authors":["Guoxi Huang","Nantheera Anantrasirichai","Fei Ye","Zipeng Qi","RuiRui Lin","Qirui Yang","David Bull"],"pdf_url":"https://arxiv.org/pdf/2501.14265v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18504v1","updated":"2025-01-30T17:13:32Z","published":"2025-01-30T17:13:32Z","title":"CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to\n  Sustainability Data Extraction","summary":"  Large Language Model (LLM) image recognition is a powerful tool for\nextracting data from images, but accuracy depends on providing sufficient cues\nin the prompt - requiring a domain expert for specialized tasks. We introduce\nCue Learning using Evolution for Accurate Recognition (CLEAR), which uses a\ncombination of LLMs and evolutionary computation to generate and optimize cues\nsuch that recognition of specialized features in images is improved. It\nachieves this by auto-generating a novel domain-specific representation and\nthen using it to optimize suitable textual cues with a genetic algorithm. We\napply CLEAR to the real-world task of identifying sustainability data from\ninterior and exterior images of buildings. We investigate the effects of using\na variable-length representation compared to fixed-length and show how LLM\nconsistency can be improved by refactoring from categorical to real-valued\nestimates. We show that CLEAR enables higher accuracy compared to expert human\nrecognition and human-authored prompts in every task with error rates improved\nby up to two orders of magnitude and an ablation study evincing solution\nconcision.\n","authors":["Peter J. Bentley","Soo Ling Lim","Fuyuki Ishikawa"],"pdf_url":"https://arxiv.org/pdf/2501.18504v1.pdf","comment":"9 pages plus 2 pages of supplemental material"},{"id":"http://arxiv.org/abs/2501.18500v1","updated":"2025-01-30T17:10:53Z","published":"2025-01-30T17:10:53Z","title":"HSRMamba: Contextual Spatial-Spectral State Space Model for Single\n  Hyperspectral Super-Resolution","summary":"  Mamba has demonstrated exceptional performance in visual tasks due to its\npowerful global modeling capabilities and linear computational complexity,\noffering considerable potential in hyperspectral image super-resolution\n(HSISR). However, in HSISR, Mamba faces challenges as transforming images into\n1D sequences neglects the spatial-spectral structural relationships between\nlocally adjacent pixels, and its performance is highly sensitive to input\norder, which affects the restoration of both spatial and spectral details. In\nthis paper, we propose HSRMamba, a contextual spatial-spectral modeling state\nspace model for HSISR, to address these issues both locally and globally.\nSpecifically, a local spatial-spectral partitioning mechanism is designed to\nestablish patch-wise causal relationships among adjacent pixels in 3D features,\nmitigating the local forgetting issue. Furthermore, a global spectral\nreordering strategy based on spectral similarity is employed to enhance the\ncausal representation of similar pixels across both spatial and spectral\ndimensions. Finally, experimental results demonstrate our HSRMamba outperforms\nthe state-of-the-art methods in quantitative quality and visual results. Code\nwill be available soon.\n","authors":["Shi Chen","Lefei Zhang","Liangpei Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.18500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18494v1","updated":"2025-01-30T17:07:24Z","published":"2025-01-30T17:07:24Z","title":"Runway vs. Taxiway: Challenges in Automated Line Identification and\n  Notation Approaches","summary":"  The increasing complexity of autonomous systems has amplified the need for\naccurate and reliable labeling of runway and taxiway markings to ensure\noperational safety. Precise detection and labeling of these markings are\ncritical for tasks such as navigation, landing assistance, and ground control\nautomation. Existing labeling algorithms, like the Automated Line\nIdentification and Notation Algorithm (ALINA), have demonstrated success in\nidentifying taxiway markings but encounter significant challenges when applied\nto runway markings. This limitation arises due to notable differences in line\ncharacteristics, environmental context, and interference from elements such as\nshadows, tire marks, and varying surface conditions. To address these\nchallenges, we modified ALINA by adjusting color thresholds and refining region\nof interest (ROI) selection to better suit runway-specific contexts. While\nthese modifications yielded limited improvements, the algorithm still struggled\nwith consistent runway identification, often mislabeling elements such as the\nhorizon or non-relevant background features. This highlighted the need for a\nmore robust solution capable of adapting to diverse visual interferences. In\nthis paper, we propose integrating a classification step using a Convolutional\nNeural Network (CNN) named AssistNet. By incorporating this classification\nstep, the detection pipeline becomes more resilient to environmental variations\nand misclassifications. This work not only identifies the challenges but also\noutlines solutions, paving the way for improved automated labeling techniques\nessential for autonomous aviation systems.\n","authors":["Parth Ganeriwala","Amy Alvarez","Abdullah AlQahtani","Siddhartha Bhattacharyya","Mohammed Abdul Hafeez Khan","Natasha Neogi"],"pdf_url":"https://arxiv.org/pdf/2501.18494v1.pdf","comment":"Accepted at SysCon 2025"},{"id":"http://arxiv.org/abs/2501.18487v1","updated":"2025-01-30T17:04:11Z","published":"2025-01-30T17:04:11Z","title":"Track-On: Transformer-based Online Point Tracking with Memory","summary":"  In this paper, we consider the problem of long-term point tracking, which\nrequires consistent identification of points across multiple frames in a video,\ndespite changes in appearance, lighting, perspective, and occlusions. We target\nonline tracking on a frame-by-frame basis, making it suitable for real-world,\nstreaming scenarios. Specifically, we introduce Track-On, a simple\ntransformer-based model designed for online long-term point tracking. Unlike\nprior methods that depend on full temporal modeling, our model processes video\nframes causally without access to future frames, leveraging two memory modules\n-- spatial memory and context memory -- to capture temporal information and\nmaintain reliable point tracking over long time horizons. At inference time, it\nemploys patch classification and refinement to identify correspondences and\ntrack points with high accuracy. Through extensive experiments, we demonstrate\nthat Track-On sets a new state-of-the-art for online models and delivers\nsuperior or competitive results compared to offline approaches on seven\ndatasets, including the TAP-Vid benchmark. Our method offers a robust and\nscalable solution for real-time tracking in diverse applications. Project page:\nhttps://kuis-ai.github.io/track_on\n","authors":["Görkay Aydemir","Xiongyi Cai","Weidi Xie","Fatma Güney"],"pdf_url":"https://arxiv.org/pdf/2501.18487v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.18478v1","updated":"2025-01-30T16:51:40Z","published":"2025-01-30T16:51:40Z","title":"SimpleDepthPose: Fast and Reliable Human Pose Estimation with\n  RGBD-Images","summary":"  In the rapidly advancing domain of computer vision, accurately estimating the\nposes of multiple individuals from various viewpoints remains a significant\nchallenge, especially when reliability is a key requirement. This paper\nintroduces a novel algorithm that excels in multi-view, multi-person pose\nestimation by incorporating depth information. An extensive evaluation\ndemonstrates that the proposed algorithm not only generalizes well to unseen\ndatasets, and shows a fast runtime performance, but also is adaptable to\ndifferent keypoints. To support further research, all of the work is publicly\naccessible.\n","authors":["Daniel Bermuth","Alexander Poeppel","Wolfgang Reif"],"pdf_url":"https://arxiv.org/pdf/2501.18478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18474v1","updated":"2025-01-30T16:48:02Z","published":"2025-01-30T16:48:02Z","title":"Tuning Vision Foundation Model via Test-Time Prompt-Guided Training for\n  VFSS Segmentations","summary":"  Vision foundation models have demonstrated exceptional generalization\ncapabilities in segmentation tasks for both generic and specialized images.\nHowever, a performance gap persists between foundation models and\ntask-specific, specialized models. Fine-tuning foundation models on downstream\ndatasets is often necessary to bridge this gap. Unfortunately, obtaining fully\nannotated ground truth for downstream datasets is both challenging and costly.\nTo address this limitation, we propose a novel test-time training paradigm that\nenhances the performance of foundation models on downstream datasets without\nrequiring full annotations. Specifically, our method employs simple point\nprompts to guide a test-time semi-self-supervised training task. The model\nlearns by resolving the ambiguity of the point prompt through various\naugmentations. This approach directly tackles challenges in the medical imaging\nfield, where acquiring annotations is both time-intensive and expensive. We\nconducted extensive experiments on our new Videofluoroscopy dataset (VFSS-5k)\nfor the instance segmentation task, achieving an average Dice coefficient of\n0.868 across 12 anatomies with a single model.\n","authors":["Chengxi Zeng","David Smithard","Alberto M Gambaruto","Tilo Burghardt"],"pdf_url":"https://arxiv.org/pdf/2501.18474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16273v2","updated":"2025-01-30T16:44:45Z","published":"2025-01-27T18:06:36Z","title":"Return of the Encoder: Maximizing Parameter Efficiency for SLMs","summary":"  The dominance of large decoder-only language models has overshadowed\nencoder-decoder architectures, despite their fundamental efficiency advantages\nin sequence processing. For small language models (SLMs) - those with 1 billion\nparameters or fewer - our systematic analysis across GPU, CPU, and NPU\nplatforms reveals that encoder-decoder architectures achieve 47% lower\nfirst-token latency and 4.7x higher throughput compared to decoder-only models\non edge devices. These gains may be attributed to encoder-decoder's one-time\ninput processing and efficient separation of understanding and generation\nphases.\n  We introduce a novel knowledge distillation framework that enables\nencoder-decoder models to leverage capabilities from large scalable\ndecoder-only teachers while preserving their architectural advantages,\nachieving up to 6 average performance points improvement across diverse tasks,\nwith significant gains in asymmetric sequence tasks where input and output\ndistributions can benefit from different processing approaches.\n  When combined with modern advances like Rotary Positional Embeddings (RoPE)\nand Vision encoders, our systematic investigation demonstrates that\nencoder-decoder architectures provide a more practical path toward deploying\ncapable language models in resource-constrained environments. Our findings\nchallenge the prevailing trend toward decoder-only scaling, showing that\narchitectural choices become increasingly crucial as parameter budgets\ndecrease, particularly for on-device and edge deployments where computational\nefficiency is paramount.\n","authors":["Mohamed Elfeki","Rui Liu","Chad Voegele"],"pdf_url":"https://arxiv.org/pdf/2501.16273v2.pdf","comment":"13 pages, 5 figures. LLMs/SLMs, encoder-decoder and decoder-only"},{"id":"http://arxiv.org/abs/2404.12920v4","updated":"2025-01-30T16:31:27Z","published":"2024-04-19T14:43:48Z","title":"Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models","summary":"  Localizing the exact pathological regions in a given medical scan is an\nimportant imaging problem that traditionally requires a large amount of\nbounding box ground truth annotations to be accurately solved. However, there\nexist alternative, potentially weaker, forms of supervision, such as\naccompanying free-text reports, which are readily available. The task of\nperforming localization with textual guidance is commonly referred to as phrase\ngrounding. In this work, we use a publicly available Foundation Model, namely\nthe Latent Diffusion Model, to perform this challenging task. This choice is\nsupported by the fact that the Latent Diffusion Model, despite being generative\nin nature, contains cross-attention mechanisms that implicitly align visual and\ntextual features, thus leading to intermediate representations that are\nsuitable for the task at hand. In addition, we aim to perform this task in a\nzero-shot manner, i.e., without any training on the target task, meaning that\nthe model's weights remain frozen. To this end, we devise strategies to select\nfeatures and also refine them via post-processing without extra learnable\nparameters. We compare our proposed method with state-of-the-art approaches\nwhich explicitly enforce image-text alignment in a joint embedding space via\ncontrastive learning. Results on a popular chest X-ray benchmark indicate that\nour method is competitive with SOTA on different types of pathology, and even\noutperforms them on average in terms of two metrics (mean IoU and AUC-ROC).\nSource code will be released upon acceptance at https://github.com/vios-s.\n","authors":["Konstantinos Vilouras","Pedro Sanchez","Alison Q. O'Neil","Sotirios A. Tsaftaris"],"pdf_url":"https://arxiv.org/pdf/2404.12920v4.pdf","comment":"10 pages, 3 figures, IEEE J-BHI Special Issue on Foundation Models in\n  Medical Imaging"},{"id":"http://arxiv.org/abs/2501.18463v1","updated":"2025-01-30T16:30:20Z","published":"2025-01-30T16:30:20Z","title":"A Benchmark and Evaluation for Real-World Out-of-Distribution Detection\n  Using Vision-Language Models","summary":"  Out-of-distribution (OOD) detection is a task that detects OOD samples during\ninference to ensure the safety of deployed models. However, conventional\nbenchmarks have reached performance saturation, making it difficult to compare\nrecent OOD detection methods. To address this challenge, we introduce three\nnovel OOD detection benchmarks that enable a deeper understanding of method\ncharacteristics and reflect real-world conditions. First, we present\nImageNet-X, designed to evaluate performance under challenging semantic shifts.\nSecond, we propose ImageNet-FS-X for full-spectrum OOD detection, assessing\nrobustness to covariate shifts (feature distribution shifts). Finally, we\npropose Wilds-FS-X, which extends these evaluations to real-world datasets,\noffering a more comprehensive testbed. Our experiments reveal that recent\nCLIP-based OOD detection methods struggle to varying degrees across the three\nproposed benchmarks, and none of them consistently outperforms the others. We\nhope the community goes beyond specific benchmarks and includes more\nchallenging conditions reflecting real-world scenarios. The code is\nhttps://github.com/hoshi23/OOD-X-Banchmarks.\n","authors":["Shiho Noda","Atsuyuki Miyai","Qing Yu","Go Irie","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2501.18463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18453v1","updated":"2025-01-30T16:05:40Z","published":"2025-01-30T16:05:40Z","title":"Transfer Learning for Keypoint Detection in Low-Resolution Thermal TUG\n  Test Images","summary":"  This study presents a novel approach to human keypoint detection in\nlow-resolution thermal images using transfer learning techniques. We introduce\nthe first application of the Timed Up and Go (TUG) test in thermal image\ncomputer vision, establishing a new paradigm for mobility assessment. Our\nmethod leverages a MobileNetV3-Small encoder and a ViTPose decoder, trained\nusing a composite loss function that balances latent representation alignment\nand heatmap accuracy. The model was evaluated using the Object Keypoint\nSimilarity (OKS) metric from the COCO Keypoint Detection Challenge. The\nproposed model achieves better performance with AP, AP50, and AP75 scores of\n0.861, 0.942, and 0.887 respectively, outperforming traditional supervised\nlearning approaches like Mask R-CNN and ViTPose-Base. Moreover, our model\ndemonstrates superior computational efficiency in terms of parameter count and\nFLOPS. This research lays a solid foundation for future clinical applications\nof thermal imaging in mobility assessment and rehabilitation monitoring.\n","authors":["Wei-Lun Chen","Chia-Yeh Hsieh","Yu-Hsiang Kao","Kai-Chun Liu","Sheng-Yu Peng","Yu Tsao"],"pdf_url":"https://arxiv.org/pdf/2501.18453v1.pdf","comment":"Accepted to AICAS 2025. This is the preprint version"},{"id":"http://arxiv.org/abs/2405.03762v4","updated":"2025-01-30T16:01:20Z","published":"2024-05-06T18:01:13Z","title":"Swin transformers are robust to distribution and concept drift in\n  endoscopy-based longitudinal rectal cancer assessment","summary":"  Endoscopic images are used at various stages of rectal cancer treatment\nstarting from cancer screening, diagnosis, during treatment to assess response\nand toxicity from treatments such as colitis, and at follow up to detect new\ntumor or local regrowth (LR). However, subjective assessment is highly variable\nand can underestimate the degree of response in some patients, subjecting them\nto unnecessary surgery, or overestimate response that places patients at risk\nof disease spread. Advances in deep learning has shown the ability to produce\nconsistent and objective response assessment for endoscopic images. However,\nmethods for detecting cancers, regrowth, and monitoring response during the\nentire course of patient treatment and follow-up are lacking. This is because,\nautomated diagnosis and rectal cancer response assessment requires methods that\nare robust to inherent imaging illumination variations and confounding\nconditions (blood, scope, blurring) present in endoscopy images as well as\nchanges to the normal lumen and tumor during treatment. Hence, a hierarchical\nshifted window (Swin) transformer was trained to distinguish rectal cancer from\nnormal lumen using endoscopy images. Swin as well as two convolutional\n(ResNet-50, WideResNet-50), and vision transformer (ViT) models were trained\nand evaluated on follow-up longitudinal images to detect LR on private dataset\nas well as on out-of-distribution (OOD) public colonoscopy datasets to detect\npre/non-cancerous polyps. Color shifts were applied using optimal transport to\nsimulate distribution shifts. Swin and ResNet models were similarly accurate in\nthe in-distribution dataset. Swin was more accurate than other methods\n(follow-up: 0.84, OOD: 0.83) even when subject to color shifts (follow-up:\n0.83, OOD: 0.87), indicating capability to provide robust performance for\nlongitudinal cancer assessment.\n","authors":["Jorge Tapias Gomez","Aneesh Rangnekar","Hannah Williams","Hannah Thompson","Julio Garcia-Aguilar","Joshua Jesse Smith","Harini Veeraraghavan"],"pdf_url":"https://arxiv.org/pdf/2405.03762v4.pdf","comment":"Accepted at SPIE Medical Imaging 2025"},{"id":"http://arxiv.org/abs/2403.13113v3","updated":"2025-01-30T15:57:48Z","published":"2024-03-19T19:36:48Z","title":"Quantifying uncertainty in lung cancer segmentation with foundation\n  models applied to mixed-domain datasets","summary":"  Medical image foundation models have shown the ability to segment organs and\ntumors with minimal fine-tuning. These models are typically evaluated on\ntask-specific in-distribution (ID) datasets. However, reliable performance on\nID datasets does not guarantee robust generalization on out-of-distribution\n(OOD) datasets. Importantly, once deployed for clinical use, it is impractical\nto have `ground truth' delineations to assess ongoing performance drifts,\nespecially when images fall into the OOD category due to different imaging\nprotocols. Hence, we introduced a comprehensive set of computationally fast\nmetrics to evaluate the performance of multiple foundation models (Swin UNETR,\nSimMIM, iBOT, SMIT) trained with self-supervised learning (SSL). All models\nwere fine-tuned on identical datasets for lung tumor segmentation from computed\ntomography (CT) scans. The evaluation was performed on two public lung cancer\ndatasets (LRAD: n = 140, 5Rater: n = 21) with different image acquisitions and\ntumor stages compared to training data (n = 317 public resource with stage\nIII-IV lung cancers) and a public non-cancer dataset containing volumetric CT\nscans of patients with pulmonary embolism (n = 120). All models produced\nsimilarly accurate tumor segmentation on the lung cancer testing datasets. SMIT\nproduced the highest F1-score (LRAD: 0.60, 5Rater: 0.64) and lowest entropy\n(LRAD: 0.06, 5Rater: 0.12), indicating higher tumor detection rate and\nconfident segmentations. In the OOD dataset, SMIT misdetected the least number\nof tumors, marked by a median volume occupancy of 5.67 cc compared to the best\nmethod SimMIM of 9.97 cc. Our analysis shows that additional metrics such as\nentropy and volume occupancy may help better understand model performance on\nmixed domain datasets.\n","authors":["Aneesh Rangnekar","Nishant Nadkarni","Jue Jiang","Harini Veeraraghavan"],"pdf_url":"https://arxiv.org/pdf/2403.13113v3.pdf","comment":"Accepted at SPIE Medical Imaging 2025"},{"id":"http://arxiv.org/abs/2501.18444v1","updated":"2025-01-30T15:56:20Z","published":"2025-01-30T15:56:20Z","title":"Adaptive Object Detection for Indoor Navigation Assistance: A\n  Performance Evaluation of Real-Time Algorithms","summary":"  This study addresses the need for accurate and efficient object detection in\nassistive technologies for visually impaired individuals. We evaluate four\nreal-time object detection algorithms YOLO, SSD, Faster R-CNN, and Mask R-CNN\nwithin the context of indoor navigation assistance. Using the Indoor Objects\nDetection dataset, we analyze detection accuracy, processing speed, and\nadaptability to indoor environments. Our findings highlight the trade-offs\nbetween precision and efficiency, offering insights into selecting optimal\nalgorithms for realtime assistive navigation. This research advances adaptive\nmachine learning applications, enhancing indoor navigation solutions for the\nvisually impaired and promoting accessibility.\n","authors":["Abhinav Pratap","Sushant Kumar","Suchinton Chakravarty"],"pdf_url":"https://arxiv.org/pdf/2501.18444v1.pdf","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2501.13964v2","updated":"2025-01-30T15:35:03Z","published":"2025-01-21T23:07:03Z","title":"Advancing the Understanding and Evaluation of AR-Generated Scenes: When\n  Vision-Language Models Shine and Stumble","summary":"  Augmented Reality (AR) enhances the real world by integrating virtual\ncontent, yet ensuring the quality, usability, and safety of AR experiences\npresents significant challenges. Could Vision-Language Models (VLMs) offer a\nsolution for the automated evaluation of AR-generated scenes? Could\nVision-Language Models (VLMs) offer a solution for the automated evaluation of\nAR-generated scenes? In this study, we evaluate the capabilities of three\nstate-of-the-art commercial VLMs -- GPT, Gemini, and Claude -- in identifying\nand describing AR scenes. For this purpose, we use DiverseAR, the first AR\ndataset specifically designed to assess VLMs' ability to analyze virtual\ncontent across a wide range of AR scene complexities. Our findings demonstrate\nthat VLMs are generally capable of perceiving and describing AR scenes,\nachieving a True Positive Rate (TPR) of up to 93% for perception and 71% for\ndescription. While they excel at identifying obvious virtual objects, such as a\nglowing apple, they struggle when faced with seamlessly integrated content,\nsuch as a virtual pot with realistic shadows. Our results highlight both the\nstrengths and the limitations of VLMs in understanding AR scenarios. We\nidentify key factors affecting VLM performance, including virtual content\nplacement, rendering quality, and physical plausibility. This study underscores\nthe potential of VLMs as tools for evaluating the quality of AR experiences.\n","authors":["Lin Duan","Yanming Xiu","Maria Gorlatova"],"pdf_url":"https://arxiv.org/pdf/2501.13964v2.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2501.18427v1","updated":"2025-01-30T15:31:48Z","published":"2025-01-30T15:31:48Z","title":"SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute\n  in Linear Diffusion Transformer","summary":"  This paper presents SANA-1.5, a linear Diffusion Transformer for efficient\nscaling in text-to-image generation. Building upon SANA-1.0, we introduce three\nkey innovations: (1) Efficient Training Scaling: A depth-growth paradigm that\nenables scaling from 1.6B to 4.8B parameters with significantly reduced\ncomputational resources, combined with a memory-efficient 8-bit optimizer. (2)\nModel Depth Pruning: A block importance analysis technique for efficient model\ncompression to arbitrary sizes with minimal quality loss. (3) Inference-time\nScaling: A repeated sampling strategy that trades computation for model\ncapacity, enabling smaller models to match larger model quality at inference\ntime. Through these strategies, SANA-1.5 achieves a text-image alignment score\nof 0.72 on GenEval, which can be further improved to 0.80 through inference\nscaling, establishing a new SoTA on GenEval benchmark. These innovations enable\nefficient model scaling across different compute budgets while maintaining high\nquality, making high-quality image generation more accessible.\n","authors":["Enze Xie","Junsong Chen","Yuyang Zhao","Jincheng Yu","Ligeng Zhu","Yujun Lin","Zhekai Zhang","Muyang Li","Junyu Chen","Han Cai","Bingchen Liu","Daquan Zhou","Song Han"],"pdf_url":"https://arxiv.org/pdf/2501.18427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18418v1","updated":"2025-01-30T15:16:02Z","published":"2025-01-30T15:16:02Z","title":"Task-based Regularization in Penalized Least-Squares for Binary Signal\n  Detection Tasks in Medical Image Denoising","summary":"  Image denoising algorithms have been extensively investigated for medical\nimaging. To perform image denoising, penalized least-squares (PLS) problems can\nbe designed and solved, in which the penalty term encodes prior knowledge of\nthe object being imaged. Sparsity-promoting penalties, such as total variation\n(TV), have been a popular choice for regularizing image denoising problems.\nHowever, such hand-crafted penalties may not be able to preserve task-relevant\ninformation in measured image data and can lead to oversmoothed image\nappearances and patchy artifacts that degrade signal detectability. Supervised\nlearning methods that employ convolutional neural networks (CNNs) have emerged\nas a popular approach to denoising medical images. However, studies have shown\nthat CNNs trained with loss functions based on traditional image quality\nmeasures can lead to a loss of task-relevant information in images. Some\nprevious works have investigated task-based loss functions that employ model\nobservers for training the CNN denoising models. However, such training\nprocesses typically require a large number of noisy and ground-truth\n(noise-free or low-noise) image data pairs. In this work, we propose a\ntask-based regularization strategy for use with PLS in medical image denoising.\nThe proposed task-based regularization is associated with the likelihood of\nlinear test statistics of noisy images for Gaussian noise models. The proposed\nmethod does not require ground-truth image data and solves an individual\noptimization problem for denoising each image. Computer-simulation studies are\nconducted that consider a multivariate-normally distributed (MVN) lumpy\nbackground and a binary texture background. It is demonstrated that the\nproposed regularization strategy can effectively improve signal detectability\nin denoised images.\n","authors":["Wentao Chen","Tianming Xu","Weimin Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.18418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11337v4","updated":"2025-01-30T15:13:01Z","published":"2022-11-21T10:37:56Z","title":"DreamArtist++: Controllable One-Shot Text-to-Image Generation via\n  Positive-Negative Adapter","summary":"  State-of-the-arts text-to-image generation models such as Imagen and Stable\nDiffusion Model have succeed remarkable progresses in synthesizing\nhigh-quality, feature-rich images with high resolution guided by human text\nprompts. Since certain characteristics of image content \\emph{e.g.}, very\nspecific object entities or styles, are very hard to be accurately described by\ntext, some example-based image generation approaches have been proposed,\n\\emph{i.e.} generating new concepts based on absorbing the salient features of\na few input references. Despite of acknowledged successes, these methods have\nstruggled on accurately capturing the reference examples' characteristics while\nkeeping diverse and high-quality image generation, particularly in the one-shot\nscenario (\\emph{i.e.} given only one reference). To tackle this problem, we\npropose a simple yet effective framework, namely DreamArtist, which adopts a\nnovel positive-negative prompt-tuning learning strategy on the pre-trained\ndiffusion model, and it has shown to well handle the trade-off between the\naccurate controllability and fidelity of image generation with only one\nreference example. Specifically, our proposed framework incorporates both\npositive and negative embeddings or adapters and optimizes them in a joint\nmanner. The positive part aggressively captures the salient characteristics of\nthe reference image to drive diversified generation and the negative part\nrectifies inadequacies from the positive part. We have conducted extensive\nexperiments and evaluated the proposed method from image similarity (fidelity)\nand diversity, generation controllability, and style cloning. And our\nDreamArtist has achieved a superior generation performance over existing\nmethods. Besides, our additional evaluation on extended tasks, including\nconcept compositions and prompt-guided image editing, demonstrates its\neffectiveness for more applications.\n","authors":["Ziyi Dong","Pengxu Wei","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2211.11337v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13693v3","updated":"2025-01-30T15:08:17Z","published":"2024-04-21T15:42:56Z","title":"PV-S3: Advancing Automatic Photovoltaic Defect Detection using\n  Semi-Supervised Semantic Segmentation of Electroluminescence Images","summary":"  Photovoltaic (PV) systems allow us to tap into all abundant solar energy,\nhowever they require regular maintenance for high efficiency and to prevent\ndegradation. Traditional manual health check, using Electroluminescence (EL)\nimaging, is expensive and logistically challenging which makes automated defect\ndetection essential. Current automation approaches require extensive manual\nexpert labeling, which is time-consuming, expensive, and prone to errors. We\npropose PV-S3 (Photovoltaic-Semi Supervised Segmentation), a Semi-Supervised\nLearning approach for semantic segmentation of defects in EL images that\nreduces reliance on extensive labeling. PV-S3 is a Deep learning model trained\nusing a few labeled images along with numerous unlabeled images. We introduce a\nnovel Semi Cross-Entropy loss function to deal with class imbalance. We\nevaluate PV-S3 on multiple datasets and demonstrate its effectiveness and\nadaptability. With merely 20% labeled samples, we achieve an absolute\nimprovement of 9.7% in IoU, 13.5% in Precision, 29.15% in Recall, and 20.42% in\nF1-Score over prior state-of-the-art supervised method (which uses 100% labeled\nsamples) on UCF-EL dataset (largest dataset available for semantic segmentation\nof EL images) showing improvement in performance while reducing the annotation\ncosts by 80%. For more details, visit our GitHub\nrepository:https://github.com/abj247/PV-S3.\n","authors":["Abhishek Jha","Yogesh Rawat","Shruti Vyas"],"pdf_url":"https://arxiv.org/pdf/2404.13693v3.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2501.18403v1","updated":"2025-01-30T14:58:33Z","published":"2025-01-30T14:58:33Z","title":"Efficient Transformer for High Resolution Image Motion Deblurring","summary":"  This paper presents a comprehensive study and improvement of the Restormer\narchitecture for high-resolution image motion deblurring. We introduce\narchitectural modifications that reduce model complexity by 18.4% while\nmaintaining or improving performance through optimized attention mechanisms.\nOur enhanced training pipeline incorporates additional transformations\nincluding color jitter, Gaussian blur, and perspective transforms to improve\nmodel robustness as well as a new frequency loss term. Extensive experiments on\nthe RealBlur-R, RealBlur-J, and Ultra-High-Definition Motion blurred (UHDM)\ndatasets demonstrate the effectiveness of our approach. The improved\narchitecture shows better convergence behavior and reduced training time while\nmaintaining competitive performance across challenging scenarios. We also\nprovide detailed ablation studies analyzing the impact of our modifications on\nmodel behavior and performance. Our results suggest that thoughtful\narchitectural simplification combined with enhanced training strategies can\nyield more efficient yet equally capable models for motion deblurring tasks.\nCode and Data Available at: https://github.com/hamzafer/image-deblurring\n","authors":["Amanturdieva Akmaral","Muhammad Hamza Zafar"],"pdf_url":"https://arxiv.org/pdf/2501.18403v1.pdf","comment":"14 pages, 18 figures Submitted as a preprint, no prior\n  journal/conference submission"},{"id":"http://arxiv.org/abs/2501.18401v1","updated":"2025-01-30T14:55:40Z","published":"2025-01-30T14:55:40Z","title":"MatIR: A Hybrid Mamba-Transformer Image Restoration Model","summary":"  In recent years, Transformers-based models have made significant progress in\nthe field of image restoration by leveraging their inherent ability to capture\ncomplex contextual features. Recently, Mamba models have made a splash in the\nfield of computer vision due to their ability to handle long-range dependencies\nand their significant computational efficiency compared to Transformers.\nHowever, Mamba currently lags behind Transformers in contextual learning\ncapabilities. To overcome the limitations of these two models, we propose a\nMamba-Transformer hybrid image restoration model called MatIR. Specifically,\nMatIR cross-cycles the blocks of the Transformer layer and the Mamba layer to\nextract features, thereby taking full advantage of the advantages of the two\narchitectures. In the Mamba module, we introduce the Image Inpainting State\nSpace (IRSS) module, which traverses along four scan paths to achieve efficient\nprocessing of long sequence data. In the Transformer module, we combine\ntriangular window-based local attention with channel-based global attention to\neffectively activate the attention mechanism over a wider range of image\npixels. Extensive experimental results and ablation studies demonstrate the\neffectiveness of our approach.\n","authors":["Juan Wen","Weiyan Hou","Luc Van Gool","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2501.18401v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2402.15648 by other authors"},{"id":"http://arxiv.org/abs/2404.11962v2","updated":"2025-01-30T14:46:45Z","published":"2024-04-18T07:48:00Z","title":"©Plug-in Authorization for Human Content Copyright Protection\n  in Text-to-Image Model","summary":"  This paper addresses the contentious issue of copyright infringement in\nimages generated by text-to-image models, sparking debates among AI developers,\ncontent creators, and legal entities. State-of-the-art models create\nhigh-quality content without crediting original creators, causing concern in\nthe artistic community. To mitigate this, we propose the \\copyright Plug-in\nAuthorization framework, introducing three operations: addition, extraction,\nand combination. Addition involves training a \\copyright plug-in for specific\ncopyright, facilitating proper credit attribution. Extraction allows creators\nto reclaim copyright from infringing models, and combination enables users to\nmerge different \\copyright plug-ins. These operations act as permits,\nincentivizing fair use and providing flexibility in authorization. We present\ninnovative approaches,\"Reverse LoRA\" for extraction and \"EasyMerge\" for\nseamless combination. Experiments in artist-style replication and cartoon IP\nrecreation demonstrate \\copyright plug-ins' effectiveness, offering a valuable\nsolution for human copyright protection in the age of generative AIs. The code\nis available at https://github.com/zc1023/-Plug-in-Authorization.git.\n","authors":["Chao Zhou","Huishuai Zhang","Jiang Bian","Weiming Zhang","Nenghai Yu"],"pdf_url":"https://arxiv.org/pdf/2404.11962v2.pdf","comment":"23 pages, 12 figures"},{"id":"http://arxiv.org/abs/2406.06967v2","updated":"2025-01-30T14:37:55Z","published":"2024-06-11T05:50:34Z","title":"Dual Thinking and Logical Processing -- Are Multi-modal Large Language\n  Models Closing the Gap with Human Vision ?","summary":"  The dual thinking framework considers fast, intuitive processing and slower,\nlogical processing. The perception of dual thinking in vision requires images\nwhere inferences from intuitive and logical processing differ. We introduce an\nadversarial dataset to provide evidence for the dual thinking framework in\nhuman vision, which also aids in studying the qualitative behavior of deep\nlearning models. The evidence underscores the importance of shape in\nidentifying instances in human vision. Our psychophysical studies show the\npresence of multiple inferences in rapid succession, and analysis of errors\nshows the early stopping of visual processing can result in missing relevant\ninformation. Our study shows that segmentation models lack an understanding of\nsub-structures, as indicated by errors related to the position and number of\nsub-components. Additionally, the similarity in errors made by models and\nintuitive human processing indicates that models only address intuitive\nthinking in human vision. In contrast, multi-modal LLMs, including open-source\nmodels, demonstrate tremendous progress on errors made in intuitive processing.\nThe models have improved performance on images that require logical reasoning\nand show recognition of sub-components. However, they have not matched the\nperformance improvements made on errors in intuitive processing.\n","authors":["Kailas Dayanandan","Nikhil Kumar","Anand Sinha","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2406.06967v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18376v1","updated":"2025-01-30T14:29:29Z","published":"2025-01-30T14:29:29Z","title":"Cracks in concrete","summary":"  Finding and properly segmenting cracks in images of concrete is a challenging\ntask. Cracks are thin and rough and being air filled do yield a very weak\ncontrast in 3D images obtained by computed tomography. Enhancing and segmenting\ndark lower-dimensional structures is already demanding. The heterogeneous\nconcrete matrix and the size of the images further increase the complexity. ML\nmethods have proven to solve difficult segmentation problems when trained on\nenough and well annotated data. However, so far, there is not much 3D image\ndata of cracks available at all, let alone annotated. Interactive annotation is\nerror-prone as humans can easily tell cats from dogs or roads without from\nroads with cars but have a hard time deciding whether a thin and dark structure\nseen in a 2D slice continues in the next one. Training networks by synthetic,\nsimulated images is an elegant way out, bears however its own challenges. In\nthis contribution, we describe how to generate semi-synthetic image data to\ntrain CNN like the well known 3D U-Net or random forests for segmenting cracks\nin 3D images of concrete. The thickness of real cracks varies widely, both,\nwithin one crack as well as from crack to crack in the same sample. The\nsegmentation method should therefore be invariant with respect to scale\nchanges. We introduce the so-called RieszNet, designed for exactly this\npurpose. Finally, we discuss how to generalize the ML crack segmentation\nmethods to other concrete types.\n","authors":["Tin Barisin","Christian Jung","Anna Nowacka","Claudia Redenbach","Katja Schladitz"],"pdf_url":"https://arxiv.org/pdf/2501.18376v1.pdf","comment":"This is a preprint of the chapter: T. Barisin, C. Jung, A. Nowacka,\n  C. Redenbach, K. Schladitz: Cracks in concrete, published in Statistical\n  Machine Learning for Engineering with Applications (LNCS), edited by J.\n  Franke, A. Sch\\\"obel, reproduced with permission of Springer Nature\n  Switzerland AG 2024. The final authenticated version is available online at:\n  https://doi.org/10.1007/978-3-031-66253-9"},{"id":"http://arxiv.org/abs/2501.18362v1","updated":"2025-01-30T14:07:56Z","published":"2025-01-30T14:07:56Z","title":"MedXpertQA: Benchmarking Expert-Level Medical Reasoning and\n  Understanding","summary":"  We introduce MedXpertQA, a highly challenging and comprehensive benchmark to\nevaluate expert-level medical knowledge and advanced reasoning. MedXpertQA\nincludes 4,460 questions spanning 17 specialties and 11 body systems. It\nincludes two subsets, Text for text evaluation and MM for multimodal\nevaluation. Notably, MM introduces expert-level exam questions with diverse\nimages and rich clinical information, including patient records and examination\nresults, setting it apart from traditional medical multimodal benchmarks with\nsimple QA pairs generated from image captions. MedXpertQA applies rigorous\nfiltering and augmentation to address the insufficient difficulty of existing\nbenchmarks like MedQA, and incorporates specialty board questions to improve\nclinical relevance and comprehensiveness. We perform data synthesis to mitigate\ndata leakage risk and conduct multiple rounds of expert reviews to ensure\naccuracy and reliability. We evaluate 16 leading models on MedXpertQA.\nMoreover, medicine is deeply connected to real-world decision-making, providing\na rich and representative setting for assessing reasoning abilities beyond\nmathematics and code. To this end, we develop a reasoning-oriented subset to\nfacilitate the assessment of o1-like models.\n","authors":["Yuxin Zuo","Shang Qu","Yifei Li","Zhangren Chen","Xuekai Zhu","Ermo Hua","Kaiyan Zhang","Ning Ding","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.18362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18361v1","updated":"2025-01-30T14:06:19Z","published":"2025-01-30T14:06:19Z","title":"Video-based Surgical Tool-tip and Keypoint Tracking using Multi-frame\n  Context-driven Deep Learning Models","summary":"  Automated tracking of surgical tool keypoints in robotic surgery videos is an\nessential task for various downstream use cases such as skill assessment,\nexpertise assessment, and the delineation of safety zones. In recent years, the\nexplosion of deep learning for vision applications has led to many works in\nsurgical instrument segmentation, while lesser focus has been on tracking\nspecific tool keypoints, such as tool tips. In this work, we propose a novel,\nmulti-frame context-driven deep learning framework to localize and track tool\nkeypoints in surgical videos. We train and test our models on the annotated\nframes from the 2015 EndoVis Challenge dataset, resulting in state-of-the-art\nperformance. By leveraging sophisticated deep learning models and multi-frame\ncontext, we achieve 90\\% keypoint detection accuracy and a localization RMS\nerror of 5.27 pixels. Results on a self-annotated JIGSAWS dataset with more\nchallenging scenarios also show that the proposed multi-frame models can\naccurately track tool-tip and tool-base keypoints, with ${<}4.2$-pixel RMS\nerror overall. Such a framework paves the way for accurately tracking surgical\ninstrument keypoints, enabling further downstream use cases. Project and\ndataset webpage: https://tinyurl.com/mfc-tracker\n","authors":["Bhargav Ghanekar","Lianne R. Johnson","Jacob L. Laughlin","Marcia K. O'Malley","Ashok Veeraraghavan"],"pdf_url":"https://arxiv.org/pdf/2501.18361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.02691v2","updated":"2025-01-30T13:16:25Z","published":"2022-05-05T14:57:38Z","title":"The Batch Artifact Scanning Protocol: A new method using computed\n  tomography (CT) to rapidly create three-dimensional models of objects from\n  large collections en masse","summary":"  Within anthropology, the use of three-dimensional (3D) imaging has become\nincreasingly common and widespread since it broadens the available avenues for\naddressing a wide range of key anthropological issues. The ease with which 3D\nmodels can be generated and shared has major impact on research, cultural\nheritage, education, science communication, and public engagement, as well as\ncontributing to the preservation of the physical specimens and archiving\ncollections in widely accessible data bases. Current scanning protocols have\nthe ability to create the required research quality 3D models; however, they\ntend to be time and labor intensive and not practical when working with large\ncollections. Here we describe a streamlined Batch Artifact Scanning Protocol to\nrapidly create 3D models using a medical CT scanner. While this method can be\nused on a variety of material types, we have, for specificity, applied our\nprotocol to a large collection of experimentally broken ungulate limb bones. By\nemploying the Batch Artifact Scanning Protocol, we were able to efficiently\ncreate 3D models of 2,474 bone fragments at a rate of less than 4 minutes per\nspecimen.\n","authors":["Katrina Yezzi-Woodley","Jeff Calder","Mckenzie Sweno","Chloe Siewert","Peter J. Olver"],"pdf_url":"https://arxiv.org/pdf/2205.02691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18328v1","updated":"2025-01-30T13:14:40Z","published":"2025-01-30T13:14:40Z","title":"CodeBrain: Impute Any Brain MRI via Instance-specific Scalar-quantized\n  Codes","summary":"  MRI imputation aims to synthesize the missing modality from one or more\navailable ones, which is highly desirable since it reduces scanning costs and\ndelivers comprehensive MRI information to enhance clinical diagnosis. In this\npaper, we propose a unified model, CodeBrain, designed to adapt to various\nbrain MRI imputation scenarios. The core design lies in casting various\ninter-modality transformations as a full-modality code prediction task. To this\nend, CodeBrain is trained in two stages: Reconstruction and Code Prediction.\nFirst, in the Reconstruction stage, we reconstruct each MRI modality, which is\nmapped into a shared latent space followed by a scalar quantization. Since such\nquantization is lossy and the code is low dimensional, another MRI modality\nbelonging to the same subject is randomly selected to generate common features\nto supplement the code and boost the target reconstruction. In the second\nstage, we train another encoder by a customized grading loss to predict the\nfull-modality codes from randomly masked MRI samples, supervised by the\ncorresponding quantized codes generated from the first stage. In this way, the\ninter-modality transformation is achieved by mapping the instance-specific\ncodes in a finite scalar space. We evaluated the proposed CodeBrain model on\ntwo public brain MRI datasets (i.e., IXI and BraTS 2023). Extensive experiments\ndemonstrate that our CodeBrain model achieves superior imputation performance\ncompared to four existing methods, establishing a new state of the art for\nunified brain MRI imputation. Codes will be released.\n","authors":["Yicheng Wu","Tao Song","Zhonghua Wu","Zongyuan Ge","Zhaolin Chen","Jianfei Cai"],"pdf_url":"https://arxiv.org/pdf/2501.18328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18324v1","updated":"2025-01-30T13:11:19Z","published":"2025-01-30T13:11:19Z","title":"A Video-grounded Dialogue Dataset and Metric for Event-driven Activities","summary":"  This paper presents VDAct, a dataset for a Video-grounded Dialogue on\nEvent-driven Activities, alongside VDEval, a session-based context evaluation\nmetric specially designed for the task. Unlike existing datasets, VDAct\nincludes longer and more complex video sequences that depict a variety of\nevent-driven activities that require advanced contextual understanding for\naccurate response generation. The dataset comprises 3,000 dialogues with over\n30,000 question-and-answer pairs, derived from 1,000 videos with diverse\nactivity scenarios. VDAct displays a notably challenging characteristic due to\nits broad spectrum of activity scenarios and wide range of question types.\nEmpirical studies on state-of-the-art vision foundation models highlight their\nlimitations in addressing certain question types on our dataset. Furthermore,\nVDEval, which integrates dialogue session history and video content summaries\nextracted from our supplementary Knowledge Graphs to evaluate individual\nresponses, demonstrates a significantly higher correlation with human\nassessments on the VDAct dataset than existing evaluation metrics that rely\nsolely on the context of single dialogue turns.\n","authors":["Wiradee Imrattanatrai","Masaki Asada","Kimihiro Hasegawa","Zhi-Qi Cheng","Ken Fukuda","Teruko Mitamura"],"pdf_url":"https://arxiv.org/pdf/2501.18324v1.pdf","comment":"Accepted at AAAI2025"},{"id":"http://arxiv.org/abs/2501.18315v1","updated":"2025-01-30T12:49:17Z","published":"2025-01-30T12:49:17Z","title":"Surface Defect Identification using Bayesian Filtering on a 3D Mesh","summary":"  This paper presents a CAD-based approach for automated surface defect\ndetection. We leverage the a-priori knowledge embedded in a CAD model and\nintegrate it with point cloud data acquired from commercially available stereo\nand depth cameras. The proposed method first transforms the CAD model into a\nhigh-density polygonal mesh, where each vertex represents a state variable in\n3D space. Subsequently, a weighted least squares algorithm is employed to\niteratively estimate the state of the scanned workpiece based on the captured\npoint cloud measurements. This framework offers the potential to incorporate\ninformation from diverse sensors into the CAD domain, facilitating a more\ncomprehensive analysis. Preliminary results demonstrate promising performance,\nwith the algorithm achieving convergence to a sub-millimeter standard deviation\nin the region of interest using only approximately 50 point cloud samples. This\nhighlights the potential of utilising commercially available stereo cameras for\nhigh-precision quality control applications.\n","authors":["Matteo Dalle Vedove","Matteo Bonetto","Edoardo Lamon","Luigi Palopoli","Matteo Saveriano","Daniele Fontanelli"],"pdf_url":"https://arxiv.org/pdf/2501.18315v1.pdf","comment":"Presented at IMEKO2024 World Congress, Hamburg, Germany, 26-29\n  October 2024"},{"id":"http://arxiv.org/abs/2501.13073v4","updated":"2025-01-30T12:46:40Z","published":"2025-01-22T18:35:57Z","title":"CHaRNet: Conditioned Heatmap Regression for Robust Dental Landmark\n  Localization","summary":"  Identifying anatomical landmarks in 3D dental models is vital for orthodontic\ntreatment, yet manual placement is complex and time-consuming. Although some\nmachine learning approaches have been proposed for automatic tooth landmark\ndetection in 3D Intraoral Scans (IOS), none provide a fully end-to-end solution\nthat bypasses teeth segmentation, limiting practical applicability. We\nintroduce CHaRNet (Conditioned Heatmap Regression Network), the first fully\nend-to-end deep learning framework for tooth landmark detection in 3D IOS.\nUnlike traditional two-stage workflows that segment teeth before detecting\nlandmarks, CHaRNet directly operates on the input point cloud, thus reducing\ncomplexity and computational overhead. Our method integrates four modules: (1)\na point cloud encoder, (2) a point cloud decoder with a heatmap regression\nhead, (3) a teeth presence classification head, and (4) the novel Conditioned\nHeatmap Regression (CHaR) module. By leveraging teeth presence classification,\nthe CHaR module dynamically adapts to missing teeth and enhances detection\naccuracy in complex dental models. We evaluate CHaRNet using five point cloud\nlearning algorithms on a clinical dataset of 1,214 annotated 3D models. Both\nthe dataset and code will be publicly released to address the lack of open\ndatasets in orthodontics and inspire further research. CHaRNet achieves a Mean\nEuclidean Distance Error (MEDE) of 0.51 mm on typical dental models and 1.28 mm\nacross all dentition types, with corresponding Mean Success Rates (MSR) of\n87.06% and 82.40%, respectively. Notably, it exhibits robust performance on\nirregular geometries, including models with missing teeth. This end-to-end\napproach streamlines orthodontic workflows, enhances 3D IOS analysis precision,\nand supports efficient computer-assisted treatment planning.\n","authors":["José Rodríguez-Ortega","Francisco Pérez-Hernández","Siham Tabik"],"pdf_url":"https://arxiv.org/pdf/2501.13073v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18314v1","updated":"2025-01-30T12:43:47Z","published":"2025-01-30T12:43:47Z","title":"AGAV-Rater: Adapting Large Multimodal Model for AI-Generated\n  Audio-Visual Quality Assessment","summary":"  Many video-to-audio (VTA) methods have been proposed for dubbing silent\nAI-generated videos. An efficient quality assessment method for AI-generated\naudio-visual content (AGAV) is crucial for ensuring audio-visual quality.\nExisting audio-visual quality assessment methods struggle with unique\ndistortions in AGAVs, such as unrealistic and inconsistent elements. To address\nthis, we introduce AGAVQA, the first large-scale AGAV quality assessment\ndataset, comprising 3,382 AGAVs from 16 VTA methods. AGAVQA includes two\nsubsets: AGAVQA-MOS, which provides multi-dimensional scores for audio quality,\ncontent consistency, and overall quality, and AGAVQA-Pair, designed for optimal\nAGAV pair selection. We further propose AGAV-Rater, a LMM-based model that can\nscore AGAVs, as well as audio and music generated from text, across multiple\ndimensions, and selects the best AGAV generated by VTA methods to present to\nthe user. AGAV-Rater achieves state-of-the-art performance on AGAVQA,\nText-to-Audio, and Text-to-Music datasets. Subjective tests also confirm that\nAGAV-Rater enhances VTA performance and user experience. The project page is\navailable at https://agav-rater.github.io.\n","authors":["Yuqin Cao","Xiongkuo Min","Yixuan Gao","Wei Sun","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2501.18314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18313v1","updated":"2025-01-30T12:43:17Z","published":"2025-01-30T12:43:17Z","title":"Simulation of microstructures and machine learning","summary":"  Machine learning offers attractive solutions to challenging image processing\ntasks. Tedious development and parametrization of algorithmic solutions can be\nreplaced by training a convolutional neural network or a random forest with a\nhigh potential to generalize. However, machine learning methods rely on huge\namounts of representative image data along with a ground truth, usually\nobtained by manual annotation. Thus, limited availability of training data is a\ncritical bottleneck. We discuss two use cases: optical quality control in\nindustrial production and segmenting crack structures in 3D images of concrete.\nFor optical quality control, all defect types have to be trained but are\ntypically not evenly represented in the training data. Additionally, manual\nannotation is costly and often inconsistent. It is nearly impossible in the\nsecond case: segmentation of crack systems in 3D images of concrete. Synthetic\nimages, generated based on realizations of stochastic geometry models, offer an\nelegant way out. A wide variety of structure types can be generated. The within\nstructure variation is naturally captured by the stochastic nature of the\nmodels and the ground truth is for free. Many new questions arise. In\nparticular, which characteristics of the real image data have to be met to\nwhich degree of fidelity.\n","authors":["Katja Schladitz","Claudia Redenbach","Tin Barisin","Christian Jung","Natascha Jeziorski","Lovro Bosnar","Juraj Fulir","Petra Gospodnetić"],"pdf_url":"https://arxiv.org/pdf/2501.18313v1.pdf","comment":"Preprint of: K. Schladitz, C. Redenbach, T. Barisin, C. Jung, N.\n  Jeziorski, L. Bosnar, J. Fulir, P. Gospodneti\\'c: Simulation of\n  Microstructures and Machine Learning, published in Continuum Models and\n  Discrete Systems by F. Willot, J. Dirrenberger, S. Forest, D. Jeulin, A.V.\n  Cherkaev (eds), 2024, Springer Cham. The final version is\n  https://doi.org/10.1007/978-3-031-58665-1"},{"id":"http://arxiv.org/abs/2409.15345v2","updated":"2025-01-30T12:20:12Z","published":"2024-09-10T10:59:32Z","title":"Neuromorphic spatiotemporal optical flow: Enabling ultrafast visual\n  perception beyond human capabilities","summary":"  Optical flow, inspired by the mechanisms of biological visual systems,\ncalculates spatial motion vectors within visual scenes that are necessary for\nenabling robotics to excel in complex and dynamic working environments.\nHowever, current optical flow algorithms, despite human-competitive task\nperformance on benchmark datasets, remain constrained by unacceptable time\ndelays (~0.6 seconds per inference, 4X human processing speed) in practical\ndeployment. Here, we introduce a neuromorphic optical flow approach that\naddresses delay bottlenecks by encoding temporal information directly in a\nsynaptic transistor array to assist spatial motion analysis. Compared to\nconventional spatial-only optical flow methods, our spatiotemporal neuromorphic\noptical flow offers the spatial-temporal consistency of motion information,\nrapidly identifying regions of interest in as little as 1-2 ms using the\ntemporal motion cues derived from the embedded temporal information in the\ntwo-dimensional floating gate synaptic transistors. Thus, the visual input can\nbe selectively filtered to achieve faster velocity calculations and various\ntask execution. At the hardware level, due to the atomically sharp interfaces\nbetween distinct functional layers in two-dimensional van der Waals\nheterostructures, the synaptic transistor offers high-frequency response (~100\n{\\mu}s), robust non-volatility (>10000 s), and excellent endurance (>8000\ncycles), enabling robust visual processing. In software benchmarks, our system\noutperforms state-of-the-art algorithms with a 400% speedup, frequently\nsurpassing human-level performance while maintaining or enhancing accuracy by\nutilizing the temporal priors provided by the embedded temporal information.\n","authors":["Shengbo Wang","Jingwen Zhao","Tongming Pu","Liangbing Zhao","Xiaoyu Guo","Yue Cheng","Cong Li","Weihao Ma","Chenyu Tang","Zhenyu Xu","Ningli Wang","Luigi Occhipinti","Arokia Nathan","Ravinder Dahiya","Huaqiang Wu","Li Tao","Shuo Gao"],"pdf_url":"https://arxiv.org/pdf/2409.15345v2.pdf","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.19243v2","updated":"2025-01-30T12:17:43Z","published":"2024-03-28T08:58:20Z","title":"Efficient Learning With Sine-Activated Low-rank Matrices","summary":"  Low-rank decomposition has emerged as a vital tool for enhancing parameter\nefficiency in neural network architectures, gaining traction across diverse\napplications in machine learning. These techniques significantly lower the\nnumber of parameters, striking a balance between compactness and performance.\nHowever, a common challenge has been the compromise between parameter\nefficiency and the accuracy of the model, where reduced parameters often lead\nto diminished accuracy compared to their full-rank counterparts. In this work,\nwe propose a novel theoretical framework that integrates a sinusoidal function\nwithin the low-rank decomposition process. This approach not only preserves the\nbenefits of the parameter efficiency characteristic of low-rank methods but\nalso increases the decomposition's rank, thereby enhancing model performance.\nOur method proves to be a plug in enhancement for existing low-rank models, as\nevidenced by its successful application in Vision Transformers (ViT), Large\nLanguage Models (LLMs), Neural Radiance Fields (NeRF) and 3D shape modelling.\n","authors":["Yiping Ji","Hemanth Saratchandran","Cameron Gordon","Zeyu Zhang","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2403.19243v2.pdf","comment":"The first two authors contributed equally. Paper accepted at ICLR\n  2025"},{"id":"http://arxiv.org/abs/2501.18294v1","updated":"2025-01-30T12:09:54Z","published":"2025-01-30T12:09:54Z","title":"A Comprehensive Analysis on Machine Learning based Methods for Lung\n  Cancer Level Classification","summary":"  Lung cancer is a major issue in worldwide public health, requiring early\ndiagnosis using stable techniques. This work begins a thorough investigation of\nthe use of machine learning (ML) methods for precise classification of lung\ncancer stages. A cautious analysis is performed to overcome overfitting issues\nin model performance, taking into account minimum child weight and learning\nrate. A set of machine learning (ML) models including XGBoost (XGB), LGBM,\nAdaboost, Logistic Regression (LR), Decision Tree (DT), Random Forest (RF),\nCatBoost, and k-Nearest Neighbor (k-NN) are run methodically and contrasted.\nFurthermore, the correlation between features and targets is examined using the\ndeep neural network (DNN) model and thus their capability in detecting complex\npatternsis established. It is argued that several ML models can be capable of\nclassifying lung cancer stages with great accuracy. In spite of the complexity\nof DNN architectures, traditional ML models like XGBoost, LGBM, and Logistic\nRegression excel with superior performance. The models perform better than the\nothers in lung cancer prediction on the complete set of comparative metrics\nlike accuracy, precision, recall, and F-1 score\n","authors":["Shayli Farshchiha","Salman Asoudeh","Maryam Shavali Kuhshuri","Mehrshad Eisaeid","Mohamadreza Azadie","Saba Hesaraki"],"pdf_url":"https://arxiv.org/pdf/2501.18294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14173v2","updated":"2025-01-30T11:28:17Z","published":"2024-12-18T18:59:59Z","title":"AniDoc: Animation Creation Made Easier","summary":"  The production of 2D animation follows an industry-standard workflow,\nencompassing four essential stages: character design, keyframe animation,\nin-betweening, and coloring. Our research focuses on reducing the labor costs\nin the above process by harnessing the potential of increasingly powerful\ngenerative AI. Using video diffusion models as the foundation, AniDoc emerges\nas a video line art colorization tool, which automatically converts sketch\nsequences into colored animations following the reference character\nspecification. Our model exploits correspondence matching as an explicit\nguidance, yielding strong robustness to the variations (e.g., posture) between\nthe reference character and each line art frame. In addition, our model could\neven automate the in-betweening process, such that users can easily create a\ntemporally consistent animation by simply providing a character image as well\nas the start and end sketches. Our code is available at:\nhttps://yihao-meng.github.io/AniDoc_demo.\n","authors":["Yihao Meng","Hao Ouyang","Hanlin Wang","Qiuyu Wang","Wen Wang","Ka Leong Cheng","Zhiheng Liu","Yujun Shen","Huamin Qu"],"pdf_url":"https://arxiv.org/pdf/2412.14173v2.pdf","comment":"Project page and code: https://yihao-meng.github.io/AniDoc_demo"},{"id":"http://arxiv.org/abs/2501.15847v2","updated":"2025-01-30T11:14:09Z","published":"2025-01-27T08:16:54Z","title":"Can Location Embeddings Enhance Super-Resolution of Satellite Imagery?","summary":"  Publicly available satellite imagery, such as Sentinel- 2, often lacks the\nspatial resolution required for accurate analysis of remote sensing tasks\nincluding urban planning and disaster response. Current super-resolution\ntechniques are typically trained on limited datasets, leading to poor\ngeneralization across diverse geographic regions. In this work, we propose a\nnovel super-resolution framework that enhances generalization by incorporating\ngeographic context through location embeddings. Our framework employs\nGenerative Adversarial Networks (GANs) and incorporates techniques from\ndiffusion models to enhance image quality. Furthermore, we address tiling\nartifacts by integrating information from neighboring images, enabling the\ngeneration of seamless, high-resolution outputs. We demonstrate the\neffectiveness of our method on the building segmentation task, showing\nsignificant improvements over state-of-the-art methods and highlighting its\npotential for real-world applications.\n","authors":["Daniel Panangian","Ksenia Bittner"],"pdf_url":"https://arxiv.org/pdf/2501.15847v2.pdf","comment":"Accepted to IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV)"},{"id":"http://arxiv.org/abs/2501.18270v1","updated":"2025-01-30T11:10:44Z","published":"2025-01-30T11:10:44Z","title":"The iToBoS dataset: skin region images extracted from 3D total body\n  photographs for lesion detection","summary":"  Artificial intelligence has significantly advanced skin cancer diagnosis by\nenabling rapid and accurate detection of malignant lesions. In this domain,\nmost publicly available image datasets consist of single, isolated skin lesions\npositioned at the center of the image. While these lesion-centric datasets have\nbeen fundamental for developing diagnostic algorithms, they lack the context of\nthe surrounding skin, which is critical for improving lesion detection. The\niToBoS dataset was created to address this challenge. It includes 16,954 images\nof skin regions from 100 participants, captured using 3D total body\nphotography. Each image roughly corresponds to a $7 \\times 9$ cm section of\nskin with all suspicious lesions annotated using bounding boxes. Additionally,\nthe dataset provides metadata such as anatomical location, age group, and sun\ndamage score for each image. This dataset aims to facilitate training and\nbenchmarking of algorithms, with the goal of enabling early detection of skin\ncancer and deployment of this technology in non-clinical environments.\n","authors":["Anup Saha","Joseph Adeola","Nuria Ferrera","Adam Mothershaw","Gisele Rezze","Séraphin Gaborit","Brian D'Alessandro","James Hudson","Gyula Szabó","Balazs Pataki","Hayat Rajani","Sana Nazari","Hassan Hayat","Clare Primiero","H. Peter Soyer","Josep Malvehy","Rafael Garcia"],"pdf_url":"https://arxiv.org/pdf/2501.18270v1.pdf","comment":"Article Submitted to Scientific Data"},{"id":"http://arxiv.org/abs/2501.18269v1","updated":"2025-01-30T11:10:18Z","published":"2025-01-30T11:10:18Z","title":"MAMS: Model-Agnostic Module Selection Framework for Video Captioning","summary":"  Multi-modal transformers are rapidly gaining attention in video captioning\ntasks. Existing multi-modal video captioning methods typically extract a fixed\nnumber of frames, which raises critical challenges. When a limited number of\nframes are extracted, important frames with essential information for caption\ngeneration may be missed. Conversely, extracting an excessive number of frames\nincludes consecutive frames, potentially causing redundancy in visual tokens\nextracted from consecutive video frames. To extract an appropriate number of\nframes for each video, this paper proposes the first model-agnostic module\nselection framework in video captioning that has two main functions: (1)\nselecting a caption generation module with an appropriate size based on visual\ntokens extracted from video frames, and (2) constructing subsets of visual\ntokens for the selected caption generation module. Furthermore, we propose a\nnew adaptive attention masking scheme that enhances attention on important\nvisual tokens. Our experiments on three different benchmark datasets\ndemonstrate that the proposed framework significantly improves the performance\nof three recent video captioning models.\n","authors":["Sangho Lee","Il Yong Chun","Hogun Park"],"pdf_url":"https://arxiv.org/pdf/2501.18269v1.pdf","comment":"Accepted to the AAAI 2025 Main Technical Track. This is an extended\n  version of the original submission"},{"id":"http://arxiv.org/abs/2406.05779v4","updated":"2025-01-30T10:55:20Z","published":"2024-06-09T13:25:02Z","title":"Learning to utilize image second-order derivative information for crisp\n  edge detection","summary":"  Edge detection is a fundamental task in computer vision. It has made great\nprogress under the development of deep convolutional neural networks (DCNNs),\nsome of which have achieved a beyond human-level performance. However, recent\ntop-performing edge detection methods tend to generate thick and noisy edge\nlines. In this work, we solve this problem from two aspects: (1) the lack of\nprior knowledge regarding image edges, and (2) the issue of imbalanced pixel\ndistribution. We propose a second-order derivative-based multi-scale contextual\nenhancement module (SDMCM) to help the model locate true edge pixels accurately\nby introducing the edge prior knowledge. We also construct a hybrid focal loss\nfunction (HFL) to alleviate the imbalanced distribution issue. In addition, we\nemploy the conditionally parameterized convolution (CondConv) to develop a\nnovel boundary refinement module (BRM), which can further refine the final\noutput edge maps. In the end, we propose a U-shape network named LUS-Net which\nis based on the SDMCM and BRM for crisp edge detection. We perform extensive\nexperiments on three standard benchmarks, and the experiment results illustrate\nthat our method can predict crisp and clean edge maps and achieves\nstate-of-the-art performance on the BSDS500 dataset (ODS=0.829), NYUD-V2\ndataset (ODS=0.768), and BIPED dataset (ODS=0.903).\n","authors":["Changsong Liu","Yimeng Fan","Mingyang Li","Wei Zhang","Yanyan Liu","Yuming Li","Wenlin Li","Liang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.05779v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17586v2","updated":"2025-01-30T10:37:04Z","published":"2025-01-29T11:41:07Z","title":"Boosting Weak Positives for Text Based Person Search","summary":"  Large vision-language models have revolutionized cross-modal object\nretrieval, but text-based person search (TBPS) remains a challenging task due\nto limited data and fine-grained nature of the task. Existing methods primarily\nfocus on aligning image-text pairs into a common representation space, often\ndisregarding the fact that real world positive image-text pairs share a varied\ndegree of similarity in between them. This leads models to prioritize easy\npairs, and in some recent approaches, challenging samples are discarded as\nnoise during training. In this work, we introduce a boosting technique that\ndynamically identifies and emphasizes these challenging samples during\ntraining. Our approach is motivated from classical boosting technique and\ndynamically updates the weights of the weak positives, wherein, the rank-1\nmatch does not share the identity of the query. The weight allows these\nmisranked pairs to contribute more towards the loss and the network has to pay\nmore attention towards such samples. Our method achieves improved performance\nacross four pedestrian datasets, demonstrating the effectiveness of our\nproposed module.\n","authors":["Akshay Modi","Ashhar Aziz","Nilanjana Chatterjee","A V Subramanyam"],"pdf_url":"https://arxiv.org/pdf/2501.17586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07783v3","updated":"2025-01-30T10:33:33Z","published":"2024-11-25T12:20:07Z","title":"Swin fMRI Transformer Predicts Early Neurodevelopmental Outcomes from\n  Neonatal fMRI","summary":"  Brain development in the first few months of human life is a critical phase\ncharacterized by rapid structural growth and functional organization.\nAccurately predicting developmental outcomes during this time is crucial for\nidentifying delays and enabling timely interventions. This study introduces the\nSwiFT (Swin 4D fMRI Transformer) model, designed to predict Bayley-III\ncomposite scores using neonatal fMRI from the Developing Human Connectome\nProject (dHCP). To enhance predictive accuracy, we apply dimensionality\nreduction via group independent component analysis (ICA) and pretrain SwiFT on\nlarge adult fMRI datasets to address the challenges of limited neonatal data.\nOur analysis shows that SwiFT significantly outperforms baseline models in\npredicting cognitive, motor, and language outcomes, leveraging both\nsingle-label and multi-label prediction strategies. The model's attention-based\narchitecture processes spatiotemporal data end-to-end, delivering superior\npredictive performance. Additionally, we use Integrated Gradients with\nSmoothgrad sQuare (IG-SQ) to interpret predictions, identifying neural spatial\nrepresentations linked to early cognitive and behavioral development. These\nfindings underscore the potential of Transformer models to advance\nneurodevelopmental research and clinical practice.\n","authors":["Patrick Styll","Dowon Kim","Jiook Cha"],"pdf_url":"https://arxiv.org/pdf/2412.07783v3.pdf","comment":"fMRI Transformer, Developing Human Connectome Project, Bayley Scales\n  of Infant Development, Personalized Therapy, XAI"},{"id":"http://arxiv.org/abs/2501.18246v1","updated":"2025-01-30T10:27:28Z","published":"2025-01-30T10:27:28Z","title":"Ground Awareness in Deep Learning for Large Outdoor Point Cloud\n  Segmentation","summary":"  This paper presents an analysis of utilizing elevation data to aid outdoor\npoint cloud semantic segmentation through existing machine-learning networks in\nremote sensing, specifically in urban, built-up areas. In dense outdoor point\nclouds, the receptive field of a machine learning model may be too small to\naccurately determine the surroundings and context of a point. By computing\nDigital Terrain Models (DTMs) from the point clouds, we extract the relative\nelevation feature, which is the vertical distance from the terrain to a point.\nRandLA-Net is employed for efficient semantic segmentation of large-scale point\nclouds. We assess its performance across three diverse outdoor datasets\ncaptured with varying sensor technologies and sensor locations. Integration of\nrelative elevation data leads to consistent performance improvements across all\nthree datasets, most notably in the Hessigheim dataset, with an increase of 3.7\npercentage points in average F1 score from 72.35% to 76.01%, by establishing\nlong-range dependencies between ground and objects. We also explore additional\nlocal features such as planarity, normal vectors, and 2D features, but their\nefficacy varied based on the characteristics of the point cloud. Ultimately,\nthis study underscores the important role of the non-local relative elevation\nfeature for semantic segmentation of point clouds in remote sensing\napplications.\n","authors":["Kevin Qiu","Dimitri Bulatov","Dorota Iwaszczuk"],"pdf_url":"https://arxiv.org/pdf/2501.18246v1.pdf","comment":"This paper has been accepted for presentation at the GRAPP 2025\n  conference"},{"id":"http://arxiv.org/abs/2501.17387v2","updated":"2025-01-30T09:56:55Z","published":"2025-01-29T02:39:57Z","title":"Assessing the Capability of YOLO- and Transformer-based Object Detectors\n  for Real-time Weed Detection","summary":"  Spot spraying represents an efficient and sustainable method for reducing the\namount of pesticides, particularly herbicides, used in agricultural fields. To\nachieve this, it is of utmost importance to reliably differentiate between\ncrops and weeds, and even between individual weed species in situ and under\nreal-time conditions. To assess suitability for real-time application,\ndifferent object detection models that are currently state-of-the-art are\ncompared. All available models of YOLOv8, YOLOv9, YOLOv10, and RT-DETR are\ntrained and evaluated with images from a real field situation. The images are\nseparated into two distinct datasets: In the initial data set, each species of\nplants is trained individually; in the subsequent dataset, a distinction is\nmade between monocotyledonous weeds, dicotyledonous weeds, and three chosen\ncrops. The results demonstrate that while all models perform equally well in\nthe metrics evaluated, the YOLOv9 models, particularly the YOLOv9s and YOLOv9e,\nstand out in terms of their strong recall scores (66.58 % and 72.36 %), as well\nas mAP50 (73.52 % and 79.86 %), and mAP50-95 (43.82 % and 47.00 %) in dataset\n2. However, the RT-DETR models, especially RT-DETR-l, excel in precision with\nreaching 82.44 \\% on dataset 1 and 81.46 % in dataset 2, making them\nparticularly suitable for scenarios where minimizing false positives is\ncritical. In particular, the smallest variants of the YOLO models (YOLOv8n,\nYOLOv9t, and YOLOv10n) achieve substantially faster inference times down to\n7.58 ms for dataset 2 on the NVIDIA GeForce RTX 4090 GPU for analyzing one\nframe, while maintaining competitive accuracy, highlighting their potential for\ndeployment in resource-constrained embedded computing devices as typically used\nin productive setups.\n","authors":["Alicia Allmendinger","Ahmet Oğuz Saltık","Gerassimos G. Peteinatos","Anthony Stein","Roland Gerhards"],"pdf_url":"https://arxiv.org/pdf/2501.17387v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18237v1","updated":"2025-01-30T09:52:15Z","published":"2025-01-30T09:52:15Z","title":"Arbitrary Data as Images: Fusion of Patient Data Across Modalities and\n  Irregular Intervals with Vision Transformers","summary":"  A patient undergoes multiple examinations in each hospital stay, where each\nprovides different facets of the health status. These assessments include\ntemporal data with varying sampling rates, discrete single-point measurements,\ntherapeutic interventions such as medication administration, and images. While\nphysicians are able to process and integrate diverse modalities intuitively,\nneural networks need specific modeling for each modality complicating the\ntraining procedure. We demonstrate that this complexity can be significantly\nreduced by visualizing all information as images along with unstructured text\nand subsequently training a conventional vision-text transformer. Our approach,\nVision Transformer for irregular sampled Multi-modal Measurements (ViTiMM), not\nonly simplifies data preprocessing and modeling but also outperforms current\nstate-of-the-art methods in predicting in-hospital mortality and phenotyping,\nas evaluated on 6,175 patients from the MIMIC-IV dataset. The modalities\ninclude patient's clinical measurements, medications, X-ray images, and\nelectrocardiography scans. We hope our work inspires advancements in\nmulti-modal medical AI by reducing the training complexity to (visual) prompt\nengineering, thus lowering entry barriers and enabling no-code solutions for\ntraining. The source code will be made publicly available.\n","authors":["Malte Tölle","Mohamad Scharaf","Samantha Fischer","Christoph Reich","Silav Zeid","Christoph Dieterich","Benjamin Meder","Norbert Frey","Philipp Wild","Sandy Engelhardt"],"pdf_url":"https://arxiv.org/pdf/2501.18237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18232v1","updated":"2025-01-30T09:45:23Z","published":"2025-01-30T09:45:23Z","title":"Free-T2M: Frequency Enhanced Text-to-Motion Diffusion Model With\n  Consistency Loss","summary":"  Rapid progress in text-to-motion generation has been largely driven by\ndiffusion models. However, existing methods focus solely on temporal modeling,\nthereby overlooking frequency-domain analysis. We identify two key phases in\nmotion denoising: the **semantic planning stage** and the **fine-grained\nimproving stage**. To address these phases effectively, we propose\n**Fre**quency **e**nhanced **t**ext-**to**-**m**otion diffusion model\n(**Free-T2M**), incorporating stage-specific consistency losses that enhance\nthe robustness of static features and improve fine-grained accuracy. Extensive\nexperiments demonstrate the effectiveness of our method. Specifically, on\nStableMoFusion, our method reduces the FID from **0.189** to **0.051**,\nestablishing a new SOTA performance within the diffusion architecture. These\nfindings highlight the importance of incorporating frequency-domain insights\ninto text-to-motion generation for more precise and robust results.\n","authors":["Wenshuo Chen","Haozhe Jia","Songning Lai","Keming Wu","Hongru Xiao","Lijie Hu","Yutao Yue"],"pdf_url":"https://arxiv.org/pdf/2501.18232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09552v2","updated":"2025-01-30T09:31:49Z","published":"2025-01-16T14:12:33Z","title":"Exploring AI-based System Design for Pixel-level Protected Health\n  Information Detection in Medical Images","summary":"  Purpose: This study aims to evaluate different setups of an AI-based solution\nto detect Protected Health Information (PHI) in medical images.\n  Materials and Methods: Text from eight PHI and eight non-PHI categories are\nsimulated and incorporated into a curated dataset comprising 1,000 medical\nimages across four modalities: CT, X-ray, bone scan, and MRI. The proposed PHI\ndetection pipeline comprises three key components: text localization,\nextraction, and analysis. Three vision and language models, YOLOv11, EasyOCR,\nand GPT-4o, are benchmarked in different setups corresponding to three key\ncomponents. The performance is evaluated with classification metrics, including\nprecision, recall, F1 score, and accuracy.\n  Results: All four setups demonstrate strong performance in detecting PHI\nimprints, with all metrics exceeding 0.9. The setup that utilizes YOLOv11 for\ntext localization and GPT-4o for text extraction and analysis achieves the\nhighest performance in PHI detection. However, this setup incurs the highest\ncost due to the increased number of generated tokens associated with GPT-4o\nmodel. Conversely, the setup using solely GPT-4o for the end-to-end pipeline\nexhibits the lowest performance but showcases the feasibility of multi-modal\nmodels in solving complex tasks.\n  Conclusion: For optimal text localization and extraction, it is recommended\nto fine-tune an object detection model and utilize built-in Optical Character\nRecognition (OCR) software. Large language models like GPT-4o can be\neffectively leveraged to reason about and semantically analyze the PHI content.\nAlthough the vision capability of GPT-4o is promising for reading image crops,\nit remains limited for end-to-end pipeline applications with whole images.\n","authors":["Tuan Truong","Ivo M. Baltruschat","Mark Klemens","Grit Werner","Matthias Lenga"],"pdf_url":"https://arxiv.org/pdf/2501.09552v2.pdf","comment":"In progress"},{"id":"http://arxiv.org/abs/2501.18219v1","updated":"2025-01-30T09:19:09Z","published":"2025-01-30T09:19:09Z","title":"Revisiting $Ψ$DONet: microlocally inspired filters for\n  incomplete-data tomographic reconstructions","summary":"  In this paper, we revisit a supervised learning approach based on unrolling,\nknown as $\\Psi$DONet, by providing a deeper microlocal interpretation for its\ntheoretical analysis, and extending its study to the case of sparse-angle\ntomography. Furthermore, we refine the implementation of the original\n$\\Psi$DONet considering special filters whose structure is specifically\ninspired by the streak artifact singularities characterizing tomographic\nreconstructions from incomplete data. This allows to considerably lower the\nnumber of (learnable) parameters while preserving (or even slightly improving)\nthe same quality for the reconstructions from limited-angle data and providing\na proof-of-concept for the case of sparse-angle tomographic data.\n","authors":["Tatiana A. Bubba","Luca Ratti","Andrea Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2501.18219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12950v2","updated":"2025-01-30T08:38:34Z","published":"2024-07-17T18:32:41Z","title":"Beyond the Veil of Similarity: Quantifying Semantic Continuity in\n  Explainable AI","summary":"  We introduce a novel metric for measuring semantic continuity in Explainable\nAI methods and machine learning models. We posit that for models to be truly\ninterpretable and trustworthy, similar inputs should yield similar\nexplanations, reflecting a consistent semantic understanding. By leveraging XAI\ntechniques, we assess semantic continuity in the task of image recognition. We\nconduct experiments to observe how incremental changes in input affect the\nexplanations provided by different XAI methods. Through this approach, we aim\nto evaluate the models' capability to generalize and abstract semantic concepts\naccurately and to evaluate different XAI methods in correctly capturing the\nmodel behaviour. This paper contributes to the broader discourse on AI\ninterpretability by proposing a quantitative measure for semantic continuity\nfor XAI methods, offering insights into the models' and explainers' internal\nreasoning processes, and promoting more reliable and transparent AI systems.\n","authors":["Qi Huang","Emanuele Mezzi","Osman Mutlu","Miltiadis Kofinas","Vidya Prasad","Shadnan Azwad Khan","Elena Ranguelova","Niki van Stein"],"pdf_url":"https://arxiv.org/pdf/2407.12950v2.pdf","comment":"25 pages, accepted at the world conference of explainable AI, 2024,\n  Malta"},{"id":"http://arxiv.org/abs/2501.18192v1","updated":"2025-01-30T08:13:01Z","published":"2025-01-30T08:13:01Z","title":"Machine Learning Fairness for Depression Detection using EEG Data","summary":"  This paper presents the very first attempt to evaluate machine learning\nfairness for depression detection using electroencephalogram (EEG) data. We\nconduct experiments using different deep learning architectures such as\nConvolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) networks,\nand Gated Recurrent Unit (GRU) networks across three EEG datasets: Mumtaz,\nMODMA and Rest. We employ five different bias mitigation strategies at the\npre-, in- and post-processing stages and evaluate their effectiveness. Our\nexperimental results show that bias exists in existing EEG datasets and\nalgorithms for depression detection, and different bias mitigation methods\naddress bias at different levels across different fairness measures.\n","authors":["Angus Man Ho Kwok","Jiaee Cheong","Sinan Kalkan","Hatice Gunes"],"pdf_url":"https://arxiv.org/pdf/2501.18192v1.pdf","comment":"To appear as part of the International Symposium on Biomedical\n  Imaging (ISBI) 2025 proceedings"},{"id":"http://arxiv.org/abs/2412.15188v3","updated":"2025-01-30T07:08:45Z","published":"2024-12-19T18:56:24Z","title":"LMFusion: Adapting Pretrained Language Models for Multimodal Generation","summary":"  We present LMFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLMFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LMFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLMFusion improves image understanding by 20% and image generation by 3.6% using\nonly 50% of the FLOPs while maintaining Llama-3's language capabilities. We\nalso demonstrate that this framework can adapt existing vision-language models\nwith multimodal generation ability. Overall, this framework not only leverages\nexisting computational investments in text-only LLMs but also enables the\nparallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.\n","authors":["Weijia Shi","Xiaochuang Han","Chunting Zhou","Weixin Liang","Xi Victoria Lin","Luke Zettlemoyer","Lili Yu"],"pdf_url":"https://arxiv.org/pdf/2412.15188v3.pdf","comment":"Name change: LlamaFusion to LMFusion"},{"id":"http://arxiv.org/abs/2412.19055v3","updated":"2025-01-30T07:00:34Z","published":"2024-12-26T04:45:05Z","title":"SpectralKD: A Unified Framework for Interpreting and Distilling Vision\n  Transformers via Spectral Analysis","summary":"  Knowledge Distillation (KD) has achieved widespread success in compressing\nlarge Vision Transformers (ViTs), but a unified theoretical framework for both\nViTs and KD is still lacking. In this paper, we propose SpectralKD, a novel\nunified analytical framework that offers deeper insights into ViTs and\noptimizes KD via spectral analysis. Our model-wise analysis reveals that CaiT\nconcentrates information in their first and last few layers, informing optimal\nlayer selection for KD. Surprisingly, our layer-wise analysis discovers that\nSwin Transformer and CaiT exhibit similar spectral encoding patterns despite\ntheir architectural differences, leading to feature map alignment guideline.\nBuilding on these insights, we propose a simple yet effective spectral\nalignment method for KD. Benefiting from the deeper understanding by above\nanalysis results, even such a simple strategy achieves state-of-the-art\nperformance on ImageNet-1K without introducing any trainable parameters,\nimproving DeiT-Tiny by $+5.2\\%$ and Swin-Tiny by $+1.4\\%$ in top-1 accuracy.\nFurthermore, our post-training analysis reveals that distilled students can\nreproduce spectral patterns similar to their teachers, opening a new area we\nterm ``distillation dynamics\". Code and experimental logs are available in\nhttps://github.com/thy960112/SpectralKD.\n","authors":["Huiyuan Tian","Bonan Xu","Shijian Li","Gang Pan"],"pdf_url":"https://arxiv.org/pdf/2412.19055v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18167v1","updated":"2025-01-30T06:31:04Z","published":"2025-01-30T06:31:04Z","title":"Scattering approach to diffusion quantifies axonal damage in brain\n  injury","summary":"  Early diagnosis and noninvasive monitoring of neurological disorders require\nsensitivity to elusive cellular-level alterations that occur much earlier than\nvolumetric changes observable with the millimeter-resolution of medical imaging\nmodalities. Morphological changes in axons, such as axonal varicosities or\nbeadings, are observed in neurological disorders, as well as in development and\naging. Here, we reveal the sensitivity of time-dependent diffusion MRI (dMRI)\nto axonal morphology at the micrometer scale. Scattering theory uncovers the\ntwo parameters that determine the diffusive dynamics of water in axons: the\naverage reciprocal cross-section and the variance of long-range cross-sectional\nfluctuations. This theoretical development allowed us to predict dMRI metrics\nsensitive to axonal alterations across tens of thousands of axons in seconds\nrather than months of simulations in a rat model of traumatic brain injury. Our\napproach bridges the gap between micrometers and millimeters in resolution,\noffering quantitative, objective biomarkers applicable to a broad spectrum of\nneurological disorders.\n","authors":["Ali Abdollahzadeh","Ricardo Coronado-Leija","Hong-Hsi Lee","Alejandra Sierra","Els Fieremans","Dmitry S. Novikov"],"pdf_url":"https://arxiv.org/pdf/2501.18167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18162v1","updated":"2025-01-30T06:10:23Z","published":"2025-01-30T06:10:23Z","title":"IROAM: Improving Roadside Monocular 3D Object Detection Learning from\n  Autonomous Vehicle Data Domain","summary":"  In autonomous driving, The perception capabilities of the ego-vehicle can be\nimproved with roadside sensors, which can provide a holistic view of the\nenvironment. However, existing monocular detection methods designed for vehicle\ncameras are not suitable for roadside cameras due to viewpoint domain gaps. To\nbridge this gap and Improve ROAdside Monocular 3D object detection, we propose\nIROAM, a semantic-geometry decoupled contrastive learning framework, which\ntakes vehicle-side and roadside data as input simultaneously. IROAM has two\nsignificant modules. In-Domain Query Interaction module utilizes a transformer\nto learn content and depth information for each domain and outputs object\nqueries. Cross-Domain Query Enhancement To learn better feature representations\nfrom two domains, Cross-Domain Query Enhancement decouples queries into\nsemantic and geometry parts and only the former is used for contrastive\nlearning. Experiments demonstrate the effectiveness of IROAM in improving\nroadside detector's performance. The results validate that IROAM has the\ncapabilities to learn cross-domain information.\n","authors":["Zhe Wang","Xiaoliang Huo","Siqi Fan","Jingjing Liu","Ya-Qin Zhang","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2501.18162v1.pdf","comment":"7 pages, 5 figures, ICRA2025"},{"id":"http://arxiv.org/abs/2501.18161v1","updated":"2025-01-30T06:06:07Z","published":"2025-01-30T06:06:07Z","title":"Using Computer Vision for Skin Disease Diagnosis in Bangladesh Enhancing\n  Interpretability and Transparency in Deep Learning Models for Skin Cancer\n  Classification","summary":"  With over 2 million new cases identified annually, skin cancer is the most\nprevalent type of cancer globally and the second most common in Bangladesh,\nfollowing breast cancer. Early detection and treatment are crucial for\nenhancing patient outcomes; however, Bangladesh faces a shortage of\ndermatologists and qualified medical professionals capable of diagnosing and\ntreating skin cancer. As a result, many cases are diagnosed only at advanced\nstages. Research indicates that deep learning algorithms can effectively\nclassify skin cancer images. However, these models typically lack\ninterpretability, making it challenging to understand their decision-making\nprocesses. This lack of clarity poses barriers to utilizing deep learning in\nimproving skin cancer detection and treatment. In this article, we present a\nmethod aimed at enhancing the interpretability of deep learning models for skin\ncancer classification in Bangladesh. Our technique employs a combination of\nsaliency maps and attention maps to visualize critical features influencing the\nmodel's diagnoses.\n","authors":["Rafiul Islam","Jihad Khan Dipu","Mehedi Hasan Tusar"],"pdf_url":"https://arxiv.org/pdf/2501.18161v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2501.18157v1","updated":"2025-01-30T05:46:30Z","published":"2025-01-30T05:46:30Z","title":"Efficient Audiovisual Speech Processing via MUTUD: Multimodal Training\n  and Unimodal Deployment","summary":"  Building reliable speech systems often requires combining multiple\nmodalities, like audio and visual cues. While such multimodal solutions\nfrequently lead to improvements in performance and may even be critical in\ncertain cases, they come with several constraints such as increased sensory\nrequirements, computational cost, and modality synchronization, to mention a\nfew. These challenges constrain the direct uses of these multimodal solutions\nin real-world applications. In this work, we develop approaches where the\nlearning happens with all available modalities but the deployment or inference\nis done with just one or reduced modalities. To do so, we propose a Multimodal\nTraining and Unimodal Deployment (MUTUD) framework which includes a Temporally\nAligned Modality feature Estimation (TAME) module that can estimate information\nfrom missing modality using modalities present during inference. This\ninnovative approach facilitates the integration of information across different\nmodalities, enhancing the overall inference process by leveraging the strengths\nof each modality to compensate for the absence of certain modalities during\ninference. We apply MUTUD to various audiovisual speech tasks and show that it\ncan reduce the performance gap between the multimodal and corresponding\nunimodal models to a considerable extent. MUTUD can achieve this while reducing\nthe model size and compute compared to multimodal models, in some cases by\nalmost 80%.\n","authors":["Joanna Hong","Sanjeel Parekh","Honglie Chen","Jacob Donley","Ke Tan","Buye Xu","Anurag Kumar"],"pdf_url":"https://arxiv.org/pdf/2501.18157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17636v2","updated":"2025-01-30T05:18:21Z","published":"2025-01-29T13:12:06Z","title":"Efficient Interactive 3D Multi-Object Removal","summary":"  Object removal is of great significance to 3D scene understanding, essential\nfor applications in content filtering and scene editing. Current mainstream\nmethods primarily focus on removing individual objects, with a few methods\ndedicated to eliminating an entire area or all objects of a certain category.\nThey however confront the challenge of insufficient granularity and flexibility\nfor real-world applications, where users demand tailored excision and\npreservation of objects within defined zones. In addition, most of the current\nmethods require kinds of priors when addressing multi-view inpainting, which is\ntime-consuming. To address these limitations, we propose an efficient and\nuser-friendly pipeline for 3D multi-object removal, enabling users to flexibly\nselect areas and define objects for removal or preservation. Concretely, to\nensure object consistency and correspondence across multiple views, we propose\na novel mask matching and refinement module, which integrates homography-based\nwarping with high-confidence anchor points for segmentation. By leveraging the\nIoU joint shape context distance loss, we enhance the accuracy of warped masks\nand improve subsequent inpainting processes. Considering the current immaturity\nof 3D multi-object removal, we provide a new evaluation dataset to bridge the\ndevelopmental void. Experimental results demonstrate that our method\nsignificantly reduces computational costs, achieving processing speeds more\nthan 80% faster than state-of-the-art methods while maintaining equivalent or\nhigher reconstruction quality.\n","authors":["Jingcheng Ni","Weiguang Zhao","Daniel Wang","Ziyao Zeng","Chenyu You","Alex Wong","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2501.17636v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14489v2","updated":"2025-01-30T05:09:17Z","published":"2024-12-19T03:26:51Z","title":"QADM-Net: Multi-Level Quality-Adaptive Dynamic Network for Reliable\n  Multimodal Classification","summary":"  Multimodal machine learning has achieved remarkable progress in many\nscenarios, but its reliability is undermined by varying sample quality. In this\npaper, we find that current multimodal classification methods lack dynamic\nnetworks for sample-specific depth and parameters to achieve reliable\ninference. To this end, a novel framework for multimodal reliable\nclassification termed Multi-Level Quality-Adaptive Dynamic Multimodal Network\n(QADM-Net) is proposed. QADM-Net first adopts a novel approach based on\nnoise-free prototypes and a classifier-free design to reliably estimate the\nquality of each sample at both modality and feature levels. It then achieves\nsample-specific network depth via the \\textbf{\\textit{Global Confidence\nNormalized Depth (GCND)}} mechanism. By normalizing depth across modalities and\nsamples, \\textit{\\textbf{GCND}} effectively mitigates the impact of challenging\nmodality inputs on dynamic depth reliability. Furthermore, QADM-Net provides\nsample-adaptive network parameters via the \\textbf{\\textit{Layer-wise Greedy\nParameter (LGP)}} mechanism driven by feature-level quality. The cross-modality\nlayer-wise greedy strategy in \\textbf{\\textit{LGP}} designs a reliable\nparameter prediction paradigm for multimodal networks with variable depths for\nthe first time. Experiments conducted on four datasets demonstrate that\nQADM-Net significantly outperforms state-of-the-art methods in classification\nperformance and reliability, exhibiting strong adaptability to data with\ndiverse quality.\n","authors":["Shu Shen","Tong Zhang","C. L. Philip Chen"],"pdf_url":"https://arxiv.org/pdf/2412.14489v2.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.01097v3","updated":"2025-01-30T04:51:26Z","published":"2025-01-02T06:46:13Z","title":"EliGen: Entity-Level Controlled Image Generation with Regional Attention","summary":"  Recent advancements in diffusion models have significantly advanced\ntext-to-image generation, yet global text prompts alone remain insufficient for\nachieving fine-grained control over individual entities within an image. To\naddress this limitation, we present EliGen, a novel framework for Entity-level\ncontrolled image Generation. Firstly, we put forward regional attention, a\nmechanism for diffusion transformers that requires no additional parameters,\nseamlessly integrating entity prompts and arbitrary-shaped spatial masks. By\ncontributing a high-quality dataset with fine-grained spatial and semantic\nentity-level annotations, we train EliGen to achieve robust and accurate\nentity-level manipulation, surpassing existing methods in both spatial\nprecision and image quality. Additionally, we propose an inpainting fusion\npipeline, extending its capabilities to multi-entity image inpainting tasks. We\nfurther demonstrate its flexibility by integrating it with other open-source\nmodels such as IP-Adapter, In-Context LoRA and MLLM, unlocking new creative\npossibilities. The source code, model, and dataset are published at\nhttps://github.com/modelscope/DiffSynth-Studio.git.\n","authors":["Hong Zhang","Zhongjie Duan","Xingjun Wang","Yingda Chen","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.01097v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18124v1","updated":"2025-01-30T03:58:41Z","published":"2025-01-30T03:58:41Z","title":"REMOTE: Real-time Ego-motion Tracking for Various Endoscopes via\n  Multimodal Visual Feature Learning","summary":"  Real-time ego-motion tracking for endoscope is a significant task for\nefficient navigation and robotic automation of endoscopy. In this paper, a\nnovel framework is proposed to perform real-time ego-motion tracking for\nendoscope. Firstly, a multi-modal visual feature learning network is proposed\nto perform relative pose prediction, in which the motion feature from the\noptical flow, the scene features and the joint feature from two adjacent\nobservations are all extracted for prediction. Due to more correlation\ninformation in the channel dimension of the concatenated image, a novel feature\nextractor is designed based on an attention mechanism to integrate\nmulti-dimensional information from the concatenation of two continuous frames.\nTo extract more complete feature representation from the fused features, a\nnovel pose decoder is proposed to predict the pose transformation from the\nconcatenated feature map at the end of the framework. At last, the absolute\npose of endoscope is calculated based on relative poses. The experiment is\nconducted on three datasets of various endoscopic scenes and the results\ndemonstrate that the proposed method outperforms state-of-the-art methods.\nBesides, the inference speed of the proposed method is over 30 frames per\nsecond, which meets the real-time requirement. The project page is here:\n\\href{https://remote-bmxs.netlify.app}{remote-bmxs.netlify.app}\n","authors":["Liangjing Shao","Benshuang Chen","Shuting Zhao","Xinrong Chen"],"pdf_url":"https://arxiv.org/pdf/2501.18124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13301v2","updated":"2025-01-30T03:40:15Z","published":"2024-06-19T07:42:02Z","title":"ARDuP: Active Region Video Diffusion for Universal Policies","summary":"  Sequential decision-making can be formulated as a text-conditioned video\ngeneration problem, where a video planner, guided by a text-defined goal,\ngenerates future frames visualizing planned actions, from which control actions\nare subsequently derived. In this work, we introduce Active Region Video\nDiffusion for Universal Policies (ARDuP), a novel framework for video-based\npolicy learning that emphasizes the generation of active regions, i.e.\npotential interaction areas, enhancing the conditional policy's focus on\ninteractive areas critical for task execution. This innovative framework\nintegrates active region conditioning with latent diffusion models for video\nplanning and employs latent representations for direct action decoding during\ninverse dynamic modeling. By utilizing motion cues in videos for automatic\nactive region discovery, our method eliminates the need for manual annotations\nof active regions. We validate ARDuP's efficacy via extensive experiments on\nsimulator CLIPort and the real-world dataset BridgeData v2, achieving notable\nimprovements in success rates and generating convincingly realistic video\nplans.\n","authors":["Shuaiyi Huang","Mara Levy","Zhenyu Jiang","Anima Anandkumar","Yuke Zhu","Linxi Fan","De-An Huang","Abhinav Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2406.13301v2.pdf","comment":"Accepted by IROS 2024 (Oral)"},{"id":"http://arxiv.org/abs/2501.18116v1","updated":"2025-01-30T03:35:03Z","published":"2025-01-30T03:35:03Z","title":"DeepFRC: An End-to-End Deep Learning Model for Functional Registration\n  and Classification","summary":"  Functional data analysis (FDA) is essential for analyzing continuous,\nhigh-dimensional data, yet existing methods often decouple functional\nregistration and classification, limiting their efficiency and performance. We\npresent DeepFRC, an end-to-end deep learning framework that unifies these tasks\nwithin a single model. Our approach incorporates an alignment module that\nlearns time warping functions via elastic function registration and a learnable\nbasis representation module for dimensionality reduction on aligned data. This\nintegration enhances both alignment accuracy and predictive performance.\nTheoretical analysis establishes that DeepFRC achieves low misalignment and\ngeneralization error, while simulations elucidate the progression of\nregistration, reconstruction, and classification during training. Experiments\non real-world datasets demonstrate that DeepFRC consistently outperforms\nstate-of-the-art methods, particularly in addressing complex registration\nchallenges. Code is available at: https://github.com/Drivergo-93589/DeepFRC.\n","authors":["Siyuan Jiang","Yihan Hu","Wenjie Li","Pengcheng Zeng"],"pdf_url":"https://arxiv.org/pdf/2501.18116v1.pdf","comment":"27 pages, 8 figures"},{"id":"http://arxiv.org/abs/2501.18110v1","updated":"2025-01-30T03:29:42Z","published":"2025-01-30T03:29:42Z","title":"Lifelong 3D Mapping Framework for Hand-held & Robot-mounted LiDAR\n  Mapping Systems","summary":"  We propose a lifelong 3D mapping framework that is modular, cloud-native by\ndesign and more importantly, works for both hand-held and robot-mounted 3D\nLiDAR mapping systems. Our proposed framework comprises of dynamic point\nremoval, multi-session map alignment, map change detection and map version\ncontrol. First, our sensor-setup agnostic dynamic point removal algorithm works\nseamlessly with both hand-held and robot-mounted setups to produce clean static\n3D maps. Second, the multi-session map alignment aligns these clean static maps\nautomatically, without manual parameter fine-tuning, into a single reference\nframe, using a two stage approach based on feature descriptor matching and fine\nregistration. Third, our novel map change detection identifies positive and\nnegative changes between two aligned maps. Finally, the map version control\nmaintains a single base map that represents the current state of the\nenvironment, and stores the detected positive and negative changes, and\nboundary information. Our unique map version control system can reconstruct any\nof the previous clean session maps and allows users to query changes between\nany two random mapping sessions, all without storing any input raw session\nmaps, making it very unique. Extensive experiments are performed using\nhand-held commercial LiDAR mapping devices and open-source robot-mounted LiDAR\nSLAM algorithms to evaluate each module and the whole 3D lifelong mapping\nframework.\n","authors":["Liudi Yang","Sai Manoj Prakhya","Senhua Zhu","Ziyuan Liu"],"pdf_url":"https://arxiv.org/pdf/2501.18110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18109v1","updated":"2025-01-30T03:23:10Z","published":"2025-01-30T03:23:10Z","title":"Influence of High-Performance Image-to-Image Translation Networks on\n  Clinical Visual Assessment and Outcome Prediction: Utilizing Ultrasound to\n  MRI Translation in Prostate Cancer","summary":"  Purpose: This study examines the core traits of image-to-image translation\n(I2I) networks, focusing on their effectiveness and adaptability in everyday\nclinical settings. Methods: We have analyzed data from 794 patients diagnosed\nwith prostate cancer (PCa), using ten prominent 2D/3D I2I networks to convert\nultrasound (US) images into MRI scans. We also introduced a new analysis of\nRadiomic features (RF) via the Spearman correlation coefficient to explore\nwhether networks with high performance (SSIM>85%) could detect subtle RFs. Our\nstudy further examined synthetic images by 7 invited physicians. As a final\nevaluation study, we have investigated the improvement that are achieved using\nthe synthetic MRI data on two traditional machine learning and one deep\nlearning method. Results: In quantitative assessment, 2D-Pix2Pix network\nsubstantially outperformed the other 7 networks, with an average SSIM~0.855.\nThe RF analysis revealed that 76 out of 186 RFs were identified using the\n2D-Pix2Pix algorithm alone, although half of the RFs were lost during the\ntranslation process. A detailed qualitative review by 7 medical doctors noted a\ndeficiency in low-level feature recognition in I2I tasks. Furthermore, the\nstudy found that synthesized image-based classification outperformed US\nimage-based classification with an average accuracy and AUC~0.93. Conclusion:\nThis study showed that while 2D-Pix2Pix outperformed cutting-edge networks in\nlow-level feature discovery and overall error and similarity metrics, it still\nrequires improvement in low-level feature performance, as highlighted by Group\n3. Further, the study found using synthetic image-based classification\noutperformed original US image-based methods.\n","authors":["Mohammad R. Salmanpour","Amin Mousavi","Yixi Xu","William B Weeks","Ilker Hacihaliloglu"],"pdf_url":"https://arxiv.org/pdf/2501.18109v1.pdf","comment":"9 pages, 4 figures and 1 table"},{"id":"http://arxiv.org/abs/2501.18098v1","updated":"2025-01-30T02:21:07Z","published":"2025-01-30T02:21:07Z","title":"Disentangling Safe and Unsafe Corruptions via Anisotropy and Locality","summary":"  State-of-the-art machine learning systems are vulnerable to small\nperturbations to their input, where ``small'' is defined according to a threat\nmodel that assigns a positive threat to each perturbation. Most prior works\ndefine a task-agnostic, isotropic, and global threat, like the $\\ell_p$ norm,\nwhere the magnitude of the perturbation fully determines the degree of the\nthreat and neither the direction of the attack nor its position in space\nmatter. However, common corruptions in computer vision, such as blur,\ncompression, or occlusions, are not well captured by such threat models. This\npaper proposes a novel threat model called \\texttt{Projected Displacement} (PD)\nto study robustness beyond existing isotropic and global threat models. The\nproposed threat model measures the threat of a perturbation via its alignment\nwith \\textit{unsafe directions}, defined as directions in the input space along\nwhich a perturbation of sufficient magnitude changes the ground truth class\nlabel. Unsafe directions are identified locally for each input based on\nobserved training data. In this way, the PD threat model exhibits anisotropy\nand locality. Experiments on Imagenet-1k data indicate that, for any input, the\nset of perturbations with small PD threat includes \\textit{safe} perturbations\nof large $\\ell_p$ norm that preserve the true label, such as noise, blur and\ncompression, while simultaneously excluding \\textit{unsafe} perturbations that\nalter the true label. Unlike perceptual threat models based on embeddings of\nlarge-vision models, the PD threat model can be readily computed for arbitrary\nclassification tasks without pre-training or finetuning. Further additional\ntask annotation such as sensitivity to image regions or concept hierarchies can\nbe easily integrated into the assessment of threat and thus the PD threat model\npresents practitioners with a flexible, task-driven threat specification.\n","authors":["Ramchandran Muthukumar","Ambar Pal","Jeremias Sulam","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2501.18098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18096v1","updated":"2025-01-30T02:16:35Z","published":"2025-01-30T02:16:35Z","title":"LLMs can see and hear without any training","summary":"  We present MILS: Multimodal Iterative LLM Solver, a surprisingly simple,\ntraining-free approach, to imbue multimodal capabilities into your favorite\nLLM. Leveraging their innate ability to perform multi-step reasoning, MILS\nprompts the LLM to generate candidate outputs, each of which are scored and fed\nback iteratively, eventually generating a solution to the task. This enables\nvarious applications that typically require training specialized models on\ntask-specific data. In particular, we establish a new state-of-the-art on\nemergent zero-shot image, video and audio captioning. MILS seamlessly applies\nto media generation as well, discovering prompt rewrites to improve\ntext-to-image generation, and even edit prompts for style transfer! Finally,\nbeing a gradient-free optimization approach, MILS can invert multimodal\nembeddings into text, enabling applications like cross-modal arithmetic.\n","authors":["Kumar Ashutosh","Yossi Gandelsman","Xinlei Chen","Ishan Misra","Rohit Girdhar"],"pdf_url":"https://arxiv.org/pdf/2501.18096v1.pdf","comment":"Code: https://github.com/facebookresearch/MILS"},{"id":"http://arxiv.org/abs/2501.17688v2","updated":"2025-01-30T02:05:11Z","published":"2025-01-29T14:56:27Z","title":"ContourFormer:Real-Time Contour-Based End-to-End Instance Segmentation\n  Transformer","summary":"  This paper presents Contourformer, a real-time contour-based instance\nsegmentation algorithm. The method is fully based on the DETR paradigm and\nachieves end-to-end inference through iterative and progressive mechanisms to\noptimize contours. To improve efficiency and accuracy, we develop two novel\ntechniques: sub-contour decoupling mechanisms and contour fine-grained\ndistribution refinement. In the sub-contour decoupling mechanism, we propose a\ndeformable attention-based module that adaptively selects sampling regions\nbased on the current predicted contour, enabling more effective capturing of\nobject boundary information. Additionally, we design a multi-stage optimization\nprocess to enhance segmentation precision by progressively refining\nsub-contours. The contour fine-grained distribution refinement technique aims\nto further improve the ability to express fine details of contours. These\ninnovations enable Contourformer to achieve stable and precise segmentation for\neach instance while maintaining real-time performance. Extensive experiments\ndemonstrate the superior performance of Contourformer on multiple benchmark\ndatasets, including SBD, COCO, and KINS. We conduct comprehensive evaluations\nand comparisons with existing state-of-the-art methods, showing significant\nimprovements in both accuracy and inference speed. This work provides a new\nsolution for contour-based instance segmentation tasks and lays a foundation\nfor future research, with the potential to become a strong baseline method in\nthis field.\n","authors":["Weiwei Yao","Chen Li","Minjun Xiong","Wenbo Dong","Hao Chen","Xiong Xiao"],"pdf_url":"https://arxiv.org/pdf/2501.17688v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15529v2","updated":"2025-01-30T01:18:59Z","published":"2024-09-23T20:27:10Z","title":"VaLID: Verification as Late Integration of Detections for LiDAR-Camera\n  Fusion","summary":"  Vehicle object detection benefits from both LiDAR and camera data, with LiDAR\noffering superior performance in many scenarios. Fusion of these modalities\nfurther enhances accuracy, but existing methods often introduce complexity or\ndataset-specific dependencies. In our study, we propose a model-adaptive\nlate-fusion method, VaLID, which validates whether each predicted bounding box\nis acceptable or not. Our method verifies the higher-performing, yet overly\noptimistic LiDAR model detections using camera detections that are obtained\nfrom either specially trained, general, or open-vocabulary models. VaLID uses a\nsimple multi-layer perceptron trained with a high recall bias to reduce the\nfalse predictions made by the LiDAR detector, while still preserving the true\nones. Evaluating with multiple combinations of LiDAR and camera detectors on\nthe KITTI dataset, we reduce false positives by an average of 63.9%, thus\noutperforming the individual detectors on 3D average precision (3DAP). Our\napproach is model-adaptive and demonstrates state-of-the-art competitive\nperformance even when using generic camera detectors that were not trained\nspecifically for this dataset.\n","authors":["Vanshika Vats","Marzia Binta Nizam","James Davis"],"pdf_url":"https://arxiv.org/pdf/2409.15529v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06259v2","updated":"2025-01-30T00:31:45Z","published":"2025-01-09T11:08:55Z","title":"Quantum Down Sampling Filter for Variational Auto-encoder","summary":"  Variational Autoencoders (VAEs) are essential tools in generative modeling\nand image reconstruction, with their performance heavily influenced by the\nencoder-decoder architecture. This study aims to improve the quality of\nreconstructed images by enhancing their resolution and preserving finer\ndetails, particularly when working with low-resolution inputs (16x16 pixels),\nwhere traditional VAEs often yield blurred or in-accurate results. To address\nthis, we propose a hybrid model that combines quantum computing techniques in\nthe VAE encoder with convolutional neural networks (CNNs) in the decoder. By\nupscaling the resolution from 16x16 to 32x32 during the encoding process, our\napproach evaluates how the model reconstructs images with enhanced resolution\nwhile maintaining key features and structures. This method tests the model's\nrobustness in handling image reconstruction and its ability to preserve\nessential details despite training on lower-resolution data. We evaluate our\nproposed down sampling filter for Quantum VAE (Q-VAE) on the MNIST and USPS\ndatasets and compare it with classical VAEs and a variant called Classical\nDirect Passing VAE (CDP-VAE), which uses windowing pooling filters in the\nencoding process. Performance is assessed using metrics such as the Frechet\nInception Distance (FID) and Mean Squared Error (MSE), which measure the\nfidelity of reconstructed images. Our results demonstrate that the Q-VAE\nconsistently outperforms both the Classical VAE and CDP-VAE, achieving\nsignificantly lower FID and MSE scores. Additionally, CDP-VAE yields better\nperformance than C-VAE. These findings highlight the potential of\nquantum-enhanced VAEs to improve image reconstruction quality by enhancing\nresolution and preserving essential features, offering a promising direction\nfor future applications in computer vision and synthetic data generation.\n","authors":["Farina Riaz","Fakhar Zaman","Hajime Suzuki","Sharif Abuadbba","David Nguyen"],"pdf_url":"https://arxiv.org/pdf/2501.06259v2.pdf","comment":"19 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.14283v2","updated":"2025-01-30T00:05:46Z","published":"2024-12-18T19:24:15Z","title":"PixelMan: Consistent Object Editing with Diffusion Models via Pixel\n  Manipulation and Generation","summary":"  Recent research explores the potential of Diffusion Models (DMs) for\nconsistent object editing, which aims to modify object position, size, and\ncomposition, etc., while preserving the consistency of objects and background\nwithout changing their texture and attributes. Current inference-time methods\noften rely on DDIM inversion, which inherently compromises efficiency and the\nachievable consistency of edited images. Recent methods also utilize energy\nguidance which iteratively updates the predicted noise and can drive the\nlatents away from the original image, resulting in distortions. In this paper,\nwe propose PixelMan, an inversion-free and training-free method for achieving\nconsistent object editing via Pixel Manipulation and generation, where we\ndirectly create a duplicate copy of the source object at target location in the\npixel space, and introduce an efficient sampling approach to iteratively\nharmonize the manipulated object into the target location and inpaint its\noriginal location, while ensuring image consistency by anchoring the edited\nimage to be generated to the pixel-manipulated image as well as by introducing\nvarious consistency-preserving optimization techniques during inference.\nExperimental evaluations based on benchmark datasets as well as extensive\nvisual comparisons show that in as few as 16 inference steps, PixelMan\noutperforms a range of state-of-the-art training-based and training-free\nmethods (usually requiring 50 steps) on multiple consistent object editing\ntasks.\n","authors":["Liyao Jiang","Negar Hassanpour","Mohammad Salameh","Mohammadreza Samadi","Jiao He","Fengyu Sun","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2412.14283v2.pdf","comment":"AAAI 2025; version includes supplementary material; 27 Pages, 15\n  Figures, 6 Tables"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2501.18539v1","updated":"2025-01-30T18:07:19Z","published":"2025-01-30T18:07:19Z","title":"Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented\n  LLM-based Retrieval Method","summary":"  Real-world open-domain questions can be complicated, particularly when\nanswering them involves information from multiple information sources. LLMs\nhave demonstrated impressive performance in decomposing complex tasks into\nsimpler steps, and previous work has used it for better retrieval in support of\ncomplex questions. However, LLM's decomposition of questions is unaware of what\ndata is available and how data is organized, often leading to a sub-optimal\nretrieval performance. Recent effort in agentic RAG proposes to perform\nretrieval in an iterative fashion, where a followup query is derived as an\naction based on previous rounds of retrieval. While this provides one way of\ninteracting with the data collection, agentic RAG's exploration of data is\ninefficient because successive queries depend on previous results rather than\nbeing guided by the organization of available data in the collection. To\naddress this problem, we propose an LLM-based retrieval method -- ARM, that\naims to better align the question with the organization of the data collection\nby exploring relationships among data objects beyond matching the utterance of\nthe query, thus leading to a retrieve-all-at-once solution for complex queries.\nWe evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperforms\nstandard RAG with query decomposition by up to 5.2 pt in execution accuracy and\nagentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and\n19.3 pt higher F1 match scores compared to these approaches.\n","authors":["Peter Baile Chen","Yi Zhang","Michael Cafarella","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2501.18539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18536v1","updated":"2025-01-30T18:02:15Z","published":"2025-01-30T18:02:15Z","title":"Illusions of Relevance: Using Content Injection Attacks to Deceive\n  Retrievers, Rerankers, and LLM Judges","summary":"  Consider a scenario in which a user searches for information, only to\nencounter texts flooded with misleading or non-relevant content. This scenario\nexemplifies a simple yet potent vulnerability in neural Information Retrieval\n(IR) pipelines: content injection attacks. We find that embedding models for\nretrieval, rerankers, and large language model (LLM) relevance judges are\nvulnerable to these attacks, in which adversaries insert misleading text into\npassages to manipulate model judgements. We identify two primary threats: (1)\ninserting unrelated or harmful content within passages that still appear\ndeceptively \"relevant\", and (2) inserting entire queries or key query terms\ninto passages to boost their perceived relevance. While the second tactic has\nbeen explored in prior research, we present, to our knowledge, the first\nempirical analysis of the first threat, demonstrating how state-of-the-art\nmodels can be easily misled. Our study systematically examines the factors that\ninfluence an attack's success, such as the placement of injected content and\nthe balance between relevant and non-relevant material. Additionally, we\nexplore various defense strategies, including adversarial passage classifiers,\nretriever fine-tuning to discount manipulated content, and prompting LLM judges\nto adopt a more cautious approach. However, we find that these countermeasures\noften involve trade-offs, sacrificing effectiveness for attack robustness and\nsometimes penalizing legitimate documents in the process. Our findings\nhighlight the need for stronger defenses against these evolving adversarial\nstrategies to maintain the trustworthiness of IR systems. We release our code\nand scripts to facilitate further research.\n","authors":["Manveer Singh Tamber","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2501.18536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18365v1","updated":"2025-01-30T14:15:09Z","published":"2025-01-30T14:15:09Z","title":"RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against\n  Retrieval Defects","summary":"  Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge retrieved from a knowledge base. However, its\neffectiveness is fundamentally constrained by the reliability of both the\nretriever and the knowledge base. In real-world scenarios, imperfections in\nthese components often lead to the retrieval of noisy, irrelevant, or\nmisleading counterfactual information, ultimately undermining the\ntrustworthiness of RAG systems. To address this challenge, we propose Robust\nFine-Tuning (RbFT), a method designed to enhance the resilience of LLMs against\nretrieval defects through two targeted fine-tuning tasks. Experimental results\ndemonstrate that RbFT significantly improves the robustness of RAG systems\nacross diverse retrieval conditions, surpassing existing methods while\nmaintaining high inference efficiency and compatibility with other robustness\ntechniques.\n","authors":["Yiteng Tu","Weihang Su","Yujia Zhou","Yiqun Liu","Qingyao Ai"],"pdf_url":"https://arxiv.org/pdf/2501.18365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18292v1","updated":"2025-01-30T12:08:00Z","published":"2025-01-30T12:08:00Z","title":"Citation Recommendation based on Argumentative Zoning of User Queries","summary":"  Citation recommendation aims to locate the important papers for scholars to\ncite. When writing the citing sentences, the authors usually hold different\nciting intents, which are referred to citation function in citation analysis.\nSince argumentative zoning is to identify the argumentative and rhetorical\nstructure in scientific literature, we want to use this information to improve\nthe citation recommendation task. In this paper, a multi-task learning model is\nbuilt for citation recommendation and argumentative zoning classification. We\nalso generated an annotated corpus of the data from PubMed Central based on a\nnew argumentative zoning schema. The experimental results show that, by\nconsidering the argumentative information in the citing sentence, citation\nrecommendation model will get better performance.\n","authors":["Shutian Ma","Chengzhi Zhang","Heng Zhang","Zheng Gao"],"pdf_url":"https://arxiv.org/pdf/2501.18292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18265v1","updated":"2025-01-30T11:04:14Z","published":"2025-01-30T11:04:14Z","title":"Collecting Cost-Effective, High-Quality Truthfulness Assessments with\n  LLM Summarized Evidence","summary":"  With the degradation of guardrails against mis- and disinformation online, it\nis more critical than ever to be able to effectively combat it. In this paper,\nwe explore the efficiency and effectiveness of using crowd-sourced truthfulness\nassessments based on condensed, large language model (LLM) generated summaries\nof online sources. We compare the use of generated summaries to the use of\noriginal web pages in an A/B testing setting, where we employ a large and\ndiverse pool of crowd-workers to perform the truthfulness assessment. We\nevaluate the quality of assessments, the efficiency with which assessments are\nperformed, and the behavior and engagement of participants. Our results\ndemonstrate that the Summary modality, which relies on summarized evidence,\noffers no significant change in assessment accuracy over the Standard modality,\nwhile significantly increasing the speed with which assessments are performed.\nWorkers using summarized evidence produce a significantly higher number of\nassessments in the same time frame, reducing the cost needed to acquire\ntruthfulness assessments. Additionally, the Summary modality maximizes both the\ninter-annotator agreements as well as the reliance on and perceived usefulness\nof evidence, demonstrating the utility of summarized evidence without\nsacrificing the quality of assessments.\n","authors":["Kevin Roitero","Dustin Wright","Michael Soprano","Isabelle Augenstein","Stefano Mizzaro"],"pdf_url":"https://arxiv.org/pdf/2501.18265v1.pdf","comment":"18 pages; 7 figures; 5 tables"},{"id":"http://arxiv.org/abs/2501.18216v1","updated":"2025-01-30T09:17:04Z","published":"2025-01-30T09:17:04Z","title":"Behavior Modeling Space Reconstruction for E-Commerce Search","summary":"  Delivering superior search services is crucial for enhancing customer\nexperience and driving revenue growth. Conventionally, search systems model\nuser behaviors by combining user preference and query item relevance\nstatically, often through a fixed logical 'and' relationship. This paper\nreexamines existing approaches through a unified lens using both causal graphs\nand Venn diagrams, uncovering two prevalent yet significant issues: entangled\npreference and relevance effects, and a collapsed modeling space. To surmount\nthese challenges, our research introduces a novel framework, DRP, which\nenhances search accuracy through two components to reconstruct the behavior\nmodeling space. Specifically, we implement preference editing to proactively\nremove the relevance effect from preference predictions, yielding untainted\nuser preferences. Additionally, we employ adaptive fusion, which dynamically\nadjusts fusion criteria to align with the varying patterns of relevance and\npreference, facilitating more nuanced and tailored behavior predictions within\nthe reconstructed modeling space. Empirical validation on two public datasets\nand a proprietary search dataset underscores the superiority of our proposed\nmethodology, demonstrating marked improvements in performance over existing\napproaches.\n","authors":["Yejing Wang","Chi Zhang","Xiangyu Zhao","Qidong Liu","Maolin Wang","Xuewei Tao","Zitao Liu","Xing Shi","Xudong Yang","Ling Zhong","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2501.18216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18210v1","updated":"2025-01-30T08:55:32Z","published":"2025-01-30T08:55:32Z","title":"Hashtag Re-Appropriation for Audience Control on Recommendation-Driven\n  Social Media Xiaohongshu (rednote)","summary":"  Algorithms have played a central role in personalized recommendations on\nsocial media. However, they also present significant obstacles for content\ncreators trying to predict and manage their audience reach. This issue is\nparticularly challenging for marginalized groups seeking to maintain safe\nspaces. Our study explores how women on Xiaohongshu (rednote), a\nrecommendation-driven social platform, proactively re-appropriate hashtags\n(e.g., #Baby Supplemental Food) by using them in posts unrelated to their\nliteral meaning. The hashtags were strategically chosen from topics that would\nbe uninteresting to the male audience they wanted to block. Through a\nmixed-methods approach, we analyzed the practice of hashtag re-appropriation\nbased on 5,800 collected posts and interviewed 24 active users from diverse\nbackgrounds to uncover users' motivations and reactions towards the\nre-appropriation. This practice highlights how users can reclaim agency over\ncontent distribution on recommendation-driven platforms, offering insights into\nself-governance within algorithmic-centered power structures.\n","authors":["Ruyuan Wan","Lingbo Tong","Tiffany Knearem","Toby Jia-Jun Li","Ting-Hao 'Kenneth' Huang","Qunfang Wu"],"pdf_url":"https://arxiv.org/pdf/2501.18210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18177v1","updated":"2025-01-30T07:14:50Z","published":"2025-01-30T07:14:50Z","title":"Investigating Tax Evasion Emergence Using Dual Large Language Model and\n  Deep Reinforcement Learning Powered Agent-based Simulation","summary":"  Tax evasion, usually the largest component of an informal economy, is a\npersistent challenge over history with significant socio-economic implications.\nMany socio-economic studies investigate its dynamics, including influencing\nfactors, the role and influence of taxation policies, and the prediction of the\ntax evasion volume over time. These studies assumed such behavior is given, as\nobserved in the real world, neglecting the \"big bang\" of such activity in a\npopulation. To this end, computational economy studies adopted developments in\ncomputer simulations, in general, and recent innovations in artificial\nintelligence (AI), in particular, to simulate and study informal economy\nappearance in various socio-economic settings. This study presents a novel\ncomputational framework to examine the dynamics of tax evasion and the\nemergence of informal economic activity. Employing an agent-based simulation\npowered by Large Language Models and Deep Reinforcement Learning, the framework\nis uniquely designed to allow informal economic behaviors to emerge\norganically, without presupposing their existence or explicitly signaling\nagents about the possibility of evasion. This provides a rigorous approach for\nexploring the socio-economic determinants of compliance behavior. The\nexperimental design, comprising model validation and exploratory phases,\ndemonstrates the framework's robustness in replicating theoretical economic\nbehaviors. Findings indicate that individual personality traits, external\nnarratives, enforcement probabilities, and the perceived efficiency of public\ngoods provision significantly influence both the timing and extent of informal\neconomic activity. The results underscore that efficient public goods provision\nand robust enforcement mechanisms are complementary; neither alone is\nsufficient to curtail informal activity effectively.\n","authors":["Teddy Lazebnik","Labib Shami"],"pdf_url":"https://arxiv.org/pdf/2501.18177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15797v2","updated":"2025-01-30T06:10:23Z","published":"2025-01-27T05:46:06Z","title":"LemmaHead: RAG Assisted Proof Generation Using Large Language Models","summary":"  Developing the logic necessary to solve mathematical problems or write\nmathematical proofs is one of the more difficult objectives for large language\nmodels (LLMS). Currently, the most popular methods in literature consists of\nfine-tuning the model on written mathematical content such as academic\npublications and textbooks, so that the model can learn to emulate the style of\nmathematical writing. In this project, we explore the effectiveness of using\nretrieval augmented generation (RAG) to address gaps in the mathematical\nreasoning of LLMs. We develop LemmaHead, a RAG knowledge base that supplements\nqueries to the model with relevant mathematical context, with particular focus\non context from published textbooks. To measure our model's performance in\nmathematical reasoning, our testing paradigm focuses on the task of automated\ntheorem proving via generating proofs to a given mathematical claim in the Lean\nformal language.\n","authors":["Tianbo Yang","Mingqi Yang","Hongyi Zhao","Tianshuo Yang"],"pdf_url":"https://arxiv.org/pdf/2501.15797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18126v1","updated":"2025-01-30T04:04:39Z","published":"2025-01-30T04:04:39Z","title":"HyperZero: A Customized End-to-End Auto-Tuning System for Recommendation\n  with Hourly Feedback","summary":"  Modern recommendation systems can be broadly divided into two key stages: the\nranking stage, where the system predicts various user engagements (e.g.,\nclick-through rate, like rate, follow rate, watch time), and the value model\nstage, which aggregates these predictive scores through a function (e.g., a\nlinear combination defined by a weight vector) to measure the value of each\ncontent by a single numerical score. Both stages play roughly equally important\nroles in real industrial systems; however, how to optimize the model weights\nfor the second stage still lacks systematic study. This paper focuses on\noptimizing the second stage through auto-tuning technology. Although general\nauto-tuning systems and solutions - both from established production practices\nand open-source solutions - can address this problem, they typically require\nweeks or even months to identify a feasible solution. Such prolonged tuning\nprocesses are unacceptable in production environments for recommendation\nsystems, as suboptimal value models can severely degrade user experience. An\neffective auto-tuning solution is required to identify a viable model within\n2-3 days, rather than the extended timelines typically associated with existing\napproaches. In this paper, we introduce a practical auto-tuning system named\nHyperZero that addresses these time constraints while effectively solving the\nunique challenges inherent in modern recommendation systems. Moreover, this\nframework has the potential to be expanded to broader tuning tasks within\nrecommendation systems.\n","authors":["Xufeng Cai","Ziwei Guan","Lei Yuan","Ali Selman Aydin","Tengyu Xu","Boying Liu","Wenbo Ren","Renkai Xiang","Songyi He","Haichuan Yang","Serena Li","Mingze Gao","Yue Weng","Ji Liu"],"pdf_url":"https://arxiv.org/pdf/2501.18126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18117v1","updated":"2025-01-30T03:37:28Z","published":"2025-01-30T03:37:28Z","title":"Improving Minimax Group Fairness in Sequential Recommendation","summary":"  Training sequential recommenders such as SASRec with uniform sample weights\nachieves good overall performance but can fall short on specific user groups.\nOne such example is popularity bias, where mainstream users receive better\nrecommendations than niche content viewers. To improve recommendation quality\nacross diverse user groups, we explore three Distributionally Robust\nOptimization(DRO) methods: Group DRO, Streaming DRO, and Conditional Value at\nRisk (CVaR) DRO. While Group and Streaming DRO rely on group annotations and\nstruggle with users belonging to multiple groups, CVaR does not require such\nannotations and can naturally handle overlapping groups. In experiments on two\nreal-world datasets, we show that the DRO methods outperform standard training,\nwith CVaR delivering the best results. Additionally, we find that Group and\nStreaming DRO are sensitive to the choice of group used for loss computation.\nOur contributions include (i) a novel application of CVaR to recommenders, (ii)\nshowing that the DRO methods improve group metrics as well as overall\nperformance, and (iii) demonstrating CVaR's effectiveness in the practical\nscenario of intersecting user groups.\n","authors":["Krishna Acharya","David Wardrope","Timos Korres","Aleksandr Petrov","Anders Uhrenholt"],"pdf_url":"https://arxiv.org/pdf/2501.18117v1.pdf","comment":"This paper has been accepted to the IR for Good track at ECIR 2025"},{"id":"http://arxiv.org/abs/2501.17799v2","updated":"2025-01-30T02:23:25Z","published":"2025-01-29T17:38:39Z","title":"Leveraging Multimodal LLM for Inspirational User Interface Search","summary":"  Inspirational search, the process of exploring designs to inform and inspire\nnew creative work, is pivotal in mobile user interface (UI) design. However,\nexploring the vast space of UI references remains a challenge. Existing\nAI-based UI search methods often miss crucial semantics like target users or\nthe mood of apps. Additionally, these models typically require metadata like\nview hierarchies, limiting their practical use. We used a multimodal large\nlanguage model (MLLM) to extract and interpret semantics from mobile UI images.\nWe identified key UI semantics through a formative study and developed a\nsemantic-based UI search system. Through computational and human evaluations,\nwe demonstrate that our approach significantly outperforms existing UI\nretrieval methods, offering UI designers a more enriched and contextually\nrelevant search experience. We enhance the understanding of mobile UI design\nsemantics and highlight MLLMs' potential in inspirational search, providing a\nrich dataset of UI semantics for future studies.\n","authors":["Seokhyeon Park","Yumin Song","Soohyun Lee","Jaeyoung Kim","Jinwook Seo"],"pdf_url":"https://arxiv.org/pdf/2501.17799v2.pdf","comment":"In Proceedings of the SIGCHI Conference on Human Factors in Computing\n  Systems (CHI '25)"},{"id":"http://arxiv.org/abs/2501.14269v2","updated":"2025-01-30T02:05:07Z","published":"2025-01-24T06:26:50Z","title":"Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential\n  Recommendation","summary":"  Multi-modal sequential recommendation (SR) leverages multi-modal data to\nlearn more comprehensive item features and user preferences than traditional SR\nmethods, which has become a critical topic in both academia and industry.\nExisting methods typically focus on enhancing multi-modal information utility\nthrough adaptive modality fusion to capture the evolving of user preference\nfrom user-item interaction sequences. However, most of them overlook the\ninterference caused by redundant interest-irrelevant information contained in\nrich multi-modal data. Additionally, they primarily rely on implicit temporal\ninformation based solely on chronological ordering, neglecting explicit\ntemporal signals that could more effectively represent dynamic user interest\nover time. To address these limitations, we propose a Hierarchical time-aware\nMixture of experts for multi-modal Sequential Recommendation (HM4SR) with a\ntwo-level Mixture of Experts (MoE) and a multi-task learning strategy.\nSpecifically, the first MoE, named Interactive MoE, extracts essential user\ninterest-related information from the multi-modal data of each item. Then, the\nsecond MoE, termed Temporal MoE, captures user dynamic interests by introducing\nexplicit temporal embeddings from timestamps in modality encoding. To further\naddress data sparsity, we propose three auxiliary supervision tasks:\nsequence-level category prediction (CP) for item feature understanding,\ncontrastive learning on ID (IDCL) to align sequence context with user\ninterests, and placeholder contrastive learning (PCL) to integrate temporal\ninformation with modalities for dynamic interest modeling. Extensive\nexperiments on four public datasets verify the effectiveness of HM4SR compared\nto several state-of-the-art approaches.\n","authors":["Shengzhe Zhang","Liyi Chen","Dazhong Shen","Chao Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2501.14269v2.pdf","comment":"Accepted to WWW 2025"},{"id":"http://arxiv.org/abs/2404.08137v3","updated":"2025-01-30T00:52:34Z","published":"2024-04-11T21:48:54Z","title":"Generative Information Retrieval Evaluation","summary":"  In this chapter, we consider generative information retrieval evaluation from\ntwo distinct but interrelated perspectives. First, large language models (LLMs)\nthemselves are rapidly becoming tools for evaluation, with current research\nindicating that LLMs may be superior to crowdsource workers and other paid\nassessors on basic relevance judgement tasks. We review past and ongoing\nrelated research, including speculation on the future of shared task\ninitiatives, such as TREC, and a discussion on the continuing need for human\nassessments. Second, we consider the evaluation of emerging LLM-based\ngenerative information retrieval (GenIR) systems, including retrieval augmented\ngeneration (RAG) systems. We consider approaches that focus both on the\nend-to-end evaluation of GenIR systems and on the evaluation of a retrieval\ncomponent as an element in a RAG system. Going forward, we expect the\nevaluation of GenIR systems to be at least partially based on LLM-based\nassessment, creating an apparent circularity, with a system seemingly\nevaluating its own output. We resolve this apparent circularity in two ways: 1)\nby viewing LLM-based assessment as a form of \"slow search\", where a slower IR\nsystem is used for evaluation and training of a faster production IR system;\nand 2) by recognizing a continuing need to ground evaluation in human\nassessment, even if the characteristics of that human assessment must change.\n","authors":["Marwah Alaofi","Negar Arabzadeh","Charles L. A. Clarke","Mark Sanderson"],"pdf_url":"https://arxiv.org/pdf/2404.08137v3.pdf","comment":"This chapter is part of the book Information Access in the Era of\n  Generative AI, co-edited by Chirag Shah and Ryen White"},{"id":"http://arxiv.org/abs/2501.13579v2","updated":"2025-01-30T00:29:20Z","published":"2025-01-23T11:38:00Z","title":"MixRec: Individual and Collective Mixing Empowers Data Augmentation for\n  Recommender Systems","summary":"  The core of the general recommender systems lies in learning high-quality\nembedding representations of users and items to investigate their positional\nrelations in the feature space. Unfortunately, data sparsity caused by\ndifficult-to-access interaction data severely limits the effectiveness of\nrecommender systems. Faced with such a dilemma, various types of\nself-supervised learning methods have been introduced into recommender systems\nin an attempt to alleviate the data sparsity through distribution modeling or\ndata augmentation. However, most data augmentation relies on elaborate manual\ndesign, which is not only not universal, but the bloated and redundant\naugmentation process may significantly slow down model training progress. To\ntackle these limitations, we propose a novel Dual Mixing-based Recommendation\nFramework (MixRec) to empower data augmentation as we wish. Specifically, we\npropose individual mixing and collective mixing, respectively. The former aims\nto provide a new positive sample that is unique to the target (user or item)\nand to make the pair-wise recommendation loss benefit from it, while the latter\naims to portray a new sample that contains group properties in a batch. The two\nmentioned mixing mechanisms allow for data augmentation with only one parameter\nthat does not need to be set multiple times and can be done in linear time\ncomplexity. Besides, we propose the dual-mixing contrastive learning to\nmaximize the utilization of these new-constructed samples to enhance the\nconsistency between pairs of positive samples. Experimental results on four\nreal-world datasets demonstrate the advantages of MixRec in terms of\neffectiveness, simplicity, efficiency, and scalability.\n","authors":["Yi Zhang","Yiwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.13579v2.pdf","comment":"Accepted by WWW'25"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2501.18596v1","updated":"2025-01-30T18:59:55Z","published":"2025-01-30T18:59:55Z","title":"DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights","summary":"  We introduce DeltaLLM, a new post-training compression technique to reduce\nthe memory footprint of LLMs. We propose an alternative way of structuring LLMs\nwith weight sharing between layers in subsequent Transformer blocks, along with\nadditional low-rank difference matrices between them. For training, we adopt\nthe progressing module replacement method and show that the lightweight\ntraining of the low-rank modules with approximately 30M-40M tokens is\nsufficient to achieve performance on par with LLMs of comparable sizes trained\nfrom scratch. We release the resultant models, DeltaLLAMA and DeltaPHI, with a\n12% parameter reduction, retaining 90% of the performance of the base Llama and\nPhi models on common knowledge and reasoning benchmarks. Our method also\noutperforms compression techniques JointDrop, LaCo, ShortGPT and SliceGPT with\nthe same number of parameters removed. For example, DeltaPhi 2.9B with a 24%\nreduction achieves similar average zero-shot accuracies as recovery fine-tuned\nSlicedPhi 3.3B with a 12% reduction, despite being approximately 400M\nparameters smaller with no fine-tuning applied. This work provides new insights\ninto LLM architecture design and compression methods when storage space is\ncritical.\n","authors":["Liana Mikaelyan","Ayyoob Imani","Mathew Salvaris","Parth Pathak","Mohsen Fayyaz"],"pdf_url":"https://arxiv.org/pdf/2501.18596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18593v1","updated":"2025-01-30T18:59:37Z","published":"2025-01-30T18:59:37Z","title":"Diffusion Autoencoders are Scalable Image Tokenizers","summary":"  Tokenizing images into compact visual representations is a key step in\nlearning efficient and high-quality image generative models. We present a\nsimple diffusion tokenizer (DiTo) that learns compact visual representations\nfor image generation models. Our key insight is that a single learning\nobjective, diffusion L2 loss, can be used for training scalable image\ntokenizers. Since diffusion is already widely used for image generation, our\ninsight greatly simplifies training such tokenizers. In contrast, current\nstate-of-the-art tokenizers rely on an empirically found combination of\nheuristics and losses, thus requiring a complex training recipe that relies on\nnon-trivially balancing different losses and pretrained supervised models. We\nshow design decisions, along with theoretical grounding, that enable us to\nscale DiTo for learning competitive image representations. Our results show\nthat DiTo is a simpler, scalable, and self-supervised alternative to the\ncurrent state-of-the-art image tokenizer which is supervised. DiTo achieves\ncompetitive or better quality than state-of-the-art in image reconstruction and\ndownstream image generation tasks.\n","authors":["Yinbo Chen","Rohit Girdhar","Xiaolong Wang","Sai Saketh Rambhatla","Ishan Misra"],"pdf_url":"https://arxiv.org/pdf/2501.18593v1.pdf","comment":"Project page: https://yinboc.github.io/dito/"},{"id":"http://arxiv.org/abs/2501.18592v1","updated":"2025-01-30T18:59:36Z","published":"2025-01-30T18:59:36Z","title":"Advances in Multimodal Adaptation and Generalization: From Traditional\n  Approaches to Foundation Models","summary":"  In real-world scenarios, achieving domain adaptation and generalization poses\nsignificant challenges, as models must adapt to or generalize across unknown\ntarget distributions. Extending these capabilities to unseen multimodal\ndistributions, i.e., multimodal domain adaptation and generalization, is even\nmore challenging due to the distinct characteristics of different modalities.\nSignificant progress has been made over the years, with applications ranging\nfrom action recognition to semantic segmentation. Besides, the recent advent of\nlarge-scale pre-trained multimodal foundation models, such as CLIP, has\ninspired works leveraging these models to enhance adaptation and generalization\nperformances or adapting them to downstream tasks. This survey provides the\nfirst comprehensive review of recent advances from traditional approaches to\nfoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal\ntest-time adaptation; (3) Multimodal domain generalization; (4) Domain\nadaptation and generalization with the help of multimodal foundation models;\nand (5) Adaptation of multimodal foundation models. For each topic, we formally\ndefine the problem and thoroughly review existing methods. Additionally, we\nanalyze relevant datasets and applications, highlighting open challenges and\npotential future research directions. We maintain an active repository that\ncontains up-to-date literature at\nhttps://github.com/donghao51/Awesome-Multimodal-Adaptation.\n","authors":["Hao Dong","Moru Liu","Kaiyang Zhou","Eleni Chatzi","Juho Kannala","Cyrill Stachniss","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2501.18592v1.pdf","comment":"Project page:\n  https://github.com/donghao51/Awesome-Multimodal-Adaptation"},{"id":"http://arxiv.org/abs/2501.18582v1","updated":"2025-01-30T18:54:22Z","published":"2025-01-30T18:54:22Z","title":"Accuracy and Robustness of Weight-Balancing Methods for Training PINNs","summary":"  Physics-Informed Neural Networks (PINNs) have emerged as powerful tools for\nintegrating physics-based models with data by minimizing both data and physics\nlosses. However, this multi-objective optimization problem is notoriously\nchallenging, with some benchmark problems leading to unfeasible solutions. To\naddress these issues, various strategies have been proposed, including adaptive\nweight adjustments in the loss function. In this work, we introduce clear\ndefinitions of accuracy and robustness in the context of PINNs and propose a\nnovel training algorithm based on the Primal-Dual (PD) optimization framework.\nOur approach enhances the robustness of PINNs while maintaining comparable\nperformance to existing weight-balancing methods. Numerical experiments\ndemonstrate that the PD method consistently achieves reliable solutions across\nall investigated cases and can be easily implemented, facilitating its\npractical adoption. The code is available at\nhttps://github.com/haoming-SHEN/Accuracy-and-Robustness-of-Weight-Balancing-Methods-for-Training-PINNs.git.\n","authors":["Matthieu Barreau","Haoming Shen"],"pdf_url":"https://arxiv.org/pdf/2501.18582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18581v1","updated":"2025-01-30T18:52:44Z","published":"2025-01-30T18:52:44Z","title":"Bias-variance decompositions: the exclusive privilege of Bregman\n  divergences","summary":"  Bias-variance decompositions are widely used to understand the generalization\nperformance of machine learning models. While the squared error loss permits a\nstraightforward decomposition, other loss functions - such as zero-one loss or\n$L_1$ loss - either fail to sum bias and variance to the expected loss or rely\non definitions that lack the essential properties of meaningful bias and\nvariance. Recent research has shown that clean decompositions can be achieved\nfor the broader class of Bregman divergences, with the cross-entropy loss as a\nspecial case. However, the necessary and sufficient conditions for these\ndecompositions remain an open question.\n  In this paper, we address this question by studying continuous, nonnegative\nloss functions that satisfy the identity of indiscernibles under mild\nregularity conditions. We prove that so-called $g$-Bregman divergences are the\nonly such loss functions that have a clean bias-variance decomposition. A\n$g$-Bregman divergence can be transformed into a standard Bregman divergence\nthrough an invertible change of variables. This makes the squared Mahalanobis\ndistance, up to such a variable transformation, the only symmetric loss\nfunction with a clean bias-variance decomposition. We also examine the impact\nof relaxing the restrictions on the loss functions and how this affects our\nresults.\n","authors":["Tom Heskes"],"pdf_url":"https://arxiv.org/pdf/2501.18581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18580v1","updated":"2025-01-30T18:52:43Z","published":"2025-01-30T18:52:43Z","title":"Node Classification and Search on the Rubik's Cube Graph with GNNs","summary":"  This study focuses on the application of deep geometric models to solve the\n3x3x3 Rubik's Cube. We begin by discussing the cube's graph representation and\ndefining distance as the model's optimization objective. The distance\napproximation task is reformulated as a node classification problem,\neffectively addressed using Graph Neural Networks (GNNs). After training the\nmodel on a random subgraph, the predicted classes are used to construct a\nheuristic for $A^*$ search. We conclude with experiments comparing our\nheuristic to that of the DeepCubeA model.\n","authors":["Alessandro Barro"],"pdf_url":"https://arxiv.org/pdf/2501.18580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18578v1","updated":"2025-01-30T18:50:25Z","published":"2025-01-30T18:50:25Z","title":"R.I.P.: Better Models by Survival of the Fittest Prompts","summary":"  Training data quality is one of the most important drivers of final model\nquality. In this work, we introduce a method for evaluating data integrity\nbased on the assumption that low-quality input prompts result in high variance\nand low quality responses. This is achieved by measuring the rejected response\nquality and the reward gap between the chosen and rejected preference pair. Our\nmethod, Rejecting Instruction Preferences (RIP) can be used to filter prompts\nfrom existing training sets, or to make high quality synthetic datasets,\nyielding large performance gains across various benchmarks compared to\nunfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC Win\nRate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama\n3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, which is from 18th\nplace to 6th overall in the leaderboard.\n","authors":["Ping Yu","Weizhe Yuan","Olga Golovneva","Tianhao Wu","Sainbayar Sukhbaatar","Jason Weston","Jing Xu"],"pdf_url":"https://arxiv.org/pdf/2501.18578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18577v1","updated":"2025-01-30T18:46:43Z","published":"2025-01-30T18:46:43Z","title":"Prediction-Powered Inference with Imputed Covariates and Nonuniform\n  Sampling","summary":"  Machine learning models are increasingly used to produce predictions that\nserve as input data in subsequent statistical analyses. For example, computer\nvision predictions of economic and environmental indicators based on satellite\nimagery are used in downstream regressions; similarly, language models are\nwidely used to approximate human ratings and opinions in social science\nresearch. However, failure to properly account for errors in the machine\nlearning predictions renders standard statistical procedures invalid. Prior\nwork uses what we call the Predict-Then-Debias estimator to give valid\nconfidence intervals when machine learning algorithms impute missing variables,\nassuming a small complete sample from the population of interest. We expand the\nscope by introducing bootstrap confidence intervals that apply when the\ncomplete data is a nonuniform (i.e., weighted, stratified, or clustered) sample\nand to settings where an arbitrary subset of features is imputed. Importantly,\nthe method can be applied to many settings without requiring additional\ncalculations. We prove that these confidence intervals are valid under no\nassumptions on the quality of the machine learning model and are no wider than\nthe intervals obtained by methods that do not use machine learning predictions.\n","authors":["Dan M. Kluger","Kerri Lu","Tijana Zrnic","Sherrie Wang","Stephen Bates"],"pdf_url":"https://arxiv.org/pdf/2501.18577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18576v1","updated":"2025-01-30T18:45:51Z","published":"2025-01-30T18:45:51Z","title":"Token-Hungry, Yet Precise: DeepSeek R1 Highlights the Need for\n  Multi-Step Reasoning Over Speed in MATH","summary":"  This study investigates the performance of the DeepSeek R1 language model on\n30 challenging mathematical problems derived from the MATH dataset, problems\nthat previously proved unsolvable by other models under time constraints.\nUnlike prior work, this research removes time limitations to explore whether\nDeepSeek R1's architecture, known for its reliance on token-based reasoning,\ncan achieve accurate solutions through a multi-step process. The study compares\nDeepSeek R1 with four other models (gemini-1.5-flash-8b,\ngpt-4o-mini-2024-07-18, llama3.1:8b, and mistral-8b-latest) across 11\ntemperature settings. Results demonstrate that DeepSeek R1 achieves superior\naccuracy on these complex problems but generates significantly more tokens than\nother models, confirming its token-intensive approach. The findings highlight a\ntrade-off between accuracy and efficiency in mathematical problem-solving with\nlarge language models: while DeepSeek R1 excels in accuracy, its reliance on\nextensive token generation may not be optimal for applications requiring rapid\nresponses. The study underscores the importance of considering task-specific\nrequirements when selecting an LLM and emphasizes the role of temperature\nsettings in optimizing performance.\n","authors":["Evgenii Evstafev"],"pdf_url":"https://arxiv.org/pdf/2501.18576v1.pdf","comment":"5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2501.18563v1","updated":"2025-01-30T18:36:48Z","published":"2025-01-30T18:36:48Z","title":"No Equations Needed: Learning System Dynamics Without Relying on\n  Closed-Form ODEs","summary":"  Data-driven modeling of dynamical systems is a crucial area of machine\nlearning. In many scenarios, a thorough understanding of the model's behavior\nbecomes essential for practical applications. For instance, understanding the\nbehavior of a pharmacokinetic model, constructed as part of drug development,\nmay allow us to both verify its biological plausibility (e.g., the drug\nconcentration curve is non-negative and decays to zero) and to design dosing\nguidelines. Discovery of closed-form ordinary differential equations (ODEs) can\nbe employed to obtain such insights by finding a compact mathematical equation\nand then analyzing it (a two-step approach). However, its widespread use is\ncurrently hindered because the analysis process may be time-consuming,\nrequiring substantial mathematical expertise, or even impossible if the\nequation is too complex. Moreover, if the found equation's behavior does not\nsatisfy the requirements, editing it or influencing the discovery algorithms to\nrectify it is challenging as the link between the symbolic form of an ODE and\nits behavior can be elusive. This paper proposes a conceptual shift to modeling\nlow-dimensional dynamical systems by departing from the traditional two-step\nmodeling process. Instead of first discovering a closed-form equation and then\nanalyzing it, our approach, direct semantic modeling, predicts the semantic\nrepresentation of the dynamical system (i.e., description of its behavior)\ndirectly from data, bypassing the need for complex post-hoc analysis. This\ndirect approach also allows the incorporation of intuitive inductive biases\ninto the optimization algorithm and editing the model's behavior directly,\nensuring that the model meets the desired specifications. Our approach not only\nsimplifies the modeling pipeline but also enhances the transparency and\nflexibility of the resulting models compared to traditional closed-form ODEs.\n","authors":["Krzysztof Kacprzyk","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2501.18563v1.pdf","comment":"To appear in the Proceedings of the Thirteenth International\n  Conference on Learning Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2501.18560v1","updated":"2025-01-30T18:36:13Z","published":"2025-01-30T18:36:13Z","title":"Bandits with Anytime Knapsacks","summary":"  We consider bandits with anytime knapsacks (BwAK), a novel version of the BwK\nproblem where there is an \\textit{anytime} cost constraint instead of a total\ncost budget. This problem setting introduces additional complexities as it\nmandates adherence to the constraint throughout the decision-making process. We\npropose SUAK, an algorithm that utilizes upper confidence bounds to identify\nthe optimal mixture of arms while maintaining a balance between exploration and\nexploitation. SUAK is an adaptive algorithm that strategically utilizes the\navailable budget in each round in the decision-making process and skips a round\nwhen it is possible to violate the anytime cost constraint. In particular, SUAK\nslightly under-utilizes the available cost budget to reduce the need for\nskipping rounds. We show that SUAK attains the same problem-dependent regret\nupper bound of $ O(K \\log T)$ established in prior work under the simpler BwK\nframework. Finally, we provide simulations to verify the utility of SUAK in\npractical settings.\n","authors":["Eray Can Elumar","Cem Tekin","Osman Yagan"],"pdf_url":"https://arxiv.org/pdf/2501.18560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07176v3","updated":"2025-01-30T18:17:13Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention enhances parameter flexibility. For example,\nunlike traditional softmax attention heads that use a static output-value (OV)\nmatrix to delete or copy inputs that the heads attend to, Cog Attention\nnaturally learns to use the sign of dynamic query-key (QK) inner products to\nrepresent these operations. This enables Cog Attention to perform multiple\noperations simultaneously within a single head. Meanwhile, Cog Attention's OV\nmatrix can focus more on refinement or modification. (2) Cog Attention enhances\nthe model's robustness against representational collapse by preventing the\n``over-squashing'' of earlier tokens into later positions. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models at various scales for language modeling and U-ViT diffusion\nmodels for image generation. Experiments show that models using Cog Attention\nexhibit superior performance compared to those employing traditional softmax\nattention modules. Our approach suggests a promising research direction for\nrethinking and breaking the entrenched constraints of traditional softmax\nattention, such as the requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Di Wang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14883v2","updated":"2025-01-30T18:13:05Z","published":"2025-01-24T19:17:06Z","title":"Verify with Caution: The Pitfalls of Relying on Imperfect Factuality\n  Metrics","summary":"  Improvements in large language models have led to increasing optimism that\nthey can serve as reliable evaluators of natural language generation outputs.\nIn this paper, we challenge this optimism by thoroughly re-evaluating five\nstate-of-the-art factuality metrics on a collection of 11 datasets for\nsummarization, retrieval-augmented generation, and question answering. We find\nthat these evaluators are inconsistent with each other and often misestimate\nsystem-level performance, both of which can lead to a variety of pitfalls. We\nfurther show that these metrics exhibit biases against highly paraphrased\noutputs and outputs that draw upon faraway parts of the source documents. We\nurge users of these factuality metrics to proceed with caution and manually\nvalidate the reliability of these metrics in their domain of interest before\nproceeding.\n","authors":["Ameya Godbole","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2501.14883v2.pdf","comment":"v2: Added Acknowledgements to funding sources and advisors"},{"id":"http://arxiv.org/abs/2501.18537v1","updated":"2025-01-30T18:06:18Z","published":"2025-01-30T18:06:18Z","title":"Loss Functions and Operators Generated by f-Divergences","summary":"  The logistic loss (a.k.a. cross-entropy loss) is one of the most popular loss\nfunctions used for multiclass classification. It is also the loss function of\nchoice for next-token prediction in language modeling. It is associated with\nthe Kullback--Leibler (KL) divergence and the softargmax operator. In this\nwork, we propose to construct new convex loss functions based on\n$f$-divergences. Our loss functions generalize the logistic loss in two\ndirections: i) by replacing the KL divergence with $f$-divergences and ii) by\nallowing non-uniform reference measures. We instantiate our framework for\nnumerous $f$-divergences, recovering existing losses and creating new ones. By\nanalogy with the logistic loss, the loss function generated by an\n$f$-divergence is associated with an operator, that we dub $f$-softargmax. We\nderive a novel parallelizable bisection algorithm for computing the\n$f$-softargmax associated with any $f$-divergence. On the empirical side, one\nof the goals of this paper is to determine the effectiveness of loss functions\nbeyond the classical cross-entropy in a language model setting, including on\npre-training, post-training (SFT) and distillation. We show that the loss\nfunction generated by the $\\alpha$-divergence (which is equivalent to Tsallis\n$\\alpha$-negentropy in the case of unit reference measures) with $\\alpha=1.5$\nperforms well across several tasks.\n","authors":["Vincent Roulet","Tianlin Liu","Nino Vieillard","Michael E. Sander","Mathieu Blondel"],"pdf_url":"https://arxiv.org/pdf/2501.18537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18535v1","updated":"2025-01-30T18:01:48Z","published":"2025-01-30T18:01:48Z","title":"A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient\n  Length Of Stay In Health Centre","summary":"  Patient length of stay (LoS) is a critical metric for evaluating the efficacy\nof hospital management. The primary objectives encompass to improve efficiency\nand reduce costs while enhancing patient outcomes and hospital capacity within\nthe patient journey. By seamlessly merging data-driven techniques with\nsimulation methodologies, the study proposes an all-encompassing framework for\nthe optimization of patient flow. Using a comprehensive dataset of 2.3 million\nde-identified patient records, we analyzed demographics, diagnoses, treatments,\nservices, costs, and charges with machine learning models (Decision Tree,\nLogistic Regression, Random Forest, Adaboost, LightGBM) and Python tools\n(Spark, AWS clusters, dimensionality reduction). Our model predicts patient\nlength of stay (LoS) upon admission using supervised learning algorithms. This\nhybrid approach enables the identification of key factors influencing LoS,\noffering a robust framework for hospitals to streamline patient flow and\nresource utilization. The research focuses on patient flow, corroborating the\nefficacy of the approach, illustrating decreased patient length of stay within\na real healthcare environment. The findings underscore the potential of hybrid\ndata-driven models in transforming hospital management practices. This\ninnovative methodology provides generally flexible decision-making, training,\nand patient flow enhancement; such a system could have huge implications for\nhealthcare administration and overall satisfaction with healthcare.\n","authors":["Tasfia Noor Chowdhury","Sanjida Afrin Mou","Kazi Naimur Rahman"],"pdf_url":"https://arxiv.org/pdf/2501.18535v1.pdf","comment":"8 pages, 15 figures"},{"id":"http://arxiv.org/abs/2501.18532v1","updated":"2025-01-30T17:58:36Z","published":"2025-01-30T17:58:36Z","title":"Differentially Private Steering for Large Language Model Alignment","summary":"  Aligning Large Language Models (LLMs) with human values and away from\nundesirable behaviors (such as hallucination) has become increasingly\nimportant. Recently, steering LLMs towards a desired behavior via activation\nediting has emerged as an effective method to mitigate harmful generations at\ninference-time. Activation editing modifies LLM representations by preserving\ninformation from positive demonstrations (e.g., truthful) and minimising\ninformation from negative demonstrations (e.g., hallucinations). When these\ndemonstrations come from a private dataset, the aligned LLM may leak private\ninformation contained in those private samples. In this work, we present the\nfirst study of aligning LLM behavior with private datasets. Our work proposes\nthe \\textit{\\underline{P}rivate \\underline{S}teering for LLM\n\\underline{A}lignment (PSA)} algorithm to edit LLM activations with\ndifferential privacy (DP) guarantees. We conduct extensive experiments on seven\ndifferent benchmarks with open-source LLMs of different sizes (0.5B to 7B) and\nmodel families (LlaMa, Qwen, Mistral and Gemma). Our results show that PSA\nachieves DP guarantees for LLM alignment with minimal loss in performance,\nincluding alignment metrics, open-ended text generation quality, and\ngeneral-purpose reasoning. We also develop the first Membership Inference\nAttack (MIA) for evaluating and auditing the empirical privacy for the problem\nof LLM steering via activation editing. Our attack is tailored for activation\nediting and relies solely on the generated texts without their associated\nprobabilities. Our experiments support the theoretical guarantees by showing\nimproved guarantees for our \\textit{PSA} algorithm compared to several existing\nnon-private techniques.\n","authors":["Anmol Goel","Yaxi Hu","Iryna Gurevych","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2501.18532v1.pdf","comment":"ICLR 2025; Code: https://github.com/UKPLab/iclr2025-psa"},{"id":"http://arxiv.org/abs/2501.18531v1","updated":"2025-01-30T17:57:15Z","published":"2025-01-30T17:57:15Z","title":"Graph Learning for Bidirectional Disease Contact Tracing on Real Human\n  Mobility Data","summary":"  For rapidly spreading diseases where many cases show no symptoms, swift and\neffective contact tracing is essential. While exposure notification\napplications provide alerts on potential exposures, a fully automated system is\nneeded to track the infectious transmission routes. To this end, our research\nleverages large-scale contact networks from real human mobility data to\nidentify the path of transmission. More precisely, we introduce a new\nInfectious Path Centrality network metric that informs a graph learning edge\nclassifier to identify important transmission events, achieving an F1-score of\n94%. Additionally, we explore bidirectional contact tracing, which quarantines\nindividuals both retroactively and proactively, and compare its effectiveness\nagainst traditional forward tracing, which only isolates individuals after\ntesting positive. Our results indicate that when only 30% of symptomatic\nindividuals are tested, bidirectional tracing can reduce infectious effective\nreproduction rate by 71%, thus significantly controlling the outbreak.\n","authors":["Sofia Hurtado","Radu Marculescu"],"pdf_url":"https://arxiv.org/pdf/2501.18531v1.pdf","comment":"Accepted into International Workshop on Disaster Network Science for\n  Building Resilient Communities (REINFORCE) held at the Advances in Social\n  Networks Analysis and Mining conference"},{"id":"http://arxiv.org/abs/2501.18530v1","updated":"2025-01-30T17:56:52Z","published":"2025-01-30T17:56:52Z","title":"Optimal generalisation and learning transition in extensive-width\n  shallow neural networks near interpolation","summary":"  We consider a teacher-student model of supervised learning with a\nfully-trained 2-layer neural network whose width $k$ and input dimension $d$\nare large and proportional. We compute the Bayes-optimal generalisation error\nof the network for any activation function in the regime where the number of\ntraining data $n$ scales quadratically with the input dimension, i.e., around\nthe interpolation threshold where the number of trainable parameters $kd+k$ and\nof data points $n$ are comparable. Our analysis tackles generic weight\ndistributions. Focusing on binary weights, we uncover a discontinuous phase\ntransition separating a \"universal\" phase from a \"specialisation\" phase. In the\nfirst, the generalisation error is independent of the weight distribution and\ndecays slowly with the sampling rate $n/d^2$, with the student learning only\nsome non-linear combinations of the teacher weights. In the latter, the error\nis weight distribution-dependent and decays faster due to the alignment of the\nstudent towards the teacher network. We thus unveil the existence of a highly\npredictive solution near interpolation, which is however potentially hard to\nfind.\n","authors":["Jean Barbier","Francesco Camilli","Minh-Toan Nguyen","Mauro Pastore","Rudy Skerk"],"pdf_url":"https://arxiv.org/pdf/2501.18530v1.pdf","comment":"8 pages + appendix, 3 figures"},{"id":"http://arxiv.org/abs/2501.13198v2","updated":"2025-01-30T17:55:31Z","published":"2025-01-22T20:00:41Z","title":"S-LoRA: Scalable Low-Rank Adaptation for Class Incremental Learning","summary":"  Continual Learning with foundation models has recently emerged as a promising\napproach to harnessing the power of pre-trained models for sequential tasks.\nExisting prompt-based methods generally use a gating mechanism to select\nrelevant prompts aligned with the test query for further processing. However,\nthe success of these methods largely depends on the precision of the gating\nmechanism, which becomes less scalable with additional computational overhead\nas tasks increases. To overcome these issues, we propose a Scalable Low-Rank\nAdaptation (S-LoRA) method for CL (in particular class incremental learning),\nwhich incrementally decouples the learning of the direction and magnitude of\nLoRA parameters. S-LoRA supports efficient inference by employing the\nlast-stage trained model for direct testing without a gating process. Our\ntheoretical and empirical analysis demonstrates that S-LoRA tends to follow a\nlow-loss trajectory that converges to an overlapped low-loss region, resulting\nin an excellent stability-plasticity trade-off in CL. Furthermore, based on our\nfindings, we develop variants of S-LoRA with further improved scalability.\nExtensive experiments across multiple CL benchmarks and various foundation\nmodels consistently validate the effectiveness of S-LoRA.\n","authors":["Yichen Wu","Hongming Piao","Long-Kai Huang","Renzhen Wang","Wanhua Li","Hanspeter Pfister","Deyu Meng","Kede Ma","Ying Wei"],"pdf_url":"https://arxiv.org/pdf/2501.13198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03101v3","updated":"2025-01-30T17:48:34Z","published":"2022-07-07T05:48:27Z","title":"A conditional gradient homotopy method with applications to Semidefinite\n  Programming","summary":"  We propose a new homotopy-based conditional gradient method for solving\nconvex optimization problems with a large number of simple conic constraints.\nInstances of this template naturally appear in semidefinite programming\nproblems arising as convex relaxations of combinatorial optimization problems.\nOur method is a double-loop algorithm in which the conic constraint is treated\nvia a self-concordant barrier, and the inner loop employs a conditional\ngradient algorithm to approximate the analytic central path, while the outer\nloop updates the accuracy imposed on the temporal solution and the homotopy\nparameter. Our theoretical iteration complexity is competitive when confronted\nto state-of-the-art SDP solvers, with the decisive advantage of cheap\nprojection-free subroutines. Preliminary numerical experiments are provided for\nillustrating the practical performance of the method.\n","authors":["Pavel Dvurechensky","Gabriele Iommazzo","Shimrit Shtern","Mathias Staudigl"],"pdf_url":"https://arxiv.org/pdf/2207.03101v3.pdf","comment":"Largely revised and extended version. Submitted for Publication"},{"id":"http://arxiv.org/abs/2501.18528v1","updated":"2025-01-30T17:46:17Z","published":"2025-01-30T17:46:17Z","title":"Joint Learning of Energy-based Models and their Partition Function","summary":"  Energy-based models (EBMs) offer a flexible framework for parameterizing\nprobability distributions using neural networks. However, learning EBMs by\nexact maximum likelihood estimation (MLE) is generally intractable, due to the\nneed to compute the partition function (normalization constant). In this paper,\nwe propose a novel formulation for approximately learning probabilistic EBMs in\ncombinatorially-large discrete spaces, such as sets or permutations. Our key\nidea is to jointly learn both an energy model and its log-partition, both\nparameterized as a neural network. Our approach not only provides a novel\ntractable objective criterion to learn EBMs by stochastic gradient descent\n(without relying on MCMC), but also a novel means to estimate the log-partition\nfunction on unseen data points. On the theoretical side, we show that our\napproach recovers the optimal MLE solution when optimizing in the space of\ncontinuous functions. Furthermore, we show that our approach naturally extends\nto the broader family of Fenchel-Young losses, allowing us to obtain the first\ntractable method for optimizing the sparsemax loss in combinatorially-large\nspaces. We demonstrate our approach on multilabel classification and label\nranking.\n","authors":["Michael E. Sander","Vincent Roulet","Tianlin Liu","Mathieu Blondel"],"pdf_url":"https://arxiv.org/pdf/2501.18528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18527v1","updated":"2025-01-30T17:44:34Z","published":"2025-01-30T17:44:34Z","title":"Neural Discovery in Mathematics: Do Machines Dream of Colored Planes?","summary":"  We demonstrate how neural networks can drive mathematical discovery through a\ncase study of the Hadwiger-Nelson problem, a long-standing open problem from\ndiscrete geometry and combinatorics about coloring the plane avoiding\nmonochromatic unit-distance pairs. Using neural networks as approximators, we\nreformulate this mixed discrete-continuous geometric coloring problem as an\noptimization task with a probabilistic, differentiable loss function. This\nenables gradient-based exploration of admissible configurations that most\nsignificantly led to the discovery of two novel six-colorings, providing the\nfirst improvements in thirty years to the off-diagonal variant of the original\nproblem (Mundinger et al., 2024a). Here, we establish the underlying machine\nlearning approach used to obtain these results and demonstrate its broader\napplicability through additional results and numerical insights.\n","authors":["Konrad Mundinger","Max Zimmer","Aldo Kiem","Christoph Spiegel","Sebastian Pokutta"],"pdf_url":"https://arxiv.org/pdf/2501.18527v1.pdf","comment":"8 pages main paper, 10 pages references and appendix, 17 figures, 1\n  table"},{"id":"http://arxiv.org/abs/2310.20671v2","updated":"2025-01-30T17:44:06Z","published":"2023-10-31T17:32:11Z","title":"Density Matrix Emulation of Quantum Recurrent Neural Networks for\n  Multivariate Time Series Prediction","summary":"  Quantum Recurrent Neural Networks (QRNNs) are robust candidates for modelling\nand predicting future values in multivariate time series. However, the\neffective implementation of some QRNN models is limited by the need for\nmid-circuit measurements. Those increase the requirements for quantum hardware,\nwhich in the current NISQ era does not allow reliable computations. Emulation\narises as the main near-term alternative to explore the potential of QRNNs, but\nexisting quantum emulators are not dedicated to circuits with multiple\nintermediate measurements. In this context, we design a specific emulation\nmethod that relies on density matrix formalism. Using a compact tensor\nnotation, we provide the mathematical formulation of the operator-sum\nrepresentation involved. This allows us to show how the present and past\ninformation from a time series is transmitted through the circuit, and how to\nreduce the computational cost in every time step of the emulated network. In\naddition, we derive the analytical gradient and the Hessian of the network\noutputs with respect to its trainable parameters, which are needed when the\noutputs have stochastic noise due to hardware errors and a finite number of\ncircuit shots (sampling). We finally test the presented methods using a\nhardware-efficient ansatz and four diverse datasets that include univariate and\nmultivariate time series, with and without sampling noise. In addition, we\ncompare the model with other existing quantum and classical approaches. Our\nresults show how QRNNs can be trained with numerical and analytical gradients\nto make accurate predictions of future values by capturing non-trivial patterns\nof input series with different complexities.\n","authors":["José Daniel Viqueira","Daniel Faílde","Mariamo M. Juane","Andrés Gómez","David Mera"],"pdf_url":"https://arxiv.org/pdf/2310.20671v2.pdf","comment":"19 pages, 8 figures"},{"id":"http://arxiv.org/abs/2501.13919v2","updated":"2025-01-30T17:35:08Z","published":"2025-01-23T18:58:03Z","title":"Temporal Preference Optimization for Long-Form Video Understanding","summary":"  Despite significant advancements in video large multimodal models\n(video-LMMs), achieving effective temporal grounding in long-form videos\nremains a challenge for existing models. To address this limitation, we propose\nTemporal Preference Optimization (TPO), a novel post-training framework\ndesigned to enhance the temporal grounding capabilities of video-LMMs through\npreference learning. TPO adopts a self-training approach that enables models to\ndifferentiate between well-grounded and less accurate temporal responses by\nleveraging curated preference datasets at two granularities: localized temporal\ngrounding, which focuses on specific video segments, and comprehensive temporal\ngrounding, which captures extended temporal dependencies across entire video\nsequences. By optimizing on these preference datasets, TPO significantly\nenhances temporal understanding while reducing reliance on manually annotated\ndata. Extensive experiments on three long-form video understanding\nbenchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness\nof TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO\nestablishes itself as the leading 7B model on the Video-MME benchmark,\nunderscoring the potential of TPO as a scalable and efficient solution for\nadvancing temporal reasoning in long-form video understanding. Project page:\nhttps://ruili33.github.io/tpo_website.\n","authors":["Rui Li","Xiaohan Wang","Yuhui Zhang","Zeyu Wang","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2501.13919v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20095v3","updated":"2025-01-30T17:34:37Z","published":"2024-06-28T17:59:12Z","title":"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy","summary":"  Vision Language Models (VLMs) have recently been leveraged to generate\nrobotic actions, forming Vision-Language-Action (VLA) models. However, directly\nadapting a pretrained VLM for robotic control remains challenging, particularly\nwhen constrained by a limited number of robot demonstrations. In this work, we\nintroduce LLaRA: Large Language and Robotics Assistant, a framework that\nformulates robot action policy as visuo-textual conversations and enables an\nefficient transfer of a pretrained VLM into a powerful VLA, motivated by the\nsuccess of visual instruction tuning in Computer Vision. First, we present an\nautomated pipeline to generate conversation-style instruction tuning data for\nrobots from existing behavior cloning datasets, aligning robotic actions with\nimage pixel coordinates. Further, we enhance this dataset in a self-supervised\nmanner by defining six auxiliary tasks, without requiring any additional action\nannotations. We show that a VLM finetuned with a limited amount of such\ndatasets can produce meaningful action decisions for robotic control. Through\nexperiments across multiple simulated and real-world tasks, we demonstrate that\nLLaRA achieves state-of-the-art performance while preserving the generalization\ncapabilities of large language models. The code, datasets, and pretrained\nmodels are available at https://github.com/LostXine/LLaRA.\n","authors":["Xiang Li","Cristina Mata","Jongwoo Park","Kumara Kahatapitiya","Yoo Sung Jang","Jinghuan Shang","Kanchana Ranasinghe","Ryan Burgert","Mu Cai","Yong Jae Lee","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2406.20095v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.18511v1","updated":"2025-01-30T17:21:44Z","published":"2025-01-30T17:21:44Z","title":"WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in\n  Post-Training","summary":"  Language model (LLM) post-training, from DPO to distillation, can refine\nbehaviors and unlock new skills, but the open science supporting these\npost-training techniques is still in its infancy. One limiting factor has been\nthe difficulty of conducting large-scale comparative analyses of synthetic data\ngenerating models and LLM judges. To close this gap, we introduce WILDCHAT-50M,\nthe largest public chat dataset to date. We extend the existing WildChat\ndataset to include responses not only from GPT, but from over 50 different\nopen-weight models, ranging in size from 0.5B to 104B parameters. We conduct an\nextensive comparative analysis and demonstrate the potential of this dataset by\ncreating RE-WILD, our own public SFT mix, which outperforms the recent Tulu-3\nSFT mixture from Allen AI with only 40% as many samples. Our dataset, samples\nand code are available at https://github.com/penfever/wildchat-50m.\n","authors":["Benjamin Feuer","Chinmay Hegde"],"pdf_url":"https://arxiv.org/pdf/2501.18511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18501v1","updated":"2025-01-30T17:11:34Z","published":"2025-01-30T17:11:34Z","title":"Beyond Prior Limits: Addressing Distribution Misalignment in Particle\n  Filtering","summary":"  Particle filtering is a Bayesian inference method and a fundamental tool in\nstate estimation for dynamic systems, but its effectiveness is often limited by\nthe constraints of the initial prior distribution, a phenomenon we define as\nthe Prior Boundary Phenomenon. This challenge arises when target states lie\noutside the prior's support, rendering traditional particle filtering methods\ninadequate for accurate estimation. Although techniques like unbounded priors\nand larger particle sets have been proposed, they remain computationally\nprohibitive and lack adaptability in dynamic scenarios. To systematically\novercome these limitations, we propose the Diffusion-Enhanced Particle\nFiltering Framework, which introduces three key innovations: adaptive diffusion\nthrough exploratory particles, entropy-driven regularisation to prevent weight\ncollapse, and kernel-based perturbations for dynamic support expansion. These\nmechanisms collectively enable particle filtering to explore beyond prior\nboundaries, ensuring robust state estimation for out-of-boundary targets.\nTheoretical analysis and extensive experiments validate framework's\neffectiveness, indicating significant improvements in success rates and\nestimation accuracy across high-dimensional and non-convex scenarios.\n","authors":["Yiwei Shi","Jingyu Hu","Yu Zhang","Mengyue Yang","Weinan Zhang","Cunjia Liu","Weiru Liu"],"pdf_url":"https://arxiv.org/pdf/2501.18501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14210v2","updated":"2025-01-30T17:08:18Z","published":"2023-12-21T10:07:52Z","title":"Fold Bifurcation Identification through Scientific Machine Learning","summary":"  This study employs scientific machine learning to identify transient time\nseries of dynamical systems near a fold bifurcation of periodic solutions. The\nunique aspect of this work is that a convolutional neural network (CNN) is\ntrained with a relatively small amount of data and on a single, very simple\nsystem, yet it is tested on much more complicated systems. This task requires\nstrong generalization capabilities, which are achieved by incorporating\nphysics-based information. This information is provided through a specific\npre-processing of the input data, which includes transformation into polar\ncoordinates, normalization, transformation into the logarithmic scale, and\nfiltering through a moving mean. The results demonstrate that such data\npre-processing enables the CNN to grasp the important features related to\ntransient time-series near a fold bifurcation, namely, the trend of the\noscillation amplitude, and disregard other characteristics that are not\nparticularly relevant, such as the vibration frequency. The developed CNN was\nable to correctly classify transient trajectories near a fold for a\nmass-on-moving-belt system, a van der Pol-Duffing oscillator with an attached\ntuned mass damper, and a pitch-and-plunge wing profile. The results contribute\nto the progress towards the development of similar CNNs effective in real-life\napplications such as safety monitoring of dynamical systems.\n","authors":["Giuseppe Habib","Ádám Horváth"],"pdf_url":"https://arxiv.org/pdf/2312.14210v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18494v1","updated":"2025-01-30T17:07:24Z","published":"2025-01-30T17:07:24Z","title":"Runway vs. Taxiway: Challenges in Automated Line Identification and\n  Notation Approaches","summary":"  The increasing complexity of autonomous systems has amplified the need for\naccurate and reliable labeling of runway and taxiway markings to ensure\noperational safety. Precise detection and labeling of these markings are\ncritical for tasks such as navigation, landing assistance, and ground control\nautomation. Existing labeling algorithms, like the Automated Line\nIdentification and Notation Algorithm (ALINA), have demonstrated success in\nidentifying taxiway markings but encounter significant challenges when applied\nto runway markings. This limitation arises due to notable differences in line\ncharacteristics, environmental context, and interference from elements such as\nshadows, tire marks, and varying surface conditions. To address these\nchallenges, we modified ALINA by adjusting color thresholds and refining region\nof interest (ROI) selection to better suit runway-specific contexts. While\nthese modifications yielded limited improvements, the algorithm still struggled\nwith consistent runway identification, often mislabeling elements such as the\nhorizon or non-relevant background features. This highlighted the need for a\nmore robust solution capable of adapting to diverse visual interferences. In\nthis paper, we propose integrating a classification step using a Convolutional\nNeural Network (CNN) named AssistNet. By incorporating this classification\nstep, the detection pipeline becomes more resilient to environmental variations\nand misclassifications. This work not only identifies the challenges but also\noutlines solutions, paving the way for improved automated labeling techniques\nessential for autonomous aviation systems.\n","authors":["Parth Ganeriwala","Amy Alvarez","Abdullah AlQahtani","Siddhartha Bhattacharyya","Mohammed Abdul Hafeez Khan","Natasha Neogi"],"pdf_url":"https://arxiv.org/pdf/2501.18494v1.pdf","comment":"Accepted at SysCon 2025"},{"id":"http://arxiv.org/abs/2501.18492v1","updated":"2025-01-30T17:06:06Z","published":"2025-01-30T17:06:06Z","title":"GuardReasoner: Towards Reasoning-based LLM Safeguards","summary":"  As LLMs increasingly impact safety-critical applications, ensuring their\nsafety using guardrails remains a key challenge. This paper proposes\nGuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to\nreason. Concretely, we first create the GuardReasonerTrain dataset, which\nconsists of 127K samples with 460K detailed reasoning steps. Then, we introduce\nreasoning SFT to unlock the reasoning capability of guard models. In addition,\nwe present hard sample DPO to further strengthen their reasoning ability. In\nthis manner, GuardReasoner achieves better performance, explainability, and\ngeneralizability. Extensive experiments and analyses on 13 benchmarks of 3\nguardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B\nsurpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on\naverage. We release the training data, code, and models with different scales\n(1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.\n","authors":["Yue Liu","Hongcheng Gao","Shengfang Zhai","Jun Xia","Tianyi Wu","Zhiwei Xue","Yulin Chen","Kenji Kawaguchi","Jiaheng Zhang","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2501.18492v1.pdf","comment":"22 pages, 18 figures"},{"id":"http://arxiv.org/abs/2408.14677v2","updated":"2025-01-30T17:04:51Z","published":"2024-08-26T22:57:01Z","title":"Can Optimization Trajectories Explain Multi-Task Transfer?","summary":"  Despite the widespread adoption of multi-task training in deep learning,\nlittle is understood about how multi-task learning (MTL) affects\ngeneralization. Prior work has conjectured that the negative effects of MTL are\ndue to optimization challenges that arise during training, and many\noptimization methods have been proposed to improve multi-task performance.\nHowever, recent work has shown that these methods fail to consistently improve\nmulti-task generalization. In this work, we seek to improve our understanding\nof these failures by empirically studying how MTL impacts the optimization of\ntasks, and whether this impact can explain the effects of MTL on\ngeneralization. We show that MTL results in a generalization gap (a gap in\ngeneralization at comparable training loss) between single-task and multi-task\ntrajectories early into training. However, we find that factors of the\noptimization trajectory previously proposed to explain generalization gaps in\nsingle-task settings cannot explain the generalization gaps between single-task\nand multi-task models. Moreover, we show that the amount of gradient conflict\nbetween tasks is correlated with negative effects to task optimization, but is\nnot predictive of generalization. Our work sheds light on the underlying causes\nfor failures in MTL and, importantly, raises questions about the role of\ngeneral purpose multi-task optimization algorithms.\n","authors":["David Mueller","Mark Dredze","Nicholas Andrews"],"pdf_url":"https://arxiv.org/pdf/2408.14677v2.pdf","comment":"13 pages; Published in TMLR"},{"id":"http://arxiv.org/abs/2412.08009v3","updated":"2025-01-30T17:02:31Z","published":"2024-12-11T01:28:48Z","title":"FLRONet: Deep Operator Learning for High-Fidelity Fluid Flow Field\n  Reconstruction from Sparse Sensor Measurements","summary":"  Reconstructing high-fidelity fluid flow fields from sparse sensor\nmeasurements is vital for many science and engineering applications but remains\nchallenging because of dimensional disparities between state and observational\nspaces. Due to such dimensional differences, the measurement operator becomes\nill-conditioned and non-invertible, making the reconstruction of flow fields\nfrom sensor measurements extremely difficult. Although sparse optimization and\nmachine learning address the above problems to some extent, questions about\ntheir generalization and efficiency remain, particularly regarding the\ndiscretization dependence of these models. In this context, deep operator\nlearning offers a better solution as this approach models mappings between\ninfinite-dimensional functional spaces, enabling superior generalization and\ndiscretization-independent reconstruction. We introduce FLRONet, a deep\noperator learning framework that is trained to reconstruct fluid flow fields\nfrom sparse sensor measurements. FLRONet employs a branch-trunk network\narchitecture to represent the inverse measurement operator that maps sensor\nobservations to the original flow field, a continuous function of both space\nand time. Validation performed on the CFDBench dataset has demonstrated that\nFLRONet consistently achieves high levels of reconstruction accuracy and\nrobustness, even in scenarios where sensor measurements are inaccurate or\nmissing. Furthermore, the operator learning approach endows FLRONet with the\ncapability to perform zero-shot super-resolution in both spatial and temporal\ndomains, offering a solution for rapid reconstruction of high-fidelity flow\nfields.\n","authors":["Hiep Vo Dang","Joseph B. Choi","Phong C. H. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2412.08009v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12394v2","updated":"2025-01-30T16:55:54Z","published":"2024-02-16T20:19:28Z","title":"Improving Model's Interpretability and Reliability using Biomarkers","summary":"  Accurate and interpretable diagnostic models are crucial in the\nsafety-critical field of medicine. We investigate the interpretability of our\nproposed biomarker-based lung ultrasound diagnostic pipeline to enhance\nclinicians' diagnostic capabilities. The objective of this study is to assess\nwhether explanations from a decision tree classifier, utilizing biomarkers, can\nimprove users' ability to identify inaccurate model predictions compared to\nconventional saliency maps. Our findings demonstrate that decision tree\nexplanations, based on clinically established biomarkers, can assist clinicians\nin detecting false positives, thus improving the reliability of diagnostic\nmodels in medicine.\n","authors":["Gautam Rajendrakumar Gare","Tom Fox","Beam Chansangavej","Amita Krishnan","Ricardo Luis Rodriguez","Bennett P deBoisblanc","Deva Kannan Ramanan","John Michael Galeotti"],"pdf_url":"https://arxiv.org/pdf/2402.12394v2.pdf","comment":"Accepted at BIAS 2023 Conference"},{"id":"http://arxiv.org/abs/2501.18475v1","updated":"2025-01-30T16:48:15Z","published":"2025-01-30T16:48:15Z","title":"CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA\n  Initialization","summary":"  Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has\nbecome a highly efficient approach for downstream tasks, particularly in\nscenarios with limited computational resources. However, applying LoRA\ntechniques to quantized LLMs poses unique challenges due to the reduced\nrepresentational precision of quantized weights. In this paper, we introduce\nCLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic\ninitialization strategy designed to overcome these challenges. Our approach\nfocuses on minimizing the layer-wise discrepancy between the original LLM and\nits quantized counterpart with LoRA components during initialization. By\nleveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM and\ndetermines the optimal LoRA components for each layer, ensuring a strong\nfoundation for subsequent fine-tuning. A key contribution of this work is a\nnovel theoretical result that enables the accurate and closed-form construction\nof these optimal LoRA components. We validate the efficacy of CLoQ across\nmultiple tasks such as language generation, arithmetic reasoning, and\ncommonsense reasoning, demonstrating that it consistently outperforms existing\nLoRA fine-tuning methods for quantized LLMs, especially at ultra low-bit\nwidths.\n","authors":["Yanxia Deng","Aozhong Zhang","Naigang Wang","Selcuk Gurses","Zi Yang","Penghang Yin"],"pdf_url":"https://arxiv.org/pdf/2501.18475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18470v1","updated":"2025-01-30T16:44:49Z","published":"2025-01-30T16:44:49Z","title":"Resampling Filter Design for Multirate Neural Audio Effect Processing","summary":"  Neural networks have become ubiquitous in audio effects modelling, especially\nfor guitar amplifiers and distortion pedals. One limitation of such models is\nthat the sample rate of the training data is implicitly encoded in the model\nweights and therefore not readily adjustable at inference. Recent work explored\nmodifications to recurrent neural network architecture to approximate a sample\nrate independent system, enabling audio processing at a rate that differs from\nthe original training rate. This method works well for integer oversampling and\ncan reduce aliasing caused by nonlinear activation functions. For small\nfractional changes in sample rate, fractional delay filters can be used to\napproximate sample rate independence, but in some cases this method fails\nentirely. Here, we explore the use of signal resampling at the input and output\nof the neural network as an alternative solution. We investigate several\nresampling filter designs and show that a two-stage design consisting of a\nhalf-band IIR filter cascaded with a Kaiser window FIR filter can give similar\nor better results to the previously proposed model adjustment method with many\nfewer operations per sample and less than one millisecond of latency at typical\naudio rates. Furthermore, we investigate interpolation and decimation filters\nfor the task of integer oversampling and show that cascaded half-band IIR and\nFIR designs can be used in conjunction with the model adjustment method to\nreduce aliasing in a range of distortion effect models.\n","authors":["Alistair Carson","Vesa Välimäki","Alec Wright","Stefan Bilbao"],"pdf_url":"https://arxiv.org/pdf/2501.18470v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.03249v3","updated":"2025-01-30T16:31:31Z","published":"2024-10-04T09:14:11Z","title":"How Much Can We Forget about Data Contamination?","summary":"  The leakage of benchmark data into the training data has emerged as a\nsignificant challenge for evaluating the capabilities of large language models\n(LLMs). In this work, we challenge the common assumption that small-scale\ncontamination renders benchmark evaluations invalid. First, we experimentally\nquantify the magnitude of benchmark overfitting based on scaling along three\ndimensions: The number of model parameters (up to 1.6B), the number of times an\nexample is seen (up to 144), and the number of training tokens (up to 40B). If\nmodel and data follow the Chinchilla scaling laws, minor contamination indeed\nleads to overfitting. At the same time, even 144 times of contamination can be\nforgotten if the training data is scaled beyond five times Chinchilla, a regime\ncharacteristic of many modern LLMs. Continual pre-training of OLMo-7B\ncorroborates these results. Next, we study the impact of the weight decay\nparameter on example forgetting, showing that empirical forgetting occurs\nfaster than the cumulative weight decay. This allows us to gauge the degree of\nexample forgetting in large-scale training runs, indicating that many LLMs,\nincluding Lllama 3 405B, have forgotten the data seen at the beginning of\ntraining.\n","authors":["Sebastian Bordt","Suraj Srinivas","Valentyn Boreiko","Ulrike von Luxburg"],"pdf_url":"https://arxiv.org/pdf/2410.03249v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12920v4","updated":"2025-01-30T16:31:27Z","published":"2024-04-19T14:43:48Z","title":"Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models","summary":"  Localizing the exact pathological regions in a given medical scan is an\nimportant imaging problem that traditionally requires a large amount of\nbounding box ground truth annotations to be accurately solved. However, there\nexist alternative, potentially weaker, forms of supervision, such as\naccompanying free-text reports, which are readily available. The task of\nperforming localization with textual guidance is commonly referred to as phrase\ngrounding. In this work, we use a publicly available Foundation Model, namely\nthe Latent Diffusion Model, to perform this challenging task. This choice is\nsupported by the fact that the Latent Diffusion Model, despite being generative\nin nature, contains cross-attention mechanisms that implicitly align visual and\ntextual features, thus leading to intermediate representations that are\nsuitable for the task at hand. In addition, we aim to perform this task in a\nzero-shot manner, i.e., without any training on the target task, meaning that\nthe model's weights remain frozen. To this end, we devise strategies to select\nfeatures and also refine them via post-processing without extra learnable\nparameters. We compare our proposed method with state-of-the-art approaches\nwhich explicitly enforce image-text alignment in a joint embedding space via\ncontrastive learning. Results on a popular chest X-ray benchmark indicate that\nour method is competitive with SOTA on different types of pathology, and even\noutperforms them on average in terms of two metrics (mean IoU and AUC-ROC).\nSource code will be released upon acceptance at https://github.com/vios-s.\n","authors":["Konstantinos Vilouras","Pedro Sanchez","Alison Q. O'Neil","Sotirios A. Tsaftaris"],"pdf_url":"https://arxiv.org/pdf/2404.12920v4.pdf","comment":"10 pages, 3 figures, IEEE J-BHI Special Issue on Foundation Models in\n  Medical Imaging"},{"id":"http://arxiv.org/abs/2411.03671v2","updated":"2025-01-30T16:30:15Z","published":"2024-11-06T05:10:20Z","title":"Energy-based physics-informed neural network for frictionless contact\n  problems under large deformation","summary":"  Numerical methods for contact mechanics are of great importance in\nengineering applications, enabling the prediction and analysis of complex\nsurface interactions under various conditions. In this work, we propose an\nenergy-based physics-informed neural network (PINNs) framework for solving\nfrictionless contact problems under large deformation. Inspired by microscopic\nLennard-Jones potential, a surface contact energy is used to describe the\ncontact phenomena. To ensure the robustness of the proposed PINN framework,\nrelaxation, gradual loading and output scaling techniques are introduced. In\nthe numerical examples, the well-known Hertz contact benchmark problem is\nconducted, demonstrating the effectiveness and robustness of the proposed PINNs\nframework. Moreover, challenging contact problems with the consideration of\ngeometrical and material nonlinearities are tested. It has been shown that the\nproposed PINNs framework provides a reliable and powerful tool for nonlinear\ncontact mechanics. More importantly, the proposed PINNs framework exhibits\ncompetitive computational efficiency to the commercial FEM software when\ndealing with those complex contact problems. The codes used in this manuscript\nare available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The code\nwill be available after acceptance)\n","authors":["Jinshuai Bai","Zhongya Lin","Yizheng Wang","Jiancong Wen","Yinghua Liu","Timon Rabczuk","YuanTong Gu","Xi-Qiao Feng"],"pdf_url":"https://arxiv.org/pdf/2411.03671v2.pdf","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.07587v5","updated":"2025-01-30T16:23:59Z","published":"2024-12-10T15:23:31Z","title":"A Hype-Adjusted Probability Measure for NLP Stock Return Forecasting","summary":"  This article introduces a Hype-Adjusted Probability Measure in the context of\na new Natural Language Processing (NLP) approach for stock return and\nvolatility forecasting. A novel sentiment score equation is proposed to\nrepresent the impact of intraday news on forecasting next-period stock return\nand volatility for selected U.S. semiconductor tickers, a very vibrant industry\nsector. This work improves the forecast accuracy by addressing news bias,\nmemory, and weight, and incorporating shifts in sentiment direction. More\nimportantly, it extends the use of the remarkable tool of change of Probability\nMeasure developed in the finance of Asset Pricing to NLP forecasting by\nconstructing a Hype-Adjusted Probability Measure, obtained from a\nredistribution of the weights in the probability space, meant to correct for\nexcessive or insufficient news.\n","authors":["Zheng Cao","Helyette Geman"],"pdf_url":"https://arxiv.org/pdf/2412.07587v5.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2501.11860v2","updated":"2025-01-30T16:16:49Z","published":"2025-01-21T03:26:16Z","title":"Bayesian Despeckling of Structured Sources","summary":"  Speckle noise is a fundamental challenge in coherent imaging systems,\nsignificantly degrading image quality. Over the past decades, numerous\ndespeckling algorithms have been developed for applications such as Synthetic\nAperture Radar (SAR) and digital holography. In this paper, we aim to establish\na theoretically grounded approach to despeckling. We propose a method\napplicable to general structured stationary stochastic sources. We demonstrate\nthe effectiveness of the proposed method on piecewise constant sources.\nAdditionally, we theoretically derive a lower bound on the despeckling\nperformance for such sources. The proposed depseckler applied to the 1-Markov\nstructured sources achieves better reconstruction performance with no strong\nsimplification of the ground truth signal model or speckle noise.\n","authors":["Ali Zafari","Shirin Jalali"],"pdf_url":"https://arxiv.org/pdf/2501.11860v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18456v1","updated":"2025-01-30T16:15:33Z","published":"2025-01-30T16:15:33Z","title":"adabmDCA 2.0 -- a flexible but easy-to-use package for Direct Coupling\n  Analysis","summary":"  In this methods article, we provide a flexible but easy-to-use implementation\nof Direct Coupling Analysis (DCA) based on Boltzmann machine learning, together\nwith a tutorial on how to use it. The package \\texttt{adabmDCA 2.0} is\navailable in different programming languages (C++, Julia, Python) usable on\ndifferent architectures (single-core and multi-core CPU, GPU) using a common\nfront-end interface. In addition to several learning protocols for dense and\nsparse generative DCA models, it allows to directly address common downstream\ntasks like residue-residue contact prediction, mutational-effect prediction,\nscoring of sequence libraries and generation of artificial sequences for\nsequence design. It is readily applicable to protein and RNA sequence data.\n","authors":["Lorenzo Rosset","Roberto Netti","Anna Paola Muntoni","Martin Weigt","Francesco Zamponi"],"pdf_url":"https://arxiv.org/pdf/2501.18456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18452v1","updated":"2025-01-30T16:05:35Z","published":"2025-01-30T16:05:35Z","title":"Clustering Properties of Self-Supervised Learning","summary":"  Self-supervised learning (SSL) methods via joint embedding architectures have\nproven remarkably effective at capturing semantically rich representations with\nstrong clustering properties, magically in the absence of label supervision.\nDespite this, few of them have explored leveraging these untapped properties to\nimprove themselves. In this paper, we provide an evidence through various\nmetrics that the encoder's output $encoding$ exhibits superior and more stable\nclustering properties compared to other components. Building on this insight,\nwe propose a novel positive-feedback SSL method, termed Representation Soft\nAssignment (ReSA), which leverages the model's clustering properties to promote\nlearning in a self-guided manner. Extensive experiments on standard SSL\nbenchmarks reveal that models pretrained with ReSA outperform other\nstate-of-the-art SSL methods by a significant margin. Finally, we analyze how\nReSA facilitates better clustering properties, demonstrating that it\neffectively enhances clustering performance at both fine-grained and\ncoarse-grained levels, shaping representations that are inherently more\nstructured and semantically meaningful.\n","authors":["Xi Weng","Jianing An","Xudong Ma","Binhang Qi","Jie Luo","Xi Yang","Jin Song Dong","Lei Huang"],"pdf_url":"https://arxiv.org/pdf/2501.18452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17556v2","updated":"2025-01-30T15:57:56Z","published":"2024-05-27T18:00:03Z","title":"Probabilistic Verification of Neural Networks using Branch and Bound","summary":"  Probabilistic verification of neural networks is concerned with formally\nanalysing the output distribution of a neural network under a probability\ndistribution of the inputs. Examples of probabilistic verification include\nverifying the demographic parity fairness notion or quantifying the safety of a\nneural network. We present a new algorithm for the probabilistic verification\nof neural networks based on an algorithm for computing and iteratively refining\nlower and upper bounds on probabilities over the outputs of a neural network.\nBy applying state-of-the-art bound propagation and branch and bound techniques\nfrom non-probabilistic neural network verification, our algorithm significantly\noutpaces existing probabilistic verification algorithms, reducing solving times\nfor various benchmarks from the literature from tens of minutes to tens of\nseconds. Furthermore, our algorithm compares favourably even to dedicated\nalgorithms for restricted subsets of probabilistic verification. We complement\nour empirical evaluation with a theoretical analysis, proving that our\nalgorithm is sound and, under mildly restrictive conditions, also complete when\nusing a suitable set of heuristics.\n","authors":["David Boetius","Stefan Leue","Tobias Sutter"],"pdf_url":"https://arxiv.org/pdf/2405.17556v2.pdf","comment":"Code available at https://github.com/sen-uni-kn/probspecs; 19 pages,\n  3 figures, 30 pages references and appendix, including 7 more figures"},{"id":"http://arxiv.org/abs/2305.15881v2","updated":"2025-01-30T15:55:29Z","published":"2023-05-25T09:23:33Z","title":"Generative Adversarial Reduced Order Modelling","summary":"  In this work, we present GAROM, a new approach for reduced order modelling\n(ROM) based on generative adversarial networks (GANs). GANs have the potential\nto learn data distribution and generate more realistic data. While widely\napplied in many areas of deep learning, little research is done on their\napplication for ROM, i.e. approximating a high-fidelity model with a simpler\none. In this work, we combine the GAN and ROM framework, by introducing a\ndata-driven generative adversarial model able to learn solutions to parametric\ndifferential equations. The latter is achieved by modelling the discriminator\nnetwork as an autoencoder, extracting relevant features of the input, and\napplying a conditioning mechanism to the generator and discriminator networks\nspecifying the differential equation parameters. We show how to apply our\nmethodology for inference, provide experimental evidence of the model\ngeneralisation, and perform a convergence study of the method.\n","authors":["Dario Coscia","Nicola Demo","Gianluigi Rozza"],"pdf_url":"https://arxiv.org/pdf/2305.15881v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18439v1","updated":"2025-01-30T15:47:59Z","published":"2025-01-30T15:47:59Z","title":"MolGraph-xLSTM: A graph-based dual-level xLSTM framework with multi-head\n  mixture-of-experts for enhanced molecular representation and interpretability","summary":"  Predicting molecular properties is essential for drug discovery, and\ncomputational methods can greatly enhance this process. Molecular graphs have\nbecome a focus for representation learning, with Graph Neural Networks (GNNs)\nwidely used. However, GNNs often struggle with capturing long-range\ndependencies. To address this, we propose MolGraph-xLSTM, a novel graph-based\nxLSTM model that enhances feature extraction and effectively models molecule\nlong-range interactions.\n  Our approach processes molecular graphs at two scales: atom-level and\nmotif-level. For atom-level graphs, a GNN-based xLSTM framework with jumping\nknowledge extracts local features and aggregates multilayer information to\ncapture both local and global patterns effectively. Motif-level graphs provide\ncomplementary structural information for a broader molecular view. Embeddings\nfrom both scales are refined via a multi-head mixture of experts (MHMoE),\nfurther enhancing expressiveness and performance.\n  We validate MolGraph-xLSTM on 10 molecular property prediction datasets,\ncovering both classification and regression tasks. Our model demonstrates\nconsistent performance across all datasets, with improvements of up to 7.03% on\nthe BBBP dataset for classification and 7.54% on the ESOL dataset for\nregression compared to baselines. On average, MolGraph-xLSTM achieves an AUROC\nimprovement of 3.18\\% for classification tasks and an RMSE reduction of 3.83\\%\nacross regression datasets compared to the baseline methods. These results\nconfirm the effectiveness of our model, offering a promising solution for\nmolecular representation learning for drug discovery.\n","authors":["Yan Sun","Yutong Lu","Yan Yi Li","Zihao Jing","Carson K. Leung","Pingzhao Hu"],"pdf_url":"https://arxiv.org/pdf/2501.18439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10898v2","updated":"2025-01-30T15:47:33Z","published":"2024-09-17T05:26:59Z","title":"LLMs & XAI for Water Sustainability: Seasonal Water Quality Prediction\n  with LIME Explainable AI and a RAG-based Chatbot for Insights","summary":"  Ensuring safe water supplies requires effective water quality monitoring,\nespecially in developing countries like Nepal, where contamination risks are\nhigh. This paper introduces a hybrid deep learning model to predict Nepal's\nseasonal water quality using a small dataset with multiple water quality\nparameters. Models such as CatBoost, XGBoost, Extra Trees, and LightGBM, along\nwith a neural network combining CNN and RNN layers, are used to capture\ntemporal and spatial patterns in the data. The model demonstrated notable\naccuracy improvements, aiding proactive water quality control. CatBoost,\nXGBoost, and Extra Trees Regressor predicted Water Quality Index (WQI) values\nwith an average RMSE of 1.2 and an R2 score of 0.99. Additionally, classifiers\nachieved 99 percent accuracy, cross-validated across models. LIME analysis\nhighlighted the importance of indicators like EC and DO levels in XGBoost\nclassification decisions. The neural network model achieved 92 percent\nclassification accuracy and an R2 score of 0.97, with an RMSE of 2.87 in\nregression analysis. Furthermore, a multifunctional application was developed\nto predict WQI values using both regression and classification methods.\n","authors":["Biplov Paneru","Bishwash Paneru"],"pdf_url":"https://arxiv.org/pdf/2409.10898v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18417v2","updated":"2025-01-30T15:45:45Z","published":"2024-10-24T04:02:30Z","title":"Large Language Models Reflect the Ideology of their Creators","summary":"  Large language models (LLMs) are trained on vast amounts of data to generate\nnatural language, enabling them to perform tasks like text summarization and\nquestion answering. These models have become popular in artificial intelligence\n(AI) assistants like ChatGPT and already play an influential role in how humans\naccess information. However, the behavior of LLMs varies depending on their\ndesign, training, and use.\n  In this paper, we prompt a diverse panel of popular LLMs to describe a large\nnumber of prominent personalities with political relevance, in all six official\nlanguages of the United Nations. By identifying and analyzing moral assessments\nreflected in their responses, we find normative differences between LLMs from\ndifferent geopolitical regions, as well as between the responses of the same\nLLM when prompted in different languages. Among only models in the United\nStates, we find that popularly hypothesized disparities in political views are\nreflected in significant normative differences related to progressive values.\nAmong Chinese models, we characterize a division between internationally- and\ndomestically-focused models.\n  Our results show that the ideological stance of an LLM appears to reflect the\nworldview of its creators. This poses the risk of political instrumentalization\nand raises concerns around technological and regulatory efforts with the stated\naim of making LLMs ideologically 'unbiased'.\n","authors":["Maarten Buyl","Alexander Rogiers","Sander Noels","Guillaume Bied","Iris Dominguez-Catena","Edith Heiter","Iman Johary","Alexandru-Cristian Mara","Raphaël Romero","Jefrey Lijffijt","Tijl De Bie"],"pdf_url":"https://arxiv.org/pdf/2410.18417v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02810v2","updated":"2025-01-30T15:36:39Z","published":"2024-12-03T20:20:39Z","title":"Universal Rates of Empirical Risk Minimization","summary":"  The well-known empirical risk minimization (ERM) principle is the basis of\nmany widely used machine learning algorithms, and plays an essential role in\nthe classical PAC theory. A common description of a learning algorithm's\nperformance is its so-called \"learning curve\", that is, the decay of the\nexpected error as a function of the input sample size. As the PAC model fails\nto explain the behavior of learning curves, recent research has explored an\nalternative universal learning model and has ultimately revealed a distinction\nbetween optimal universal and uniform learning rates (Bousquet et al., 2021).\nHowever, a basic understanding of such differences with a particular focus on\nthe ERM principle has yet to be developed.\n  In this paper, we consider the problem of universal learning by ERM in the\nrealizable case and study the possible universal rates. Our main result is a\nfundamental tetrachotomy: there are only four possible universal learning rates\nby ERM, namely, the learning curves of any concept class learnable by ERM decay\neither at $e^{-n}$, $1/n$, $\\log(n)/n$, or arbitrarily slow rates. Moreover, we\nprovide a complete characterization of which concept classes fall into each of\nthese categories, via new complexity structures. We also develop new\ncombinatorial dimensions which supply sharp asymptotically-valid constant\nfactors for these rates, whenever possible.\n","authors":["Steve Hanneke","Mingyue Xu"],"pdf_url":"https://arxiv.org/pdf/2412.02810v2.pdf","comment":"This paper has been accepted to the 38th Conference on Neural\n  Information Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2404.10995v2","updated":"2025-01-30T15:32:08Z","published":"2024-04-17T02:17:05Z","title":"Clipped SGD Algorithms for Performative Prediction: Tight Bounds for\n  Clipping Bias and Remedies","summary":"  This paper studies the convergence of clipped stochastic gradient descent\n(SGD) algorithms with decision-dependent data distribution. Our setting is\nmotivated by privacy preserving optimization algorithms that interact with\nperformative data where the prediction models can influence future outcomes.\nThis challenging setting involves the non-smooth clipping operator and\nnon-gradient dynamics due to distribution shifts. We make two contributions in\npursuit for a performative stable solution using clipped SGD algorithms. First,\nwe characterize the clipping bias with projected clipped SGD (PCSGD) algorithm\nwhich is caused by the clipping operator that prevents PCSGD from reaching a\nstable solution. When the loss function is strongly convex, we quantify the\nlower and upper bounds for this clipping bias and demonstrate a bias\namplification phenomenon with the sensitivity of data distribution. When the\nloss function is non-convex, we bound the magnitude of stationarity bias.\nSecond, we propose remedies to mitigate the bias either by utilizing an optimal\nstep size design for PCSGD, or to apply the recent DiceSGD algorithm [Zhang et\nal., 2024]. Our analysis is also extended to show that the latter algorithm is\nfree from clipping bias in the performative setting. Numerical experiments\nverify our findings.\n","authors":["Qiang Li","Michal Yemini","Hoi-To Wai"],"pdf_url":"https://arxiv.org/pdf/2404.10995v2.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2310.00965v5","updated":"2025-01-30T15:30:55Z","published":"2023-10-02T08:12:51Z","title":"Effective Learning with Node Perturbation in Multi-Layer Neural Networks","summary":"  Backpropagation (BP) remains the dominant and most successful method for\ntraining parameters of deep neural network models. However, BP relies on two\ncomputationally distinct phases, does not provide a satisfactory explanation of\nbiological learning, and can be challenging to apply for training of networks\nwith discontinuities or noisy node dynamics. By comparison, node perturbation\n(NP) proposes learning by the injection of noise into network activations, and\nsubsequent measurement of the induced loss change. NP relies on two forward\n(inference) passes, does not make use of network derivatives, and has been\nproposed as a model for learning in biological systems. However, standard NP is\nhighly data inefficient and unstable due to its unguided noise-based search\nprocess. In this work, we investigate different formulations of NP and relate\nit to the concept of directional derivatives as well as combining it with a\ndecorrelating mechanism for layer-wise inputs. We find that a closer alignment\nwith directional derivatives together with input decorrelation at every layer\nstrongly enhances performance of NP learning with large improvements in\nparameter convergence and much higher performance on the test data, approaching\nthat of BP. Furthermore, our novel formulation allows for application to noisy\nsystems in which the noise process itself is inaccessible.\n","authors":["Sander Dalm","Marcel van Gerven","Nasir Ahmad"],"pdf_url":"https://arxiv.org/pdf/2310.00965v5.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2501.18426v1","updated":"2025-01-30T15:29:41Z","published":"2025-01-30T15:29:41Z","title":"Guaranteed confidence-band enclosures for PDE surrogates","summary":"  We propose a method for obtaining statistically guaranteed confidence bands\nfor functional machine learning techniques: surrogate models which map between\nfunction spaces, motivated by the need build reliable PDE emulators. The method\nconstructs nested confidence sets on a low-dimensional representation (an SVD)\nof the surrogate model's prediction error, and then maps these sets to the\nprediction space using set-propagation techniques. The result are\nconformal-like coverage guaranteed prediction sets for functional surrogate\nmodels. We use zonotopes as basis of the set construction, due to their well\nstudied set-propagation and verification properties. The method is model\nagnostic and can thus be applied to complex Sci-ML models, including Neural\nOperators, but also in simpler settings. We also elicit a technique to capture\nthe truncation error of the SVD, ensuring the guarantees of the method.\n","authors":["Ander Gray","Vignesh Gopakumar","Sylvain Rousseau","Sébastien Destercke"],"pdf_url":"https://arxiv.org/pdf/2501.18426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02200v2","updated":"2025-01-30T15:26:39Z","published":"2024-10-03T04:30:24Z","title":"Revisiting Prefix-tuning: Statistical Benefits of Reparameterization\n  among Prompts","summary":"  Prompt-based techniques, such as prompt-tuning and prefix-tuning, have gained\nprominence for their efficiency in fine-tuning large pre-trained models.\nDespite their widespread adoption, the theoretical foundations of these methods\nremain limited. For instance, in prefix-tuning, we observe that a key factor in\nachieving performance parity with full fine-tuning lies in the\nreparameterization strategy. However, the theoretical principles underpinning\nthe effectiveness of this approach have yet to be thoroughly examined. Our\nstudy demonstrates that reparameterization is not merely an engineering trick\nbut is grounded in deep theoretical foundations. Specifically, we show that the\nreparameterization strategy implicitly encodes a shared structure between\nprefix key and value vectors. Building on recent insights into the connection\nbetween prefix-tuning and mixture of experts models, we further illustrate that\nthis shared structure significantly improves sample efficiency in parameter\nestimation compared to non-shared alternatives. The effectiveness of\nprefix-tuning across diverse tasks is empirically confirmed to be enhanced by\nthe shared structure, through extensive experiments in both visual and language\ndomains. Additionally, we uncover similar structural benefits in prompt-tuning,\noffering new perspectives on its success. Our findings provide theoretical and\nempirical contributions, advancing the understanding of prompt-based methods\nand their underlying mechanisms. Our code is publicly available at\nhttps://github.com/Minhchuyentoancbn/ReparamPrefix\n","authors":["Minh Le","Chau Nguyen","Huy Nguyen","Quyen Tran","Trung Le","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2410.02200v2.pdf","comment":"Accepted to ICLR 2025. 42 pages, 8 tables, 3 figures"},{"id":"http://arxiv.org/abs/2501.18423v1","updated":"2025-01-30T15:25:30Z","published":"2025-01-30T15:25:30Z","title":"DeepExtractor: Time-domain reconstruction of signals and glitches in\n  gravitational wave data with deep learning","summary":"  Gravitational wave (GW) interferometers, detect faint signals from distant\nastrophysical events, such as binary black hole mergers. However, their high\nsensitivity also makes them susceptible to background noise, which can obscure\nthese signals. This noise often includes transient artifacts called \"glitches\"\nthat can mimic astrophysical signals or mask their characteristics. Fast and\naccurate reconstruction of both signals and glitches is crucial for reliable\nscientific inference. In this study, we present DeepExtractor, a deep learning\nframework designed to reconstruct signals and glitches with power exceeding\ninterferometer noise, regardless of their source. We design DeepExtractor to\nmodel the inherent noise distribution of GW interferometers, following\nconventional assumptions that the noise is Gaussian and stationary over short\ntime scales. It operates by predicting and subtracting the noise component of\nthe data, retaining only the clean reconstruction. Our approach achieves\nsuperior generalization capabilities for arbitrary signals and glitches\ncompared to methods that directly map inputs to the clean training waveforms.\nWe validate DeepExtractor's effectiveness through three experiments: (1)\nreconstructing simulated glitches injected into simulated detector noise, (2)\ncomparing performance with the state-of-the-art BayesWave algorithm, and (3)\nanalyzing real data from the Gravity Spy dataset to demonstrate effective\nglitch subtraction from LIGO strain data. DeepExtractor achieves a median\nmismatch of only 0.9% for simulated glitches, outperforming several deep\nlearning baselines. Additionally, DeepExtractor surpasses BayesWave in glitch\nrecovery, offering a dramatic computational speedup by reconstructing one\nglitch sample in approx. 0.1 seconds on a CPU, compared to BayesWave's\nprocessing time of approx. one hour per glitch.\n","authors":["Tom Dooney","Harsh Narola","Stefano Bromuri","R. Lyana Curier","Chris Van Den Broeck","Sarah Caudill","Daniel Stanley Tan"],"pdf_url":"https://arxiv.org/pdf/2501.18423v1.pdf","comment":"22 pages, 16 figures, 4 tables"},{"id":"http://arxiv.org/abs/2411.07066v3","updated":"2025-01-30T15:24:28Z","published":"2024-11-11T15:30:16Z","title":"Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training","summary":"  Network pruning focuses on computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has been pruning and re-training, which nowadays\nis inconvenient due to the vast amount of pre-trained models, which are in any\ncase too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAL}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs,\nwhich modifies the block-wise and row-wise sparsity exploiting information from\nboth the dense model and its sparse version to maximize the \\emph{neuron\nalignment} among activations. Differently from existing methods, our approach\nadaptively selects the best hyperparameters for the block-wise and row-wise\nsparsity ratios w.r.t. the model and the desired sparsity, and requires\n\\emph{no re-training}. We test our method over 276 cases combining four LLM\nfamilies, three sparsity ratios, and ten language tasks (three language\nmodeling and seven zero-shot datasets), showing how it consistently outperforms\nthe latest state-of-the-art methods in terms of performance-runtime trade-off.\nThe code is available at\n\\href{https://github.com/eliacunegatti/NeuroAL}{https://github.com/eliacunegatti/NeuroAL}.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2411.07066v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2407.19540v4","updated":"2025-01-30T15:21:50Z","published":"2024-07-28T17:14:27Z","title":"Overcoming Uncertain Incompleteness for Robust Multimodal Sequential\n  Diagnosis Prediction via Curriculum Data Erasing Guided Knowledge\n  Distillation","summary":"  In this paper, we present NECHO v2, a novel framework designed to enhance the\npredictive accuracy of multimodal sequential patient diagnoses under uncertain\nmissing visit sequences, a common challenge in real clinical settings. Firstly,\nwe modify NECHO, designed in a diagnosis code-centric fashion, to handle\nuncertain modality representation dominance under the imperfect data. Secondly,\nwe develop a systematic knowledge distillation by employing the modified NECHO\nas both teacher and student. It encompasses a modality-wise contrastive and\nhierarchical distillation, transformer representation random distillation,\nalong with other distillations to align representations between teacher and\nstudent tightly and effectively. We also propose curriculum learning guided\nrandom data erasing within sequences during both training and distillation of\nthe teacher to lightly simulate scenario with missing visit information,\nthereby fostering effective knowledge transfer. As a result, NECHO v2 verifies\nitself by showing robust superiority in multimodal sequential diagnosis\nprediction under both balanced and imbalanced incomplete settings on multimodal\nhealthcare data.\n","authors":["Heejoon Koo"],"pdf_url":"https://arxiv.org/pdf/2407.19540v4.pdf","comment":"Accepted by ICASSP 2025 (2025 IEEE International Conference on\n  Acoustics, Speech, and Signal Processing)"},{"id":"http://arxiv.org/abs/2501.18417v1","updated":"2025-01-30T15:15:17Z","published":"2025-01-30T15:15:17Z","title":"Causal Inference Real-Time Anomaly Detection with Synthetic Anomaly\n  Monitoring (SAM)","summary":"  Anomaly detection is essential for identifying rare and significant events\nacross diverse domains such as finance, cybersecurity, and network monitoring.\nThis paper presents Synthetic Anomaly Monitoring (SAM), an innovative approach\nthat applies synthetic control methods from causal inference to improve both\nthe accuracy and interpretability of anomaly detection processes. By modeling\nnormal behavior through the treatment of each feature as a control unit, SAM\nidentifies anomalies as deviations within this causal framework. We conducted\nextensive experiments comparing SAM with established benchmark models,\nincluding Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors\n(kNN), and One-Class Support Vector Machine (SVM), across five diverse\ndatasets, including Credit Card Fraud, HTTP Dataset CSIC 2010, and KDD Cup\n1999, among others. Our results demonstrate that SAM consistently delivers\nrobust performance, highlighting its potential as a powerful tool for real-time\nanomaly detection in dynamic and complex environments.\n","authors":["Emanuele Luzio","Moacir Antonelli Ponti"],"pdf_url":"https://arxiv.org/pdf/2501.18417v1.pdf","comment":"19 pages, 3 figures, submitted for publication"},{"id":"http://arxiv.org/abs/2501.18416v1","updated":"2025-01-30T15:14:55Z","published":"2025-01-30T15:14:55Z","title":"Exploring Potential Prompt Injection Attacks in Federated Military LLMs\n  and Their Mitigation","summary":"  Federated Learning (FL) is increasingly being adopted in military\ncollaborations to develop Large Language Models (LLMs) while preserving data\nsovereignty. However, prompt injection attacks-malicious manipulations of input\nprompts-pose new threats that may undermine operational security, disrupt\ndecision-making, and erode trust among allies. This perspective paper\nhighlights four potential vulnerabilities in federated military LLMs: secret\ndata leakage, free-rider exploitation, system disruption, and misinformation\nspread. To address these potential risks, we propose a human-AI collaborative\nframework that introduces both technical and policy countermeasures. On the\ntechnical side, our framework uses red/blue team wargaming and quality\nassurance to detect and mitigate adversarial behaviors of shared LLM weights.\nOn the policy side, it promotes joint AI-human policy development and\nverification of security protocols. Our findings will guide future research and\nemphasize proactive strategies for emerging military contexts.\n","authors":["Youngjoon Lee","Taehyun Park","Yunho Lee","Jinu Gong","Joonhyuk Kang"],"pdf_url":"https://arxiv.org/pdf/2501.18416v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2501.18415v1","updated":"2025-01-30T15:14:30Z","published":"2025-01-30T15:14:30Z","title":"Consensus statement on the credibility assessment of ML predictors","summary":"  The rapid integration of machine learning (ML) predictors into in silico\nmedicine has revolutionized the estimation of quantities of interest (QIs) that\nare otherwise challenging to measure directly. However, the credibility of\nthese predictors is critical, especially when they inform high-stakes\nhealthcare decisions. This position paper presents a consensus statement\ndeveloped by experts within the In Silico World Community of Practice. We\noutline twelve key statements forming the theoretical foundation for evaluating\nthe credibility of ML predictors, emphasizing the necessity of causal\nknowledge, rigorous error quantification, and robustness to biases. By\ncomparing ML predictors with biophysical models, we highlight unique challenges\nassociated with implicit causal knowledge and propose strategies to ensure\nreliability and applicability. Our recommendations aim to guide researchers,\ndevelopers, and regulators in the rigorous assessment and deployment of ML\npredictors in clinical and biomedical contexts.\n","authors":["Alessandra Aldieri","Thiranja Prasad Babarenda Gamage","Antonino Amedeo La Mattina","Yi Li","Axel Loewe","Francesco Pappalardo","Marco Viceconti Italy"],"pdf_url":"https://arxiv.org/pdf/2501.18415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18413v1","updated":"2025-01-30T15:09:26Z","published":"2025-01-30T15:09:26Z","title":"GBFRS: Robust Fuzzy Rough Sets via Granular-ball Computing","summary":"  Fuzzy rough set theory is effective for processing datasets with complex\nattributes, supported by a solid mathematical foundation and closely linked to\nkernel methods in machine learning. Attribute reduction algorithms and\nclassifiers based on fuzzy rough set theory exhibit promising performance in\nthe analysis of high-dimensional multivariate complex data. However, most\nexisting models operate at the finest granularity, rendering them inefficient\nand sensitive to noise, especially for high-dimensional big data. Thus,\nenhancing the robustness of fuzzy rough set models is crucial for effective\nfeature selection. Muiti-garanularty granular-ball computing, a recent\ndevelopment, uses granular-balls of different sizes to adaptively represent and\ncover the sample space, performing learning based on these granular-balls. This\npaper proposes integrating multi-granularity granular-ball computing into fuzzy\nrough set theory, using granular-balls to replace sample points. The\ncoarse-grained characteristics of granular-balls make the model more robust.\nAdditionally, we propose a new method for generating granular-balls, scalable\nto the entire supervised method based on granular-ball computing. A forward\nsearch algorithm is used to select feature sequences by defining the\ncorrelation between features and categories through dependence functions.\nExperiments demonstrate the proposed model's effectiveness and superiority over\nbaseline methods.\n","authors":["Shuyin Xia","Xiaoyu Lian","Binbin Sang","Guoyin Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2501.18413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18405v1","updated":"2025-01-30T15:02:30Z","published":"2025-01-30T15:02:30Z","title":"Segmentation of cracks in 3d images of fiber reinforced concrete using\n  deep learning","summary":"  Cracks in concrete structures are very common and are an integral part of\nthis heterogeneous material. Characteristics of cracks induced by standardized\ntests yield valuable information about the tested concrete formulation and its\nmechanical properties. Observing cracks on the surface of the concrete\nstructure leaves a wealth of structural information unused. Computed tomography\nenables looking into the sample without interfering or destroying the\nmicrostructure. The reconstructed tomographic images are 3d images, consisting\nof voxels whose gray values represent local X-ray absorption. In order to\nidentify voxels belonging to the crack, so to segment the crack structure in\nthe images, appropriate algorithms need to be developed. Convolutional neural\nnetworks are known to solve this type of task very well given enough and\nconsistent training data. We adapted a 3d version of the well-known U-Net and\ntrained it on semi-synthetic 3d images of real concrete samples equipped with\nsimulated crack structures. Here, we explain the general approach. Moreover, we\nshow how to teach the network to detect also real crack systems in 3d images of\nvarying types of real concrete, in particular of fiber reinforced concrete.\n","authors":["Anna Nowacka","Katja Schladitz","Szymon Grzesiak","Matthias Pahn"],"pdf_url":"https://arxiv.org/pdf/2501.18405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00367v2","updated":"2025-01-30T15:01:45Z","published":"2024-10-01T03:39:12Z","title":"ROK Defense M&S in the Age of Hyperscale AI: Concepts, Challenges, and\n  Future Directions","summary":"  Integrating hyperscale AI into national defense M&S(Modeling and Simulation),\nunder the expanding IoMDT(Internet of Military Defense Things) framework, is\ncrucial for boosting strategic and operational readiness. We examine how\nIoMDT-driven hyperscale AI can provide high accuracy, speed, and the ability to\nsimulate complex, interconnected battlefield scenarios in defense M&S.\nCountries like the United States and China are leading the adoption of these\ntechnologies, with varying levels of success. However, realizing the full\npotential of hyperscale AI requires overcoming challenges such as closed\nnetworks, sparse or long-tail data, complex decision-making processes, and a\nshortage of experts. Future directions highlight the need to adopt domestic\nfoundation models, expand GPU/NPU investments, leverage large tech services,\nand employ open source solutions. These efforts will enhance national security,\nmaintain a competitive edge, and spur broader technological and economic\ngrowth. With this blueprint, the Republic of Korea can strengthen its defense\nposture and stay ahead of emerging threats in modern warfare.\n","authors":["Youngjoon Lee","Taehyun Park","Yeongjoon Kang","Jonghoe Kim","Joonhyuk Kang"],"pdf_url":"https://arxiv.org/pdf/2410.00367v2.pdf","comment":"Accepted to IEEE Internet of Things Magazine"},{"id":"http://arxiv.org/abs/2409.17931v2","updated":"2025-01-30T14:48:00Z","published":"2024-09-26T15:08:38Z","title":"Remaining Useful Life Prediction for Batteries Utilizing an Explainable\n  AI Approach with a Predictive Application for Decision-Making","summary":"  Accurately estimating the Remaining Useful Life (RUL) of a battery is\nessential for determining its lifespan and recharge requirements. In this work,\nwe develop machine learning-based models to predict and classify battery RUL.\nWe introduce a two-level ensemble learning (TLE) framework and a CNN+MLP hybrid\nmodel for RUL prediction, comparing their performance against traditional,\ndeep, and hybrid machine learning models. Our analysis evaluates various models\nfor both prediction and classification while incorporating interpretability\nthrough SHAP. The proposed TLE model consistently outperforms baseline models\nin RMSE, MAE, and R squared error, demonstrating its superior predictive\ncapabilities. Additionally, the XGBoost classifier achieves an impressive 99%\nclassification accuracy, validated through cross-validation techniques. The\nmodels effectively predict relay-based charging triggers, enabling automated\nand energy-efficient charging processes. This automation reduces energy\nconsumption and enhances battery performance by optimizing charging cycles.\nSHAP interpretability analysis highlights the cycle index and charging\nparameters as the most critical factors influencing RUL. To improve\naccessibility, we developed a Tkinter-based GUI that allows users to input new\ndata and predict RUL in real time. This practical solution supports sustainable\nbattery management by enabling data-driven decisions about battery usage and\nmaintenance, contributing to energy-efficient and innovative battery life\nprediction.\n","authors":["Biplov Paneru","Bipul Thapa","Durga Prasad Mainali","Bishwash Paneru","Krishna Bikram Shah"],"pdf_url":"https://arxiv.org/pdf/2409.17931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11962v2","updated":"2025-01-30T14:46:45Z","published":"2024-04-18T07:48:00Z","title":"©Plug-in Authorization for Human Content Copyright Protection\n  in Text-to-Image Model","summary":"  This paper addresses the contentious issue of copyright infringement in\nimages generated by text-to-image models, sparking debates among AI developers,\ncontent creators, and legal entities. State-of-the-art models create\nhigh-quality content without crediting original creators, causing concern in\nthe artistic community. To mitigate this, we propose the \\copyright Plug-in\nAuthorization framework, introducing three operations: addition, extraction,\nand combination. Addition involves training a \\copyright plug-in for specific\ncopyright, facilitating proper credit attribution. Extraction allows creators\nto reclaim copyright from infringing models, and combination enables users to\nmerge different \\copyright plug-ins. These operations act as permits,\nincentivizing fair use and providing flexibility in authorization. We present\ninnovative approaches,\"Reverse LoRA\" for extraction and \"EasyMerge\" for\nseamless combination. Experiments in artist-style replication and cartoon IP\nrecreation demonstrate \\copyright plug-ins' effectiveness, offering a valuable\nsolution for human copyright protection in the age of generative AIs. The code\nis available at https://github.com/zc1023/-Plug-in-Authorization.git.\n","authors":["Chao Zhou","Huishuai Zhang","Jiang Bian","Weiming Zhang","Nenghai Yu"],"pdf_url":"https://arxiv.org/pdf/2404.11962v2.pdf","comment":"23 pages, 12 figures"},{"id":"http://arxiv.org/abs/2501.18388v1","updated":"2025-01-30T14:38:26Z","published":"2025-01-30T14:38:26Z","title":"Improved Replicable Boosting with Majority-of-Majorities","summary":"  We introduce a new replicable boosting algorithm which significantly improves\nthe sample complexity compared to previous algorithms. The algorithm works by\ndoing two layers of majority voting, using an improved version of the\nreplicable boosting algorithm introduced by Impagliazzo et al. [2022] in the\nbottom layer.\n","authors":["Kasper Green Larsen","Markus Engelund Mathiasen","Clement Svendsen"],"pdf_url":"https://arxiv.org/pdf/2501.18388v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2411.00109v2","updated":"2025-01-30T14:36:04Z","published":"2024-10-31T18:03:17Z","title":"Prospective Learning: Learning for a Dynamic Future","summary":"  In real-world applications, the distribution of the data, and our goals,\nevolve over time. The prevailing theoretical framework for studying machine\nlearning, namely probably approximately correct (PAC) learning, largely ignores\ntime. As a consequence, existing strategies to address the dynamic nature of\ndata and goals exhibit poor real-world performance. This paper develops a\ntheoretical framework called \"Prospective Learning\" that is tailored for\nsituations when the optimal hypothesis changes over time. In PAC learning,\nempirical risk minimization (ERM) is known to be consistent. We develop a\nlearner called Prospective ERM, which returns a sequence of predictors that\nmake predictions on future data. We prove that the risk of prospective ERM\nconverges to the Bayes risk under certain assumptions on the stochastic process\ngenerating the data. Prospective ERM, roughly speaking, incorporates time as an\ninput in addition to the data. We show that standard ERM as done in PAC\nlearning, without incorporating time, can result in failure to learn when\ndistributions are dynamic. Numerical experiments illustrate that prospective\nERM can learn synthetic and visual recognition problems constructed from MNIST\nand CIFAR-10. Code at https://github.com/neurodata/prolearn.\n","authors":["Ashwin De Silva","Rahul Ramesh","Rubing Yang","Siyu Yu","Joshua T Vogelstein","Pratik Chaudhari"],"pdf_url":"https://arxiv.org/pdf/2411.00109v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.18381v1","updated":"2025-01-30T14:31:28Z","published":"2025-01-30T14:31:28Z","title":"Implicit Riemannian Optimism with Applications to Min-Max Problems","summary":"  We introduce a Riemannian optimistic online learning algorithm for Hadamard\nmanifolds based on inexact implicit updates. Unlike prior work, our method can\nhandle in-manifold constraints, and matches the best known regret bounds in the\nEuclidean setting with no dependence on geometric constants, like the minimum\ncurvature. Building on this, we develop algorithms for g-convex, g-concave\nsmooth min-max problems on Hadamard manifolds. Notably, one method nearly\nmatches the gradient oracle complexity of the lower bound for Euclidean\nproblems, for the first time.\n","authors":["Christophe Roux","David Martínez-Rubio","Sebastian Pokutta"],"pdf_url":"https://arxiv.org/pdf/2501.18381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18373v1","updated":"2025-01-30T14:26:23Z","published":"2025-01-30T14:26:23Z","title":"Function Encoders: A Principled Approach to Transfer Learning in Hilbert\n  Spaces","summary":"  A central challenge in transfer learning is designing algorithms that can\nquickly adapt and generalize to new tasks without retraining. Yet, the\nconditions of when and how algorithms can effectively transfer to new tasks is\npoorly characterized. We introduce a geometric characterization of transfer in\nHilbert spaces and define three types of inductive transfer: interpolation\nwithin the convex hull, extrapolation to the linear span, and extrapolation\noutside the span. We propose a method grounded in the theory of function\nencoders to achieve all three types of transfer. Specifically, we introduce a\nnovel training scheme for function encoders using least-squares optimization,\nprove a universal approximation theorem for function encoders, and provide a\ncomprehensive comparison with existing approaches such as transformers and\nmeta-learning on four diverse benchmarks. Our experiments demonstrate that the\nfunction encoder outperforms state-of-the-art methods on four benchmark tasks\nand on all three types of transfer.\n","authors":["Tyler Ingebrand","Adam J. Thorpe","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2501.18373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18369v1","updated":"2025-01-30T14:24:03Z","published":"2025-01-30T14:24:03Z","title":"A Cartesian Encoding Graph Neural Network for Crystal Structures\n  Property Prediction: Application to Thermal Ellipsoid Estimation","summary":"  In diffraction-based crystal structure analysis, thermal ellipsoids,\nquantified via Anisotropic Displacement Parameters (ADPs), are critical yet\nchallenging to determine. ADPs capture atomic vibrations, reflecting thermal\nand structural properties, but traditional computation is often expensive. This\npaper introduces CartNet, a novel graph neural network (GNN) for efficiently\npredicting crystal properties by encoding atomic geometry into Cartesian\ncoordinates alongside the crystal temperature. CartNet integrates a neighbour\nequalization technique to emphasize covalent and contact interactions, and a\nCholesky-based head to ensure valid ADP predictions. We also propose a\nrotational SO(3) data augmentation strategy during training to handle unseen\norientations. An ADP dataset with over 200,000 experimental crystal structures\nfrom the Cambridge Structural Database (CSD) was curated to validate the\napproach. CartNet significantly reduces computational costs and outperforms\nexisting methods in ADP prediction by 10.87%, while delivering a 34.77%\nimprovement over theoretical approaches. We further evaluated CartNet on other\ndatasets covering formation energy, band gap, total energy, energy above the\nconvex hull, bulk moduli, and shear moduli, achieving 7.71% better results on\nthe Jarvis Dataset and 13.16% on the Materials Project Dataset. These gains\nestablish CartNet as a state-of-the-art solution for diverse crystal property\npredictions. Project website and online demo: https://www.ee.ub.edu/cartnet\n","authors":["Àlex Solé","Albert Mosella-Montoro","Joan Cardona","Silvia Gómez-Coca","Daniel Aravena","Eliseo Ruiz","Javier Ruiz-Hidalgo"],"pdf_url":"https://arxiv.org/pdf/2501.18369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07601v2","updated":"2025-01-30T14:20:33Z","published":"2025-01-10T22:31:53Z","title":"Real-Time Decision-Making for Digital Twin in Additive Manufacturing\n  with Model Predictive Control using Time-Series Deep Neural Networks","summary":"  Digital Twin-a virtual replica of a physical system enabling real-time\nmonitoring, model updating, prediction, and decision-making-combined with\nrecent advances in machine learning (ML), offers new opportunities for\nproactive control strategies in autonomous manufacturing. However, achieving\nreal-time decision-making with Digital Twins requires efficient optimization\ndriven by accurate predictions of highly nonlinear manufacturing systems. This\npaper presents a simultaneous multi-step Model Predictive Control (MPC)\nframework for real-time decision-making, using a multi-variate deep neural\nnetwork (DNN), named Time-Series Dense Encoder (TiDE), as the surrogate model.\nDifferent from the models in conventional MPC which only provide one-step ahead\nprediction, TiDE is capable of predicting future states within the prediction\nhorizon in one shot (multi-step), significantly accelerating MPC. Using\nDirected Energy Deposition additive manufacturing as a case study, we\ndemonstrate the effectiveness of the proposed MPC in achieving melt pool\ntemperature tracking to ensure part quality, while reducing porosity defects by\nregulating laser power to maintain melt pool depth constraints. In this work,\nwe first show that TiDE is capable of accurately predicting melt pool\ntemperature and depth. Second, we demonstrate that the proposed MPC achieves\nprecise temperature tracking while satisfying melt pool depth constraints\nwithin a targeted dilution range (10%-30%), reducing potential porosity\ndefects. Compared to the PID controller, MPC results in smoother and less\nfluctuating laser power profiles with competitive or superior melt pool\ntemperature control performance. This demonstrates MPC's proactive control\ncapabilities, leveraging time-series prediction and real-time optimization,\npositioning it as a powerful tool for future Digital Twin applications and\nreal-time process optimization in manufacturing.\n","authors":["Yi-Ping Chen","Vispi Karkaria","Ying-Kuan Tsai","Faith Rolark","Daniel Quispe","Robert X. Gao","Jian Cao","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2501.07601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18367v1","updated":"2025-01-30T14:20:11Z","published":"2025-01-30T14:20:11Z","title":"A Learnable Multi-views Contrastive Framework with Reconstruction\n  Discrepancy for Medical Time-Series","summary":"  In medical time series disease diagnosis, two key challenges are\nidentified.First, the high annotation cost of medical data leads to overfitting\nin models trained on label-limited, single-center datasets. To address this, we\npropose incorporating external data from related tasks and leveraging AE-GAN to\nextract prior knowledge,providing valuable references for downstream tasks.\nSecond, many existing studies employ contrastive learning to derive more\ngeneralized medical sequence representations for diagnostic tasks, usually\nrelying on manually designed diverse positive and negative sample\npairs.However, these approaches are complex, lack generalizability, and fail to\nadaptively capture disease-specific features across different conditions.To\novercome this, we introduce LMCF (Learnable Multi-views Contrastive Framework),\na framework that integrates a multi-head attention mechanism and adaptively\nlearns representations from different views through inter-view and intra-view\ncontrastive learning strategies.Additionally, the pre-trained AE-GAN is used to\nreconstruct discrepancies in the target data as disease probabilities, which\nare then integrated into the contrastive learning process.Experiments on three\ntarget datasets demonstrate that our method consistently outperforms seven\nother baselines, highlighting its significant impact on healthcare applications\nsuch as the diagnosis of myocardial infarction, Alzheimer's disease, and\nParkinson's disease.\n","authors":["Yifan Wang","Hongfeng Ai","Ruiqi Li","Maowei Jiang","Cheng Jiang","Chenzhong Li"],"pdf_url":"https://arxiv.org/pdf/2501.18367v1.pdf","comment":"15 pages,6 figures"},{"id":"http://arxiv.org/abs/2402.06282v5","updated":"2025-01-30T14:14:57Z","published":"2024-02-09T09:48:38Z","title":"Retrieve, Merge, Predict: Augmenting Tables with Data Lakes","summary":"  Machine-learning from a disparate set of tables, a data lake, requires\nassembling features by merging and aggregating tables. Data discovery can\nextend autoML to data tables by automating these steps. We present an in-depth\nanalysis of such automated table augmentation for machine learning tasks,\nanalyzing different methods for the three main steps: retrieving joinable\ntables, merging information, and predicting with the resultant table. We use\ntwo data lakes: Open Data US, a well-referenced real data lake, and a novel\nsemi-synthetic dataset, YADL (Yet Another Data Lake), which we developed as a\ntool for benchmarking this data discovery task. Systematic exploration on both\nlakes outlines 1) the importance of accurately retrieving join candidates, 2)\nthe efficiency of simple merging methods, and 3) the resilience of tree-based\nlearners to noisy conditions. Our experimental environment is easily\nreproducible and based on open data, to foster more research on feature\nengineering, autoML, and learning in data lakes.\n","authors":["Riccardo Cappuzzo","Aimee Coelho","Felix Lefebvre","Paolo Papotti","Gael Varoquaux"],"pdf_url":"https://arxiv.org/pdf/2402.06282v5.pdf","comment":"12 pages + references, 6 figures in main body. 15 pages + 11 figures\n  in appendix"},{"id":"http://arxiv.org/abs/2501.05867v2","updated":"2025-01-30T14:12:35Z","published":"2025-01-10T11:08:40Z","title":"Neural Network Verification is a Programming Language Challenge","summary":"  Neural network verification is a new and rapidly developing field of\nresearch. So far, the main priority has been establishing efficient\nverification algorithms and tools, while proper support from the programming\nlanguage perspective has been considered secondary or unimportant. Yet, there\nis mounting evidence that insights from the programming language community may\nmake a difference in the future development of this domain. In this paper, we\nformulate neural network verification challenges as programming language\nchallenges and suggest possible future solutions.\n","authors":["Lucas C. Cordeiro","Matthew L. Daggitt","Julien Girard-Satabin","Omri Isac","Taylor T. Johnson","Guy Katz","Ekaterina Komendantskaya","Augustin Lemesle","Edoardo Manino","Artjoms Šinkarovs","Haoze Wu"],"pdf_url":"https://arxiv.org/pdf/2501.05867v2.pdf","comment":"Accepted at ESOP 2025, European Symposium on Programming Languages"},{"id":"http://arxiv.org/abs/2501.02481v2","updated":"2025-01-30T14:11:25Z","published":"2025-01-05T09:06:17Z","title":"The Meta-Representation Hypothesis","summary":"  Humans rely on high-level understandings of things, i.e.,\nmeta-representations, to engage in abstract reasoning. In complex cognitive\ntasks, these meta-representations help individuals abstract general rules from\nexperience. However, constructing such meta-representations from\nhigh-dimensional observations remains a longstanding challenge for\nreinforcement learning (RL) agents. For instance, a well-trained agent often\nfails to generalize to even minor variations of the same task, such as changes\nin background color, while humans can easily handle. In this paper, we\ntheoretically investigate how meta-representations contribute to the\ngeneralization ability of RL agents, demonstrating that learning\nmeta-representations from high-dimensional observations enhance an agent's\nability to generalize across varied environments. We further hypothesize that\ndeep mutual learning (DML) among agents can help them learn the\nmeta-representations that capture the underlying essence of the task. Empirical\nresults provide strong support for both our theory and hypothesis. Overall,\nthis work provides a new perspective on the generalization of deep\nreinforcement learning.\n","authors":["Zhengpeng Xie","Jiahang Cao","Qiang Zhang","Jianxiong Zhang","Changwei Wang","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2501.02481v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18363v1","updated":"2025-01-30T14:08:26Z","published":"2025-01-30T14:08:26Z","title":"Robust Online Conformal Prediction under Uniform Label Noise","summary":"  Conformal prediction is an emerging technique for uncertainty quantification\nthat constructs prediction sets guaranteed to contain the true label with a\npredefined probability. Recent work develops online conformal prediction\nmethods that adaptively construct prediction sets to accommodate distribution\nshifts. However, existing algorithms typically assume perfect label accuracy\nwhich rarely holds in practice. In this work, we investigate the robustness of\nonline conformal prediction under uniform label noise with a known noise rate,\nin both constant and dynamic learning rate schedules. We show that label noise\ncauses a persistent gap between the actual mis-coverage rate and the desired\nrate $\\alpha$, leading to either overestimated or underestimated coverage\nguarantees. To address this issue, we propose Noise Robust Online Conformal\nPrediction (dubbed NR-OCP) by updating the threshold with a novel robust\npinball los}, which provides an unbiased estimate of clean pinball loss without\nrequiring ground-truth labels. Our theoretical analysis shows that NR-OCP\neliminates the coverage gap in both constant and dynamic learning rate\nschedules, achieving a convergence rate of $\\mathcal{O}(T^{-1/2})$ for both\nempirical and expected coverage errors under uniform label noise. Extensive\nexperiments demonstrate the effectiveness of our method by achieving both\nprecise coverage and improved efficiency.\n","authors":["Huajun Xi","Kangdao Liu","Hao Zeng","Wenguang Sun","Hongxin Wei"],"pdf_url":"https://arxiv.org/pdf/2501.18363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18362v1","updated":"2025-01-30T14:07:56Z","published":"2025-01-30T14:07:56Z","title":"MedXpertQA: Benchmarking Expert-Level Medical Reasoning and\n  Understanding","summary":"  We introduce MedXpertQA, a highly challenging and comprehensive benchmark to\nevaluate expert-level medical knowledge and advanced reasoning. MedXpertQA\nincludes 4,460 questions spanning 17 specialties and 11 body systems. It\nincludes two subsets, Text for text evaluation and MM for multimodal\nevaluation. Notably, MM introduces expert-level exam questions with diverse\nimages and rich clinical information, including patient records and examination\nresults, setting it apart from traditional medical multimodal benchmarks with\nsimple QA pairs generated from image captions. MedXpertQA applies rigorous\nfiltering and augmentation to address the insufficient difficulty of existing\nbenchmarks like MedQA, and incorporates specialty board questions to improve\nclinical relevance and comprehensiveness. We perform data synthesis to mitigate\ndata leakage risk and conduct multiple rounds of expert reviews to ensure\naccuracy and reliability. We evaluate 16 leading models on MedXpertQA.\nMoreover, medicine is deeply connected to real-world decision-making, providing\na rich and representative setting for assessing reasoning abilities beyond\nmathematics and code. To this end, we develop a reasoning-oriented subset to\nfacilitate the assessment of o1-like models.\n","authors":["Yuxin Zuo","Shang Qu","Yifei Li","Zhangren Chen","Xuekai Zhu","Ermo Hua","Kaiyan Zhang","Ning Ding","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.18362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18359v1","updated":"2025-01-30T14:05:20Z","published":"2025-01-30T14:05:20Z","title":"Contextual Online Decision Making with Infinite-Dimensional Functional\n  Regression","summary":"  Contextual sequential decision-making problems play a crucial role in machine\nlearning, encompassing a wide range of downstream applications such as bandits,\nsequential hypothesis testing and online risk control. These applications often\nrequire different statistical measures, including expectation, variance and\nquantiles. In this paper, we provide a universal admissible algorithm framework\nfor dealing with all kinds of contextual online decision-making problems that\ndirectly learns the whole underlying unknown distribution instead of focusing\non individual statistics. This is much more difficult because the dimension of\nthe regression is uncountably infinite, and any existing linear contextual\nbandits algorithm will result in infinite regret. To overcome this issue, we\npropose an efficient infinite-dimensional functional regression oracle for\ncontextual cumulative distribution functions (CDFs), where each data point is\nmodeled as a combination of context-dependent CDF basis functions. Our analysis\nreveals that the decay rate of the eigenvalue sequence of the design integral\noperator governs the regression error rate and, consequently, the utility\nregret rate. Specifically, when the eigenvalue sequence exhibits a polynomial\ndecay of order $\\frac{1}{\\gamma}\\ge 1$, the utility regret is bounded by\n$\\tilde{\\mathcal{O}}\\Big(T^{\\frac{3\\gamma+2}{2(\\gamma+2)}}\\Big)$. By setting\n$\\gamma=0$, this recovers the existing optimal regret rate for contextual\nbandits with finite-dimensional regression and is optimal under a stronger\nexponential decay assumption. Additionally, we provide a numerical method to\ncompute the eigenvalue sequence of the integral operator, enabling the\npractical implementation of our framework.\n","authors":["Haichen Hu","Rui Ai","Stephen Bates","David Simchi-Levi"],"pdf_url":"https://arxiv.org/pdf/2501.18359v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2501.18357v1","updated":"2025-01-30T14:03:45Z","published":"2025-01-30T14:03:45Z","title":"Contrastive Learning Meets Pseudo-label-assisted Mixup Augmentation: A\n  Comprehensive Graph Representation Framework from Local to Global","summary":"  Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness in\nvarious graph representation learning tasks. However, most existing GNNs focus\nprimarily on capturing local information through explicit graph convolution,\noften neglecting global message-passing. This limitation hinders the\nestablishment of a collaborative interaction between global and local\ninformation, which is crucial for comprehensively understanding graph data. To\naddress these challenges, we propose a novel framework called Comprehensive\nGraph Representation Learning (ComGRL). ComGRL integrates local information\ninto global information to derive powerful representations. It achieves this by\nimplicitly smoothing local information through flexible graph contrastive\nlearning, ensuring reliable representations for subsequent global exploration.\nThen ComGRL transfers the locally derived representations to a multi-head\nself-attention module, enhancing their discriminative ability by uncovering\ndiverse and rich global correlations. To further optimize local information\ndynamically under the self-supervision of pseudo-labels, ComGRL employs a\ntriple sampling strategy to construct mixed node pairs and applies reliable\nMixup augmentation across attributes and structure for local contrastive\nlearning. This approach broadens the receptive field and facilitates\ncoordination between local and global representation learning, enabling them to\nreinforce each other. Experimental results across six widely used graph\ndatasets demonstrate that ComGRL achieves excellent performance in node\nclassification tasks. The code could be available at\nhttps://github.com/JinluWang1002/ComGRL.\n","authors":["Jinlu Wang","Yanfeng Sun","Jiapu Wang","Junbin Gao","Shaofan Wang","Jipeng Guo"],"pdf_url":"https://arxiv.org/pdf/2501.18357v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2501.18356v1","updated":"2025-01-30T14:03:36Z","published":"2025-01-30T14:03:36Z","title":"State Stream Transformer (SST) : Emergent Metacognitive Behaviours\n  Through Latent State Persistence","summary":"  We introduce the State Stream Transformer (SST), a novel LLM architecture\nthat reveals emergent reasoning behaviours and capabilities latent in\npretrained weights through addressing a fundamental limitation in traditional\ntransformer models: the lack of latent computational continuity across\nautoregressive generations in the state space. SST introduces a sliding window\nlatent state (FFN) cache with weighted decay that maintains and evolves\npersistent latent processes throughout autoregressive generations. Through\ncontrolled experiments comparing base and SST architectures using the same\nfrozen weights, we demonstrate that this architectural modification alone\nenables enhanced reasoning capabilities which appear best explained by some\nform of potential higher-order processing, as evidenced by emergent\nmetacognitive behaviours. These behaviours persist under controlled conditions\ndesigned to eliminate confounding factors such as stochastic variation or\nlearned response patterns. Analysis of latent state distributions and\nprocessing dynamics provides evidence that it is solely the 'state stream' that\nis responsible for these phenomena. In quantitative evaluations, the SST\nachieves substantial performance improvements over the base model on two\nreasoning benchmarks, reaching 89.01\\% accuracy on GSM-8K (0-shot) and 91.04\\%\non ARC Challenge (0-shot CoT). These findings indicate that persistent\ncomputation in the latent state space enables fundamentally different\ninformation processing and internal reasoning strategies, with implications for\nour understanding of artificial intelligence systems.\n","authors":["Thea Aviss"],"pdf_url":"https://arxiv.org/pdf/2501.18356v1.pdf","comment":"25 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.23749v3","updated":"2025-01-30T13:50:52Z","published":"2024-10-31T09:09:39Z","title":"LSEAttention is All You Need for Time Series Forecasting","summary":"  Transformer-based architectures have achieved remarkable success in natural\nlanguage processing and computer vision. However, their performance in\nmultivariate long-term forecasting often falls short compared to simpler linear\nbaselines. Previous research has identified the traditional attention mechanism\nas a key factor limiting their effectiveness in this domain. To bridge this\ngap, we introduce LATST, a novel approach designed to mitigate entropy collapse\nand training instability common challenges in Transformer-based time series\nforecasting. We rigorously evaluate LATST across multiple real-world\nmultivariate time series datasets, demonstrating its ability to outperform\nexisting state-of-the-art Transformer models. Notably, LATST manages to achieve\ncompetitive performance with fewer parameters than some linear models on\ncertain datasets, highlighting its efficiency and effectiveness.\n","authors":["Dizhen Liang"],"pdf_url":"https://arxiv.org/pdf/2410.23749v3.pdf","comment":"8 pages with referencing, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2312.06531v2","updated":"2025-01-30T13:49:20Z","published":"2023-12-11T17:09:12Z","title":"Uncertainty quantification in automated valuation models with spatially\n  weighted conformal prediction","summary":"  Non-parametric machine learning models, such as random forests and gradient\nboosted trees, are frequently used to estimate house prices due to their\npredictive accuracy, but a main drawback of such methods is their limited\nability to quantify prediction uncertainty. Conformal prediction (CP) is a\nmodel-agnostic framework for constructing confidence sets around predictions of\nmachine learning models with minimal assumptions. However, due to the spatial\ndependencies observed in house prices, direct application of CP leads to\nconfidence sets that are not calibrated everywhere, i.e., the confidence sets\nwill be too large in certain geographical regions and too small in others. We\nsurvey various approaches to adjust the CP confidence set to account for this\nand demonstrate their performance on a data set from the housing market in\nOslo, Norway. Our findings indicate that calibrating the confidence sets on a\nspatially weighted version of the non-conformity scores makes the coverage more\nconsistently calibrated across geographical regions. We also perform a\nsimulation study on synthetically generated sale prices to empirically explore\nthe performance of CP on housing market data under idealized conditions with\nknown data-generating mechanisms.\n","authors":["Anders Hjort","Gudmund Horn Hermansen","Johan Pensar","Jonathan P. Williams"],"pdf_url":"https://arxiv.org/pdf/2312.06531v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18344v1","updated":"2025-01-30T13:46:48Z","published":"2025-01-30T13:46:48Z","title":"Transfer Learning of Surrogate Models: Integrating Domain Warping and\n  Affine Transformations","summary":"  Surrogate models provide efficient alternatives to computationally demanding\nreal-world processes but often require large datasets for effective training. A\npromising solution to this limitation is the transfer of pre-trained surrogate\nmodels to new tasks. Previous studies have investigated the transfer of\ndifferentiable and non-differentiable surrogate models, typically assuming an\naffine transformation between the source and target functions. This paper\nextends previous research by addressing a broader range of transformations,\nincluding linear and nonlinear variations. Specifically, we consider the\ncombination of an unknown input warping, such as one modelled by the beta\ncumulative distribution function, with an unspecified affine transformation.\nOur approach achieves transfer learning by employing a limited number of data\npoints from the target task to optimize these transformations, minimizing\nempirical loss on the transfer dataset. We validate the proposed method on the\nwidely used Black-Box Optimization Benchmark (BBOB) testbed and a real-world\ntransfer learning task from the automobile industry. The results underscore the\nsignificant advantages of the approach, revealing that the transferred\nsurrogate significantly outperforms both the original surrogate and the one\nbuilt from scratch using the transfer dataset, particularly in data-scarce\nscenarios.\n","authors":["Shuaiqun Pan","Diederick Vermetten","Manuel López-Ibáñez","Thomas Bäck","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2501.18344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18337v1","updated":"2025-01-30T13:34:48Z","published":"2025-01-30T13:34:48Z","title":"Unfaithful Probability Distributions in Binary Triple of Causality\n  Directed Acyclic Graph","summary":"  Faithfulness is the foundation of probability distribution and graph in\ncausal discovery and causal inference. In this paper, several unfaithful\nprobability distribution examples are constructed in three--vertices binary\ncausality directed acyclic graph (DAG) structure, which are not faithful to\ncausal DAGs described in J.M.,Robins,et al. Uniform consistency in causal\ninference. Biometrika (2003),90(3): 491--515. And the general unfaithful\nprobability distribution with multiple independence and conditional\nindependence in binary triple causal DAG is given.\n","authors":["Jingwei Liu"],"pdf_url":"https://arxiv.org/pdf/2501.18337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18331v1","updated":"2025-01-30T13:18:59Z","published":"2025-01-30T13:18:59Z","title":"Stream-Based Monitoring of Algorithmic Fairness","summary":"  Automatic decision and prediction systems are increasingly deployed in\napplications where they significantly impact the livelihood of people, such as\nfor predicting the creditworthiness of loan applicants or the recidivism risk\nof defendants. These applications have given rise to a new class of\nalgorithmic-fairness specifications that require the systems to decide and\npredict without bias against social groups. Verifying these specifications\nstatically is often out of reach for realistic systems, since the systems may,\ne.g., employ complex learning components, and reason over a large input space.\nIn this paper, we therefore propose stream-based monitoring as a solution for\nverifying the algorithmic fairness of decision and prediction systems at\nruntime. Concretely, we present a principled way to formalize algorithmic\nfairness over temporal data streams in the specification language RTLola and\ndemonstrate the efficacy of this approach on a number of benchmarks. Besides\nsynthetic scenarios that particularly highlight its efficiency on streams with\na scaling amount of data, we notably evaluate the monitor on real-world data\nfrom the recidivism prediction tool COMPAS.\n","authors":["Jan Baumeister","Bernd Finkbeiner","Frederik Scheerer","Julian Siber","Tobias Wagenpfeil"],"pdf_url":"https://arxiv.org/pdf/2501.18331v1.pdf","comment":"31st International Conference on Tools and Algorithms for the\n  Construction and Analysis of Systems (TACAS 2025)"},{"id":"http://arxiv.org/abs/2501.18322v1","updated":"2025-01-30T13:04:54Z","published":"2025-01-30T13:04:54Z","title":"A Unified Perspective on the Dynamics of Deep Transformers","summary":"  Transformers, which are state-of-the-art in most machine learning tasks,\nrepresent the data as sequences of vectors called tokens. This representation\nis then exploited by the attention function, which learns dependencies between\ntokens and is key to the success of Transformers. However, the iterative\napplication of attention across layers induces complex dynamics that remain to\nbe fully understood. To analyze these dynamics, we identify each input sequence\nwith a probability measure and model its evolution as a Vlasov equation called\nTransformer PDE, whose velocity field is non-linear in the probability measure.\nOur first set of contributions focuses on compactly supported initial data. We\nshow the Transformer PDE is well-posed and is the mean-field limit of an\ninteracting particle system, thus generalizing and extending previous analysis\nto several variants of self-attention: multi-head attention, L2 attention,\nSinkhorn attention, Sigmoid attention, and masked attention--leveraging a\nconditional Wasserstein framework. In a second set of contributions, we are the\nfirst to study non-compactly supported initial conditions, by focusing on\nGaussian initial data. Again for different types of attention, we show that the\nTransformer PDE preserves the space of Gaussian measures, which allows us to\nanalyze the Gaussian case theoretically and numerically to identify typical\nbehaviors. This Gaussian analysis captures the evolution of data anisotropy\nthrough a deep Transformer. In particular, we highlight a clustering phenomenon\nthat parallels previous results in the non-normalized discrete case.\n","authors":["Valérie Castin","Pierre Ablin","José Antonio Carrillo","Gabriel Peyré"],"pdf_url":"https://arxiv.org/pdf/2501.18322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18517v4","updated":"2025-01-30T12:49:38Z","published":"2024-03-27T12:49:14Z","title":"Efficient Algorithms for Regularized Nonnegative Scale-invariant\n  Low-rank Approximation Models","summary":"  Regularized nonnegative low-rank approximations, such as sparse Nonnegative\nMatrix Factorization or sparse Nonnegative Tucker Decomposition, form an\nimportant branch of dimensionality reduction models known for their enhanced\ninterpretability. From a practical perspective, however, selecting appropriate\nregularizers and regularization coefficients, as well as designing efficient\nalgorithms, remains challenging due to the multifactor nature of these models\nand the limited theoretical guidance available. This paper addresses these\nchallenges by studying a more general model, the Homogeneous Regularized\nScale-Invariant model. We prove that the scale-invariance inherent to low-rank\napproximation models induces an implicit regularization effect that balances\nsolutions. This insight provides a deeper understanding of the role of\nregularization functions in low-rank approximation models, informs the\nselection of regularization hyperparameters, and enables the design of\nbalancing strategies to accelerate the empirical convergence of optimization\nalgorithms.\n  Additionally, we propose a generic Majorization-Minimization (MM) algorithm\ncapable of handling $\\ell_p^p$-regularized nonnegative low-rank approximations\nwith non-Euclidean loss functions, with convergence guarantees. Our\ncontributions are demonstrated on sparse Nonnegative Matrix Factorization,\nridge-regularized Nonnegative Canonical Polyadic Decomposition, and sparse\nNonnegative Tucker Decomposition.\n","authors":["Jeremy E. Cohen","Valentin Leplat"],"pdf_url":"https://arxiv.org/pdf/2403.18517v4.pdf","comment":"Version after acceptance in SIAM Journal on Mathematics of Data\n  Science (SIMODS)"},{"id":"http://arxiv.org/abs/2409.03577v2","updated":"2025-01-30T12:44:14Z","published":"2024-09-05T14:31:05Z","title":"CHIRPs: Change-Induced Regret Proxy metrics for Lifelong Reinforcement\n  Learning","summary":"  Reinforcement learning (RL) agents are costly to train and fragile to\nenvironmental changes. They often perform poorly when there are many changing\ntasks, prohibiting their widespread deployment in the real world. Many Lifelong\nRL agent designs have been proposed to mitigate issues such as catastrophic\nforgetting or demonstrate positive characteristics like forward transfer when\nchange occurs. However, no prior work has established whether the impact on\nagent performance can be predicted from the change itself. Understanding this\nrelationship will help agents proactively mitigate a change's impact for\nimproved learning performance. We propose Change-Induced Regret Proxy (CHIRP)\nmetrics to link change to agent performance drops and use two environments to\ndemonstrate a CHIRP's utility in lifelong learning. A simple CHIRP-based agent\nachieved $48\\%$ higher performance than the next best method in one benchmark\nand attained the best success rates in 8 of 10 tasks in a second benchmark\nwhich proved difficult for existing lifelong RL agents.\n","authors":["John Birkbeck","Adam Sobey","Federico Cerutti","Katherine Heseltine Hurley Flynn","Timothy J. Norman"],"pdf_url":"https://arxiv.org/pdf/2409.03577v2.pdf","comment":"7 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.18310v1","updated":"2025-01-30T12:37:06Z","published":"2025-01-30T12:37:06Z","title":"Efficient Neural Theorem Proving via Fine-grained Proof Structure\n  Analysis","summary":"  The synergy between deep learning models and traditional automation tools\nplays a pivotal role in developing robust neural theorem provers (NTPs).\nHowever, for proof synthesis with LLMs, previous work applies automation tools\neither only when the model explicitly calls the method, or only at a single\ngranularity level, failing to fully exploit the power of built-in tactics and\noff-the-shelf automated theorem provers. In this work, we propose ProofAug, a\nnovel theorem proving method that enjoys superior sample efficiency through\nequipping proof-generation LLMs with automation methods in different\ngranularities via fine-grained structure analysis of model-generated proof\nproposals. Furthermore, ProofAug serves as a versatile plug-and-play module\nthat seamlessly integrates with any tree-search algorithm, enabling our\nconstruction of an efficient recursive proving (ERP) module to further enhance\nperformance. The superiority of our method is validated on the miniF2F-test\nbenchmark using the open-source deepseek-math-7b-base model and the Isabelle\nproof assistant. Notably, by additionally employing a mixed prompting strategy,\nwe achieve a cumulative pass rate of 66.0% after curation of the dataset (61.9%\nfor the original version), setting a new SOTA across all proof languages with a\ntotal sample budget of only 2100. Our code is available at\nhttps://github.com/haoxiongliu/ProofAug.\n","authors":["Haoxiong Liu","Jiacheng Sun","Zhenguo Li","Andrew C Yao"],"pdf_url":"https://arxiv.org/pdf/2501.18310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18298v1","updated":"2025-01-30T12:18:27Z","published":"2025-01-30T12:18:27Z","title":"Update Estimation and Scheduling for Over-the-Air Federated Learning\n  with Energy Harvesting Devices","summary":"  We study over-the-air (OTA) federated learning (FL) for energy harvesting\ndevices with heterogeneous data distribution over wireless fading multiple\naccess channel (MAC). To address the impact of low energy arrivals and data\nheterogeneity on global learning, we propose user scheduling strategies.\nSpecifically, we develop two approaches: 1) entropy-based scheduling for known\ndata distributions and 2) least-squares-based user representation estimation\nfor scheduling with unknown data distributions at the parameter server. Both\nmethods aim to select diverse users, mitigating bias and enhancing convergence.\nNumerical and analytical results demonstrate improved learning performance by\nreducing redundancy and conserving energy.\n","authors":["Furkan Bagci","Busra Tegin","Mohammad Kazemi","Tolga M. Duman"],"pdf_url":"https://arxiv.org/pdf/2501.18298v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2403.19243v2","updated":"2025-01-30T12:17:43Z","published":"2024-03-28T08:58:20Z","title":"Efficient Learning With Sine-Activated Low-rank Matrices","summary":"  Low-rank decomposition has emerged as a vital tool for enhancing parameter\nefficiency in neural network architectures, gaining traction across diverse\napplications in machine learning. These techniques significantly lower the\nnumber of parameters, striking a balance between compactness and performance.\nHowever, a common challenge has been the compromise between parameter\nefficiency and the accuracy of the model, where reduced parameters often lead\nto diminished accuracy compared to their full-rank counterparts. In this work,\nwe propose a novel theoretical framework that integrates a sinusoidal function\nwithin the low-rank decomposition process. This approach not only preserves the\nbenefits of the parameter efficiency characteristic of low-rank methods but\nalso increases the decomposition's rank, thereby enhancing model performance.\nOur method proves to be a plug in enhancement for existing low-rank models, as\nevidenced by its successful application in Vision Transformers (ViT), Large\nLanguage Models (LLMs), Neural Radiance Fields (NeRF) and 3D shape modelling.\n","authors":["Yiping Ji","Hemanth Saratchandran","Cameron Gordon","Zeyu Zhang","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2403.19243v2.pdf","comment":"The first two authors contributed equally. Paper accepted at ICLR\n  2025"},{"id":"http://arxiv.org/abs/2409.10496v3","updated":"2025-01-30T12:13:04Z","published":"2024-09-16T17:28:21Z","title":"MusicLIME: Explainable Multimodal Music Understanding","summary":"  Multimodal models are critical for music understanding tasks, as they capture\nthe complex interplay between audio and lyrics. However, as these models become\nmore prevalent, the need for explainability grows-understanding how these\nsystems make decisions is vital for ensuring fairness, reducing bias, and\nfostering trust. In this paper, we introduce MusicLIME, a model-agnostic\nfeature importance explanation method designed for multimodal music models.\nUnlike traditional unimodal methods, which analyze each modality separately\nwithout considering the interaction between them, often leading to incomplete\nor misleading explanations, MusicLIME reveals how audio and lyrical features\ninteract and contribute to predictions, providing a holistic view of the\nmodel's decision-making. Additionally, we enhance local explanations by\naggregating them into global explanations, giving users a broader perspective\nof model behavior. Through this work, we contribute to improving the\ninterpretability of multimodal music models, empowering users to make informed\nchoices, and fostering more equitable, fair, and transparent music\nunderstanding systems.\n","authors":["Theodoros Sotirou","Vassilis Lyberatos","Orfeas Menis Mastromichalakis","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2409.10496v3.pdf","comment":"GitHub repository: https://github.com/IamTheo2000/MusicLIME. To be\n  presented at ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.18283v1","updated":"2025-01-30T11:46:00Z","published":"2025-01-30T11:46:00Z","title":"Random Feature Representation Boosting","summary":"  We introduce Random Feature Representation Boosting (RFRBoost), a novel\nmethod for constructing deep residual random feature neural networks (RFNNs)\nusing boosting theory. RFRBoost uses random features at each layer to learn the\nfunctional gradient of the network representation, enhancing performance while\npreserving the convex optimization benefits of RFNNs. In the case of MSE loss,\nwe obtain closed-form solutions to greedy layer-wise boosting with random\nfeatures. For general loss functions, we show that fitting random feature\nresidual blocks reduces to solving a quadratically constrained least squares\nproblem. We demonstrate, through numerical experiments on 91 tabular datasets\nfor regression and classification, that RFRBoost significantly outperforms\ntraditional RFNNs and end-to-end trained MLP ResNets, while offering\nsubstantial computational advantages and theoretical guarantees stemming from\nboosting theory.\n","authors":["Nikita Zozoulenko","Thomas Cass","Lukas Gonon"],"pdf_url":"https://arxiv.org/pdf/2501.18283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18282v1","updated":"2025-01-30T11:41:13Z","published":"2025-01-30T11:41:13Z","title":"Leveraging Sparsity for Sample-Efficient Preference Learning: A\n  Theoretical Perspective","summary":"  This paper considers the sample-efficiency of preference learning, which\nmodels and predicts human choices based on comparative judgments. The minimax\noptimal estimation rate $\\Theta(d/n)$ in traditional estimation theory requires\nthat the number of samples $n$ scales linearly with the dimensionality of the\nfeature space $d$. However, the high dimensionality of the feature space and\nthe high cost of collecting human-annotated data challenge the efficiency of\ntraditional estimation methods. To remedy this, we leverage sparsity in the\npreference model and establish sharp estimation rates. We show that under the\nsparse random utility model, where the parameter of the reward function is\n$k$-sparse, the minimax optimal rate can be reduced to $\\Theta(k/n \\log(d/k))$.\nFurthermore, we analyze the $\\ell_{1}$-regularized estimator and show that it\nachieves near-optimal rate under mild assumptions on the Gram matrix.\nExperiments on synthetic data and LLM alignment data validate our theoretical\nfindings, showing that sparsity-aware methods significantly reduce sample\ncomplexity and improve prediction accuracy.\n","authors":["Yunzhen Yao","Lie He","Michael Gastpar"],"pdf_url":"https://arxiv.org/pdf/2501.18282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16002v2","updated":"2025-01-30T11:40:01Z","published":"2025-01-27T12:39:16Z","title":"ScaDyG:A New Paradigm for Large-scale Dynamic Graph Learning","summary":"  Dynamic graphs (DGs), which capture time-evolving relationships between graph\nentities, have widespread real-world applications. To efficiently encode DGs\nfor downstream tasks, most dynamic graph neural networks follow the traditional\nmessage-passing mechanism and extend it with time-based techniques. Despite\ntheir effectiveness, the growth of historical interactions introduces\nsignificant scalability issues, particularly in industry scenarios. To address\nthis limitation, we propose ScaDyG, with the core idea of designing a\ntime-aware scalable learning paradigm as follows: 1) Time-aware Topology\nReformulation: ScaDyG first segments historical interactions into time steps\n(intra and inter) based on dynamic modeling, enabling weight-free and\ntime-aware graph propagation within pre-processing. 2) Dynamic Temporal\nEncoding: To further achieve fine-grained graph propagation within time steps,\nScaDyG integrates temporal encoding through a combination of exponential\nfunctions in a scalable manner. 3) Hypernetwork-driven Message Aggregation:\nAfter obtaining the propagated features (i.e., messages), ScaDyG utilizes\nhypernetwork to analyze historical dependencies, implementing node-wise\nrepresentation by an adaptive temporal fusion. Extensive experiments on 12\ndatasets demonstrate that ScaDyG performs comparably well or even outperforms\nother SOTA methods in both node and link-level downstream tasks, with fewer\nlearnable parameters and higher efficiency.\n","authors":["Xiang Wu","Xunkai Li","Rong-Hua Li","Kangfei Zhao","Guoren Wang"],"pdf_url":"https://arxiv.org/pdf/2501.16002v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18280v1","updated":"2025-01-30T11:37:40Z","published":"2025-01-30T11:37:40Z","title":"Jailbreaking LLMs' Safeguard with Universal Magic Words for Text\n  Embedding Models","summary":"  The security issue of large language models (LLMs) has gained significant\nattention recently, with various defense mechanisms developed to prevent\nharmful outputs, among which safeguards based on text embedding models serve as\na fundamental defense. Through testing, we discover that the distribution of\ntext embedding model outputs is significantly biased with a large mean.\nInspired by this observation, we propose novel efficient methods to search for\nuniversal magic words that can attack text embedding models. The universal\nmagic words as suffixes can move the embedding of any text towards the bias\ndirection, therefore manipulate the similarity of any text pair and mislead\nsafeguards. By appending magic words to user prompts and requiring LLMs to end\nanswers with magic words, attackers can jailbreak the safeguard. To eradicate\nthis security risk, we also propose defense mechanisms against such attacks,\nwhich can correct the biased distribution of text embeddings in a train-free\nmanner.\n","authors":["Haoyu Liang","Youran Sun","Yunfeng Cai","Jun Zhu","Bo Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.18280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18278v1","updated":"2025-01-30T11:34:03Z","published":"2025-01-30T11:34:03Z","title":"ReactEmbed: A Cross-Domain Framework for Protein-Molecule Representation\n  Learning via Biochemical Reaction Networks","summary":"  The challenge in computational biology and drug discovery lies in creating\ncomprehensive representations of proteins and molecules that capture their\nintrinsic properties and interactions. Traditional methods often focus on\nunimodal data, such as protein sequences or molecular structures, limiting\ntheir ability to capture complex biochemical relationships. This work enhances\nthese representations by integrating biochemical reactions encompassing\ninteractions between molecules and proteins. By leveraging reaction data\nalongside pre-trained embeddings from state-of-the-art protein and molecule\nmodels, we develop ReactEmbed, a novel method that creates a unified embedding\nspace through contrastive learning. We evaluate ReactEmbed across diverse\ntasks, including drug-target interaction, protein-protein interaction, protein\nproperty prediction, and molecular property prediction, consistently surpassing\nall current state-of-the-art models. Notably, we showcase ReactEmbed's\npractical utility through successful implementation in lipid nanoparticle-based\ndrug delivery, enabling zero-shot prediction of blood-brain barrier\npermeability for protein-nanoparticle complexes. The code and comprehensive\ndatabase of reaction pairs are available for open use at\n\\href{https://github.com/amitaysicherman/ReactEmbed}{GitHub}.\n","authors":["Amitay Sicherman","Kira Radinsky"],"pdf_url":"https://arxiv.org/pdf/2501.18278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18277v1","updated":"2025-01-30T11:31:38Z","published":"2025-01-30T11:31:38Z","title":"Sebra: Debiasing Through Self-Guided Bias Ranking","summary":"  Ranking samples by fine-grained estimates of spuriosity (the degree to which\nspurious cues are present) has recently been shown to significantly benefit\nbias mitigation, over the traditional binary biased-\\textit{vs}-unbiased\npartitioning of train sets. However, this spuriosity ranking comes with the\nrequirement of human supervision. In this paper, we propose a debiasing\nframework based on our novel \\ul{Se}lf-Guided \\ul{B}ias \\ul{Ra}nking\n(\\emph{Sebra}), that mitigates biases (spurious correlations) via an automatic\nranking of data points by spuriosity within their respective classes. Sebra\nleverages a key local symmetry in Empirical Risk Minimization (ERM) training --\nthe ease of learning a sample via ERM inversely correlates with its\nspuriousity; the fewer spurious correlations a sample exhibits, the harder it\nis to learn, and vice versa. However, globally across iterations, ERM tends to\ndeviate from this symmetry. Sebra dynamically steers ERM to correct this\ndeviation, facilitating the sequential learning of attributes in increasing\norder of difficulty, \\ie, decreasing order of spuriosity. As a result, the\nsequence in which Sebra learns samples naturally provides spuriousity rankings.\nWe use the resulting fine-grained bias characterization in a contrastive\nlearning framework to mitigate biases from multiple sources. Extensive\nexperiments show that Sebra consistently outperforms previous state-of-the-art\nunsupervised debiasing techniques across multiple standard benchmarks,\nincluding UrbanCars, BAR, CelebA, and ImageNet-1K. Code, pre-trained models,\nand training logs are available at https://kadarsh22.github.io/sebra_iclr25/.\n","authors":["Adarsh Kappiyath","Abhra Chaudhuri","Ajay Jaiswal","Ziquan Liu","Yunpeng Li","Xiatian Zhu","Lu Yin"],"pdf_url":"https://arxiv.org/pdf/2501.18277v1.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2501.18271v1","updated":"2025-01-30T11:10:46Z","published":"2025-01-30T11:10:46Z","title":"Pre-Trained Vision-Language Model Selection and Reuse for Downstream\n  Tasks","summary":"  Pre-trained Vision-Language Models (VLMs) are becoming increasingly popular\nacross various visual tasks, and several open-sourced VLM variants have been\nreleased. However, selecting the best-performing pre-trained VLM for a specific\ndownstream task is challenging since no single VLM can achieve promising\nperformance on all downstream tasks, and evaluating all available VLMs is\nimpossible due to time and data limitations. To address this problem, this\npaper proposes a novel paradigm to select and reuse VLM for downstream tasks,\ncalled Model Label Learning (MLL). The proposal contains three key modules:\n\\emph{model labeling}, which assigns labels to each VLM to describe their\nspecialty and utility; \\emph{model selection}, which matches the requirements\nof the target task with model labels; and \\emph{model reuse}, which applies\nselected VLMs to the target task in an ensemble manner. The proposal is highly\ncomputationally efficient and growable since the model labeling process is\ncompleted target task independent and the ability could grow with the number of\ncandidate VLMs. We also introduce a new benchmark for evaluating VLM selection\nmethods, including 49 VLMs and 17 target task datasets. Experimental results\nclearly demonstrate the effectiveness of the proposed method for selecting and\nreusing VLMs.\n","authors":["Hao-Zhe Tan","Zhi Zhou","Lan-Zhe Guo","Yu-Feng Li"],"pdf_url":"https://arxiv.org/pdf/2501.18271v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18268v1","updated":"2025-01-30T11:05:59Z","published":"2025-01-30T11:05:59Z","title":"Reducing Aleatoric and Epistemic Uncertainty through Multi-modal Data\n  Acquisition","summary":"  To generate accurate and reliable predictions, modern AI systems need to\ncombine data from multiple modalities, such as text, images, audio,\nspreadsheets, and time series. Multi-modal data introduces new opportunities\nand challenges for disentangling uncertainty: it is commonly assumed in the\nmachine learning community that epistemic uncertainty can be reduced by\ncollecting more data, while aleatoric uncertainty is irreducible. However, this\nassumption is challenged in modern AI systems when information is obtained from\ndifferent modalities. This paper introduces an innovative data acquisition\nframework where uncertainty disentanglement leads to actionable decisions,\nallowing sampling in two directions: sample size and data modality. The main\nhypothesis is that aleatoric uncertainty decreases as the number of modalities\nincreases, while epistemic uncertainty decreases by collecting more\nobservations. We provide proof-of-concept implementations on two multi-modal\ndatasets to showcase our data acquisition framework, which combines ideas from\nactive learning, active feature acquisition and uncertainty quantification.\n","authors":["Arthur Hoarau","Benjamin Quost","Sébastien Destercke","Willem Waegeman"],"pdf_url":"https://arxiv.org/pdf/2501.18268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11409v2","updated":"2025-01-30T10:51:36Z","published":"2025-01-20T11:16:44Z","title":"Unsupervised Learning in Echo State Networks for Input Reconstruction","summary":"  Conventional echo state networks (ESNs) require supervised learning to train\nthe readout layer, using the desired outputs as training data. In this study,\nwe focus on input reconstruction (IR), which refers to training the readout\nlayer to reproduce the input time series in its output. We reformulate the\nlearning algorithm of the ESN readout layer to perform IR using unsupervised\nlearning (UL). By conducting theoretical analysis and numerical experiments, we\ndemonstrate that IR in ESNs can be effectively implemented under realistic\nconditions without explicitly using the desired outputs as training data; in\nthis way, UL is enabled. Furthermore, we demonstrate that applications relying\non IR, such as dynamical system replication and noise filtering, can be\nreformulated within the UL framework. Our findings establish a theoretically\nsound and universally applicable IR formulation, along with its related tasks\nin ESNs. This work paves the way for novel predictions and highlights\nunresolved theoretical challenges in ESNs, particularly in the context of\ntime-series processing methods and computational models of the brain.\n","authors":["Taiki Yamada","Yuichi Katori","Kantaro Fujiwara"],"pdf_url":"https://arxiv.org/pdf/2501.11409v2.pdf","comment":"16 pages, 7 figures, regular paper"},{"id":"http://arxiv.org/abs/2501.18258v1","updated":"2025-01-30T10:39:52Z","published":"2025-01-30T10:39:52Z","title":"PDE-DKL: PDE-constrained deep kernel learning in high dimensionality","summary":"  Many physics-informed machine learning methods for PDE-based problems rely on\nGaussian processes (GPs) or neural networks (NNs). However, both face\nlimitations when data are scarce and the dimensionality is high. Although GPs\nare known for their robust uncertainty quantification in low-dimensional\nsettings, their computational complexity becomes prohibitive as the\ndimensionality increases. In contrast, while conventional NNs can accommodate\nhigh-dimensional input, they often require extensive training data and do not\noffer uncertainty quantification. To address these challenges, we propose a\nPDE-constrained Deep Kernel Learning (PDE-DKL) framework that combines DL and\nGPs under explicit PDE constraints. Specifically, NNs learn a low-dimensional\nlatent representation of the high-dimensional PDE problem, reducing the\ncomplexity of the problem. GPs then perform kernel regression subject to the\ngoverning PDEs, ensuring accurate solutions and principled uncertainty\nquantification, even when available data are limited. This synergy unifies the\nstrengths of both NNs and GPs, yielding high accuracy, robust uncertainty\nestimates, and computational efficiency for high-dimensional PDEs. Numerical\nexperiments demonstrate that PDE-DKL achieves high accuracy with reduced data\nrequirements. They highlight its potential as a practical, reliable, and\nscalable solver for complex PDE-based applications in science and engineering.\n","authors":["Weihao Yan","Christoph Brune","Mengwu Guo"],"pdf_url":"https://arxiv.org/pdf/2501.18258v1.pdf","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.17586v2","updated":"2025-01-30T10:37:04Z","published":"2025-01-29T11:41:07Z","title":"Boosting Weak Positives for Text Based Person Search","summary":"  Large vision-language models have revolutionized cross-modal object\nretrieval, but text-based person search (TBPS) remains a challenging task due\nto limited data and fine-grained nature of the task. Existing methods primarily\nfocus on aligning image-text pairs into a common representation space, often\ndisregarding the fact that real world positive image-text pairs share a varied\ndegree of similarity in between them. This leads models to prioritize easy\npairs, and in some recent approaches, challenging samples are discarded as\nnoise during training. In this work, we introduce a boosting technique that\ndynamically identifies and emphasizes these challenging samples during\ntraining. Our approach is motivated from classical boosting technique and\ndynamically updates the weights of the weak positives, wherein, the rank-1\nmatch does not share the identity of the query. The weight allows these\nmisranked pairs to contribute more towards the loss and the network has to pay\nmore attention towards such samples. Our method achieves improved performance\nacross four pedestrian datasets, demonstrating the effectiveness of our\nproposed module.\n","authors":["Akshay Modi","Ashhar Aziz","Nilanjana Chatterjee","A V Subramanyam"],"pdf_url":"https://arxiv.org/pdf/2501.17586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.14422v2","updated":"2025-01-30T10:34:10Z","published":"2023-04-27T09:11:40Z","title":"MINN: Learning the dynamics of differential-algebraic equations and\n  application to battery modeling","summary":"  The concept of integrating physics-based and data-driven approaches has\nbecome popular for modeling sustainable energy systems. However, the existing\nliterature mainly focuses on the data-driven surrogates generated to replace\nphysics-based models. These models often trade accuracy for speed but lack the\ngeneralizability, adaptability, and interpretability inherent in physics-based\nmodels, which are often indispensable in modeling real-world dynamic systems\nfor optimization and control purposes. We propose a novel machine learning\narchitecture, termed model-integrated neural networks (MINN), that can learn\nthe physics-based dynamics of general autonomous or non-autonomous systems\nconsisting of partial differential-algebraic equations (PDAEs). The obtained\narchitecture systematically solves an unsettled research problem in\ncontrol-oriented modeling, i.e., how to obtain optimally simplified models that\nare physically insightful, numerically accurate, and computationally tractable\nsimultaneously. We apply the proposed neural network architecture to model the\nelectrochemical dynamics of lithium-ion batteries and show that MINN is\nextremely data-efficient to train while being sufficiently generalizable to\npreviously unseen input data, owing to its underlying physical invariants. The\nMINN battery model has an accuracy comparable to the first principle-based\nmodel in predicting both the system outputs and any locally distributed\nelectrochemical behaviors but achieves two orders of magnitude reduction in the\nsolution time.\n","authors":["Yicun Huang","Changfu Zou","Yang Li","Torsten Wik"],"pdf_url":"https://arxiv.org/pdf/2304.14422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07783v3","updated":"2025-01-30T10:33:33Z","published":"2024-11-25T12:20:07Z","title":"Swin fMRI Transformer Predicts Early Neurodevelopmental Outcomes from\n  Neonatal fMRI","summary":"  Brain development in the first few months of human life is a critical phase\ncharacterized by rapid structural growth and functional organization.\nAccurately predicting developmental outcomes during this time is crucial for\nidentifying delays and enabling timely interventions. This study introduces the\nSwiFT (Swin 4D fMRI Transformer) model, designed to predict Bayley-III\ncomposite scores using neonatal fMRI from the Developing Human Connectome\nProject (dHCP). To enhance predictive accuracy, we apply dimensionality\nreduction via group independent component analysis (ICA) and pretrain SwiFT on\nlarge adult fMRI datasets to address the challenges of limited neonatal data.\nOur analysis shows that SwiFT significantly outperforms baseline models in\npredicting cognitive, motor, and language outcomes, leveraging both\nsingle-label and multi-label prediction strategies. The model's attention-based\narchitecture processes spatiotemporal data end-to-end, delivering superior\npredictive performance. Additionally, we use Integrated Gradients with\nSmoothgrad sQuare (IG-SQ) to interpret predictions, identifying neural spatial\nrepresentations linked to early cognitive and behavioral development. These\nfindings underscore the potential of Transformer models to advance\nneurodevelopmental research and clinical practice.\n","authors":["Patrick Styll","Dowon Kim","Jiook Cha"],"pdf_url":"https://arxiv.org/pdf/2412.07783v3.pdf","comment":"fMRI Transformer, Developing Human Connectome Project, Bayley Scales\n  of Infant Development, Personalized Therapy, XAI"},{"id":"http://arxiv.org/abs/2501.18243v1","updated":"2025-01-30T10:21:10Z","published":"2025-01-30T10:21:10Z","title":"Statistical multi-metric evaluation and visualization of LLM system\n  predictive performance","summary":"  The evaluation of generative or discriminative large language model\n(LLM)-based systems is often a complex multi-dimensional problem. Typically, a\nset of system configuration alternatives are evaluated on one or more benchmark\ndatasets, each with one or more evaluation metrics, which may differ between\ndatasets. We often want to evaluate -- with a statistical measure of\nsignificance -- whether systems perform differently either on a given dataset\naccording to a single metric, on aggregate across metrics on a dataset, or\nacross datasets. Such evaluations can be done to support decision-making, such\nas deciding whether a particular system component change (e.g., choice of LLM\nor hyperparameter values) significantly improves performance over the current\nsystem configuration, or, more generally, whether a fixed set of system\nconfigurations (e.g., a leaderboard list) have significantly different\nperformances according to metrics of interest. We present a framework\nimplementation that automatically performs the correct statistical tests,\nproperly aggregates the statistical results across metrics and datasets (a\nnontrivial task), and can visualize the results. The framework is demonstrated\non the multi-lingual code generation benchmark CrossCodeEval, for several\nstate-of-the-art LLMs.\n","authors":["Samuel Ackerman","Eitan Farchi","Orna Raz","Assaf Toledo"],"pdf_url":"https://arxiv.org/pdf/2501.18243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.08167v4","updated":"2025-01-30T10:10:55Z","published":"2023-07-16T22:35:52Z","title":"Computing the gradients with respect to all parameters of a quantum\n  neural network using a single circuit","summary":"  Finding gradients is a crucial step in training machine learning models. For\nquantum neural networks, computing gradients using the parameter-shift rule\nrequires calculating the cost function twice for each adjustable parameter in\nthe network. When the total number of parameters is large, the quantum circuit\nmust be repeatedly adjusted and executed, leading to significant computational\noverhead. Here we propose an approach to compute all gradients using a single\ncircuit only, significantly reducing both the circuit depth and the number of\nclassical registers required. We experimentally validate our approach on both\nquantum simulators and IBM's real quantum hardware, demonstrating that our\nmethod significantly reduces circuit compilation time compared to the\nconventional approach, resulting in a substantial speedup in total runtime.\n","authors":["Guang Ping He"],"pdf_url":"https://arxiv.org/pdf/2307.08167v4.pdf","comment":"Fixed an incomplete link"},{"id":"http://arxiv.org/abs/2305.19706v4","updated":"2025-01-30T10:03:32Z","published":"2023-05-31T10:03:04Z","title":"Necessary and Sufficient Conditions for Optimal Decision Trees using\n  Dynamic Programming","summary":"  Global optimization of decision trees has shown to be promising in terms of\naccuracy, size, and consequently human comprehensibility. However, many of the\nmethods used rely on general-purpose solvers for which scalability remains an\nissue. Dynamic programming methods have been shown to scale much better because\nthey exploit the tree structure by solving subtrees as independent subproblems.\nHowever, this only works when an objective can be optimized separately for\nsubtrees. We explore this relationship in detail and show the necessary and\nsufficient conditions for such separability and generalize previous dynamic\nprogramming approaches into a framework that can optimize any combination of\nseparable objectives and constraints. Experiments on five application domains\nshow the general applicability of this framework, while outperforming the\nscalability of general-purpose solvers by a large margin.\n","authors":["Jacobus G. M. van der Linden","Mathijs M. de Weerdt","Emir Demirović"],"pdf_url":"https://arxiv.org/pdf/2305.19706v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18223v1","updated":"2025-01-30T09:24:58Z","published":"2025-01-30T09:24:58Z","title":"Exploring Large Protein Language Models in Constrained Evaluation\n  Scenarios within the FLIP Benchmark","summary":"  In this study, we expand upon the FLIP benchmark-designed for evaluating\nprotein fitness prediction models in small, specialized prediction tasks-by\nassessing the performance of state-of-the-art large protein language models,\nincluding ESM-2 and SaProt on the FLIP dataset. Unlike larger, more diverse\nbenchmarks such as ProteinGym, which cover a broad spectrum of tasks, FLIP\nfocuses on constrained settings where data availability is limited. This makes\nit an ideal framework to evaluate model performance in scenarios with scarce\ntask-specific data. We investigate whether recent advances in protein language\nmodels lead to significant improvements in such settings. Our findings provide\nvaluable insights into the performance of large-scale models in specialized\nprotein prediction tasks.\n","authors":["Manuel F. Mollon","Joaquin Gonzalez-Rodriguez","Alicia Lozano-Diez","Daniel Ramos","Doroteo T. Toledano"],"pdf_url":"https://arxiv.org/pdf/2501.18223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18219v1","updated":"2025-01-30T09:19:09Z","published":"2025-01-30T09:19:09Z","title":"Revisiting $Ψ$DONet: microlocally inspired filters for\n  incomplete-data tomographic reconstructions","summary":"  In this paper, we revisit a supervised learning approach based on unrolling,\nknown as $\\Psi$DONet, by providing a deeper microlocal interpretation for its\ntheoretical analysis, and extending its study to the case of sparse-angle\ntomography. Furthermore, we refine the implementation of the original\n$\\Psi$DONet considering special filters whose structure is specifically\ninspired by the streak artifact singularities characterizing tomographic\nreconstructions from incomplete data. This allows to considerably lower the\nnumber of (learnable) parameters while preserving (or even slightly improving)\nthe same quality for the reconstructions from limited-angle data and providing\na proof-of-concept for the case of sparse-angle tomographic data.\n","authors":["Tatiana A. Bubba","Luca Ratti","Andrea Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2501.18219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10979v2","updated":"2025-01-30T09:17:22Z","published":"2025-01-19T08:06:06Z","title":"Control LLM: Controlled Evolution for Intelligence Retention in LLM","summary":"  Large Language Models (LLMs) demand significant computational resources,\nmaking it essential to enhance their capabilities without retraining from\nscratch. A key challenge in this domain is \\textit{catastrophic forgetting}\n(CF), which hampers performance during Continuous Pre-training (CPT) and\nContinuous Supervised Fine-Tuning (CSFT). We propose \\textbf{Control LLM}, a\nnovel approach that leverages parallel pre-trained and expanded transformer\nblocks, aligning their hidden-states through interpolation strategies This\nmethod effectively preserves performance on existing tasks while seamlessly\nintegrating new knowledge.\n  Extensive experiments demonstrate the effectiveness of Control LLM in both\nCPT and CSFT. On Llama3.1-8B-Instruct, it achieves significant improvements in\nmathematical reasoning ($+14.4\\%$ on Math-Hard) and coding performance ($+10\\%$\non MBPP-PLUS). On Llama3.1-8B, it enhances multilingual capabilities ($+10.6\\%$\non C-Eval, $+6.8\\%$ on CMMLU, and $+30.2\\%$ on CMMLU-0shot-CoT). It surpasses\nexisting methods and achieves SOTA among open-source models tuned from the same\nbase model, using substantially less data and compute. Crucially, these gains\nare realized while preserving strong original capabilities, with minimal\ndegradation ($<4.3\\% \\text{on MMLU}$) compared to $>35\\%$ in open-source Math\nand Coding models. This approach has been successfully deployed in LinkedIn's\nGenAI-powered job seeker and Ads unit products.\n  To support further research, we release the training and evaluation code\n(https://github.com/linkedin/ControlLLM) along with models trained on public\ndatasets (https://huggingface.co/ControlLLM) to the community.\n","authors":["Haichao Wei","Yunxiang Ren","Zhoutong Fu","Aman Lunia","Yi-Lin Chen","Alice Leung","Ya Xu"],"pdf_url":"https://arxiv.org/pdf/2501.10979v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2411.13117v2","updated":"2025-01-30T09:15:26Z","published":"2024-11-20T08:21:53Z","title":"Compute Optimal Inference and Provable Amortisation Gap in Sparse\n  Autoencoders","summary":"  A recent line of work has shown promise in using sparse autoencoders (SAEs)\nto uncover interpretable features in neural network representations. However,\nthe simple linear-nonlinear encoding mechanism in SAEs limits their ability to\nperform accurate sparse inference. Using compressed sensing theory, we prove\nthat an SAE encoder is inherently insufficient for accurate sparse inference,\neven in solvable cases. We then decouple encoding and decoding processes to\nempirically explore conditions where more sophisticated sparse inference\nmethods outperform traditional SAE encoders. Our results reveal substantial\nperformance gains with minimal compute increases in correct inference of sparse\ncodes. We demonstrate this generalises to SAEs applied to large language\nmodels, where more expressive encoders achieve greater interpretability. This\nwork opens new avenues for understanding neural network representations and\nanalysing large language model activations.\n","authors":["Charles O'Neill","Alim Gumran","David Klindt"],"pdf_url":"https://arxiv.org/pdf/2411.13117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.12430v2","updated":"2025-01-30T09:14:32Z","published":"2021-06-23T14:35:38Z","title":"Beyond Predictions in Neural ODEs: Identification and Interventions","summary":"  Spurred by tremendous success in pattern matching and prediction tasks,\nresearchers increasingly resort to machine learning to aid original scientific\ndiscovery. Given large amounts of observational data about a system, can we\nuncover the rules that govern its evolution? Solving this task holds the great\npromise of fully understanding the causal interactions and being able to make\nreliable predictions about the system's behavior under interventions. We take a\nstep towards answering this question for time-series data generated from\nsystems of ordinary differential equations (ODEs). While the governing ODEs\nmight not be identifiable from data alone, we show that combining simple\nregularization schemes with flexible neural ODEs can robustly recover the\ndynamics and causal structures from time-series data. Our results on a variety\nof (non)-linear first and second order systems as well as real data validate\nour method. We conclude by showing that we can also make accurate predictions\nunder interventions on variables or the system itself.\n","authors":["Hananeh Aliee","Fabian J. Theis","Niki Kilbertus"],"pdf_url":"https://arxiv.org/pdf/2106.12430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04443v2","updated":"2025-01-30T09:07:46Z","published":"2025-01-08T11:52:43Z","title":"Revisiting LocalSGD and SCAFFOLD: Improved Rates and Missing Analysis","summary":"  LocalSGD and SCAFFOLD are widely used methods in distributed stochastic\noptimization, with numerous applications in machine learning, large-scale data\nprocessing, and federated learning. However, rigorously establishing their\ntheoretical advantages over simpler methods, such as minibatch SGD (MbSGD), has\nproven challenging, as existing analyses often rely on strong assumptions,\nunrealistic premises, or overly restrictive scenarios.\n  In this work, we revisit the convergence properties of LocalSGD and SCAFFOLD\nunder a variety of existing or weaker conditions, including gradient\nsimilarity, Hessian similarity, weak convexity, and Lipschitz continuity of the\nHessian. Our analysis shows that (i) LocalSGD achieves faster convergence\ncompared to MbSGD for weakly convex functions without requiring stronger\ngradient similarity assumptions; (ii) LocalSGD benefits significantly from\nhigher-order similarity and smoothness; and (iii) SCAFFOLD demonstrates faster\nconvergence than MbSGD for a broader class of non-quadratic functions. These\ntheoretical insights provide a clearer understanding of the conditions under\nwhich LocalSGD and SCAFFOLD outperform MbSGD.\n","authors":["Ruichen Luo","Sebastian U Stich","Samuel Horváth","Martin Takáč"],"pdf_url":"https://arxiv.org/pdf/2501.04443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11439v2","updated":"2025-01-30T09:03:11Z","published":"2024-12-16T04:43:54Z","title":"Bayesian Flow Is All You Need to Sample Out-of-Distribution Chemical\n  Spaces","summary":"  Generating novel molecules with higher properties than the training space,\nnamely the out-of-distribution generation, is important for ${de~novo}$ drug\ndesign. However, it is not easy for distribution learning-based models, for\nexample diffusion models, to solve this challenge as these methods are designed\nto fit the distribution of training data as close as possible. In this paper,\nwe show that Bayesian flow network is capable of effortlessly generating high\nquality out-of-distribution samples that meet several scenarios. We introduce a\nsemi-autoregressive training/sampling method that helps to enhance the model\nperformance and surpass the state-of-the-art models.\n","authors":["Nianze Tao"],"pdf_url":"https://arxiv.org/pdf/2412.11439v2.pdf","comment":"25 pages, 10 figures, 8 tables"},{"id":"http://arxiv.org/abs/2309.08911v2","updated":"2025-01-30T09:02:00Z","published":"2023-09-16T07:30:12Z","title":"Efficient Methods for Non-stationary Online Learning","summary":"  Non-stationary online learning has drawn much attention in recent years. In\nparticular, dynamic regret and adaptive regret are proposed as two principled\nperformance measures for online convex optimization in non-stationary\nenvironments. To optimize them, a two-layer online ensemble is usually deployed\ndue to the inherent uncertainty of the non-stationarity, in which a group of\nbase-learners are maintained and a meta-algorithm is employed to track the best\none on the fly. However, the two-layer structure raises the concern about the\ncomputational complexity -- those methods typically maintain $\\mathcal{O}(\\log\nT)$ base-learners simultaneously for a $T$-round online game and thus perform\nmultiple projections onto the feasible domain per round, which becomes the\ncomputational bottleneck when the domain is complicated. In this paper, we\nfirst present efficient methods for optimizing dynamic regret and adaptive\nregret, which reduce the number of projections per round from $\\mathcal{O}(\\log\nT)$ to $1$. The obtained algorithms require only one gradient query and one\nfunction evaluation at each round. Our technique hinges on the reduction\nmechanism developed in parameter-free online learning and requires non-trivial\ntwists on non-stationary online methods. Furthermore, we study an even\nstrengthened measure, namely the ``interval dynamic regret'', and reduce the\nnumber of projections per round from $\\mathcal{O}(\\log^2 T)$ to $1$ to minimize\nit. Our reduction demonstrates great generalizability and can be applied to two\nimportant applications: online stochastic control and online principal\ncomponent analysis, resulting in methods that are both efficient and optimal.\nFinally, empirical studies verify our theoretical findings.\n","authors":["Peng Zhao","Yan-Feng Xie","Lijun Zhang","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2309.08911v2.pdf","comment":"preliminary conference version appeared at NeurIPS 2022; this\n  extended version improves the paper presentation, further investigates the\n  interval dynamic regret, and adds two applications (online non-stochastic\n  control and online PCA)"},{"id":"http://arxiv.org/abs/2409.18968v2","updated":"2025-01-30T08:55:23Z","published":"2024-09-11T13:47:47Z","title":"Safety challenges of AI in medicine in the era of large language models","summary":"  Recent advancements in artificial intelligence (AI), particularly in large\nlanguage models (LLMs), have unlocked significant potential to enhance the\nquality and efficiency of medical care. By introducing a novel way to interact\nwith AI and data through natural language, LLMs offer new opportunities for\nmedical practitioners, patients, and researchers. However, as AI and LLMs\nbecome more powerful and especially achieve superhuman performance in some\nmedical tasks, public concerns over their safety have intensified. These\nconcerns about AI safety have emerged as the most significant obstacles to the\nadoption of AI in medicine. In response, this review examines emerging risks in\nAI utilization during the LLM era. First, we explore LLM-specific safety\nchallenges from functional and communication perspectives, addressing issues\nacross data collection, model training, and real-world application. We then\nconsider inherent safety problems shared by all AI systems, along with\nadditional complications introduced by LLMs. Last, we discussed how safety\nissues of using AI in clinical practice and healthcare system operation would\nundermine trust among patient, clinicians and the public, and how to build\nconfidence in these systems. By emphasizing the development of safe AI, we\nbelieve these technologies can be more rapidly and reliably integrated into\neveryday medical practice to benefit both patients and clinicians.\n","authors":["Xiaoye Wang","Nicole Xi Zhang","Hongyu He","Trang Nguyen","Kun-Hsing Yu","Hao Deng","Cynthia Brandt","Danielle S. Bitterman","Ling Pan","Ching-Yu Cheng","James Zou","Dianbo Liu"],"pdf_url":"https://arxiv.org/pdf/2409.18968v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18199v1","updated":"2025-01-30T08:44:54Z","published":"2025-01-30T08:44:54Z","title":"HKAN: Hierarchical Kolmogorov-Arnold Network without Backpropagation","summary":"  This paper introduces the Hierarchical Kolmogorov-Arnold Network (HKAN), a\nnovel network architecture that offers a competitive alternative to the\nrecently proposed Kolmogorov-Arnold Network (KAN). Unlike KAN, which relies on\nbackpropagation, HKAN adopts a randomized learning approach, where the\nparameters of its basis functions are fixed, and linear aggregations are\noptimized using least-squares regression. HKAN utilizes a hierarchical\nmulti-stacking framework, with each layer refining the predictions from the\nprevious one by solving a series of linear regression problems. This\nnon-iterative training method simplifies computation and eliminates sensitivity\nto local minima in the loss function. Empirical results show that HKAN delivers\ncomparable, if not superior, accuracy and stability relative to KAN across\nvarious regression tasks, while also providing insights into variable\nimportance. The proposed approach seamlessly integrates theoretical insights\nwith practical applications, presenting a robust and efficient alternative for\nneural network modeling.\n","authors":["Grzegorz Dudek","Tomasz Rodak"],"pdf_url":"https://arxiv.org/pdf/2501.18199v1.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2407.12950v2","updated":"2025-01-30T08:38:34Z","published":"2024-07-17T18:32:41Z","title":"Beyond the Veil of Similarity: Quantifying Semantic Continuity in\n  Explainable AI","summary":"  We introduce a novel metric for measuring semantic continuity in Explainable\nAI methods and machine learning models. We posit that for models to be truly\ninterpretable and trustworthy, similar inputs should yield similar\nexplanations, reflecting a consistent semantic understanding. By leveraging XAI\ntechniques, we assess semantic continuity in the task of image recognition. We\nconduct experiments to observe how incremental changes in input affect the\nexplanations provided by different XAI methods. Through this approach, we aim\nto evaluate the models' capability to generalize and abstract semantic concepts\naccurately and to evaluate different XAI methods in correctly capturing the\nmodel behaviour. This paper contributes to the broader discourse on AI\ninterpretability by proposing a quantitative measure for semantic continuity\nfor XAI methods, offering insights into the models' and explainers' internal\nreasoning processes, and promoting more reliable and transparent AI systems.\n","authors":["Qi Huang","Emanuele Mezzi","Osman Mutlu","Miltiadis Kofinas","Vidya Prasad","Shadnan Azwad Khan","Elena Ranguelova","Niki van Stein"],"pdf_url":"https://arxiv.org/pdf/2407.12950v2.pdf","comment":"25 pages, accepted at the world conference of explainable AI, 2024,\n  Malta"},{"id":"http://arxiv.org/abs/2411.07099v2","updated":"2025-01-30T08:37:52Z","published":"2024-11-11T16:24:03Z","title":"Bounded Rationality Equilibrium Learning in Mean Field Games","summary":"  Mean field games (MFGs) tractably model behavior in large agent populations.\nThe literature on learning MFG equilibria typically focuses on finding Nash\nequilibria (NE), which assume perfectly rational agents and are hence\nimplausible in many realistic situations. To overcome these limitations, we\nincorporate bounded rationality into MFGs by leveraging the well-known concept\nof quantal response equilibria (QRE). Two novel types of MFG QRE enable the\nmodeling of large agent populations where individuals only noisily estimate the\ntrue objective. We also introduce a second source of bounded rationality to\nMFGs by restricting agents' planning horizon. The resulting novel receding\nhorizon (RH) MFGs are combined with QRE and existing approaches to model\ndifferent aspects of bounded rationality in MFGs. We formally define MFG QRE\nand RH MFGs and compare them to existing equilibrium concepts such as\nentropy-regularized NE. Subsequently, we design generalized fixed point\niteration and fictitious play algorithms to learn QRE and RH equilibria. After\na theoretical analysis, we give different examples to evaluate the capabilities\nof our learning algorithms and outline practical differences between the\nequilibrium concepts.\n","authors":["Yannick Eich","Christian Fabian","Kai Cui","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2411.07099v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2501.18197v1","updated":"2025-01-30T08:31:09Z","published":"2025-01-30T08:31:09Z","title":"Fundamental Challenges in Evaluating Text2SQL Solutions and Detecting\n  Their Limitations","summary":"  In this work, we dive into the fundamental challenges of evaluating Text2SQL\nsolutions and highlight potential failure causes and the potential risks of\nrelying on aggregate metrics in existing benchmarks. We identify two largely\nunaddressed limitations in current open benchmarks: (1) data quality issues in\nthe evaluation data, mainly attributed to the lack of capturing the\nprobabilistic nature of translating a natural language description into a\nstructured query (e.g., NL ambiguity), and (2) the bias introduced by using\ndifferent match functions as approximations for SQL equivalence.\n  To put both limitations into context, we propose a unified taxonomy of all\nText2SQL limitations that can lead to both prediction and evaluation errors. We\nthen motivate the taxonomy by providing a survey of Text2SQL limitations using\nstate-of-the-art Text2SQL solutions and benchmarks. We describe the causes of\nlimitations with real-world examples and propose potential mitigation solutions\nfor each category in the taxonomy. We conclude by highlighting the open\nchallenges encountered when deploying such mitigation strategies or attempting\nto automatically apply the taxonomy.\n","authors":["Cedric Renggli","Ihab F. Ilyas","Theodoros Rekatsinas"],"pdf_url":"https://arxiv.org/pdf/2501.18197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18196v1","updated":"2025-01-30T08:22:51Z","published":"2025-01-30T08:22:51Z","title":"GDformer: Going Beyond Subsequence Isolation for Multivariate Time\n  Series Anomaly Detection","summary":"  Unsupervised anomaly detection of multivariate time series is a challenging\ntask, given the requirements of deriving a compact detection criterion without\naccessing the anomaly points. The existing methods are mainly based on\nreconstruction error or association divergence, which are both confined to\nisolated subsequences with limited horizons, hardly promising unified\nseries-level criterion. In this paper, we propose the Global\nDictionary-enhanced Transformer (GDformer) with a renovated dictionary-based\ncross attention mechanism to cultivate the global representations shared by all\nnormal points in the entire series. Accordingly, the cross-attention maps\nreflect the correlation weights between the point and global representations,\nwhich naturally leads to the representation-wise similarity-based detection\ncriterion. To foster more compact detection boundary, prototypes are introduced\nto capture the distribution of normal point-global correlation weights.\nGDformer consistently achieves state-of-the-art unsupervised anomaly detection\nperformance on five real-world benchmark datasets. Further experiments validate\nthe global dictionary has great transferability among various datasets. The\ncode is available at https://github.com/yuppielqx/GDformer.\n","authors":["Qingxiang Liu","Chenghao Liu","Sheng Sun","Di Yao","Yuxuan Liang"],"pdf_url":"https://arxiv.org/pdf/2501.18196v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.05798v2","updated":"2025-01-30T08:17:51Z","published":"2023-09-11T20:06:00Z","title":"Enhancing Hyperedge Prediction with Context-Aware Self-Supervised\n  Learning","summary":"  Hypergraphs can naturally model group-wise relations (e.g., a group of users\nwho co-purchase an item) as hyperedges. Hyperedge prediction is to predict\nfuture or unobserved hyperedges, which is a fundamental task in many real-world\napplications (e.g., group recommendation). Despite the recent breakthrough of\nhyperedge prediction methods, the following challenges have been rarely\nstudied: (C1) How to aggregate the nodes in each hyperedge candidate for\naccurate hyperedge prediction? and (C2) How to mitigate the inherent data\nsparsity problem in hyperedge prediction? To tackle both challenges together,\nin this paper, we propose a novel hyperedge prediction framework (CASH) that\nemploys (1) context-aware node aggregation to precisely capture complex\nrelations among nodes in each hyperedge for (C1) and (2) self-supervised\ncontrastive learning in the context of hyperedge prediction to enhance\nhypergraph representations for (C2). Furthermore, as for (C2), we propose a\nhyperedge-aware augmentation method to fully exploit the latent semantics\nbehind the original hypergraph and consider both node-level and group-level\ncontrasts (i.e., dual contrasts) for better node and hyperedge representations.\nExtensive experiments on six real-world hypergraphs reveal that CASH\nconsistently outperforms all competing methods in terms of the accuracy in\nhyperedge prediction and each of the proposed strategies is effective in\nimproving the model accuracy of CASH. For the detailed information of CASH, we\nprovide the code and datasets at: https://github.com/yy-ko/cash.\n","authors":["Yunyong Ko","Hanghang Tong","Sang-Wook Kim"],"pdf_url":"https://arxiv.org/pdf/2309.05798v2.pdf","comment":"13 pages, 7 figures, 4 tables, accepted in IEEE TKDE"},{"id":"http://arxiv.org/abs/2501.18192v1","updated":"2025-01-30T08:13:01Z","published":"2025-01-30T08:13:01Z","title":"Machine Learning Fairness for Depression Detection using EEG Data","summary":"  This paper presents the very first attempt to evaluate machine learning\nfairness for depression detection using electroencephalogram (EEG) data. We\nconduct experiments using different deep learning architectures such as\nConvolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) networks,\nand Gated Recurrent Unit (GRU) networks across three EEG datasets: Mumtaz,\nMODMA and Rest. We employ five different bias mitigation strategies at the\npre-, in- and post-processing stages and evaluate their effectiveness. Our\nexperimental results show that bias exists in existing EEG datasets and\nalgorithms for depression detection, and different bias mitigation methods\naddress bias at different levels across different fairness measures.\n","authors":["Angus Man Ho Kwok","Jiaee Cheong","Sinan Kalkan","Hatice Gunes"],"pdf_url":"https://arxiv.org/pdf/2501.18192v1.pdf","comment":"To appear as part of the International Symposium on Biomedical\n  Imaging (ISBI) 2025 proceedings"},{"id":"http://arxiv.org/abs/2501.18189v1","updated":"2025-01-30T07:44:21Z","published":"2025-01-30T07:44:21Z","title":"Neural Network Modeling of Microstructure Complexity Using Digital\n  Libraries","summary":"  Microstructure evolution in matter is often modeled numerically using field\nor level-set solvers, mirroring the dual representation of spatiotemporal\ncomplexity in terms of pixel or voxel data, and geometrical forms in vector\ngraphics. Motivated by this analog, as well as the structural and event-driven\nnature of artificial and spiking neural networks, respectively, we evaluate\ntheir performance in learning and predicting fatigue crack growth and Turing\npattern development. Predictions are made based on digital libraries\nconstructed from computer simulations, which can be replaced by experimental\ndata to lift the mathematical overconstraints of physics. Our assessment\nsuggests that the leaky integrate-and-fire neuron model offers superior\npredictive accuracy with fewer parameters and less memory usage, alleviating\nthe accuracy-cost tradeoff in contrast to the common practices in computer\nvision tasks. Examination of network architectures shows that these benefits\narise from its reduced weight range and sparser connections. The study\nhighlights the capability of event-driven models in tackling problems with\nevolutionary bulk-phase and interface behaviors using the digital library\napproach.\n","authors":["Yingjie Zhao","Zhiping Xu"],"pdf_url":"https://arxiv.org/pdf/2501.18189v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17704v2","updated":"2025-01-30T07:41:58Z","published":"2024-09-26T10:20:59Z","title":"Transfer Learning in $\\ell_1$ Regularized Regression: Hyperparameter\n  Selection Strategy based on Sharp Asymptotic Analysis","summary":"  Transfer learning techniques aim to leverage information from multiple\nrelated datasets to enhance prediction quality against a target dataset. Such\nmethods have been adopted in the context of high-dimensional sparse regression,\nand some Lasso-based algorithms have been invented: Trans-Lasso and Pretraining\nLasso are such examples. These algorithms require the statistician to select\nhyperparameters that control the extent and type of information transfer from\nrelated datasets. However, selection strategies for these hyperparameters, as\nwell as the impact of these choices on the algorithm's performance, have been\nlargely unexplored. To address this, we conduct a thorough, precise study of\nthe algorithm in a high-dimensional setting via an asymptotic analysis using\nthe replica method. Our approach reveals a surprisingly simple behavior of the\nalgorithm: Ignoring one of the two types of information transferred to the\nfine-tuning stage has little effect on generalization performance, implying\nthat efforts for hyperparameter selection can be significantly reduced. Our\ntheoretical findings are also empirically supported by applications on\nreal-world and semi-artificial datasets using the IMDb and MNIST datasets,\nrespectively.\n","authors":["Koki Okajima","Tomoyuki Obuchi"],"pdf_url":"https://arxiv.org/pdf/2409.17704v2.pdf","comment":"23 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.18187v1","updated":"2025-01-30T07:41:20Z","published":"2025-01-30T07:41:20Z","title":"In-Context Learning of Polynomial Kernel Regression in Transformers with\n  GLU Layers","summary":"  Transformer-based models have demonstrated remarkable ability in in-context\nlearning (ICL), where they can adapt to unseen tasks from a prompt with a few\nexamples, without requiring parameter updates. Recent research has provided\ninsight into how linear Transformers can perform ICL by implementing gradient\ndescent estimators. In particular, it has been shown that the optimal linear\nself-attention (LSA) mechanism can implement one step of gradient descent with\nrespect to a linear least-squares objective when trained on random linear\nregression tasks.\n  However, the theoretical understanding of ICL for nonlinear function classes\nremains limited. In this work, we address this gap by first showing that LSA is\ninherently restricted to solving linear least-squares objectives and thus, the\nsolutions in prior works cannot readily extend to nonlinear ICL tasks. To\novercome this limitation, drawing inspiration from modern architectures, we\nstudy a mechanism that combines LSA with GLU-like feed-forward layers and show\nthat this allows the model to perform one step of gradient descent on a\npolynomial kernel regression. Further, we characterize the scaling behavior of\nthe resulting Transformer model, highlighting the necessary model size to\neffectively handle quadratic ICL tasks. Our findings highlight the distinct\nroles of attention and feed-forward layers in nonlinear ICL and identify key\nchallenges when extending ICL to nonlinear function classes.\n","authors":["Haoyuan Sun","Ali Jadbabaie","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2501.18187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18184v1","updated":"2025-01-30T07:35:43Z","published":"2025-01-30T07:35:43Z","title":"Genetic Algorithm with Border Trades (GAB)","summary":"  This paper introduces a novel approach to improving Genetic Algorithms (GA)\nin large or complex problem spaces by incorporating new chromosome patterns in\nthe breeding process through border trade activities. These strategies increase\nchromosome diversity, preventing premature convergence and enhancing the GA's\nability to explore the solution space more effectively. Empirical evidence\ndemonstrates significant improvements in convergence behavior. This approach\noffers a promising pathway to addressing challenges in optimizing large or\ncomplex problem domains.\n","authors":["Qingchuan Lyu"],"pdf_url":"https://arxiv.org/pdf/2501.18184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18183v1","updated":"2025-01-30T07:28:34Z","published":"2025-01-30T07:28:34Z","title":"Decentralized Projection-free Online Upper-Linearizable Optimization\n  with Applications to DR-Submodular Optimization","summary":"  We introduce a novel framework for decentralized projection-free\noptimization, extending projection-free methods to a broader class of\nupper-linearizable functions. Our approach leverages decentralized optimization\ntechniques with the flexibility of upper-linearizable function frameworks,\neffectively generalizing traditional DR-submodular function optimization. We\nobtain the regret of $O(T^{1-\\theta/2})$ with communication complexity of\n$O(T^{\\theta})$ and number of linear optimization oracle calls of\n$O(T^{2\\theta})$ for decentralized upper-linearizable function optimization,\nfor any $0\\le \\theta \\le 1$. This approach allows for the first results for\nmonotone up-concave optimization with general convex constraints and\nnon-monotone up-concave optimization with general convex constraints. Further,\nthe above results for first order feedback are extended to zeroth order,\nsemi-bandit, and bandit feedback.\n","authors":["Yiyang Lu","Mohammad Pedramfar","Vaneet Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2501.18183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18178v1","updated":"2025-01-30T07:15:38Z","published":"2025-01-30T07:15:38Z","title":"Estimating Multi-chirp Parameters using Curvature-guided Langevin Monte\n  Carlo","summary":"  This paper considers the problem of estimating chirp parameters from a noisy\nmixture of chirps. While a rich body of work exists in this area, challenges\nremain when extending these techniques to chirps of higher order polynomials.\nWe formulate this as a non-convex optimization problem and propose a modified\nLangevin Monte Carlo (LMC) sampler that exploits the average curvature of the\nobjective function to reliably find the minimizer. Results show that our\nCurvature-guided LMC (CG-LMC) algorithm is robust and succeeds even in low SNR\nregimes, making it viable for practical applications.\n","authors":["Sattwik Basu","Debottam Dutta","Yu-Lin Wei","Romit Roy Choudhury"],"pdf_url":"https://arxiv.org/pdf/2501.18178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.14185v4","updated":"2025-01-30T07:12:45Z","published":"2023-04-27T13:41:12Z","title":"HPSCAN: Human Perception-Based Scattered Data Clustering","summary":"  Cluster separation is a task typically tackled by widely used clustering\ntechniques, such as k-means or DBSCAN. However, these algorithms are based on\nnon-perceptual metrics, and our experiments demonstrate that their output does\nnot reflect human cluster perception. To bridge the gap between human cluster\nperception and machine-computed clusters, we propose HPSCAN, a learning\nstrategy that operates directly on scattered data. To learn perceptual cluster\nseparation on such data, we crowdsourced the labeling of 7,320 bivariate\n(scatterplot) datasets to 384 human participants. We train our HPSCAN model on\nthese human-annotated data. Instead of rendering these data as scatterplot\nimages, we used their x and y point coordinates as input to a modified\nPointNet++ architecture, enabling direct inference on point clouds. In this\nwork, we provide details on how we collected our dataset, report statistics of\nthe resulting annotations, and investigate the perceptual agreement of cluster\nseparation for real-world data. We also report the training and evaluation\nprotocol for HPSCAN and introduce a novel metric, that measures the accuracy\nbetween a clustering technique and a group of human annotators. We explore\npredicting point-wise human agreement to detect ambiguities. Finally, we\ncompare our approach to ten established clustering techniques and demonstrate\nthat HPSCAN is capable of generalizing to unseen and out-of-scope data.\n","authors":["Sebastian Hartwig","Christian van Onzenoodt","Dominik Engel","Pedro Hermosilla","Timo Ropinski"],"pdf_url":"https://arxiv.org/pdf/2304.14185v4.pdf","comment":"Currently, this manuscript is under revision at CGF"},{"id":"http://arxiv.org/abs/2412.15188v3","updated":"2025-01-30T07:08:45Z","published":"2024-12-19T18:56:24Z","title":"LMFusion: Adapting Pretrained Language Models for Multimodal Generation","summary":"  We present LMFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLMFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LMFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLMFusion improves image understanding by 20% and image generation by 3.6% using\nonly 50% of the FLOPs while maintaining Llama-3's language capabilities. We\nalso demonstrate that this framework can adapt existing vision-language models\nwith multimodal generation ability. Overall, this framework not only leverages\nexisting computational investments in text-only LLMs but also enables the\nparallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.\n","authors":["Weijia Shi","Xiaochuang Han","Chunting Zhou","Weixin Liang","Xi Victoria Lin","Luke Zettlemoyer","Lili Yu"],"pdf_url":"https://arxiv.org/pdf/2412.15188v3.pdf","comment":"Name change: LlamaFusion to LMFusion"},{"id":"http://arxiv.org/abs/2501.18174v1","updated":"2025-01-30T07:03:29Z","published":"2025-01-30T07:03:29Z","title":"Advancing Personalized Federated Learning: Integrative Approaches with\n  AI for Enhanced Privacy and Customization","summary":"  In the age of data-driven decision making, preserving privacy while providing\npersonalized experiences has become paramount. Personalized Federated Learning\n(PFL) offers a promising framework by decentralizing the learning process, thus\nensuring data privacy and reducing reliance on centralized data repositories.\nHowever, the integration of advanced Artificial Intelligence (AI) techniques\nwithin PFL remains underexplored. This paper proposes a novel approach that\nenhances PFL with cutting-edge AI methodologies including adaptive\noptimization, transfer learning, and differential privacy. We present a model\nthat not only boosts the performance of individual client models but also\nensures robust privacy-preserving mechanisms and efficient resource utilization\nacross heterogeneous networks. Empirical results demonstrate significant\nimprovements in model accuracy and personalization, along with stringent\nprivacy adherence, as compared to conventional federated learning models. This\nwork paves the way for a new era of truly personalized and privacy-conscious AI\nsystems, offering significant implications for industries requiring compliance\nwith stringent data protection regulations.\n","authors":["Kevin Cooper","Michael Geller"],"pdf_url":"https://arxiv.org/pdf/2501.18174v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2501.16758"},{"id":"http://arxiv.org/abs/2412.19055v3","updated":"2025-01-30T07:00:34Z","published":"2024-12-26T04:45:05Z","title":"SpectralKD: A Unified Framework for Interpreting and Distilling Vision\n  Transformers via Spectral Analysis","summary":"  Knowledge Distillation (KD) has achieved widespread success in compressing\nlarge Vision Transformers (ViTs), but a unified theoretical framework for both\nViTs and KD is still lacking. In this paper, we propose SpectralKD, a novel\nunified analytical framework that offers deeper insights into ViTs and\noptimizes KD via spectral analysis. Our model-wise analysis reveals that CaiT\nconcentrates information in their first and last few layers, informing optimal\nlayer selection for KD. Surprisingly, our layer-wise analysis discovers that\nSwin Transformer and CaiT exhibit similar spectral encoding patterns despite\ntheir architectural differences, leading to feature map alignment guideline.\nBuilding on these insights, we propose a simple yet effective spectral\nalignment method for KD. Benefiting from the deeper understanding by above\nanalysis results, even such a simple strategy achieves state-of-the-art\nperformance on ImageNet-1K without introducing any trainable parameters,\nimproving DeiT-Tiny by $+5.2\\%$ and Swin-Tiny by $+1.4\\%$ in top-1 accuracy.\nFurthermore, our post-training analysis reveals that distilled students can\nreproduce spectral patterns similar to their teachers, opening a new area we\nterm ``distillation dynamics\". Code and experimental logs are available in\nhttps://github.com/thy960112/SpectralKD.\n","authors":["Huiyuan Tian","Bonan Xu","Shijian Li","Gang Pan"],"pdf_url":"https://arxiv.org/pdf/2412.19055v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06490v2","updated":"2025-01-30T06:58:58Z","published":"2024-10-09T02:31:49Z","title":"Adaptive Guidance for Local Training in Heterogeneous Federated Learning","summary":"  Model heterogeneity poses a significant challenge in Heterogeneous Federated\nLearning (HtFL). In scenarios with diverse model architectures, directly\naggregating model parameters is impractical, leading HtFL methods to\nincorporate an extra objective alongside the original local objective on each\nclient to facilitate collaboration. However, this often results in a mismatch\nbetween the extra and local objectives. To resolve this, we propose Federated\nLearning-to-Guide (FedL2G), a method that adaptively learns to guide local\ntraining in a federated manner, ensuring the added objective aligns with each\nclient's original goal. With theoretical guarantees, FedL2G utilizes only\nfirst-order derivatives w.r.t. model parameters, achieving a non-convex\nconvergence rate of O(1/T). We conduct extensive experiments across two data\nheterogeneity and six model heterogeneity settings, using 14 heterogeneous\nmodel architectures (e.g., CNNs and ViTs). The results show that FedL2G\nsignificantly outperforms seven state-of-the-art methods.\n","authors":["Jianqing Zhang","Yang Liu","Yang Hua","Jian Cao","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.06490v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18170v1","updated":"2025-01-30T06:49:57Z","published":"2025-01-30T06:49:57Z","title":"Continually Evolved Multimodal Foundation Models for Cancer Prognosis","summary":"  Cancer prognosis is a critical task that involves predicting patient outcomes\nand survival rates. To enhance prediction accuracy, previous studies have\nintegrated diverse data modalities, such as clinical notes, medical images, and\ngenomic data, leveraging their complementary information. However, existing\napproaches face two major limitations. First, they struggle to incorporate\nnewly arrived data with varying distributions into training, such as patient\nrecords from different hospitals, thus rendering sub-optimal generalizability\nand limited utility in real-world applications. Second, most multimodal\nintegration methods rely on simplistic concatenation or task-specific\npipelines, which fail to capture the complex interdependencies across\nmodalities. To address these, we propose a continually evolving multi-modal\nfoundation model. Extensive experiments on the TCGA dataset demonstrate the\neffectiveness of our approach, highlighting its potential to advance cancer\nprognosis by enabling robust and adaptive multimodal integration.\n","authors":["Jie Peng","Shuang Zhou","Longwei Yang","Yiran Song","Mohan Zhang","Kaixiong Zhou","Feng Xie","Mingquan Lin","Rui Zhang","Tianlong Chen"],"pdf_url":"https://arxiv.org/pdf/2501.18170v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2411.06572v2","updated":"2025-01-30T06:31:26Z","published":"2024-11-10T19:38:35Z","title":"Fitting Multiple Machine Learning Models with Performance Based\n  Clustering","summary":"  Traditional machine learning approaches assume that data comes from a single\ngenerating mechanism, which may not hold for most real life data. In these\ncases, the single mechanism assumption can result in suboptimal performance. We\nintroduce a clustering framework that eliminates this assumption by grouping\nthe data according to the relations between the features and the target values\nand we obtain multiple separate models to learn different parts of the data. We\nfurther extend our framework to applications having streaming data where we\nproduce outcomes using an ensemble of models. For this, the ensemble weights\nare updated based on the incoming data batches. We demonstrate the performance\nof our approach over the widely-studied real life datasets, showing significant\nimprovements over the traditional single-model approaches.\n","authors":["Mehmet Efe Lorasdagi","Ahmet Berker Koc","Ali Taha Koc","Suleyman Serdar Kozat"],"pdf_url":"https://arxiv.org/pdf/2411.06572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18164v1","updated":"2025-01-30T06:23:28Z","published":"2025-01-30T06:23:28Z","title":"Faster Convergence of Riemannian Stochastic Gradient Descent with\n  Increasing Batch Size","summary":"  Many models used in machine learning have become so large that even computer\ncomputation of the full gradient of the loss function is impractical. This has\nmade it necessary to efficiently train models using limited available\ninformation, such as batch size and learning rate. We have theoretically\nanalyzed the use of Riemannian stochastic gradient descent (RSGD) and found\nthat using an increasing batch size leads to faster RSGD convergence than using\na constant batch size not only with a constant learning rate but also with a\ndecaying learning rate, such as cosine annealing decay and polynomial decay. In\nparticular, RSGD has a better convergence rate $O(\\frac{1}{\\sqrt{T}})$ than the\nexisting rate $O(\\frac{\\sqrt{\\log T}}{\\sqrt[4]{T}})$ with a diminishing\nlearning rate, where $T$ is the number of iterations. The results of\nexperiments on principal component analysis and low-rank matrix completion\nproblems confirmed that, except for the MovieLens dataset and a constant\nlearning rate, using a polynomial growth batch size or an exponential growth\nbatch size results in better performance than using a constant batch size.\n","authors":["Kanata Oowada","Hideaki Iiduka"],"pdf_url":"https://arxiv.org/pdf/2501.18164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07727v2","updated":"2025-01-30T06:21:12Z","published":"2025-01-13T22:29:31Z","title":"Stronger Than You Think: Benchmarking Weak Supervision on Realistic\n  Tasks","summary":"  Weak supervision (WS) is a popular approach for label-efficient learning,\nleveraging diverse sources of noisy but inexpensive weak labels to\nautomatically annotate training data. Despite its wide usage, WS and its\npractical value are challenging to benchmark due to the many knobs in its\nsetup, including: data sources, labeling functions (LFs), aggregation\ntechniques (called label models), and end model pipelines. Existing evaluation\nsuites tend to be limited, focusing on particular components or specialized use\ncases. Moreover, they often involve simplistic benchmark tasks or de-facto LF\nsets that are suboptimally written, producing insights that may not generalize\nto real-world settings. We address these limitations by introducing a new\nbenchmark, BOXWRENCH, designed to more accurately reflect real-world usages of\nWS. This benchmark features tasks with (1) higher class cardinality and\nimbalance, (2) notable domain expertise requirements, and (3) opportunities to\nre-use LFs across parallel multilingual corpora. For all tasks, LFs are written\nusing a careful procedure aimed at mimicking real-world settings. In contrast\nto existing WS benchmarks, we show that supervised learning requires\nsubstantial amounts (1000+) of labeled examples to match WS in many settings.\n","authors":["Tianyi Zhang","Linrong Cai","Jeffrey Li","Nicholas Roberts","Neel Guha","Jinoh Lee","Frederic Sala"],"pdf_url":"https://arxiv.org/pdf/2501.07727v2.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2501.15797v2","updated":"2025-01-30T06:10:23Z","published":"2025-01-27T05:46:06Z","title":"LemmaHead: RAG Assisted Proof Generation Using Large Language Models","summary":"  Developing the logic necessary to solve mathematical problems or write\nmathematical proofs is one of the more difficult objectives for large language\nmodels (LLMS). Currently, the most popular methods in literature consists of\nfine-tuning the model on written mathematical content such as academic\npublications and textbooks, so that the model can learn to emulate the style of\nmathematical writing. In this project, we explore the effectiveness of using\nretrieval augmented generation (RAG) to address gaps in the mathematical\nreasoning of LLMs. We develop LemmaHead, a RAG knowledge base that supplements\nqueries to the model with relevant mathematical context, with particular focus\non context from published textbooks. To measure our model's performance in\nmathematical reasoning, our testing paradigm focuses on the task of automated\ntheorem proving via generating proofs to a given mathematical claim in the Lean\nformal language.\n","authors":["Tianbo Yang","Mingqi Yang","Hongyi Zhao","Tianshuo Yang"],"pdf_url":"https://arxiv.org/pdf/2501.15797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18158v1","updated":"2025-01-30T05:48:13Z","published":"2025-01-30T05:48:13Z","title":"Large Language Models for Cryptocurrency Transaction Analysis: A Bitcoin\n  Case Study","summary":"  Cryptocurrencies are widely used, yet current methods for analyzing\ntransactions heavily rely on opaque, black-box models. These lack\ninterpretability and adaptability, failing to effectively capture behavioral\npatterns. Many researchers, including us, believe that Large Language Models\n(LLMs) could bridge this gap due to their robust reasoning abilities for\ncomplex tasks. In this paper, we test this hypothesis by applying LLMs to\nreal-world cryptocurrency transaction graphs, specifically within the Bitcoin\nnetwork. We introduce a three-tiered framework to assess LLM capabilities:\nfoundational metrics, characteristic overview, and contextual interpretation.\nThis includes a new, human-readable graph representation format, LLM4TG, and a\nconnectivity-enhanced sampling algorithm, CETraS, which simplifies larger\ntransaction graphs. Experimental results show that LLMs excel at foundational\nmetrics and offer detailed characteristic overviews. Their effectiveness in\ncontextual interpretation suggests they can provide useful explanations of\ntransaction behaviors, even with limited labeled data.\n","authors":["Yuchen Lei","Yuexin Xiang","Qin Wang","Rafael Dowsley","Tsz Hon Yuen","Jiangshan Yu"],"pdf_url":"https://arxiv.org/pdf/2501.18158v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17762v2","updated":"2025-01-30T05:26:05Z","published":"2025-01-29T16:53:16Z","title":"Improving Privacy Benefits of Redaction","summary":"  We propose a novel redaction methodology that can be used to sanitize natural\ntext data. Our new technique provides better privacy benefits than other state\nof the art techniques while maintaining lower redaction levels.\n","authors":["Vaibhav Gusain","Douglas Leith"],"pdf_url":"https://arxiv.org/pdf/2501.17762v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18143v1","updated":"2025-01-30T05:21:08Z","published":"2025-01-30T05:21:08Z","title":"Dual-Bounded Nonlinear Optimal Transport for Size Constrained Min Cut\n  Clustering","summary":"  Min cut is an important graph partitioning method. However, current solutions\nto the min cut problem suffer from slow speeds, difficulty in solving, and\noften converge to simple solutions. To address these issues, we relax the min\ncut problem into a dual-bounded constraint and, for the first time, treat the\nmin cut problem as a dual-bounded nonlinear optimal transport problem.\nAdditionally, we develop a method for solving dual-bounded nonlinear optimal\ntransport based on the Frank-Wolfe method (abbreviated as DNF). Notably, DNF\nnot only solves the size constrained min cut problem but is also applicable to\nall dual-bounded nonlinear optimal transport problems. We prove that for convex\nproblems satisfying Lipschitz smoothness, the DNF method can achieve a\nconvergence rate of \\(\\mathcal{O}(\\frac{1}{t})\\). We apply the DNF method to\nthe min cut problem and find that it achieves state-of-the-art performance in\nterms of both the loss function and clustering accuracy at the fastest speed,\nwith a convergence rate of \\(\\mathcal{O}(\\frac{1}{\\sqrt{t}})\\). Moreover, the\nDNF method for the size constrained min cut problem requires no parameters and\nexhibits better stability.\n","authors":["Fangyuan Xie","Jinghui Yuan","Feiping Nie","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2501.18143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18138v1","updated":"2025-01-30T05:02:33Z","published":"2025-01-30T05:02:33Z","title":"B3C: A Minimalist Approach to Offline Multi-Agent Reinforcement Learning","summary":"  Overestimation arising from selecting unseen actions during policy evaluation\nis a major challenge in offline reinforcement learning (RL). A minimalist\napproach in the single-agent setting -- adding behavior cloning (BC)\nregularization to existing online RL algorithms -- has been shown to be\neffective; however, this approach is understudied in multi-agent settings. In\nparticular, overestimation becomes worse in multi-agent settings due to the\npresence of multiple actions, resulting in the BC regularization-based approach\neasily suffering from either over-regularization or critic divergence. To\naddress this, we propose a simple yet effective method, Behavior Cloning\nregularization with Critic Clipping (B3C), which clips the target critic value\nin policy evaluation based on the maximum return in the dataset and pushes the\nlimit of the weight on the RL objective over BC regularization, thereby\nimproving performance. Additionally, we leverage existing value factorization\ntechniques, particularly non-linear factorization, which is understudied in\noffline settings. Integrated with non-linear value factorization, B3C\noutperforms state-of-the-art algorithms on various offline multi-agent\nbenchmarks.\n","authors":["Woojun Kim","Katia Sycara"],"pdf_url":"https://arxiv.org/pdf/2501.18138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18137v1","updated":"2025-01-30T04:59:21Z","published":"2025-01-30T04:59:21Z","title":"Tensor Completion for Surrogate Modeling of Material Property Prediction","summary":"  When designing materials to optimize certain properties, there are often many\npossible configurations of designs that need to be explored. For example, the\nmaterials' composition of elements will affect properties such as strength or\nconductivity, which are necessary to know when developing new materials.\nExploring all combinations of elements to find optimal materials becomes very\ntime consuming, especially when there are more design variables. For this\nreason, there is growing interest in using machine learning (ML) to predict a\nmaterial's properties. In this work, we model the optimization of certain\nmaterial properties as a tensor completion problem, to leverage the structure\nof our datasets and navigate the vast number of combinations of material\nconfigurations. Across a variety of material property prediction tasks, our\nexperiments show tensor completion methods achieving 10-20% decreased error\ncompared with baseline ML models such as GradientBoosting and Multilayer\nPerceptron (MLP), while maintaining similar training speed.\n","authors":["Shaan Pakala","Dawon Ahn","Evangelos Papalexakis"],"pdf_url":"https://arxiv.org/pdf/2501.18137v1.pdf","comment":"2 page paper accepted to AAAI KGML 2025 bridge program"},{"id":"http://arxiv.org/abs/2410.08709v2","updated":"2025-01-30T04:41:19Z","published":"2024-10-11T10:53:03Z","title":"Distillation of Discrete Diffusion through Dimensional Correlations","summary":"  Diffusion models have demonstrated exceptional performances in various fields\nof generative modeling, but suffer from slow sampling speed due to their\niterative nature. While this issue is being addressed in continuous domains,\ndiscrete diffusion models face unique challenges, particularly in capturing\ndependencies between elements (e.g., pixel relationships in image, sequential\ndependencies in language) mainly due to the computational cost of processing\nhigh-dimensional joint distributions. In this paper, (i) we propose \"mixture\"\nmodels for discrete diffusion that are capable of treating dimensional\ncorrelations while remaining scalable, and (ii) we provide a set of loss\nfunctions for distilling the iterations of existing models. Two primary\ntheoretical insights underpin our approach: First, conventional models with\nelement-wise independence can well approximate the data distribution, but\nessentially require many sampling steps. Second, our loss functions enable the\nmixture models to distill such many-step conventional models into just a few\nsteps by learning the dimensional correlations. Our experimental results show\nthe effectiveness of the proposed method in distilling pretrained discrete\ndiffusion models across image and language domains.\n","authors":["Satoshi Hayakawa","Yuhta Takida","Masaaki Imaizumi","Hiromi Wakaki","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.08709v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2305.06584v2","updated":"2025-01-30T04:08:58Z","published":"2023-05-11T05:44:36Z","title":"Active Learning For Contextual Linear Optimization: A Margin-Based\n  Approach","summary":"  We develop the first active learning method for contextual linear\noptimization. Specifically, we introduce a label acquisition algorithm that\nsequentially decides whether to request the ``labels'' of feature samples from\nan unlabeled data stream, where the labels correspond to the coefficients of\nthe objective in the linear optimization. Our method is the first to be\ndirectly informed by the decision loss induced by the predicted coefficients,\nreferred to as the Smart Predict-then-Optimize (SPO) loss. Motivated by the\nstructure of the SPO loss, our algorithm adopts a margin-based criterion\nutilizing the concept of distance to degeneracy. In particular, we design an\nefficient active learning algorithm with theoretical excess risk (i.e.,\ngeneralization) guarantees. We derive upper bounds on the label complexity,\ndefined as the number of samples whose labels are acquired to achieve a desired\nsmall level of SPO risk. These bounds show that our algorithm has a much\nsmaller label complexity than the naive supervised learning approach that\nlabels all samples, particularly when the SPO loss is minimized directly on the\ncollected data. To address the discontinuity and nonconvexity of the SPO loss,\nwe derive label complexity bounds under tractable surrogate loss functions.\nUnder natural margin conditions, these bounds also outperform naive supervised\nlearning. Using the SPO+ loss, a specialized surrogate of the SPO loss, we\nestablish even tighter bounds under separability conditions. Finally, we\npresent numerical evidence showing the practical value of our algorithms in\nsettings such as personalized pricing and the shortest path problem.\n","authors":["Mo Liu","Paul Grigas","Heyuan Liu","Zuo-Jun Max Shen"],"pdf_url":"https://arxiv.org/pdf/2305.06584v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18126v1","updated":"2025-01-30T04:04:39Z","published":"2025-01-30T04:04:39Z","title":"HyperZero: A Customized End-to-End Auto-Tuning System for Recommendation\n  with Hourly Feedback","summary":"  Modern recommendation systems can be broadly divided into two key stages: the\nranking stage, where the system predicts various user engagements (e.g.,\nclick-through rate, like rate, follow rate, watch time), and the value model\nstage, which aggregates these predictive scores through a function (e.g., a\nlinear combination defined by a weight vector) to measure the value of each\ncontent by a single numerical score. Both stages play roughly equally important\nroles in real industrial systems; however, how to optimize the model weights\nfor the second stage still lacks systematic study. This paper focuses on\noptimizing the second stage through auto-tuning technology. Although general\nauto-tuning systems and solutions - both from established production practices\nand open-source solutions - can address this problem, they typically require\nweeks or even months to identify a feasible solution. Such prolonged tuning\nprocesses are unacceptable in production environments for recommendation\nsystems, as suboptimal value models can severely degrade user experience. An\neffective auto-tuning solution is required to identify a viable model within\n2-3 days, rather than the extended timelines typically associated with existing\napproaches. In this paper, we introduce a practical auto-tuning system named\nHyperZero that addresses these time constraints while effectively solving the\nunique challenges inherent in modern recommendation systems. Moreover, this\nframework has the potential to be expanded to broader tuning tasks within\nrecommendation systems.\n","authors":["Xufeng Cai","Ziwei Guan","Lei Yuan","Ali Selman Aydin","Tengyu Xu","Boying Liu","Wenbo Ren","Renkai Xiang","Songyi He","Haichuan Yang","Serena Li","Mingze Gao","Yue Weng","Ji Liu"],"pdf_url":"https://arxiv.org/pdf/2501.18126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17186v2","updated":"2025-01-30T04:02:48Z","published":"2025-01-26T09:43:39Z","title":"Complete Chess Games Enable LLM Become A Chess Master","summary":"  Large language models (LLM) have shown remarkable abilities in text\ngeneration, question answering, language translation, reasoning and many other\ntasks. It continues to advance rapidly and is becoming increasingly influential\nin various fields, from technology and business to education and entertainment.\nDespite LLM's success in multiple areas, its ability to play abstract games,\nsuch as chess, is underexplored. Chess-playing requires the language models to\noutput legal and reasonable moves from textual inputs. Here, we propose the\nLarge language model ChessLLM to play full chess games. We transform the game\ninto a textual format with the best move represented in the Forsyth-Edwards\nNotation. We show that by simply supervised fine-tuning, our model has achieved\na professional-level Elo rating of 1788 in matches against the standard\nElo-rated Stockfish when permitted to sample 10 times. We further show that\ndata quality is important. Long-round data supervision enjoys a 350 Elo rating\nimprovement over short-round data.\n","authors":["Yinqi Zhang","Xintian Han","Haolong Li","Kedi Chen","Shaohui Lin"],"pdf_url":"https://arxiv.org/pdf/2501.17186v2.pdf","comment":"NAACL 2025"},{"id":"http://arxiv.org/abs/2501.18123v1","updated":"2025-01-30T03:55:56Z","published":"2025-01-30T03:55:56Z","title":"Battery State of Health Estimation Using LLM Framework","summary":"  Battery health monitoring is critical for the efficient and reliable\noperation of electric vehicles (EVs). This study introduces a transformer-based\nframework for estimating the State of Health (SoH) and predicting the Remaining\nUseful Life (RUL) of lithium titanate (LTO) battery cells by utilizing both\ncycle-based and instantaneous discharge data. Testing on eight LTO cells under\nvarious cycling conditions over 500 cycles, we demonstrate the impact of charge\ndurations on energy storage trends and apply Differential Voltage Analysis\n(DVA) to monitor capacity changes (dQ/dV) across voltage ranges. Our LLM model\nachieves superior performance, with a Mean Absolute Error (MAE) as low as\n0.87\\% and varied latency metrics that support efficient processing,\ndemonstrating its strong potential for real-time integration into EVs. The\nframework effectively identifies early signs of degradation through anomaly\ndetection in high-resolution data, facilitating predictive maintenance to\nprevent sudden battery failures and enhance energy efficiency.\n","authors":["Aybars Yunusoglu","Dexter Le","Karn Tiwari","Murat Isik","I. Can Dikmen"],"pdf_url":"https://arxiv.org/pdf/2501.18123v1.pdf","comment":"Accepted at The 26th International Symposium on Quality Electronic\n  Design (ISQED'25)"},{"id":"http://arxiv.org/abs/2501.18122v1","updated":"2025-01-30T03:52:37Z","published":"2025-01-30T03:52:37Z","title":"VQLTI: Long-Term Tropical Cyclone Intensity Forecasting with Physical\n  Constraints","summary":"  Tropical cyclone (TC) intensity forecasting is crucial for early disaster\nwarning and emergency decision-making. Numerous researchers have explored\ndeep-learning methods to address computational and post-processing issues in\noperational forecasting. Regrettably, they exhibit subpar long-term forecasting\ncapabilities. We use two strategies to enhance long-term forecasting. (1) By\nenhancing the matching between TC intensity and spatial information, we can\nimprove long-term forecasting performance. (2) Incorporating physical knowledge\nand physical constraints can help mitigate the accumulation of forecasting\nerrors. To achieve the above strategies, we propose the VQLTI framework. VQLTI\ntransfers the TC intensity information to a discrete latent space while\nretaining the spatial information differences, using large-scale spatial\nmeteorological data as conditions. Furthermore, we leverage the forecast from\nthe weather prediction model FengWu to provide additional physical knowledge\nfor VQLTI. Additionally, we calculate the potential intensity (PI) to impose\nphysical constraints on the latent variables. In the global long-term TC\nintensity forecasting, VQLTI achieves state-of-the-art results for the 24h to\n120h, with the MSW (Maximum Sustained Wind) forecast error reduced by\n35.65%-42.51% compared to ECMWF-IFS.\n","authors":["Xinyu Wang","Lei Liu","Kang Chen","Tao Han","Bin Li","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2501.18122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18121v1","updated":"2025-01-30T03:51:25Z","published":"2025-01-30T03:51:25Z","title":"Optimal Survey Design for Private Mean Estimation","summary":"  This work identifies the first privacy-aware stratified sampling scheme that\nminimizes the variance for general private mean estimation under the Laplace,\nDiscrete Laplace (DLap) and Truncated-Uniform-Laplace (TuLap) mechanisms within\nthe framework of differential privacy (DP). We view stratified sampling as a\nsubsampling operation, which amplifies the privacy guarantee; however, to have\nthe same final privacy guarantee for each group, different nominal privacy\nbudgets need to be used depending on the subsampling rate. Ignoring the effect\nof DP, traditional stratified sampling strategies risk significant variance\ninflation. We phrase our optimal survey design as an optimization problem,\nwhere we determine the optimal subsampling sizes for each group with the goal\nof minimizing the variance of the resulting estimator. We establish strong\nconvexity of the variance objective, propose an efficient algorithm to identify\nthe integer-optimal design, and offer insights on the structure of the optimal\ndesign.\n","authors":["Yu-Wei Chen","Raghu Pasupathy","Jordan A. Awan"],"pdf_url":"https://arxiv.org/pdf/2501.18121v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2501.18588v1","updated":"2025-01-30T18:59:04Z","published":"2025-01-30T18:59:04Z","title":"Inkspire: Supporting Design Exploration with Generative AI through\n  Analogical Sketching","summary":"  With recent advancements in the capabilities of Text-to-Image (T2I) AI\nmodels, product designers have begun experimenting with them in their work.\nHowever, T2I models struggle to interpret abstract language and the current\nuser experience of T2I tools can induce design fixation rather than a more\niterative, exploratory process. To address these challenges, we developed\nInkspire, a sketch-driven tool that supports designers in prototyping product\ndesign concepts with analogical inspirations and a complete\nsketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we\nconducted an exchange session with designers and distilled design goals for\nimproving T2I interactions. In a within-subjects study comparing Inkspire to\nControlNet, we found that Inkspire supported designers with more inspiration\nand exploration of design ideas, and improved aspects of the co-creative\nprocess by allowing designers to effectively grasp the current state of the AI\nto guide it towards novel design intentions.\n","authors":["David Chuan-En Lin","Hyeonsu B. Kang","Nikolas Martelaro","Aniket Kittur","Yan-Ying Chen","Matthew K. Hong"],"pdf_url":"https://arxiv.org/pdf/2501.18588v1.pdf","comment":"Accepted to CHI 2025"},{"id":"http://arxiv.org/abs/2211.11337v4","updated":"2025-01-30T15:13:01Z","published":"2022-11-21T10:37:56Z","title":"DreamArtist++: Controllable One-Shot Text-to-Image Generation via\n  Positive-Negative Adapter","summary":"  State-of-the-arts text-to-image generation models such as Imagen and Stable\nDiffusion Model have succeed remarkable progresses in synthesizing\nhigh-quality, feature-rich images with high resolution guided by human text\nprompts. Since certain characteristics of image content \\emph{e.g.}, very\nspecific object entities or styles, are very hard to be accurately described by\ntext, some example-based image generation approaches have been proposed,\n\\emph{i.e.} generating new concepts based on absorbing the salient features of\na few input references. Despite of acknowledged successes, these methods have\nstruggled on accurately capturing the reference examples' characteristics while\nkeeping diverse and high-quality image generation, particularly in the one-shot\nscenario (\\emph{i.e.} given only one reference). To tackle this problem, we\npropose a simple yet effective framework, namely DreamArtist, which adopts a\nnovel positive-negative prompt-tuning learning strategy on the pre-trained\ndiffusion model, and it has shown to well handle the trade-off between the\naccurate controllability and fidelity of image generation with only one\nreference example. Specifically, our proposed framework incorporates both\npositive and negative embeddings or adapters and optimizes them in a joint\nmanner. The positive part aggressively captures the salient characteristics of\nthe reference image to drive diversified generation and the negative part\nrectifies inadequacies from the positive part. We have conducted extensive\nexperiments and evaluated the proposed method from image similarity (fidelity)\nand diversity, generation controllability, and style cloning. And our\nDreamArtist has achieved a superior generation performance over existing\nmethods. Besides, our additional evaluation on extended tasks, including\nconcept compositions and prompt-guided image editing, demonstrates its\neffectiveness for more applications.\n","authors":["Ziyi Dong","Pengxu Wei","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2211.11337v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18314v1","updated":"2025-01-30T12:43:47Z","published":"2025-01-30T12:43:47Z","title":"AGAV-Rater: Adapting Large Multimodal Model for AI-Generated\n  Audio-Visual Quality Assessment","summary":"  Many video-to-audio (VTA) methods have been proposed for dubbing silent\nAI-generated videos. An efficient quality assessment method for AI-generated\naudio-visual content (AGAV) is crucial for ensuring audio-visual quality.\nExisting audio-visual quality assessment methods struggle with unique\ndistortions in AGAVs, such as unrealistic and inconsistent elements. To address\nthis, we introduce AGAVQA, the first large-scale AGAV quality assessment\ndataset, comprising 3,382 AGAVs from 16 VTA methods. AGAVQA includes two\nsubsets: AGAVQA-MOS, which provides multi-dimensional scores for audio quality,\ncontent consistency, and overall quality, and AGAVQA-Pair, designed for optimal\nAGAV pair selection. We further propose AGAV-Rater, a LMM-based model that can\nscore AGAVs, as well as audio and music generated from text, across multiple\ndimensions, and selects the best AGAV generated by VTA methods to present to\nthe user. AGAV-Rater achieves state-of-the-art performance on AGAVQA,\nText-to-Audio, and Text-to-Music datasets. Subjective tests also confirm that\nAGAV-Rater enhances VTA performance and user experience. The project page is\navailable at https://agav-rater.github.io.\n","authors":["Yuqin Cao","Xiongkuo Min","Yixuan Gao","Wei Sun","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2501.18314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08988v2","updated":"2025-01-30T11:15:36Z","published":"2024-12-12T06:39:49Z","title":"EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing","summary":"  Given a piece of text, a video clip, and a reference audio, the movie dubbing\ntask aims to generate speech that aligns with the video while cloning the\ndesired voice. The existing methods have two primary deficiencies: (1) They\nstruggle to simultaneously hold audio-visual sync and achieve clear\npronunciation; (2) They lack the capacity to express user-defined emotions. To\naddress these problems, we propose EmoDubber, an emotion-controllable dubbing\narchitecture that allows users to specify emotion type and emotional intensity\nwhile satisfying high-quality lip sync and pronunciation. Specifically, we\nfirst design Lip-related Prosody Aligning (LPA), which focuses on learning the\ninherent consistency between lip motion and prosody variation by duration level\ncontrastive learning to incorporate reasonable alignment. Then, we design\nPronunciation Enhancing (PE) strategy to fuse the video-level phoneme sequences\nby efficient conformer to improve speech intelligibility. Next, the speaker\nidentity adapting module aims to decode acoustics prior and inject the speaker\nstyle embedding. After that, the proposed Flow-based User Emotion Controlling\n(FUEC) is used to synthesize waveform by flow matching prediction network\nconditioned on acoustics prior. In this process, the FUEC determines the\ngradient direction and guidance scale based on the user's emotion instructions\nby the positive and negative guidance mechanism, which focuses on amplifying\nthe desired emotion while suppressing others. Extensive experimental results on\nthree benchmark datasets demonstrate favorable performance compared to several\nstate-of-the-art methods.\n","authors":["Gaoxiang Cong","Jiadong Pan","Liang Li","Yuankai Qi","Yuxin Peng","Anton van den Hengel","Jian Yang","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2412.08988v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2501.18157v1","updated":"2025-01-30T05:46:30Z","published":"2025-01-30T05:46:30Z","title":"Efficient Audiovisual Speech Processing via MUTUD: Multimodal Training\n  and Unimodal Deployment","summary":"  Building reliable speech systems often requires combining multiple\nmodalities, like audio and visual cues. While such multimodal solutions\nfrequently lead to improvements in performance and may even be critical in\ncertain cases, they come with several constraints such as increased sensory\nrequirements, computational cost, and modality synchronization, to mention a\nfew. These challenges constrain the direct uses of these multimodal solutions\nin real-world applications. In this work, we develop approaches where the\nlearning happens with all available modalities but the deployment or inference\nis done with just one or reduced modalities. To do so, we propose a Multimodal\nTraining and Unimodal Deployment (MUTUD) framework which includes a Temporally\nAligned Modality feature Estimation (TAME) module that can estimate information\nfrom missing modality using modalities present during inference. This\ninnovative approach facilitates the integration of information across different\nmodalities, enhancing the overall inference process by leveraging the strengths\nof each modality to compensate for the absence of certain modalities during\ninference. We apply MUTUD to various audiovisual speech tasks and show that it\ncan reduce the performance gap between the multimodal and corresponding\nunimodal models to a considerable extent. MUTUD can achieve this while reducing\nthe model size and compute compared to multimodal models, in some cases by\nalmost 80%.\n","authors":["Joanna Hong","Sanjeel Parekh","Honglie Chen","Jacob Donley","Ke Tan","Buye Xu","Anurag Kumar"],"pdf_url":"https://arxiv.org/pdf/2501.18157v1.pdf","comment":null}]},"2025-01-29T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2501.18045v1","updated":"2025-01-29T23:17:43Z","published":"2025-01-29T23:17:43Z","title":"From tools to thieves: Measuring and understanding public perceptions of\n  AI through crowdsourced metaphors","summary":"  How has the public responded to the increasing prevalence of artificial\nintelligence (AI)-based technologies? We investigate public perceptions of AI\nby collecting over 12,000 responses over 12 months from a nationally\nrepresentative U.S. sample. Participants provided open-ended metaphors\nreflecting their mental models of AI, a methodology that overcomes the\nlimitations of traditional self-reported measures. Using a mixed-methods\napproach combining quantitative clustering and qualitative coding, we identify\n20 dominant metaphors shaping public understanding of AI. To analyze these\nmetaphors systematically, we present a scalable framework integrating language\nmodeling (LM)-based techniques to measure key dimensions of public perception:\nanthropomorphism (attribution of human-like qualities), warmth, and competence.\nWe find that Americans generally view AI as warm and competent, and that over\nthe past year, perceptions of AI's human-likeness and warmth have significantly\nincreased ($+34\\%, r = 0.80, p < 0.01; +41\\%, r = 0.62, p < 0.05$).\nFurthermore, these implicit perceptions, along with the identified dominant\nmetaphors, strongly predict trust in and willingness to adopt AI ($r^2 = 0.21,\n0.18, p < 0.001$). We further explore how differences in metaphors and implicit\nperceptions--such as the higher propensity of women, older individuals, and\npeople of color to anthropomorphize AI--shed light on demographic disparities\nin trust and adoption. In addition to our dataset and framework for tracking\nevolving public attitudes, we provide actionable insights on using metaphors\nfor inclusive and responsible AI development.\n","authors":["Myra Cheng","Angela Y. Lee","Kristina Rapuano","Kate Niederhoffer","Alex Liebscher","Jeffrey Hancock"],"pdf_url":"https://arxiv.org/pdf/2501.18045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.09831v3","updated":"2025-01-29T23:10:09Z","published":"2024-09-15T19:11:01Z","title":"Generating Synthetic Free-text Medical Records with Low\n  Re-identification Risk using Masked Language Modeling","summary":"  The vast amount of available medical records has the potential to improve\nhealthcare and biomedical research. However, privacy restrictions make these\ndata accessible for internal use only. Recent works have addressed this problem\nby generating synthetic data using Causal Language Modeling. Unfortunately, by\ntaking this approach, it is often impossible to guarantee patient privacy while\noffering the ability to control the diversity of generations without increasing\nthe cost of generating such data. In contrast, we present a system for\ngenerating synthetic free-text medical records using Masked Language Modeling.\nThe system preserves critical medical information while introducing diversity\nin the generations and minimising re-identification risk. The system's size is\nabout 120M parameters, minimising inference cost. The results demonstrate\nhigh-quality synthetic data with a HIPAA-compliant PHI recall rate of 96% and a\nre-identification risk of 3.5%. Moreover, downstream evaluations show that the\ngenerated data can effectively train a model with performance comparable to\nreal data.\n","authors":["Samuel Belkadi","Libo Ren","Nicolo Micheletti","Lifeng Han","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2409.09831v3.pdf","comment":"Rewrote manuscript and moved content to appendix"},{"id":"http://arxiv.org/abs/2410.09013v3","updated":"2025-01-29T22:51:42Z","published":"2024-10-11T17:30:02Z","title":"The Impact of Visual Information in Chinese Characters: Evaluating Large\n  Models' Ability to Recognize and Utilize Radicals","summary":"  The glyphic writing system of Chinese incorporates information-rich visual\nfeatures in each character, such as radicals that provide hints about meaning\nor pronunciation. However, there has been no investigation into whether\ncontemporary Large Language Models (LLMs) and Vision-Language Models (VLMs) can\nharness these sub-character features in Chinese through prompting. In this\nstudy, we establish a benchmark to evaluate LLMs' and VLMs' understanding of\nvisual elements in Chinese characters, including radicals, composition\nstructures, strokes, and stroke counts. Our results reveal that models\nsurprisingly exhibit some, but still limited, knowledge of the visual\ninformation, regardless of whether images of characters are provided. To incite\nmodels' ability to use radicals, we further experiment with incorporating\nradicals into the prompts for Chinese language processing (CLP) tasks. We\nobserve consistent improvement in Part-Of-Speech tagging when providing\nadditional information about radicals, suggesting the potential to enhance CLP\nby integrating sub-character information.\n","authors":["Xiaofeng Wu","Karl Stratos","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2410.09013v3.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2501.17994v1","updated":"2025-01-29T21:01:44Z","published":"2025-01-29T21:01:44Z","title":"InnerThoughts: Disentangling Representations and Predictions in Large\n  Language Models","summary":"  Large language models (LLMs) contain substantial factual knowledge which is\ncommonly elicited by multiple-choice question-answering prompts. Internally,\nsuch models process the prompt through multiple transformer layers, building\nvarying representations of the problem within its hidden states. Ultimately,\nhowever, only the hidden state corresponding to the final layer and token\nposition are used to predict the answer label. In this work, we propose instead\nto learn a small separate neural network predictor module on a collection of\ntraining questions, that take the hidden states from all the layers at the last\ntemporal position as input and outputs predictions. In effect, such a framework\ndisentangles the representational abilities of LLMs from their predictive\nabilities. On a collection of hard benchmarks, our method achieves considerable\nimprovements in performance, sometimes comparable to supervised fine-tuning\nprocedures, but at a fraction of the computational cost.\n","authors":["Didier Chételat","Joseph Cotnareanu","Rylee Thompson","Yingxue Zhang","Mark Coates"],"pdf_url":"https://arxiv.org/pdf/2501.17994v1.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2501.17070v2","updated":"2025-01-29T20:02:43Z","published":"2025-01-28T16:55:39Z","title":"Context is Key for Agent Security","summary":"  Judging the safety of an action, whether taken by a human or a system, must\ntake into account the context in which the action takes place. For example,\ndeleting an email from a user's mailbox may or may not be appropriate depending\non the email's content, the user's goals, or even available space. Systems\ntoday that make these judgements -- providing security against harmful or\ninappropriate actions -- rely on manually-crafted policies or user confirmation\nfor each relevant context. With the upcoming deployment of systems like\ngeneralist agents, we argue that we must rethink security designs to adapt to\nthe scale of contexts and capabilities of these systems. As a first step, this\npaper explores contextual security in the domain of agents and proposes\ncontextual security for agents (Conseca), a framework to generate just-in-time,\ncontextual, and human-verifiable security policies.\n","authors":["Lillian Tsai","Eugene Bagdasarian"],"pdf_url":"https://arxiv.org/pdf/2501.17070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17860v1","updated":"2025-01-29T18:58:48Z","published":"2025-01-29T18:58:48Z","title":"Dialogue is Better Than Monologue: Instructing Medical LLMs via\n  Strategical Conversations","summary":"  Current medical AI systems often fail to replicate real-world clinical\nreasoning, as they are predominantly trained and evaluated on static text and\nquestion-answer tasks. These tuning methods and benchmarks overlook critical\naspects like evidence-based reasoning and handling distracting information. To\nbridge this gap, we introduce a novel benchmark that simulates real-world\ndiagnostic scenarios, integrating noise and difficulty levels aligned with\nUSMLE standards. Moreover, we explore dialogue-based fine-tuning, which\ntransforms static datasets into conversational formats to better capture\niterative reasoning processes. Experiments show that dialogue-tuned models\noutperform traditional methods, with improvements of $9.64\\%$ in multi-round\nreasoning scenarios and $6.18\\%$ in accuracy in a noisy environment. Our\nfindings highlight dialogue tuning as a promising approach for advancing\nclinically aligned and robust medical AI systems.\n","authors":["Zijie Liu","Xinyu Zhao","Jie Peng","Zhuangdi Zhu","Qingyu Chen","Xia Hu","Tianlong Chen"],"pdf_url":"https://arxiv.org/pdf/2501.17860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17858v1","updated":"2025-01-29T18:57:29Z","published":"2025-01-29T18:57:29Z","title":"Improving Your Model Ranking on Chatbot Arena by Vote Rigging","summary":"  Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles,\nwhere users vote for their preferred response from two randomly sampled\nanonymous models. While Chatbot Arena is widely regarded as a reliable LLM\nranking leaderboard, we show that crowdsourced voting can be rigged to improve\n(or decrease) the ranking of a target model $m_{t}$. We first introduce a\nstraightforward target-only rigging strategy that focuses on new battles\ninvolving $m_{t}$, identifying it via watermarking or a binary classifier, and\nexclusively voting for $m_{t}$ wins. However, this strategy is practically\ninefficient because there are over $190$ models on Chatbot Arena and on average\nonly about $1\\%$ of new battles will involve $m_{t}$. To overcome this, we\npropose omnipresent rigging strategies, exploiting the Elo rating mechanism of\nChatbot Arena that any new vote on a battle can influence the ranking of the\ntarget model $m_{t}$, even if $m_{t}$ is not directly involved in the battle.\nWe conduct experiments on around $1.7$ million historical votes from the\nChatbot Arena Notebook, showing that omnipresent rigging strategies can improve\nmodel rankings by rigging only hundreds of new votes. While we have evaluated\nseveral defense mechanisms, our findings highlight the importance of continued\nefforts to prevent vote rigging. Our code is available at\nhttps://github.com/sail-sg/Rigging-ChatbotArena.\n","authors":["Rui Min","Tianyu Pang","Chao Du","Qian Liu","Minhao Cheng","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2501.17858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17148v2","updated":"2025-01-29T18:52:56Z","published":"2025-01-28T18:51:24Z","title":"AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse\n  Autoencoders","summary":"  Fine-grained steering of language model outputs is essential for safety and\nreliability. Prompting and finetuning are widely used to achieve these goals,\nbut interpretability researchers have proposed a variety of\nrepresentation-based techniques as well, including sparse autoencoders (SAEs),\nlinear artificial tomography, supervised steering vectors, linear probes, and\nrepresentation finetuning. At present, there is no benchmark for making direct\ncomparisons between these proposals. Therefore, we introduce AxBench, a\nlarge-scale benchmark for steering and concept detection, and report\nexperiments on Gemma-2-2B and 9B. For steering, we find that prompting\noutperforms all existing methods, followed by finetuning. For concept\ndetection, representation-based methods such as difference-in-means, perform\nthe best. On both evaluations, SAEs are not competitive. We introduce a novel\nweakly-supervised representational method (Rank-1 Representation Finetuning;\nReFT-r1), which is competitive on both tasks while providing the\ninterpretability advantages that prompting lacks. Along with AxBench, we train\nand publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.\n","authors":["Zhengxuan Wu","Aryaman Arora","Atticus Geiger","Zheng Wang","Jing Huang","Dan Jurafsky","Christopher D. Manning","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2501.17148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15004v2","updated":"2025-01-29T18:49:15Z","published":"2024-12-19T16:20:22Z","title":"Large Language Models and Code Security: A Systematic Literature Review","summary":"  Large Language Models (LLMs) have emerged as powerful tools for automating\nvarious programming tasks, including security-related ones, such as detecting\nand fixing vulnerabilities. Despite their promising capabilities, when required\nto produce or modify pre-existing code, LLMs could introduce vulnerabilities\nunbeknown to the programmer. When analyzing code, they could miss clear\nvulnerabilities or signal nonexistent ones. In this Systematic Literature\nReview (SLR), we aim to investigate both the security benefits and potential\ndrawbacks of using LLMs for a variety of code-related tasks. In particular,\nfirst we focus on the types of vulnerabilities that could be introduced by\nLLMs, when used for producing code. Second, we analyze the capabilities of LLMs\nto detect and fix vulnerabilities, in any given code, and how the prompting\nstrategy of choice impacts their performance in these two tasks. Last, we\nprovide an in-depth analysis on how data poisoning attacks on LLMs can impact\nperformance in the aforementioned tasks.\n","authors":["Enna Basic","Alberto Giaretta"],"pdf_url":"https://arxiv.org/pdf/2412.15004v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15124v3","updated":"2025-01-29T18:46:59Z","published":"2024-11-22T18:44:04Z","title":"Tulu 3: Pushing Frontiers in Open Language Model Post-Training","summary":"  Language model post-training is applied to refine behaviors and unlock new\nskills across a wide range of recent language models, but open recipes for\napplying these techniques lag behind proprietary ones. The underlying training\ndata and recipes for post-training are simultaneously the most important pieces\nof the puzzle and the portion with the least transparency. To bridge this gap,\nwe introduce Tulu 3, a family of fully-open state-of-the-art post-trained\nmodels, alongside its data, code, and training recipes, serving as a\ncomprehensive guide for modern post-training techniques. Tulu 3, which builds\non Llama 3.1 base models, achieves results surpassing the instruct versions of\nLlama 3.1, Qwen 2.5, Mistral, and even closed models such as GPT-4o-mini and\nClaude 3.5-Haiku. The training algorithms for our models include supervised\nfinetuning (SFT), Direct Preference Optimization (DPO), and a novel method we\ncall Reinforcement Learning with Verifiable Rewards (RLVR). With Tulu 3, we\nintroduce a multi-task evaluation scheme for post-training recipes with\ndevelopment and unseen evaluations, standard benchmark implementations, and\nsubstantial decontamination of existing open datasets on said benchmarks. We\nconclude with analysis and discussion of training methods that did not reliably\nimprove performance.\n  In addition to the Tulu 3 model weights and demo, we release the complete\nrecipe -- including datasets for diverse core skills, a robust toolkit for data\ncuration and evaluation, the training code and infrastructure, and, most\nimportantly, a detailed report for reproducing and further adapting the Tulu 3\napproach to more domains.\n","authors":["Nathan Lambert","Jacob Morrison","Valentina Pyatkin","Shengyi Huang","Hamish Ivison","Faeze Brahman","Lester James V. Miranda","Alisa Liu","Nouha Dziri","Shane Lyu","Yuling Gu","Saumya Malik","Victoria Graf","Jena D. Hwang","Jiangjiang Yang","Ronan Le Bras","Oyvind Tafjord","Chris Wilhelm","Luca Soldaini","Noah A. Smith","Yizhong Wang","Pradeep Dasigi","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2411.15124v3.pdf","comment":"Added Tulu 3 405B results and additional analyses"},{"id":"http://arxiv.org/abs/2501.17840v1","updated":"2025-01-29T18:40:32Z","published":"2025-01-29T18:40:32Z","title":"Learning Beyond the Surface: How Far Can Continual Pre-Training with\n  LoRA Enhance LLMs' Domain-Specific Insight Learning?","summary":"  Large Language Models (LLMs) have demonstrated remarkable performance on\nvarious tasks, yet their ability to extract and internalize deeper insights\nfrom domain-specific datasets remains underexplored. In this study, we\ninvestigate how continual pre-training can enhance LLMs' capacity for insight\nlearning across three distinct forms: declarative, statistical, and\nprobabilistic insights. Focusing on two critical domains: medicine and finance,\nwe employ LoRA to train LLMs on two existing datasets. To evaluate each insight\ntype, we create benchmarks to measure how well continual pre-training helps\nmodels go beyond surface-level knowledge. We also assess the impact of document\nmodification on capturing insights. The results show that, while continual\npre-training on original documents has a marginal effect, modifying documents\nto retain only essential information significantly enhances the\ninsight-learning capabilities of LLMs.\n","authors":["Pouya Pezeshkpour","Estevam Hruschka"],"pdf_url":"https://arxiv.org/pdf/2501.17840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17830v1","updated":"2025-01-29T18:22:14Z","published":"2025-01-29T18:22:14Z","title":"A Comprehensive Survey on Legal Summarization: Challenges and Future\n  Directions","summary":"  This article provides a systematic up-to-date survey of automatic\nsummarization techniques, datasets, models, and evaluation methods in the legal\ndomain. Through specific source selection criteria, we thoroughly review over\n120 papers spanning the modern `transformer' era of natural language processing\n(NLP), thus filling a gap in existing systematic surveys on the matter. We\npresent existing research along several axes and discuss trends, challenges,\nand opportunities for future research.\n","authors":["Mousumi Akter","Erion Çano","Erik Weber","Dennis Dobler","Ivan Habernal"],"pdf_url":"https://arxiv.org/pdf/2501.17830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17811v1","updated":"2025-01-29T18:00:19Z","published":"2025-01-29T18:00:19Z","title":"Janus-Pro: Unified Multimodal Understanding and Generation with Data and\n  Model Scaling","summary":"  In this work, we introduce Janus-Pro, an advanced version of the previous\nwork Janus. Specifically, Janus-Pro incorporates (1) an optimized training\nstrategy, (2) expanded training data, and (3) scaling to larger model size.\nWith these improvements, Janus-Pro achieves significant advancements in both\nmultimodal understanding and text-to-image instruction-following capabilities,\nwhile also enhancing the stability of text-to-image generation. We hope this\nwork will inspire further exploration in the field. Code and models are\npublicly available.\n","authors":["Xiaokang Chen","Zhiyu Wu","Xingchao Liu","Zizheng Pan","Wen Liu","Zhenda Xie","Xingkai Yu","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2501.17811v1.pdf","comment":"Research paper. arXiv admin note: text overlap with arXiv:2410.13848"},{"id":"http://arxiv.org/abs/2501.17790v1","updated":"2025-01-29T17:31:26Z","published":"2025-01-29T17:31:26Z","title":"BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone\n  Disambiguation -- Challenges and Insights","summary":"  We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted\nfor Taiwanese Mandarin, highlighting phonetic control abilities to address the\nunique challenges of polyphone disambiguation in the language. Building upon\nCosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an\noptimal-transport conditional flow matching model (OT-CFM), and a grapheme to\nphoneme prediction model, to generate realistic speech that closely mimics\nhuman utterances. Our evaluation demonstrates BreezyVoice's superior\nperformance in both general and code-switching contexts, highlighting its\nrobustness and effectiveness in generating high-fidelity speech. Additionally,\nwe address the challenges of generalizability in modeling long-tail speakers\nand polyphone disambiguation. Our approach significantly enhances performance\nand offers valuable insights into the workings of neural codec TTS systems.\n","authors":["Chan-Jan Hsu","Yi-Cheng Lin","Chia-Chun Lin","Wei-Chih Chen","Ho Lam Chung","Chen-An Li","Yi-Chang Chen","Chien-Yu Yu","Ming-Ji Lee","Chien-Cheng Chen","Ru-Heng Huang","Hung-yi Lee","Da-Shan Shiu"],"pdf_url":"https://arxiv.org/pdf/2501.17790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17785v1","updated":"2025-01-29T17:24:19Z","published":"2025-01-29T17:24:19Z","title":"Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare\n  Scripts","summary":"  We explore the capabilities of LVLMs and LLMs in deciphering rare scripts not\nencoded in Unicode. We introduce a novel approach to construct a multimodal\ndataset of linguistic puzzles involving such scripts, utilizing a tokenization\nmethod for language glyphs. Our methods include the Picture Method for LVLMs\nand the Description Method for LLMs, enabling these models to tackle these\nchallenges. We conduct experiments using prominent models, GPT-4o, Gemini, and\nClaude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths and\nlimitations of current AI methods in linguistic decipherment, highlighting the\nimpact of Unicode encoding on model performance and the challenges of modeling\nvisual language tokens through descriptions. Our study advances understanding\nof AI's potential in linguistic decipherment and underscores the need for\nfurther research.\n","authors":["Yu-Fei Shih","Zheng-Lin Lin","Shu-Kai Hsieh"],"pdf_url":"https://arxiv.org/pdf/2501.17785v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2404.11891v3","updated":"2025-01-29T17:24:03Z","published":"2024-04-18T04:36:37Z","title":"Large Language Models Can Solve Real-World Planning Rigorously with\n  Formal Verification Tools","summary":"  Large Language Models (LLMs) struggle to directly generate correct plans for\ncomplex multi-constraint planning problems, even with self-verification and\nself-critique. For example, a U.S. domestic travel planning benchmark\nTravelPlanner was proposed in Xie et al. (2024), where the best LLM OpenAI\no1-preview can only find viable travel plans with a 10% success rate given all\nneeded information. In this work, we tackle this by proposing an LLM-based\nplanning framework that formalizes and solves complex multi-constraint planning\nproblems as constrained satisfiability problems, which are further consumed by\nsound and complete satisfiability solvers. We start with TravelPlanner as the\nprimary use case and show that our framework achieves a success rate of 93.9%\nand is effective with diverse paraphrased prompts. More importantly, our\nframework has strong zero-shot generalizability, successfully handling unseen\nconstraints in our newly created unseen international travel dataset and\ngeneralizing well to new fundamentally different domains. Moreover, when user\ninput queries are infeasible, our framework can identify the unsatisfiable\ncore, provide failure reasons, and offers personalized modification\nsuggestions. We show that our framework can modify and solve for an average of\n81.6% and 91.7% unsatisfiable queries from two datasets and prove with\nablations that all key components of our framework are effective and necessary.\nProject page: https://sites.google.com/view/llm-rwplanning.\n","authors":["Yilun Hao","Yongchao Chen","Yang Zhang","Chuchu Fan"],"pdf_url":"https://arxiv.org/pdf/2404.11891v3.pdf","comment":"50 pages, 6 figures, 8 tables"},{"id":"http://arxiv.org/abs/2501.17771v1","updated":"2025-01-29T17:05:33Z","published":"2025-01-29T17:05:33Z","title":"2SSP: A Two-Stage Framework for Structured Pruning of LLMs","summary":"  We propose a novel Two-Stage framework for Structured Pruning (2SSP) for\npruning Large Language Models (LLMs), which combines two different strategies\nof pruning, namely Width and Depth Pruning. The first stage (Width Pruning)\nremoves entire neurons, hence their corresponding rows and columns, aiming to\npreserve the connectivity among the pruned structures in the intermediate state\nof the Feed-Forward Networks in each Transformer block. This is done based on\nan importance score measuring the impact of each neuron over the output\nmagnitude. The second stage (Depth Pruning), instead, removes entire Attention\nsubmodules. This is done by applying an iterative process that removes the\nAttention submodules with the minimum impact on a given metric of interest (in\nour case, perplexity). We also propose a novel mechanism to balance the\nsparsity rate of the two stages w.r.t. to the desired global sparsity. We test\n2SSP on four LLM families and three sparsity rates (25\\%, 37.5\\%, and 50\\%),\nmeasuring the resulting perplexity over three language modeling datasets as\nwell as the performance over six downstream tasks. Our method consistently\noutperforms five state-of-the-art competitors over three language modeling and\nsix downstream tasks, with an up to two-order-of-magnitude gain in terms of\npruning time. The code is available at available at\n\\url{https://github.com/FabrizioSandri/2SSP}.\n","authors":["Fabrizio Sandri","Elia Cunegatti","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2501.17771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17767v1","updated":"2025-01-29T16:58:18Z","published":"2025-01-29T16:58:18Z","title":"Hybrid Graphs for Table-and-Text based Question Answering using LLMs","summary":"  Answering questions that require reasoning and aggregation across both\nstructured (tables) and unstructured (raw text) data sources presents\nsignificant challenges. Current methods rely on fine-tuning and high-quality,\nhuman-curated data, which is difficult to obtain. Recent advances in Large\nLanguage Models (LLMs) have shown promising results for multi-hop question\nanswering (QA) over single-source text data in a zero-shot setting, yet\nexploration into multi-source Table-Text QA remains limited. In this paper, we\npresent a novel Hybrid Graph-based approach for Table-Text QA that leverages\nLLMs without fine-tuning. Our method constructs a unified Hybrid Graph from\ntextual and tabular data, pruning information based on the input question to\nprovide the LLM with relevant context concisely. We evaluate our approach on\nthe challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,\nincluding GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot\nperformance on both datasets, improving Exact Match scores by up to 10% on\nHybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up\nto 53% compared to the original context.\n","authors":["Ankush Agarwal","Ganesh S","Chaitanya Devaguptapu"],"pdf_url":"https://arxiv.org/pdf/2501.17767v1.pdf","comment":"Accepted at NAACL 2025 Main Track"},{"id":"http://arxiv.org/abs/2501.15398v2","updated":"2025-01-29T16:36:20Z","published":"2025-01-26T04:37:27Z","title":"How Green are Neural Language Models? Analyzing Energy Consumption in\n  Text Summarization Fine-tuning","summary":"  Artificial intelligence systems significantly impact the environment,\nparticularly in natural language processing (NLP) tasks. These tasks often\nrequire extensive computational resources to train deep neural networks,\nincluding large-scale language models containing billions of parameters. This\nstudy analyzes the trade-offs between energy consumption and performance across\nthree neural language models: two pre-trained models (T5-base and BART-base),\nand one large language model (LLaMA 3-8B). These models were fine-tuned for the\ntext summarization task, focusing on generating research paper highlights that\nencapsulate the core themes of each paper. A wide range of evaluation metrics,\nincluding ROUGE, METEOR, MoverScore, BERTScore, and SciBERTScore, were employed\nto assess their performance. Furthermore, the carbon footprint associated with\nfine-tuning each model was measured, offering a comprehensive assessment of\ntheir environmental impact. This research underscores the importance of\nincorporating environmental considerations into the design and implementation\nof neural language models and calls for the advancement of energy-efficient AI\nmethodologies.\n","authors":["Tohida Rehman","Debarshi Kumar Sanyal","Samiran Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2501.15398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12112v2","updated":"2025-01-29T16:31:53Z","published":"2024-10-15T23:20:54Z","title":"Planning Anything with Rigor: General-Purpose Zero-Shot Planning with\n  LLM-based Formalized Programming","summary":"  While large language models (LLMs) have recently demonstrated strong\npotential in solving planning problems, there is a trade-off between\nflexibility and complexity. LLMs, as zero-shot planners themselves, are still\nnot capable of directly generating valid plans for complex planning problems\nsuch as multi-constraint or long-horizon tasks. On the other hand, many\nframeworks aiming to solve complex planning problems often rely on\ntask-specific preparatory efforts, such as task-specific in-context examples\nand pre-defined critics/verifiers, which limits their cross-task generalization\ncapability. In this paper, we tackle these challenges by observing that the\ncore of many planning problems lies in optimization problems: searching for the\noptimal solution (best plan) with goals subject to constraints (preconditions\nand effects of decisions). With LLMs' commonsense, reasoning, and programming\ncapabilities, this opens up the possibilities of a universal LLM-based approach\nto planning problems. Inspired by this observation, we propose LLMFP, a\ngeneral-purpose framework that leverages LLMs to capture key information from\nplanning problems and formally formulate and solve them as optimization\nproblems from scratch, with no task-specific examples needed. We apply LLMFP to\n9 planning problems, ranging from multi-constraint decision making to\nmulti-step planning problems, and demonstrate that LLMFP achieves on average\n83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet,\nsignificantly outperforming the best baseline (direct planning with OpenAI\no1-preview) with 37.6% and 40.7% improvements. We also validate components of\nLLMFP with ablation experiments and analyzed the underlying success and failure\nreasons. Project page: https://sites.google.com/view/llmfp.\n","authors":["Yilun Hao","Yang Zhang","Chuchu Fan"],"pdf_url":"https://arxiv.org/pdf/2410.12112v2.pdf","comment":"57 pages, 25 figures, 15 tables"},{"id":"http://arxiv.org/abs/2501.17726v1","updated":"2025-01-29T16:02:16Z","published":"2025-01-29T16:02:16Z","title":"VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies\n  in Generated Report Without Human Feedback","summary":"  As artificial intelligence (AI) becomes increasingly central to healthcare,\nthe demand for explainable and trustworthy models is paramount. Current report\ngeneration systems for chest X-rays (CXR) often lack mechanisms for validating\noutputs without expert oversight, raising concerns about reliability and\ninterpretability. To address these challenges, we propose a novel multimodal\nframework designed to enhance the semantic alignment and localization accuracy\nof AI-generated medical reports. Our framework integrates two key modules: a\nPhrase Grounding Model, which identifies and localizes pathologies in CXR\nimages based on textual prompts, and a Text-to-Image Diffusion Module, which\ngenerates synthetic CXR images from prompts while preserving anatomical\nfidelity. By comparing features between the original and generated images, we\nintroduce a dual-scoring system: one score quantifies localization accuracy,\nwhile the other evaluates semantic consistency. This approach significantly\noutperforms existing methods, achieving state-of-the-art results in pathology\nlocalization and text-to-image alignment. The integration of phrase grounding\nwith diffusion models, coupled with the dual-scoring evaluation system,\nprovides a robust mechanism for validating report quality, paving the way for\nmore trustworthy and transparent AI in medical imaging.\n","authors":["Sayeh Gholipour Picha","Dawood Al Chanti","Alice Caplier"],"pdf_url":"https://arxiv.org/pdf/2501.17726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17725v1","updated":"2025-01-29T15:57:43Z","published":"2025-01-29T15:57:43Z","title":"Using Code Generation to Solve Open Instances of Combinatorial Design\n  Problems","summary":"  The Handbook of Combinatorial Designs catalogs many types of combinatorial\ndesigns, together with lists of open instances for which existence has not yet\nbeen determined. We develop a constructive protocol CPro1, which uses Large\nLanguage Models (LLMs) to generate code that constructs combinatorial designs\nand resolves some of these open instances. The protocol starts from a\ndefinition of a particular type of design, and a verifier that reliably\nconfirms whether a proposed design is valid. The LLM selects strategies and\nimplements them in code, and scaffolding provides automated hyperparameter\ntuning and execution feedback using the verifier. Most generated code fails,\nbut by generating many candidates, the protocol automates exploration of a\nvariety of standard methods (e.g. simulated annealing, genetic algorithms) and\nexperimentation with variations (e.g. cost functions) to find successful\napproaches. Testing on 16 different types of designs, CPro1 constructs\nsolutions to open instances for 6 of them: Symmetric and Skew Weighing\nMatrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary\nDesigns, and Florentine Rectangles.\n","authors":["Christopher D. Rosin"],"pdf_url":"https://arxiv.org/pdf/2501.17725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10996v3","updated":"2025-01-29T15:34:02Z","published":"2024-06-16T16:17:46Z","title":"Towards Lifelong Dialogue Agents via Timeline-based Memory Management","summary":"  To achieve lifelong human-agent interaction, dialogue agents need to\nconstantly memorize perceived information and properly retrieve it for response\ngeneration (RG). While prior studies focus on getting rid of outdated memories\nto improve retrieval quality, we argue that such memories provide rich,\nimportant contextual cues for RG (e.g., changes in user behaviors) in long-term\nconversations. We present THEANINE, a framework for LLM-based lifelong dialogue\nagents. THEANINE discards memory removal and manages large-scale memories by\nlinking them based on their temporal and cause-effect relation. Enabled by this\nlinking structure, THEANINE augments RG with memory timelines - series of\nmemories representing the evolution or causality of relevant past events. Along\nwith THEANINE, we introduce TeaFarm, a counterfactual-driven evaluation scheme,\naddressing the limitation of G-Eval and human efforts when assessing agent\nperformance in integrating past memories into RG. A supplementary video for\nTHEANINE and data for TeaFarm are at\nhttps://huggingface.co/spaces/ResearcherScholar/Theanine.\n","authors":["Kai Tzu-iunn Ong","Namyoung Kim","Minju Gwak","Hyungjoo Chae","Taeyoon Kwon","Yohan Jo","Seung-won Hwang","Dongha Lee","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2406.10996v3.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2501.17715v1","updated":"2025-01-29T15:32:27Z","published":"2025-01-29T15:32:27Z","title":"RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts","summary":"  User interactions with conversational agents (CAs) evolve in the era of\nheavily guardrailed large language models (LLMs). As users push beyond\nprogrammed boundaries to explore and build relationships with these systems,\nthere is a growing concern regarding the potential for unauthorized access or\nmanipulation, commonly referred to as \"jailbreaking.\" Moreover, with CAs that\npossess highly human-like qualities, users show a tendency toward initiating\nintimate sexual interactions or attempting to tame their chatbots. To capture\nand reflect these in-the-wild interactions into chatbot designs, we propose\nRICoTA, a Korean red teaming dataset that consists of 609 prompts challenging\nLLMs with in-the-wild user-made dialogues capturing jailbreak attempts. We\nutilize user-chatbot conversations that were self-posted on a Korean\nReddit-like community, containing specific testing and gaming intentions with a\nsocial chatbot. With these prompts, we aim to evaluate LLMs' ability to\nidentify the type of conversation and users' testing purposes to derive chatbot\ndesign implications for mitigating jailbreaking risks. Our dataset will be made\npublicly available via GitHub.\n","authors":["Eujeong Choi","Younghun Jeong","Soomin Kim","Won Ik Cho"],"pdf_url":"https://arxiv.org/pdf/2501.17715v1.pdf","comment":"PACLIC 38"},{"id":"http://arxiv.org/abs/2401.04482v4","updated":"2025-01-29T14:55:28Z","published":"2024-01-09T10:39:17Z","title":"Continuously Learning New Words in Automatic Speech Recognition","summary":"  Despite recent advances, Automatic Speech Recognition (ASR) systems are still\nfar from perfect. Typical errors include acronyms, named entities, and\ndomain-specific special words for which little or no labeled data is available.\nTo address the problem of recognizing these words, we propose a self-supervised\ncontinual learning approach: Given the audio of a lecture talk with the\ncorresponding slides, we bias the model towards decoding new words from the\nslides by using a memory-enhanced ASR model from the literature. Then, we\nperform inference on the talk, collecting utterances that contain detected new\nwords into an adaptation data set. Continual learning is then performed by\ntraining adaptation weights added to the model on this data set. The whole\nprocedure is iterated for many talks. We show that with this approach, we\nobtain increasing performance on the new words when they occur more frequently\n(more than 80% recall) while preserving the general performance of the model.\n","authors":["Christian Huber","Alexander Waibel"],"pdf_url":"https://arxiv.org/pdf/2401.04482v4.pdf","comment":"Accepted at ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.17905v1","updated":"2025-01-29T14:28:11Z","published":"2025-01-29T14:28:11Z","title":"DReSS: Data-driven Regularized Structured Streamlining for Large\n  Language Models","summary":"  Large language models (LLMs) have achieved significant progress across\nvarious domains, but their increasing scale results in high computational and\nmemory costs. Recent studies have revealed that LLMs exhibit sparsity,\nproviding the potential to reduce model size through pruning techniques.\nHowever, existing pruning methods typically follow a prune-then-finetune\nparadigm. Since the pruned components still contain valuable information, their\ndirect removal often leads to irreversible performance degradation, imposing a\nsubstantial computational burden to recover performance during finetuning. In\nthis paper, we propose a novel paradigm that first applies regularization, then\nprunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a\nsimple and effective Data-driven Regularized Structured Streamlining method for\nLLMs. By leveraging a small amount of data to regularize the components to be\npruned, DReSS explicitly transfers the important information to the remaining\nparts of the model in advance. Compared to direct pruning, this can reduce the\ninformation loss caused by parameter removal, thereby enhancing its language\nmodeling capabilities. Experimental results demonstrate that DReSS\nsignificantly outperforms existing pruning methods even under extreme pruning\nratios, significantly reducing latency and increasing throughput.\n","authors":["Mingkuan Feng","Jinyang Wu","Shuai Zhang","Pengpeng Shao","Ruihan Jin","Zhengqi Wen","Jianhua Tao","Feihu Che"],"pdf_url":"https://arxiv.org/pdf/2501.17905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12419v3","updated":"2025-01-29T14:21:42Z","published":"2024-06-18T09:12:11Z","title":"AI-Assisted Human Evaluation of Machine Translation","summary":"  Annually, research teams spend large amounts of money to evaluate the quality\nof machine translation systems (WMT, inter alia). This is expensive because it\nrequires a lot of expert human labor. In the recently adopted annotation\nprotocol, Error Span Annotation (ESA), annotators mark erroneous parts of the\ntranslation and then assign a final score. A lot of the annotator time is spent\non scanning the translation for possible errors. In our work, we help the\nannotators by pre-filling the error annotations with recall-oriented automatic\nquality estimation. With this AI assistance, we obtain annotations at the same\nquality level while cutting down the time per span annotation by half\n(71s/error span $\\rightarrow$ 31s/error span). The biggest advantage of the\nESA$^\\mathrm{AI}$ protocol is an accurate priming of annotators (pre-filled\nerror spans) before they assign the final score. This alleviates a potential\nautomation bias, which we confirm to be low. In our experiments, we find that\nthe annotation budget can be further reduced by almost 25% with filtering of\nexamples that the AI deems to be likely to be correct.\n","authors":["Vilém Zouhar","Tom Kocmi","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2406.12419v3.pdf","comment":"NAACL 2025"},{"id":"http://arxiv.org/abs/2412.16135v3","updated":"2025-01-29T13:52:31Z","published":"2024-12-20T18:31:24Z","title":"Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models\n  into Assembly Code Obfuscation","summary":"  Malware authors often employ code obfuscations to make their malware harder\nto detect. Existing tools for generating obfuscated code often require access\nto the original source code (e.g., C++ or Java), and adding new obfuscations is\na non-trivial, labor-intensive process. In this study, we ask the following\nquestion: Can Large Language Models (LLMs) potentially generate a new\nobfuscated assembly code? If so, this poses a risk to anti-virus engines and\npotentially increases the flexibility of attackers to create new obfuscation\npatterns. We answer this in the affirmative by developing the MetamorphASM\nbenchmark comprising MetamorphASM Dataset (MAD) along with three code\nobfuscation techniques: dead code, register substitution, and control flow\nchange. The MetamorphASM systematically evaluates the ability of LLMs to\ngenerate and analyze obfuscated code using MAD, which contains 328,200\nobfuscated assembly code samples. We release this dataset and analyze the\nsuccess rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder,\nCodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly\ncode. The evaluation was performed using established information-theoretic\nmetrics and manual human review to ensure correctness and provide the\nfoundation for researchers to study and develop remediations to this risk.\n","authors":["Seyedreza Mohseni","Seyedali Mohammadi","Deepa Tilwani","Yash Saxena","Gerald Ketu Ndawula","Sriram Vema","Edward Raff","Manas Gaur"],"pdf_url":"https://arxiv.org/pdf/2412.16135v3.pdf","comment":"To appear in AAAI 2025, Main Track"},{"id":"http://arxiv.org/abs/2501.17654v1","updated":"2025-01-29T13:39:53Z","published":"2025-01-29T13:39:53Z","title":"Exploring Vision Language Models for Multimodal and Multilingual Stance\n  Detection","summary":"  Social media's global reach amplifies the spread of information, highlighting\nthe need for robust Natural Language Processing tasks like stance detection\nacross languages and modalities. Prior research predominantly focuses on\ntext-only inputs, leaving multimodal scenarios, such as those involving both\nimages and text, relatively underexplored. Meanwhile, the prevalence of\nmultimodal posts has increased significantly in recent years. Although\nstate-of-the-art Vision-Language Models (VLMs) show promise, their performance\non multimodal and multilingual stance detection tasks remains largely\nunexamined. This paper evaluates state-of-the-art VLMs on a newly extended\ndataset covering seven languages and multimodal inputs, investigating their use\nof visual cues, language-specific performance, and cross-modality interactions.\nOur results show that VLMs generally rely more on text than images for stance\ndetection and this trend persists across languages. Additionally, VLMs rely\nsignificantly more on text contained within the images than other visual\ncontent. Regarding multilinguality, the models studied tend to generate\nconsistent predictions across languages whether they are explicitly\nmultilingual or not, although there are outliers that are incongruous with\nmacro F1, language support, and model size.\n","authors":["Jake Vasilakes","Carolina Scarton","Zhixue Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.17654v1.pdf","comment":"Submitted to the International AAAI Conference on Web and Social\n  Media (ICWSM) 2025"},{"id":"http://arxiv.org/abs/2410.04472v3","updated":"2025-01-29T13:30:57Z","published":"2024-10-06T13:09:48Z","title":"Collapsed Language Models Promote Fairness","summary":"  To mitigate societal biases implicitly encoded in recent successful\npretrained language models, a diverse array of approaches have been proposed to\nencourage model fairness, focusing on prompting, data augmentation, regularized\nfine-tuning, and more. Despite the development, it is nontrivial to reach a\nprincipled understanding of fairness and an effective algorithm that can\nconsistently debias language models. In this work, by rigorous evaluations of\nNeural Collapse -- a learning phenomenon happen in last-layer representations\nand classifiers in deep networks -- on fairness-related words, we find that\ndebiased language models exhibit collapsed alignment between token\nrepresentations and word embeddings. More importantly, this observation\ninspires us to design a principled fine-tuning method that can effectively\nimprove fairness in a wide range of debiasing methods, while still preserving\nthe performance of language models on standard natural language understanding\ntasks. We attach our code at https://github.com/Xujxyang/Fairness-NC-main.\n","authors":["Jingxuan Xu","Wuyang Chen","Linyi Li","Yao Zhao","Yunchao Wei"],"pdf_url":"https://arxiv.org/pdf/2410.04472v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.17643v1","updated":"2025-01-29T13:25:20Z","published":"2025-01-29T13:25:20Z","title":"Tonguescape: Exploring Language Models Understanding of Vowel\n  Articulation","summary":"  Vowels are primarily characterized by tongue position. Humans have discovered\nthese features of vowel articulation through their own experience and explicit\nobjective observation such as using MRI. With this knowledge and our\nexperience, we can explain and understand the relationship between tongue\npositions and vowels, and this knowledge is helpful for language learners to\nlearn pronunciation. Since language models (LMs) are trained on a large amount\nof data that includes linguistic and medical fields, our preliminary studies\nindicate that an LM is able to explain the pronunciation mechanisms of vowels.\nHowever, it is unclear whether multi-modal LMs, such as vision LMs, align\ntextual information with visual information. One question arises: do LMs\nassociate real tongue positions with vowel articulation? In this study, we\ncreated video and image datasets from the existing real-time MRI dataset and\ninvestigated whether LMs can understand vowel articulation based on tongue\npositions using vision-based information. Our findings suggest that LMs exhibit\npotential for understanding vowels and tongue positions when reference examples\nare provided while they have difficulties without them. Our code for dataset\nbuilding is available on GitHub.\n","authors":["Haruki Sakajo","Yusuke Sakai","Hidetaka Kamigaito","Taro Watanabe"],"pdf_url":"https://arxiv.org/pdf/2501.17643v1.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2501.17630v1","updated":"2025-01-29T13:08:17Z","published":"2025-01-29T13:08:17Z","title":"Uncertainty Quantification and Decomposition for LLM-based\n  Recommendation","summary":"  Despite the widespread adoption of large language models (LLMs) for\nrecommendation, we demonstrate that LLMs often exhibit uncertainty in their\nrecommendations. To ensure the trustworthy use of LLMs in generating\nrecommendations, we emphasize the importance of assessing the reliability of\nrecommendations generated by LLMs. We start by introducing a novel framework\nfor estimating the predictive uncertainty to quantitatively measure the\nreliability of LLM-based recommendations. We further propose to decompose the\npredictive uncertainty into recommendation uncertainty and prompt uncertainty,\nenabling in-depth analyses of the primary source of uncertainty. Through\nextensive experiments, we (1) demonstrate predictive uncertainty effectively\nindicates the reliability of LLM-based recommendations, (2) investigate the\norigins of uncertainty with decomposed uncertainty measures, and (3) propose\nuncertainty-aware prompting for a lower predictive uncertainty and enhanced\nrecommendation. Our source code and model weights are available at\nhttps://github.com/WonbinKweon/UNC_LLM_REC_WWW2025\n","authors":["Wonbin Kweon","Sanghwan Jang","SeongKu Kang","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2501.17630v1.pdf","comment":"WWW 2025"},{"id":"http://arxiv.org/abs/2501.17617v1","updated":"2025-01-29T12:46:42Z","published":"2025-01-29T12:46:42Z","title":"Structured Context Recomposition for Large Language Models Using\n  Probabilistic Layer Realignment","summary":"  Extended sequence generation often leads to degradation in contextual\nconsistency due to the inability of conventional self-attention mechanisms to\neffectively retain long-range dependencies. Existing approaches, including\nmemory compression and retrieval-augmented conditioning, introduce\ncomputational trade-offs that either increase inference latency or impose\nadditional storage overhead. Structured Context Recomposition (SCR) introduces\na probabilistic layer realignment strategy that dynamically adjusts learned\nrepresentations within transformer layers, ensuring that semantically relevant\nembeddings persist throughout extended transformations. The proposed method\nenhances coherence retention through a recursive weighting function that\nredistributes representational emphasis based on inferred contextual relevance\nrather than relying on fixed token-level attention scores. Empirical results\nindicate that probabilistic realignment mitigates abrupt topic shifts and\nlogical inconsistencies, particularly in scenarios where sequences exceed\nstandard attention window constraints. Sequence-level entropy analysis further\nreveals that SCR moderates representational variability without introducing\nexcessive output regularization, allowing models to sustain generative\ndiversity while preserving contextual alignment. Attention head deviation\nmeasurements confirm that hierarchical reweighting contributes to smoother\ntoken dependency transitions across transformer layers, reinforcing the\nstability of multi-turn interactions and document-level reasoning.\nComputational resource assessments show that while SCR incurs a moderate\nincrease in processing time, memory overhead remains within feasible limits,\nmaking it suitable for practical deployment in autoregressive generative\napplications.\n","authors":["Jonathan Teel","Jocasta Cumberbatch","Raphael Benington","Quentin Baskerville"],"pdf_url":"https://arxiv.org/pdf/2501.17617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17615v1","updated":"2025-01-29T12:44:30Z","published":"2025-01-29T12:44:30Z","title":"Cross-lingual Embedding Clustering for Hierarchical Softmax in\n  Low-Resource Multilingual Speech Recognition","summary":"  We present a novel approach centered on the decoding stage of Automatic\nSpeech Recognition (ASR) that enhances multilingual performance, especially for\nlow-resource languages. It utilizes a cross-lingual embedding clustering method\nto construct a hierarchical Softmax (H-Softmax) decoder, which enables similar\ntokens across different languages to share similar decoder representations. It\naddresses the limitations of the previous Huffman-based H-Softmax method, which\nrelied on shallow features in token similarity assessments. Through experiments\non a downsampled dataset of 15 languages, we demonstrate the effectiveness of\nour approach in improving low-resource multilingual ASR accuracy.\n","authors":["Zhengdong Yang","Qianying Liu","Sheng Li","Fei Cheng","Chenhui Chu"],"pdf_url":"https://arxiv.org/pdf/2501.17615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14326v2","updated":"2025-01-29T12:27:41Z","published":"2024-06-20T13:56:52Z","title":"medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced\n  Clinical Diagnosis on EMRs","summary":"  Electronic Medical Records (EMRs), while integral to modern healthcare,\npresent challenges for clinical reasoning and diagnosis due to their complexity\nand information redundancy. To address this, we proposed medIKAL (Integrating\nKnowledge Graphs as Assistants of LLMs), a framework that combines Large\nLanguage Models (LLMs) with knowledge graphs (KGs) to enhance diagnostic\ncapabilities. medIKAL assigns weighted importance to entities in medical\nrecords based on their type, enabling precise localization of candidate\ndiseases within KGs. It innovatively employs a residual network-like approach,\nallowing initial diagnosis by the LLM to be merged into KG search results.\nThrough a path-based reranking algorithm and a fill-in-the-blank style prompt\ntemplate, it further refined the diagnostic process. We validated medIKAL's\neffectiveness through extensive experiments on a newly introduced open-sourced\nChinese EMR dataset, demonstrating its potential to improve clinical diagnosis\nin real-world settings.\n","authors":["Mingyi Jia","Junwen Duan","Yan Song","Jianxin Wang"],"pdf_url":"https://arxiv.org/pdf/2406.14326v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17598v1","updated":"2025-01-29T12:03:11Z","published":"2025-01-29T12:03:11Z","title":"Semantic Consistency Regularization with Large Language Models for\n  Semi-supervised Sentiment Analysis","summary":"  Accurate sentiment analysis of texts is crucial for a variety of\napplications, such as understanding customer feedback, monitoring market\ntrends, and detecting public sentiment. However, manually annotating large\nsentiment corpora for supervised learning is labor-intensive and\ntime-consuming. Therefore, it is essential and effective to develop a\nsemi-supervised method for the sentiment analysis task. Although some methods\nhave been proposed for semi-supervised text classification, they rely on the\nintrinsic information within the unlabeled data and the learning capability of\nthe NLP model, which lack generalization ability to the sentiment analysis\nscenario and may prone to overfit. Inspired by the ability of pretrained Large\nLanguage Models (LLMs) in following instructions and generating coherent text,\nwe propose a Semantic Consistency Regularization with Large Language Models\n(SCR) framework for semi-supervised sentiment analysis. We introduce two\nprompting strategies to semantically enhance unlabeled text using LLMs. The\nfirst is Entity-based Enhancement (SCR-EE), which involves extracting entities\nand numerical information, and querying the LLM to reconstruct the textual\ninformation. The second is Concept-based Enhancement (SCR-CE), which directly\nqueries the LLM with the original sentence for semantic reconstruction.\nSubsequently, the LLM-augmented data is utilized for a consistency loss with\nconfidence thresholding, which preserves high-quality agreement samples to\nprovide additional supervision signals during training. Furthermore, to fully\nutilize the uncertain unlabeled data samples, we propose a class re-assembling\nstrategy inspired by the class space shrinking theorem. Experiments show our\nmethod achieves remarkable performance over prior semi-supervised methods.\n","authors":["Kunrong Li","Xinyu Liu","Zhen Chen"],"pdf_url":"https://arxiv.org/pdf/2501.17598v1.pdf","comment":"ICONIP 2024"},{"id":"http://arxiv.org/abs/2501.17584v1","updated":"2025-01-29T11:40:46Z","published":"2025-01-29T11:40:46Z","title":"GLLM: Self-Corrective G-Code Generation using Large Language Models with\n  User Feedback","summary":"  This paper introduces GLLM, an innovative tool that leverages Large Language\nModels (LLMs) to automatically generate G-code from natural language\ninstructions for Computer Numerical Control (CNC) machining. GLLM addresses the\nchallenges of manual G-code writing by bridging the gap between human-readable\ntask descriptions and machine-executable code. The system incorporates a\nfine-tuned StarCoder-3B model, enhanced with domain-specific training data and\na Retrieval-Augmented Generation (RAG) mechanism. GLLM employs advanced\nprompting strategies and a novel self-corrective code generation approach to\nensure both syntactic and semantic correctness of the generated G-code. The\narchitecture includes robust validation mechanisms, including syntax checks,\nG-code-specific verifications, and functional correctness evaluations using\nHausdorff distance. By combining these techniques, GLLM aims to democratize CNC\nprogramming, making it more accessible to users without extensive programming\nexperience while maintaining high accuracy and reliability in G-code\ngeneration.\n","authors":["Mohamed Abdelaal","Samuel Lokadjaja","Gilbert Engert"],"pdf_url":"https://arxiv.org/pdf/2501.17584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17581v1","updated":"2025-01-29T11:38:29Z","published":"2025-01-29T11:38:29Z","title":"CSEval: Towards Automated, Multi-Dimensional, and Reference-Free\n  Counterspeech Evaluation using Auto-Calibrated LLMs","summary":"  Counterspeech has been popular as an effective approach to counter online\nhate speech, leading to increasing research interest in automated counterspeech\ngeneration using language models. However, this field lacks standardised\nevaluation protocols and robust automated evaluation metrics that align with\nhuman judgement. Current automatic evaluation methods, primarily based on\nsimilarity metrics, do not effectively capture the complex and independent\nattributes of counterspeech quality, such as contextual relevance,\naggressiveness, or argumentative coherence. This has led to an increased\ndependency on labor-intensive human evaluations to assess automated\ncounter-speech generation methods. To address these challenges, we introduce\nCSEval, a novel dataset and framework for evaluating counterspeech quality\nacross four dimensions: contextual-relevance, aggressiveness,\nargument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated\nCOT for Counterspeech Evaluation (ACE), a prompt-based method with\nauto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large\nlanguage models. Our experiments show that ACE outperforms traditional metrics\nlike ROUGE, METEOR, and BertScore in correlating with human judgement,\nindicating a significant advancement in automated counterspeech evaluation.\n","authors":["Amey Hengle","Aswini Kumar","Anil Bandhakavi","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2501.17581v1.pdf","comment":"17 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2309.13308 by other authors"},{"id":"http://arxiv.org/abs/2310.08225v2","updated":"2025-01-29T11:28:34Z","published":"2023-10-12T11:17:40Z","title":"Fast Word Error Rate Estimation Using Self-Supervised Representations\n  for Speech and Text","summary":"  Word error rate (WER) estimation aims to evaluate the quality of an automatic\nspeech recognition (ASR) system's output without requiring ground-truth labels.\nThis task has gained increasing attention as advanced ASR systems are trained\non large amounts of data. In this context, the computational efficiency of a\nWER estimator becomes essential in practice. However, previous works have not\nprioritised this aspect. In this paper, a Fast estimator for WER (Fe-WER) is\nintroduced, utilizing average pooling over self-supervised learning\nrepresentations for speech and text. Our results demonstrate that Fe-WER\noutperformed a baseline relatively by 14.10% in root mean square error and\n1.22% in Pearson correlation coefficient on Ted-Lium3. Moreover, a comparative\nanalysis of the distributions of target WER and WER estimates was conducted,\nincluding an examination of the average values per speaker. Lastly, the\ninference speed was approximately 3.4 times faster in the real-time factor.\n","authors":["Chanho Park","Chengsong Lu","Mingjie Chen","Thomas Hain"],"pdf_url":"https://arxiv.org/pdf/2310.08225v2.pdf","comment":"5 pages, accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.17569v1","updated":"2025-01-29T11:05:20Z","published":"2025-01-29T11:05:20Z","title":"A linguistically-motivated evaluation methodology for unraveling model's\n  abilities in reading comprehension tasks","summary":"  We introduce an evaluation methodology for reading comprehension tasks based\non the intuition that certain examples, by the virtue of their linguistic\ncomplexity, consistently yield lower scores regardless of model size or\narchitecture. We capitalize on semantic frame annotation for characterizing\nthis complexity, and study seven complexity factors that may account for\nmodel's difficulty. We first deploy this methodology on a carefully annotated\nFrench reading comprehension benchmark showing that two of those complexity\nfactors are indeed good predictors of models' failure, while others are less\nso. We further deploy our methodology on a well studied English benchmark by\nusing Chat-GPT as a proxy for semantic annotation. Our study reveals that\nfine-grained linguisticallymotivated automatic evaluation of a reading\ncomprehension task is not only possible, but helps understand models' abilities\nto handle specific linguistic characteristics of input examples. It also shows\nthat current state-of-the-art models fail with some for those characteristics\nwhich suggests that adequately handling them requires more than merely\nincreasing model size.\n","authors":["Elie Antoine","Frédéric Béchet","Géraldine Damnati","Philippe Langlais"],"pdf_url":"https://arxiv.org/pdf/2501.17569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17549v1","updated":"2025-01-29T10:35:41Z","published":"2025-01-29T10:35:41Z","title":"Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language\n  Models","summary":"  Graph-structured data plays a vital role in numerous domains, such as social\nnetworks, citation networks, commonsense reasoning graphs and knowledge graphs.\nWhile graph neural networks have been employed for graph processing, recent\nadvancements have explored integrating large language models for graph-based\ntasks. In this paper, we propose a novel approach named Learnable Graph Pooling\nToken (LGPT), which addresses the limitations of the scalability issues in\nnode-level projection and information loss in graph-level projection. LGPT\nenables flexible and efficient graph representation by introducing learnable\nparameters that act as tokens in large language models, balancing fine-grained\nand global graph information. Additionally, we investigate an Early Query\nFusion technique, which fuses query context before constructing the graph\nrepresentation, leading to more effective graph embeddings. Our method achieves\na 4.13\\% performance improvement on the GraphQA benchmark without training the\nlarge language model, demonstrating significant gains in handling complex\ntextual-attributed graph data.\n","authors":["Wooyoung Kim","Byungyoon Park","Wooju Kim"],"pdf_url":"https://arxiv.org/pdf/2501.17549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08782v3","updated":"2025-01-29T10:25:02Z","published":"2024-08-16T14:54:41Z","title":"EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling\n  MiXed Emotions and Discourse Dynamics","summary":"  Designing emotionally intelligent conversational systems to provide comfort\nand advice to people experiencing distress is a compelling area of research.\nRecently, with advancements in large language models (LLMs), end-to-end\ndialogue agents without explicit strategy prediction steps have become\nprevalent. However, implicit strategy planning lacks transparency, and recent\nstudies show that LLMs' inherent preference bias towards certain\nsocio-emotional strategies hinders the delivery of high-quality emotional\nsupport. To address this challenge, we propose decoupling strategy prediction\nfrom language generation, and introduce a novel dialogue strategy prediction\nframework, EmoDynamiX, which models the discourse dynamics between user\nfine-grained emotions and system strategies using a heterogeneous graph for\nbetter performance and transparency. Experimental results on two ESC datasets\nshow EmoDynamiX outperforms previous state-of-the-art methods with a\nsignificant margin (better proficiency and lower preference bias). Our approach\nalso exhibits better transparency by allowing backtracing of decision making.\n","authors":["Chenwei Wan","Matthieu Labeau","Chloé Clavel"],"pdf_url":"https://arxiv.org/pdf/2408.08782v3.pdf","comment":"Accepted to NAACL 2025 main, camera ready version"},{"id":"http://arxiv.org/abs/2404.19369v2","updated":"2025-01-29T09:54:00Z","published":"2024-04-30T08:55:01Z","title":"Evaluating Telugu Proficiency in Large Language Models_ A Comparative\n  Analysis of ChatGPT and Gemini","summary":"  The growing prominence of large language models (LLMs) necessitates the\nexploration of their capabilities beyond English. This research investigates\nthe Telugu language proficiency of ChatGPT and Gemini, two leading LLMs.\nThrough a designed set of 20 questions encompassing greetings, grammar,\nvocabulary, common phrases, task completion, and situational reasoning, the\nstudy delves into their strengths and weaknesses in handling Telugu. The\nanalysis aims to identify the LLM that demonstrates a deeper understanding of\nTelugu grammatical structures, possesses a broader vocabulary, and exhibits\nsuperior performance in tasks like writing and reasoning. By comparing their\nability to comprehend and use everyday Telugu expressions, the research sheds\nlight on their suitability for real-world language interaction. Furthermore,\nthe evaluation of adaptability and reasoning capabilities provides insights\ninto how each LLM leverages Telugu to respond to dynamic situations. This\ncomparative analysis contributes to the ongoing discussion on multilingual\ncapabilities in AI and paves the way for future research in developing LLMs\nthat can seamlessly integrate with Telugu-speaking communities.\n","authors":["Katikela Sreeharsha Kishore","Rahimanuddin Shaik"],"pdf_url":"https://arxiv.org/pdf/2404.19369v2.pdf","comment":"Disparities in fundamental understandings about the article between\n  the authors"},{"id":"http://arxiv.org/abs/2410.13498v2","updated":"2025-01-29T09:53:38Z","published":"2024-10-17T12:43:49Z","title":"Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum\n  Learning, Semi-Supervised Training, and Advanced Optimization Techniques","summary":"  Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.\n","authors":["Rahimanuddin Shaik","Katikela Sreeharsha Kishore"],"pdf_url":"https://arxiv.org/pdf/2410.13498v2.pdf","comment":"Disparities in fundamental understandings about the article between\n  the authors"},{"id":"http://arxiv.org/abs/2501.17510v1","updated":"2025-01-29T09:27:27Z","published":"2025-01-29T09:27:27Z","title":"LLM Assistance for Pediatric Depression","summary":"  Traditional depression screening methods, such as the PHQ-9, are particularly\nchallenging for children in pediatric primary care due to practical\nlimitations. AI has the potential to help, but the scarcity of annotated\ndatasets in mental health, combined with the computational costs of training,\nhighlights the need for efficient, zero-shot approaches. In this work, we\ninvestigate the feasibility of state-of-the-art LLMs for depressive symptom\nextraction in pediatric settings (ages 6-24). This approach aims to complement\ntraditional screening and minimize diagnostic errors.\n  Our findings show that all LLMs are 60% more efficient than word match, with\nFlan leading in precision (average F1: 0.65, precision: 0.78), excelling in the\nextraction of more rare symptoms like \"sleep problems\" (F1: 0.92) and\n\"self-loathing\" (F1: 0.8). Phi strikes a balance between precision (0.44) and\nrecall (0.60), performing well in categories like \"Feeling depressed\" (0.69)\nand \"Weight change\" (0.78). Llama 3, with the highest recall (0.90),\novergeneralizes symptoms, making it less suitable for this type of analysis.\nChallenges include the complexity of clinical notes and overgeneralization from\nPHQ-9 scores. The main challenges faced by LLMs include navigating the complex\nstructure of clinical notes with content from different times in the patient\ntrajectory, as well as misinterpreting elevated PHQ-9 scores.\n  We finally demonstrate the utility of symptom annotations provided by Flan as\nfeatures in an ML algorithm, which differentiates depression cases from\ncontrols with high precision of 0.78, showing a major performance boost\ncompared to a baseline that does not use these features.\n","authors":["Mariia Ignashina","Paulina Bondaronek","Dan Santel","John Pestian","Julia Ive"],"pdf_url":"https://arxiv.org/pdf/2501.17510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17486v1","updated":"2025-01-29T08:53:29Z","published":"2025-01-29T08:53:29Z","title":"DINT Transformer","summary":"  DIFF Transformer addresses the issue of irrelevant context interference by\nintroducing a differential attention mechanism that enhances the robustness of\nlocal attention. However, it has two critical limitations: the lack of global\ncontext modeling, which is essential for identifying globally significant\ntokens, and numerical instability due to the absence of strict row\nnormalization in the attention matrix. To overcome these challenges, we propose\nDINT Transformer, which extends DIFF Transformer by incorporating a\ndifferential-integral mechanism. By computing global importance scores and\nintegrating them into the attention matrix, DINT Transformer improves its\nability to capture global dependencies. Moreover, the unified parameter design\nenforces row-normalized attention matrices, improving numerical stability.\nExperimental results demonstrate that DINT Transformer excels in accuracy and\nrobustness across various practical applications, such as long-context language\nmodeling and key information retrieval. These results position DINT Transformer\nas a highly effective and promising architecture.\n","authors":["Yueyang Cang","Yuhang Liu","Xiaoteng Zhang","Erlu Zhao","Li Shi"],"pdf_url":"https://arxiv.org/pdf/2501.17486v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2410.05258 by other authors"},{"id":"http://arxiv.org/abs/2404.01054v4","updated":"2025-01-29T08:52:40Z","published":"2024-04-01T11:26:50Z","title":"Regularized Best-of-N Sampling with Minimum Bayes Risk Objective for\n  Language Model Alignment","summary":"  Best-of-N (BoN) sampling with a reward model has been shown to be an\neffective strategy for aligning Large Language Models (LLMs) to human\npreferences at the time of decoding. BoN sampling is susceptible to a problem\nknown as reward hacking when the accuracy of the reward model is not high\nenough due to the quality or the quantity of the preference dataset. Because\nthe reward model is an imperfect proxy for the true objective, over-optimizing\nits value can compromise its performance on the true objective. In this\nresearch, we propose MBR-BoN, a variant of BoN that aims to mitigate reward\nhacking at inference time by incorporating the Minimum Bayes Risk (MBR)\nobjective as a proximity regularization term. We show empirically and\nanalytically that the MBR objective quantifies the proximity of the response to\nthe reference policy, serving as a proximity regularizer. We evaluate MBR-BoN\non the AlpacaFarm and Anthropic's hh-rlhf datasets and show that it outperforms\nboth BoN sampling and MBR decoding. We also evaluate MBR-BoN to generate a\npairwise preference learning dataset for Direct Preference Optimization (DPO).\nEmpirical results show that models trained on a dataset generated with MBR-BoN\noutperform those with vanilla BoN. Our code is available at\nhttps://github.com/CyberAgentAILab/regularized-bon\n","authors":["Yuu Jinnai","Tetsuro Morimura","Kaito Ariu","Kenshi Abe"],"pdf_url":"https://arxiv.org/pdf/2404.01054v4.pdf","comment":"NAACL 2025"},{"id":"http://arxiv.org/abs/2501.17479v1","updated":"2025-01-29T08:44:45Z","published":"2025-01-29T08:44:45Z","title":"DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance","summary":"  Large Language Models (LLMs) have shown remarkable capabilities across\nvarious natural language processing tasks but often struggle to excel uniformly\nin diverse or complex domains. We propose a novel ensemble method - Diverse\nFingerprint Ensemble (DFPE), which leverages the complementary strengths of\nmultiple LLMs to achieve more robust performance. Our approach involves: (1)\nclustering models based on response \"fingerprints\" patterns, (2) applying a\nquantile-based filtering mechanism to remove underperforming models at a\nper-subject level, and (3) assigning adaptive weights to remaining models based\non their subject-wise validation accuracy. In experiments on the Massive\nMultitask Language Understanding (MMLU) benchmark, DFPE outperforms the best\nsingle model by 3% overall accuracy and 5% in discipline-level accuracy. This\nmethod increases the robustness and generalization of LLMs and underscores how\nmodel selection, diversity preservation, and performance-driven weighting can\neffectively address challenging, multi-faceted language understanding tasks.\n","authors":["Seffi Cohen","Niv Goldshlager","Nurit Cohen-Inger","Bracha Shapira","Lior Rokach"],"pdf_url":"https://arxiv.org/pdf/2501.17479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17459v1","updated":"2025-01-29T07:35:56Z","published":"2025-01-29T07:35:56Z","title":"Large Language Models for Single-Step and Multi-Step Flight Trajectory\n  Prediction","summary":"  Flight trajectory prediction is a critical time series task in aviation.\nWhile deep learning methods have shown significant promise, the application of\nlarge language models (LLMs) to this domain remains underexplored. This study\npioneers the use of LLMs for flight trajectory prediction by reframing it as a\nlanguage modeling problem. Specifically, We extract features representing the\naircraft's position and status from ADS-B flight data to construct a\nprompt-based dataset, where trajectory waypoints are converted into language\ntokens. The dataset is then employed to fine-tune LLMs, enabling them to learn\ncomplex spatiotemporal patterns for accurate predictions. Comprehensive\nexperiments demonstrate that LLMs achieve notable performance improvements in\nboth single-step and multi-step predictions compared to traditional methods,\nwith LLaMA-3.1 model achieving the highest overall accuracy. However, the high\ninference latency of LLMs poses a challenge for real-time applications,\nunderscoring the need for further research in this promising direction.\n","authors":["Kaiwei Luo","Jiliu Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.17459v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2501.17456v1","updated":"2025-01-29T07:33:36Z","published":"2025-01-29T07:33:36Z","title":"A review on the novelty measurements of academic papers","summary":"  Novelty evaluation is vital for the promotion and management of innovation.\nWith the advancement of information techniques and the open data movement, some\nprogress has been made in novelty measurements. Tracking and reviewing novelty\nmeasures provides a data-driven way to assess contributions, progress, and\nemerging directions in the science field. As academic papers serve as the\nprimary medium for the dissemination, validation, and discussion of scientific\nknowledge, this review aims to offer a systematic analysis of novelty\nmeasurements for scientific papers. We began by comparing the differences\nbetween scientific novelty and four similar concepts, including originality,\nscientific innovation, creativity, and scientific breakthrough. Next, we\nreviewed the types of scientific novelty. Then, we classified existing novelty\nmeasures according to data types and reviewed the measures for each type.\nSubsequently, we surveyed the approaches employed in validating novelty\nmeasures and examined the current tools and datasets associated with these\nmeasures. Finally, we proposed several open issues for future studies.\n","authors":["Yi Zhao","Chengzhi Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.17456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17449v1","updated":"2025-01-29T07:13:27Z","published":"2025-01-29T07:13:27Z","title":"Cross-Language Approach for Quranic QA","summary":"  Question answering systems face critical limitations in languages with\nlimited resources and scarce data, making the development of robust models\nespecially challenging. The Quranic QA system holds significant importance as\nit facilitates a deeper understanding of the Quran, a Holy text for over a\nbillion people worldwide. However, these systems face unique challenges,\nincluding the linguistic disparity between questions written in Modern Standard\nArabic and answers found in Quranic verses written in Classical Arabic, and the\nsmall size of existing datasets, which further restricts model performance. To\naddress these challenges, we adopt a cross-language approach by (1) Dataset\nAugmentation: expanding and enriching the dataset through machine translation\nto convert Arabic questions into English, paraphrasing questions to create\nlinguistic diversity, and retrieving answers from an English translation of the\nQuran to align with multilingual training requirements; and (2) Language Model\nFine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base,\nDeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the\nspecific requirements of Quranic QA. Experimental results demonstrate that this\ncross-language approach significantly improves model performance, with\nRoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while\nDeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These\nfindings underscore the effectiveness of cross-language strategies in\novercoming linguistic barriers and advancing Quranic QA systems\n","authors":["Islam Oshallah","Mohamed Basem","Ali Hamdi","Ammar Mohammed"],"pdf_url":"https://arxiv.org/pdf/2501.17449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07623v5","updated":"2025-01-29T07:07:54Z","published":"2024-05-13T10:30:33Z","title":"COBias and Debias: Balancing Class Accuracies for Language Models in\n  Inference Time via Nonlinear Integer Programming","summary":"  Large language models (LLMs) are good knowledge bases but struggle to perform\nequally well for all classes in text classification tasks. This paper\ninvestigates a fundamental inference-time problem in language models:\nimbalanced class accuracies. We find what's underneath the issue is a tendency\nto over-predict some classes while under-predicting some others. This class\naccuracy imbalance is difficult to solve from the root via better pre-training\nor fine-tuning strategies, but we show it can be effectively mitigated via\ninference-time combinatorial optimization. To this end, we conceptualize and\nquantify the over- and under-prediction issue as the Contextual Oddity Bias\n(COBias), and propose the Debiasing as Nonlinear Integer Programming (DNIP)\nmodel to correct in-context learned class probabilities based on minimizing\nCOBias and maximizing overall accuracy, without LLM parameter update.\nConsidering that the DNIP model implicitly contains non-differentiable\nelements, we therefore use the simulated annealing algorithm to solve it.\nExtensive evaluations on three LLMs across seven NLP classification tasks in\ndifferent prompting settings show that DNIP simultaneously achieves significant\nCOBias reduction (-27%) and accuracy improvement (+12%) over the conventional\nICL approach, suggesting that inference-time mitigation of class accuracy\nimbalance is a promising direction to push forward LLM performances.\n","authors":["Ruixi Lin","Yang You"],"pdf_url":"https://arxiv.org/pdf/2405.07623v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17441v1","updated":"2025-01-29T06:43:38Z","published":"2025-01-29T06:43:38Z","title":"Towards Making Flowchart Images Machine Interpretable","summary":"  Computer programming textbooks and software documentations often contain\nflowcharts to illustrate the flow of an algorithm or procedure. Modern OCR\nengines often tag these flowcharts as graphics and ignore them in further\nprocessing. In this paper, we work towards making flowchart images\nmachine-interpretable by converting them to executable Python codes. To this\nend, inspired by the recent success in natural language to code generation\nliterature, we present a novel transformer-based framework, namely FloCo-T5.\nOur model is well-suited for this task,as it can effectively learn semantics,\nstructure, and patterns of programming languages, which it leverages to\ngenerate syntactically correct code. We also used a task-specific pre-training\nobjective to pre-train FloCo-T5 using a large number of logic-preserving\naugmented code samples. Further, to perform a rigorous study of this problem,\nwe introduce theFloCo dataset that contains 11,884 flowchart images and their\ncorresponding Python codes. Our experiments show promising results, and\nFloCo-T5 clearly outperforms related competitive baselines on code generation\nmetrics. We make our dataset and implementation publicly available.\n","authors":["Shreya Shukla","Prajwal Gatti","Yogesh Kumar","Vikash Yadav","Anand Mishra"],"pdf_url":"https://arxiv.org/pdf/2501.17441v1.pdf","comment":"Published at: ICDAR 2023, Project Page:\n  https://vl2g.github.io/projects/floco/"},{"id":"http://arxiv.org/abs/2501.17433v1","updated":"2025-01-29T06:24:58Z","published":"2025-01-29T06:24:58Z","title":"Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing\n  Guardrail Moderation","summary":"  Recent research shows that Large Language Models (LLMs) are vulnerable to\nharmful fine-tuning attacks -- models lose their safety alignment ability after\nfine-tuning on a few harmful samples. For risk mitigation, a guardrail is\ntypically used to filter out harmful samples before fine-tuning. By designing a\nnew red-teaming method, we in this paper show that purely relying on the\nmoderation guardrail for data filtration is not reliable. Our proposed attack\nmethod, dubbed Virus, easily bypasses the guardrail moderation by slightly\nmodifying the harmful data. Experimental results show that the harmful data\noptimized by Virus is not detectable by the guardrail with up to 100\\% leakage\nratio, and can simultaneously achieve superior attack performance. Finally, the\nkey message we want to convey through this paper is that: \\textbf{it is\nreckless to consider guardrail moderation as a clutch at straws towards harmful\nfine-tuning attack}, as it cannot solve the inherent safety issue of the\npre-trained LLMs. Our code is available at https://github.com/git-disl/Virus\n","authors":["Tiansheng Huang","Sihao Hu","Fatih Ilhan","Selim Furkan Tekin","Ling Liu"],"pdf_url":"https://arxiv.org/pdf/2501.17433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16937v2","updated":"2025-01-29T05:51:25Z","published":"2025-01-28T13:31:18Z","title":"TAID: Temporally Adaptive Interpolated Distillation for Efficient\n  Knowledge Transfer in Language Models","summary":"  Causal language models have demonstrated remarkable capabilities, but their\nsize poses significant challenges for deployment in resource-constrained\nenvironments. Knowledge distillation, a widely-used technique for transferring\nknowledge from a large teacher model to a small student model, presents a\npromising approach for model compression. A significant remaining issue lies in\nthe major differences between teacher and student models, namely the\nsubstantial capacity gap, mode averaging, and mode collapse, which pose\nbarriers during distillation. To address these issues, we introduce\n$\\textit{Temporally Adaptive Interpolated Distillation (TAID)}$, a novel\nknowledge distillation approach that dynamically interpolates student and\nteacher distributions through an adaptive intermediate distribution, gradually\nshifting from the student's initial distribution towards the teacher's\ndistribution. We provide a theoretical analysis demonstrating TAID's ability to\nprevent mode collapse and empirically show its effectiveness in addressing the\ncapacity gap while balancing mode averaging and mode collapse. Our\ncomprehensive experiments demonstrate TAID's superior performance across\nvarious model sizes and architectures in both instruction tuning and\npre-training scenarios. Furthermore, we showcase TAID's practical impact by\ndeveloping two state-of-the-art compact foundation models:\n$\\texttt{TAID-LLM-1.5B}$ for language tasks and $\\texttt{TAID-VLM-2B}$ for\nvision-language tasks. These results demonstrate TAID's effectiveness in\ncreating high-performing and efficient models, advancing the development of\nmore accessible AI technologies.\n","authors":["Makoto Shing","Kou Misaki","Han Bao","Sho Yokoi","Takuya Akiba"],"pdf_url":"https://arxiv.org/pdf/2501.16937v2.pdf","comment":"To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2501.17420v1","updated":"2025-01-29T05:21:31Z","published":"2025-01-29T05:21:31Z","title":"Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases\n  in Language Models","summary":"  While advances in fairness and alignment have helped mitigate overt biases\nexhibited by large language models (LLMs) when explicitly prompted, we\nhypothesize that these models may still exhibit implicit biases when simulating\nhuman behavior. To test this hypothesis, we propose a technique to\nsystematically uncover such biases across a broad range of sociodemographic\ncategories by assessing decision-making disparities among agents with\nLLM-generated, sociodemographically-informed personas. Using our technique, we\ntested six LLMs across three sociodemographic groups and four decision-making\nscenarios. Our results show that state-of-the-art LLMs exhibit significant\nsociodemographic disparities in nearly all simulations, with more advanced\nmodels exhibiting greater implicit biases despite reducing explicit biases.\nFurthermore, when comparing our findings to real-world disparities reported in\nempirical studies, we find that the biases we uncovered are directionally\naligned but markedly amplified. This directional alignment highlights the\nutility of our technique in uncovering systematic biases in LLMs rather than\nrandom variations; moreover, the presence and amplification of implicit biases\nemphasizes the need for novel strategies to address these biases.\n","authors":["Yuxuan Li","Hirokazu Shirado","Sauvik Das"],"pdf_url":"https://arxiv.org/pdf/2501.17420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17403v1","updated":"2025-01-29T03:57:56Z","published":"2025-01-29T03:57:56Z","title":"General Scene Adaptation for Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on\none-time execution of individual instructions across multiple environments,\naiming to develop agents capable of functioning in any environment in a\nzero-shot manner. However, real-world navigation robots often operate in\npersistent environments with relatively consistent physical layouts, visual\nobservations, and language styles from instructors. Such a gap in the task\nsetting presents an opportunity to improve VLN agents by incorporating\ncontinuous adaptation to specific environments. To better reflect these\nreal-world conditions, we introduce GSA-VLN, a novel task requiring agents to\nexecute navigation instructions within a specific scene and simultaneously\nadapt to it for improved performance over time. To evaluate the proposed task,\none has to address two challenges in existing VLN datasets: the lack of OOD\ndata, and the limited number and style diversity of instructions for each\nscene. Therefore, we propose a new dataset, GSA-R2R, which significantly\nexpands the diversity and quantity of environments and instructions for the R2R\ndataset to evaluate agent adaptability in both ID and OOD contexts.\nFurthermore, we design a three-stage instruction orchestration pipeline that\nleverages LLMs to refine speaker-generated instructions and apply role-playing\ntechniques to rephrase instructions into different speaking styles. This is\nmotivated by the observation that each individual user often has consistent\nsignatures or preferences in their instructions. We conducted extensive\nexperiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various\nmethods. Based on our findings, we propose a novel method, GR-DUET, which\nincorporates memory-based navigation graphs with an environment-specific\ntraining strategy, achieving state-of-the-art results on all GSA-R2R splits.\n","authors":["Haodong Hong","Yanyuan Qiao","Sen Wang","Jiajun Liu","Qi Wu"],"pdf_url":"https://arxiv.org/pdf/2501.17403v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.16411v2","updated":"2025-01-29T03:52:39Z","published":"2025-01-27T18:59:58Z","title":"PhysBench: Benchmarking and Enhancing Vision-Language Models for\n  Physical World Understanding","summary":"  Understanding the physical world is a fundamental challenge in embodied AI,\ncritical for enabling agents to perform complex tasks and operate safely in\nreal-world environments. While Vision-Language Models (VLMs) have shown great\npromise in reasoning and task planning for embodied agents, their ability to\ncomprehend physical phenomena remains extremely limited. To close this gap, we\nintroduce PhysBench, a comprehensive benchmark designed to evaluate VLMs'\nphysical world understanding capability across a diverse set of tasks.\nPhysBench contains 10,002 entries of interleaved video-image-text data,\ncategorized into four major domains: physical object properties, physical\nobject relationships, physical scene understanding, and physics-based dynamics,\nfurther divided into 19 subclasses and 8 distinct capability dimensions. Our\nextensive experiments, conducted on 75 representative VLMs, reveal that while\nthese models excel in common-sense reasoning, they struggle with understanding\nthe physical world -- likely due to the absence of physical knowledge in their\ntraining data and the lack of embedded physical priors. To tackle the\nshortfall, we introduce PhysAgent, a novel framework that combines the\ngeneralization strengths of VLMs with the specialized expertise of vision\nmodels, significantly enhancing VLMs' physical understanding across a variety\nof tasks, including an 18.4\\% improvement on GPT-4o. Furthermore, our results\ndemonstrate that enhancing VLMs' physical world understanding capabilities can\nhelp embodied agents such as MOKA. We believe that PhysBench and PhysAgent\noffer valuable insights and contribute to bridging the gap between VLMs and\nphysical world understanding.\n","authors":["Wei Chow","Jiageng Mao","Boyi Li","Daniel Seita","Vitor Guizilini","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2501.16411v2.pdf","comment":"ICLR 2025. Project page: https://physbench.github.io/ Dataset:\n  https://huggingface.co/datasets/USC-GVL/PhysBench"},{"id":"http://arxiv.org/abs/2501.17399v1","updated":"2025-01-29T03:29:24Z","published":"2025-01-29T03:29:24Z","title":"MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark\n  Challenging to Frontier LLMs","summary":"  We present MultiChallenge, a pioneering benchmark evaluating large language\nmodels (LLMs) on conducting multi-turn conversations with human users, a\ncrucial yet underexamined capability for their applications. MultiChallenge\nidentifies four categories of challenges in multi-turn conversations that are\nnot only common and realistic among current human-LLM interactions, but are\nalso challenging to all current frontier LLMs. All 4 challenges require\naccurate instruction-following, context allocation, and in-context reasoning at\nthe same time. We also develop LLM as judge with instance-level rubrics to\nfacilitate an automatic evaluation method with fair agreement with experienced\nhuman raters. Despite achieving near-perfect scores on existing multi-turn\nevaluation benchmarks, all frontier models have less than 50% accuracy on\nMultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving\njust a 41.4% average accuracy.\n","authors":["Ved Sirdeshmukh","Kaustubh Deshpande","Johannes Mols","Lifeng Jin","Ed-Yeremai Cardona","Dean Lee","Jeremy Kritz","Willow Primack","Summer Yue","Chen Xing"],"pdf_url":"https://arxiv.org/pdf/2501.17399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17397v1","updated":"2025-01-29T03:25:19Z","published":"2025-01-29T03:25:19Z","title":"Leveraging In-Context Learning and Retrieval-Augmented Generation for\n  Automatic Question Generation in Educational Domains","summary":"  Question generation in education is a time-consuming and cognitively\ndemanding task, as it requires creating questions that are both contextually\nrelevant and pedagogically sound. Current automated question generation methods\noften generate questions that are out of context. In this work, we explore\nadvanced techniques for automated question generation in educational contexts,\nfocusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG),\nand a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL\nusing few-shot examples and BART with a retrieval module for RAG. The Hybrid\nModel combines RAG and ICL to address these issues and improve question\nquality. Evaluation is conducted using automated metrics, followed by human\nevaluation metrics. Our results show that both the ICL approach and the Hybrid\nModel consistently outperform other methods, including baseline models, by\ngenerating more contextually accurate and relevant questions.\n","authors":["Subhankar Maity","Aniket Deroy","Sudeshna Sarkar"],"pdf_url":"https://arxiv.org/pdf/2501.17397v1.pdf","comment":"Accepted at the 16th Meeting of the Forum for Information Retrieval\n  Evaluation as a Regular Paper"},{"id":"http://arxiv.org/abs/2501.12570v2","updated":"2025-01-29T03:11:03Z","published":"2025-01-22T01:35:11Z","title":"O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning","summary":"  Recently, long-thought reasoning LLMs, such as OpenAI's O1, adopt extended\nreasoning processes similar to how humans ponder over complex problems. This\nreasoning paradigm significantly enhances the model's problem-solving abilities\nand has achieved promising results. However, long-thought reasoning process\nleads to a substantial increase in inference time. A pressing challenge is\nreducing the inference overhead of long-thought LLMs while ensuring accuracy.\nIn this paper, we experimentally demonstrate that long-thought reasoning models\nstruggle to effectively allocate token budgets based on problem difficulty and\nreasoning redundancies. To address this, we propose Length-Harmonizing\nFine-Tuning (O1-Pruner), aiming at minimizing reasoning overhead while\nmaintaining accuracy. This effective fine-tuning method first estimates the\nLLM's baseline performance through pre-sampling and then uses RL-style\nfine-tuning to encourage the model to generate shorter reasoning processes\nunder accuracy constraints. This allows the model to achieve efficient\nreasoning with lower redundancy while maintaining accuracy. Experiments on\nvarious mathematical reasoning benchmarks show that O1-Pruner not only\nsignificantly reduces inference overhead but also achieves higher accuracy,\nproviding a novel and promising solution to this challenge. Our code is coming\nsoon at https://github.com/StarDewXXX/O1-Pruner\n","authors":["Haotian Luo","Li Shen","Haiying He","Yibo Wang","Shiwei Liu","Wei Li","Naiqiang Tan","Xiaochun Cao","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2501.12570v2.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2501.17391v1","updated":"2025-01-29T02:52:32Z","published":"2025-01-29T02:52:32Z","title":"Learning Free Token Reduction for Multi-Modal LLM","summary":"  Vision-Language Models (VLMs) have achieved remarkable success across a range\nof multimodal tasks; however, their practical deployment is often constrained\nby high computational costs and prolonged inference times. Since the vision\nmodality typically carries more information than the text modality, compressing\nvisual prompts offers a promising solution to alleviate these challenges.\nExisting approaches predominantly focus on refining model architectures or\ndirectly reducing the number of visual tokens. However, these methods often\ncompromise inference performance due to a lack of consideration for the unique\nspatial and temporal characteristics of visual data. In this work, we propose a\ntoken compression paradigm that operates on both spatial and temporal\ndimensions. Our approach includes a learning-free, plug-and-play compression\npipeline that can be seamlessly integrated into most Multimodal Large Language\nModel (MLLM) frameworks. By leveraging this method, we enhance the model\ninference capability while simultaneously reducing its computational cost.\nExperimental results on the Video-QA task demonstrate the effectiveness of the\nproposed approach, showcasing significant improvements in efficiency without\nsacrificing performance.\n","authors":["Zihui Zhao","Yingxin Li","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2501.17391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17386v1","updated":"2025-01-29T02:38:28Z","published":"2025-01-29T02:38:28Z","title":"Context-Aware Semantic Recomposition Mechanism for Large Language Models","summary":"  Context-aware processing mechanisms have increasingly become a critical area\nof exploration for improving the semantic and contextual capabilities of\nlanguage generation models. The Context-Aware Semantic Recomposition Mechanism\n(CASRM) was introduced as a novel framework designed to address limitations in\ncoherence, contextual adaptability, and error propagation in large-scale text\ngeneration tasks. Through the integration of dynamically generated context\nvectors and attention modulation layers, CASRM enhances the alignment between\ntoken-level representations and broader contextual dependencies. Experimental\nevaluations demonstrated significant improvements in semantic coherence across\nmultiple domains, including technical, conversational, and narrative text. The\nability to adapt to unseen domains and ambiguous inputs was evaluated using a\ndiverse set of test scenarios, highlighting the robustness of the proposed\nmechanism. A detailed computational analysis revealed that while CASRM\nintroduces additional processing overhead, the gains in linguistic precision\nand contextual relevance outweigh the marginal increase in complexity. The\nframework also successfully mitigates error propagation in sequential tasks,\nimproving performance in dialogue continuation and multi-step text synthesis.\nAdditional investigations into token-level attention distribution emphasized\nthe dynamic focus shifts enabled through context-aware enhancements. The\nfindings suggest that CASRM offers a scalable and flexible solution for\nintegrating contextual intelligence into existing language model architectures.\n","authors":["Richard Katrix","Quentin Carroway","Rowan Hawkesbury","Matthias Heathfield"],"pdf_url":"https://arxiv.org/pdf/2501.17386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09615v5","updated":"2025-01-29T00:34:35Z","published":"2024-02-14T23:09:15Z","title":"API Pack: A Massive Multi-Programming Language Dataset for API Call\n  Generation","summary":"  We introduce API Pack, a massive multi-programming language dataset\ncontaining over one million instruction-API calls for improving the API call\ngeneration capabilities of large language models. Our evaluation highlights\nthree key findings: First, fine-tuning on API Pack enables open-source models\nto outperform GPT-3.5 and GPT-4 in generating code for entirely new API calls.\nWe show this by fine-tuning CodeLlama-13B on 20,000 Python instances from API\nPack. Second, fine-tuning on a large dataset in one language, combined with\nsmaller datasets from others, improves API generation accuracy across multiple\nlanguages. Third, we confirm the benefits of larger datasets for API\ngeneralization, as increasing fine-tuning data to one million instances\nenhances generalization to new APIs. To support further research, we\nopen-source the API Pack dataset, trained model, and code at\nhttps://github.com/zguo0525/API-Pack.\n","authors":["Zhen Guo","Adriana Meza Soria","Wei Sun","Yikang Shen","Rameswar Panda"],"pdf_url":"https://arxiv.org/pdf/2402.09615v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02189v3","updated":"2025-01-29T00:26:29Z","published":"2025-01-04T04:59:33Z","title":"Benchmark Evaluations, Applications, and Challenges of Large Vision\n  Language Models: A Survey","summary":"  Multimodal Vision Language Models (VLMs) have emerged as a transformative\ntechnology at the intersection of computer vision and natural language\nprocessing, enabling machines to perceive and reason about the world through\nboth visual and textual modalities. For example, models such as CLIP, Claude,\nand GPT-4V demonstrate strong reasoning and understanding abilities on visual\nand textual data and beat classical single modality vision models on zero-shot\nclassification. Despite their rapid advancements in research and growing\npopularity in applications, a comprehensive survey of existing studies on VLMs\nis notably lacking, particularly for researchers aiming to leverage VLMs in\ntheir specific domains. To this end, we provide a systematic overview of VLMs\nin the following aspects: model information of the major VLMs developed over\nthe past five years (2019-2024); the main architectures and training methods of\nthese VLMs; summary and categorization of the popular benchmarks and evaluation\nmetrics of VLMs; the applications of VLMs including embodied agents, robotics,\nand video generation; the challenges and issues faced by current VLMs such as\nhallucination, fairness, and safety. Detailed collections including papers and\nmodel repository links are listed in\nhttps://github.com/zli12321/Awesome-VLM-Papers-And-Models.git.\n","authors":["Zongxia Li","Xiyang Wu","Hongyang Du","Huy Nghiem","Guangyao Shi"],"pdf_url":"https://arxiv.org/pdf/2501.02189v3.pdf","comment":"35 pages, 3 figures"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2501.13354v2","updated":"2025-01-29T23:57:36Z","published":"2025-01-23T03:42:22Z","title":"NUDT4MSTAR: A Large Dataset and Benchmark Towards Remote Sensing Object\n  Recognition in the Wild","summary":"  As an indispensable sensor for Remote sensing, Synthetic Aperture Radar (SAR)\nhas a unique capability for all-day imaging. Nevertheless, in a data-driven\nera, the scarcity of large-scale datasets poses a significant bottleneck to\nadvancing SAR automatic target recognition (ATR) technology. This paper\nintroduces NUDT4MSTAR, a large-scale SAR dataset for remote sensing target\nrecognition in the wild, including 40 vehicle target types and various imaging\nconditions across 5 realistic scenes. NUDT4MSTAR represents a significant leap\nforward in dataset scale, containing over 190,000 images-tenfold the size of\nits predecessors. We meticulously annotate each image with detailed target\ninformation and imaging conditions. Besides, data in both processed magnitude\nimages and original complex formats are provided. Then, we construct a\ncomprehensive benchmark consisting of 7 experiments with 15 recognition methods\nfocusing on the stable and effective ATR issues. Besides, we conduct transfer\nlearning experiments utilizing various models training on NUDT4MSTAR and apply\nthem to three other target datasets, demonstrating its substantial potential\nfor the broader field of ground objects ATR. Finally, we discuss this dataset's\napplication value and ATR's significant challenges. To the best of our\nknowledge, this work marks the first-ever endeavor to create a large-scale\ndataset benchmark for fine-grained SAR recognition in the wild, featuring an\nextensive collection of exhaustively annotated vehicle images. We expect that\nthe open source of NUDT4MSTAR will facilitate the development of SAR ATR and\nattract a wider community of researchers.\n","authors":["Yongxiang Liu","Weijie Li","Li Liu","Jie Zhou","Xuying Xiong","Bowen Peng","Yafei Song","Wei Yang","Tianpeng Liu","Zhen Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2501.13354v2.pdf","comment":"18 pages, 14 figures; NUDT4MSTAR:\n  https://github.com/waterdisappear/NUDT4MSTAR"},{"id":"http://arxiv.org/abs/2410.19785v2","updated":"2025-01-29T22:51:58Z","published":"2024-10-14T22:25:06Z","title":"How to Backdoor Consistency Models?","summary":"  Consistency models are a new class of models that generate images by directly\nmapping noise to data, allowing for one-step generation and significantly\naccelerating the sampling process. However, their robustness against\nadversarial attacks has not yet been thoroughly investigated. In this work, we\nconduct the first study on the vulnerability of consistency models to backdoor\nattacks. While previous research has explored backdoor attacks on diffusion\nmodels, those studies have primarily focused on conventional diffusion models,\nemploying a customized backdoor training process and objective, whereas\nconsistency models have distinct training processes and objectives. Our\nproposed framework demonstrates the vulnerability of consistency models to\nbackdoor attacks. During image generation, poisoned consistency models produce\nimages with a Fr\\'echet Inception Distance (FID) comparable to that of a clean\nmodel when sampling from Gaussian noise. However, once the trigger is\nactivated, they generate backdoor target images. We explore various trigger and\ntarget configurations to evaluate the vulnerability of consistency models,\nincluding the use of random noise as a trigger. This novel trigger is visually\ninconspicuous, more challenging to detect, and aligns well with the sampling\nprocess of consistency models. Across all configurations, our framework\nsuccessfully compromises the consistency models while maintaining high utility\nand specificity. We also examine the stealthiness of our proposed attack, which\nis attributed to the unique properties of consistency models and the elusive\nnature of the Gaussian noise trigger.\n","authors":["Chengen Wang","Murat Kantarcioglu"],"pdf_url":"https://arxiv.org/pdf/2410.19785v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18033v1","updated":"2025-01-29T22:42:05Z","published":"2025-01-29T22:42:05Z","title":"Generative AI for Vision: A Comprehensive Study of Frameworks and\n  Applications","summary":"  Generative AI is transforming image synthesis, enabling the creation of\nhigh-quality, diverse, and photorealistic visuals across industries like\ndesign, media, healthcare, and autonomous systems. Advances in techniques such\nas image-to-image translation, text-to-image generation, domain transfer, and\nmultimodal alignment have broadened the scope of automated visual content\ncreation, supporting a wide spectrum of applications. These advancements are\ndriven by models like Generative Adversarial Networks (GANs), conditional\nframeworks, and diffusion-based approaches such as Stable Diffusion. This work\npresents a structured classification of image generation techniques based on\nthe nature of the input, organizing methods by input modalities like noisy\nvectors, latent representations, and conditional inputs. We explore the\nprinciples behind these models, highlight key frameworks including DALL-E,\nControlNet, and DeepSeek Janus-Pro, and address challenges such as\ncomputational costs, data biases, and output alignment with user intent. By\noffering this input-centric perspective, this study bridges technical depth\nwith practical insights, providing researchers and practitioners with a\ncomprehensive resource to harness generative AI for real-world applications.\n","authors":["Fouad Bousetouane"],"pdf_url":"https://arxiv.org/pdf/2501.18033v1.pdf","comment":"53 pages, 18 figures"},{"id":"http://arxiv.org/abs/2501.18011v1","updated":"2025-01-29T21:54:31Z","published":"2025-01-29T21:54:31Z","title":"Anatomy Might Be All You Need: Forecasting What to Do During Surgery","summary":"  Surgical guidance can be delivered in various ways. In neurosurgery, spatial\nguidance and orientation are predominantly achieved through neuronavigation\nsystems that reference pre-operative MRI scans. Recently, there has been\ngrowing interest in providing live guidance by analyzing video feeds from tools\nsuch as endoscopes. Existing approaches, including anatomy detection,\norientation feedback, phase recognition, and visual question-answering,\nprimarily focus on aiding surgeons in assessing the current surgical scene.\nThis work aims to provide guidance on a finer scale, aiming to provide guidance\nby forecasting the trajectory of the surgical instrument, essentially\naddressing the question of what to do next. To address this task, we propose a\nmodel that not only leverages the historical locations of surgical instruments\nbut also integrates anatomical features. Importantly, our work does not rely on\nexplicit ground truth labels for instrument trajectories. Instead, the ground\ntruth is generated by a detection model trained to detect both anatomical\nstructures and instruments within surgical videos of a comprehensive dataset\ncontaining pituitary surgery videos. By analyzing the interaction between\nanatomy and instrument movements in these videos and forecasting future\ninstrument movements, we show that anatomical features are a valuable asset in\naddressing this challenging task. To the best of our knowledge, this work is\nthe first attempt to address this task for manually operated surgeries.\n","authors":["Gary Sarwin","Alessandro Carretta","Victor Staartjes","Matteo Zoli","Diego Mazzatenta","Luca Regli","Carlo Serra","Ender Konukoglu"],"pdf_url":"https://arxiv.org/pdf/2501.18011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17987v1","updated":"2025-01-29T20:49:59Z","published":"2025-01-29T20:49:59Z","title":"Pressure Field Reconstruction with SIREN: A Mesh-Free Approach for Image\n  Velocimetry in Complex Noisy Environments","summary":"  This work presents a novel approach for pressure field reconstruction from\nimage velocimetry data using SIREN (Sinusoidal Representation Network),\nemphasizing its effectiveness as an implicit neural representation in noisy\nenvironments and its mesh-free nature. While we briefly assess two recently\nproposed methods - one-shot matrix-omnidirectional integration (OS-MODI) and\nGreen's function integral (GFI) - the primary focus is on the advantages of the\nSIREN approach. The OS-MODI technique performs well in noise-free conditions\nand with structured meshes but struggles when applied to unstructured meshes\nwith high aspect ratio. Similarly, the GFI method encounters difficulties due\nto singularities inherent from the Newtonian kernel. In contrast, the proposed\nSIREN approach is a mesh-free method that directly reconstructs the pressure\nfield, bypassing the need for an intrinsic grid connectivity and, hence,\navoiding the challenges associated with ill-conditioned cells and unstructured\nmeshes. This provides a distinct advantage over traditional mesh-based methods.\nMoreover, it is shown that changes in the architecture of the SIREN can be used\nto filter out inherent noise from velocimetry data. This work positions SIREN\nas a robust and versatile solution for pressure reconstruction, particularly in\nnoisy environments characterized by the absence of mesh structure, opening new\navenues for innovative applications in this field.\n","authors":["Renato F. Miotto","William R. Wolf","Fernando Zigunov"],"pdf_url":"https://arxiv.org/pdf/2501.17987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17983v1","updated":"2025-01-29T20:39:16Z","published":"2025-01-29T20:39:16Z","title":"Efficient Feature Fusion for UAV Object Detection","summary":"  Object detection in unmanned aerial vehicle (UAV) remote sensing images poses\nsignificant challenges due to unstable image quality, small object sizes,\ncomplex backgrounds, and environmental occlusions. Small objects, in\nparticular, occupy minimal portions of images, making their accurate detection\nhighly difficult. Existing multi-scale feature fusion methods address these\nchallenges to some extent by aggregating features across different resolutions.\nHowever, these methods often fail to effectively balance classification and\nlocalization performance for small objects, primarily due to insufficient\nfeature representation and imbalanced network information flow. In this paper,\nwe propose a novel feature fusion framework specifically designed for UAV\nobject detection tasks to enhance both localization accuracy and classification\nperformance. The proposed framework integrates hybrid upsampling and\ndownsampling modules, enabling feature maps from different network depths to be\nflexibly adjusted to arbitrary resolutions. This design facilitates cross-layer\nconnections and multi-scale feature fusion, ensuring improved representation of\nsmall objects. Our approach leverages hybrid downsampling to enhance\nfine-grained feature representation, improving spatial localization of small\ntargets, even under complex conditions. Simultaneously, the upsampling module\naggregates global contextual information, optimizing feature consistency across\nscales and enhancing classification robustness in cluttered scenes.\nExperimental results on two public UAV datasets demonstrate the effectiveness\nof the proposed framework. Integrated into the YOLO-V10 model, our method\nachieves a 2\\% improvement in average precision (AP) compared to the baseline\nYOLO-V10 model, while maintaining the same number of parameters. These results\nhighlight the potential of our framework for accurate and efficient UAV object\ndetection.\n","authors":["Xudong Wang","Chaomin Shen","Yaxin Peng"],"pdf_url":"https://arxiv.org/pdf/2501.17983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17978v1","updated":"2025-01-29T20:23:48Z","published":"2025-01-29T20:23:48Z","title":"VoD-3DGS: View-opacity-Dependent 3D Gaussian Splatting","summary":"  Reconstructing a 3D scene from images is challenging due to the different\nways light interacts with surfaces depending on the viewer's position and the\nsurface's material. In classical computer graphics, materials can be classified\nas diffuse or specular, interacting with light differently. The standard 3D\nGaussian Splatting model struggles to represent view-dependent content, since\nit cannot differentiate an object within the scene from the light interacting\nwith its specular surfaces, which produce highlights or reflections. In this\npaper, we propose to extend the 3D Gaussian Splatting model by introducing an\nadditional symmetric matrix to enhance the opacity representation of each 3D\nGaussian. This improvement allows certain Gaussians to be suppressed based on\nthe viewer's perspective, resulting in a more accurate representation of\nview-dependent reflections and specular highlights without compromising the\nscene's integrity. By allowing the opacity to be view dependent, our enhanced\nmodel achieves state-of-the-art performance on Mip-Nerf, Tanks\\&Temples, Deep\nBlending, and Nerf-Synthetic datasets without a significant loss in rendering\nspeed, achieving >60FPS, and only incurring a minimal increase in memory used.\n","authors":["Nowak Mateusz","Jarosz Wojciech","Chin Peter"],"pdf_url":"https://arxiv.org/pdf/2501.17978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17977v1","updated":"2025-01-29T20:21:41Z","published":"2025-01-29T20:21:41Z","title":"TransRAD: Retentive Vision Transformer for Enhanced Radar Object\n  Detection","summary":"  Despite significant advancements in environment perception capabilities for\nautonomous driving and intelligent robotics, cameras and LiDARs remain\nnotoriously unreliable in low-light conditions and adverse weather, which\nlimits their effectiveness. Radar serves as a reliable and low-cost sensor that\ncan effectively complement these limitations. However, radar-based object\ndetection has been underexplored due to the inherent weaknesses of radar data,\nsuch as low resolution, high noise, and lack of visual information. In this\npaper, we present TransRAD, a novel 3D radar object detection model designed to\naddress these challenges by leveraging the Retentive Vision Transformer (RMT)\nto more effectively learn features from information-dense radar\nRange-Azimuth-Doppler (RAD) data. Our approach leverages the Retentive\nManhattan Self-Attention (MaSA) mechanism provided by RMT to incorporate\nexplicit spatial priors, thereby enabling more accurate alignment with the\nspatial saliency characteristics of radar targets in RAD data and achieving\nprecise 3D radar detection across Range-Azimuth-Doppler dimensions.\nFurthermore, we propose Location-Aware NMS to effectively mitigate the common\nissue of duplicate bounding boxes in deep radar object detection. The\nexperimental results demonstrate that TransRAD outperforms state-of-the-art\nmethods in both 2D and 3D radar detection tasks, achieving higher accuracy,\nfaster inference speed, and reduced computational complexity. Code is available\nat https://github.com/radar-lab/TransRAD\n","authors":["Lei Cheng","Siyang Cao"],"pdf_url":"https://arxiv.org/pdf/2501.17977v1.pdf","comment":"Accepted by IEEE Transactions on Radar Systems"},{"id":"http://arxiv.org/abs/2501.09905v4","updated":"2025-01-29T19:58:23Z","published":"2025-01-17T01:32:18Z","title":"SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon\n  Visuomotor Learning","summary":"  We present a low-cost legged mobile manipulation system that solves\nlong-horizon real-world tasks, trained by reinforcement learning purely in\nsimulation. This system is made possible by 1) a hierarchical design of a\nhigh-level policy for visual-mobile manipulation following task instructions,\nand a low-level quadruped locomotion policy, 2) a teacher and student training\npipeline for the high level, which trains a teacher to tackle long-horizon\ntasks using privileged task decomposition and target object information, and\nfurther trains a student for visual-mobile manipulation via RL guided by the\nteacher's behavior, and 3) a suite of techniques for minimizing the sim-to-real\ngap.\n  In contrast to many previous works that use high-end equipments, our system\ndemonstrates effective performance with more accessible hardware --\nspecifically, a Unitree Go1 quadruped, a WidowX-250S arm, and a single\nwrist-mounted RGB camera -- despite the increased challenges of sim-to-real\ntransfer. Trained fully in simulation, a single policy autonomously solves\nlong-horizon tasks involving search, move to, grasp, transport, and drop into,\nachieving nearly 80% real-world success. This performance is comparable to that\nof expert human teleoperation on the same tasks while the robot is more\nefficient, operating at about 1.5x the speed of the teleoperation. Finally, we\nperform extensive ablations on key techniques for efficient RL training and\neffective sim-to-real transfer, and demonstrate effective deployment across\ndiverse indoor and outdoor scenes under various lighting conditions.\n","authors":["Haichao Zhang","Haonan Yu","Le Zhao","Andrew Choi","Qinxun Bai","Break Yang","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2501.09905v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17823v1","updated":"2025-01-29T18:15:49Z","published":"2025-01-29T18:15:49Z","title":"U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal\n  Learning","summary":"  Multimodal learning often relies on designing new models and complex training\nstrategies to achieve optimal performance. We present Unified Unimodal\nAdaptation (U2A), which jointly fine-tunes pretrained unimodal encoders using\nlow-rank adaptation (LoRA) for various multimodal tasks. Our method\nsignificantly reduces the number of learnable parameters and eliminates the\nneed for complex training strategies, such as alternating training, gradient\nmodifications, or unimodal fine-tuning. To address missing modalities during\nboth training and testing, we introduce Mask Tokens (MT), which generate\nmissing modality features from available modalities using a single token per\nmodality. This simplifies the process, removing the need for specialized\nfeature estimation or prompt-tuning methods. Our evaluation demonstrates that\nU2A matches or outperforms state-of-the-art methods in both complete and\nmissing modality settings, showcasing strong performance and robustness across\nvarious modalities, tasks, and datasets. We also analyze and report the\neffectiveness of Mask Tokens in different missing modality scenarios. Overall,\nour method provides a robust, flexible, and efficient solution for multimodal\nlearning, with minimal computational overhead.\n","authors":["Md Kaykobad Reza","Niki Nezakati","Ameya Patil","Mashhour Solh","M. Salman Asif"],"pdf_url":"https://arxiv.org/pdf/2501.17823v1.pdf","comment":"14 Pages, 6 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2501.17822v1","updated":"2025-01-29T18:14:51Z","published":"2025-01-29T18:14:51Z","title":"Aggregation Schemes for Single-Vector WSI Representation Learning in\n  Digital Pathology","summary":"  A crucial step to efficiently integrate Whole Slide Images (WSIs) in\ncomputational pathology is assigning a single high-quality feature vector,\ni.e., one embedding, to each WSI. With the existence of many pre-trained deep\nneural networks and the emergence of foundation models, extracting embeddings\nfor sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,\ngiven their high resolution and gigapixel nature, inputting them into existing\nGPUs as a single image is not feasible. As a result, WSIs are usually split\ninto many patches. Feeding each patch to a pre-trained model, each WSI can then\nbe represented by a set of patches, hence, a set of embeddings. Hence, in such\na setup, WSI representation learning reduces to set representation learning\nwhere for each WSI we have access to a set of patch embeddings. To obtain a\nsingle embedding from a set of patch embeddings for each WSI, multiple\nset-based learning schemes have been proposed in the literature. In this paper,\nwe evaluate the WSI search performance of multiple recently developed\naggregation techniques (mainly set representation learning techniques)\nincluding simple average or max pooling operations, Deep Sets, Memory networks,\nFocal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse\nand binary Fisher Vector on four different primary sites including bladder,\nbreast, kidney, and Colon from TCGA. Further, we benchmark the search\nperformance of these methods against the median of minimum distances of patch\nembeddings, a non-aggregating approach used for WSI retrieval.\n","authors":["Sobhan Hemati","Ghazal Alabtah","Saghir Alfasly","H. R. Tizhoosh"],"pdf_url":"https://arxiv.org/pdf/2501.17822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17821v1","updated":"2025-01-29T18:14:16Z","published":"2025-01-29T18:14:16Z","title":"SSF: Sparse Long-Range Scene Flow for Autonomous Driving","summary":"  Scene flow enables an understanding of the motion characteristics of the\nenvironment in the 3D world. It gains particular significance in the\nlong-range, where object-based perception methods might fail due to sparse\nobservations far away. Although significant advancements have been made in\nscene flow pipelines to handle large-scale point clouds, a gap remains in\nscalability with respect to long-range. We attribute this limitation to the\ncommon design choice of using dense feature grids, which scale quadratically\nwith range. In this paper, we propose Sparse Scene Flow (SSF), a general\npipeline for long-range scene flow, adopting a sparse convolution based\nbackbone for feature extraction. This approach introduces a new challenge: a\nmismatch in size and ordering of sparse feature maps between time-sequential\npoint scans. To address this, we propose a sparse feature fusion scheme, that\naugments the feature maps with virtual voxels at missing locations.\nAdditionally, we propose a range-wise metric that implicitly gives greater\nimportance to faraway points. Our method, SSF, achieves state-of-the-art\nresults on the Argoverse2 dataset, demonstrating strong performance in\nlong-range scene flow estimation. Our code will be released at\nhttps://github.com/KTH-RPL/SSF.git.\n","authors":["Ajinkya Khoche","Qingwen Zhang","Laura Pereira Sanchez","Aron Asefaw","Sina Sharif Mansouri","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2501.17821v1.pdf","comment":"7 pages, 3 figures, accepted to International Conference on Robotics\n  and Automation (ICRA) 2025"},{"id":"http://arxiv.org/abs/2501.17813v1","updated":"2025-01-29T18:06:08Z","published":"2025-01-29T18:06:08Z","title":"P-TAME: Explain Any Image Classifier with Trained Perturbations","summary":"  The adoption of Deep Neural Networks (DNNs) in critical fields where\npredictions need to be accompanied by justifications is hindered by their\ninherent black-box nature. In this paper, we introduce P-TAME\n(Perturbation-based Trainable Attention Mechanism for Explanations), a\nmodel-agnostic method for explaining DNN-based image classifiers. P-TAME\nemploys an auxiliary image classifier to extract features from the input image,\nbypassing the need to tailor the explanation method to the internal\narchitecture of the backbone classifier being explained. Unlike traditional\nperturbation-based methods, which have high computational requirements, P-TAME\noffers an efficient alternative by generating high-resolution explanations in a\nsingle forward pass during inference. We apply P-TAME to explain the decisions\nof VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image\nclassifiers. Quantitative and qualitative results show that our method matches\nor outperforms previous explainability methods, including model-specific\napproaches. Code and trained models will be released upon acceptance.\n","authors":["Mariano V. Ntrougkas","Vasileios Mezaris","Ioannis Patras"],"pdf_url":"https://arxiv.org/pdf/2501.17813v1.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2501.17811v1","updated":"2025-01-29T18:00:19Z","published":"2025-01-29T18:00:19Z","title":"Janus-Pro: Unified Multimodal Understanding and Generation with Data and\n  Model Scaling","summary":"  In this work, we introduce Janus-Pro, an advanced version of the previous\nwork Janus. Specifically, Janus-Pro incorporates (1) an optimized training\nstrategy, (2) expanded training data, and (3) scaling to larger model size.\nWith these improvements, Janus-Pro achieves significant advancements in both\nmultimodal understanding and text-to-image instruction-following capabilities,\nwhile also enhancing the stability of text-to-image generation. We hope this\nwork will inspire further exploration in the field. Code and models are\npublicly available.\n","authors":["Xiaokang Chen","Zhiyu Wu","Xingchao Liu","Zizheng Pan","Wen Liu","Zhenda Xie","Xingkai Yu","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2501.17811v1.pdf","comment":"Research paper. arXiv admin note: text overlap with arXiv:2410.13848"},{"id":"http://arxiv.org/abs/2501.17792v1","updated":"2025-01-29T17:31:46Z","published":"2025-01-29T17:31:46Z","title":"CrowdSplat: Exploring Gaussian Splatting For Crowd Rendering","summary":"  We present CrowdSplat, a novel approach that leverages 3D Gaussian Splatting\nfor real-time, high-quality crowd rendering. Our method utilizes 3D Gaussian\nfunctions to represent animated human characters in diverse poses and outfits,\nwhich are extracted from monocular videos. We integrate Level of Detail (LoD)\nrendering to optimize computational efficiency and quality. The CrowdSplat\nframework consists of two stages: (1) avatar reconstruction and (2) crowd\nsynthesis. The framework is also optimized for GPU memory usage to enhance\nscalability. Quantitative and qualitative evaluations show that CrowdSplat\nachieves good levels of rendering quality, memory efficiency, and computational\nperformance. Through these experiments, we demonstrate that CrowdSplat is a\nviable solution for dynamic, realistic crowd simulation in real-time\napplications.\n","authors":["Xiaohan Sun","Yinghan Xu","John Dingliana","Carol O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2501.17792v1.pdf","comment":"4 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.06828v2","updated":"2025-01-29T17:18:18Z","published":"2024-08-13T11:39:14Z","title":"PIR: Photometric Inverse Rendering with Shading Cues Modeling and\n  Surface Reflectance Regularization","summary":"  This paper addresses the problem of inverse rendering from photometric\nimages. Existing approaches for this problem suffer from the effects of\nself-shadows, inter-reflections, and lack of constraints on the surface\nreflectance, leading to inaccurate decomposition of reflectance and\nillumination due to the ill-posed nature of inverse rendering. In this work, we\npropose a new method for neural inverse rendering. Our method jointly optimizes\nthe light source position to account for the self-shadows in images, and\ncomputes indirect illumination using a differentiable rendering layer and an\nimportance sampling strategy. To enhance surface reflectance decomposition, we\nintroduce a new regularization by distilling DINO features to foster accurate\nand consistent material decomposition. Extensive experiments on synthetic and\nreal datasets demonstrate that our method outperforms the state-of-the-art\nmethods in reflectance decomposition.\n","authors":["Jingzhi Bao","Guanying Chen","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2408.06828v2.pdf","comment":"Accepted to 3DV 2025. Project page:\n  https://jzbao03.site/projects/PIR/"},{"id":"http://arxiv.org/abs/2501.17758v1","updated":"2025-01-29T16:50:04Z","published":"2025-01-29T16:50:04Z","title":"Glioma Multimodal MRI Analysis System for Tumor Layered Diagnosis via\n  Multi-task Semi-supervised Learning","summary":"  Gliomas are the most common primary tumors of the central nervous system.\nMultimodal MRI is widely used for the preliminary screening of gliomas and\nplays a crucial role in auxiliary diagnosis, therapeutic efficacy, and\nprognostic evaluation. Currently, the computer-aided diagnostic studies of\ngliomas using MRI have focused on independent analysis events such as tumor\nsegmentation, grading, and radiogenomic classification, without studying\ninter-dependencies among these events. In this study, we propose a Glioma\nMultimodal MRI Analysis System (GMMAS) that utilizes a deep learning network\nfor processing multiple events simultaneously, leveraging their\ninter-dependencies through an uncertainty-based multi-task learning\narchitecture and synchronously outputting tumor region segmentation, glioma\nhistological subtype, IDH mutation genotype, and 1p/19q chromosome disorder\nstatus. Compared with the reported single-task analysis models, GMMAS improves\nthe precision across tumor layered diagnostic tasks. Additionally, we have\nemployed a two-stage semi-supervised learning method, enhancing model\nperformance by fully exploiting both labeled and unlabeled MRI samples.\nFurther, by utilizing an adaptation module based on knowledge self-distillation\nand contrastive learning for cross-modal feature extraction, GMMAS exhibited\nrobustness in situations of modality absence and revealed the differing\nsignificance of each MRI modal. Finally, based on the analysis outputs of the\nGMMAS, we created a visual and user-friendly platform for doctors and patients,\nintroducing GMMAS-GPT to generate personalized prognosis evaluations and\nsuggestions.\n","authors":["Yihao Liu","Zhihao Cui","Liming Li","Junjie You","Xinle Feng","Jianxin Wang","Xiangyu Wang","Qing Liu","Minghua Wu"],"pdf_url":"https://arxiv.org/pdf/2501.17758v1.pdf","comment":"23 pages, 13 figures"},{"id":"http://arxiv.org/abs/2501.14704v2","updated":"2025-01-29T16:46:59Z","published":"2025-01-24T18:29:34Z","title":"Stroke classification using Virtual Hybrid Edge Detection from in silico\n  electrical impedance tomography data","summary":"  Electrical impedance tomography (EIT) is a non-invasive imaging method for\nrecovering the internal conductivity of a physical body from electric boundary\nmeasurements. EIT combined with machine learning has shown promise for the\nclassification of strokes. However, most previous works have used raw EIT\nvoltage data as network inputs. We build upon a recent development which\nsuggested the use of special noise-robust Virtual Hybrid Edge Detection (VHED)\nfunctions as network inputs, although that work used only highly simplified and\nmathematically ideal models. In this work we strengthen the case for the use of\nEIT, and VHED functions especially, for stroke classification. We design models\nwith high detail and mathematical realism to test the use of VHED functions as\ninputs. Virtual patients are created using a physically detailed 2D head model\nwhich includes features known to create challenges in real-world imaging\nscenarios. Conductivity values are drawn from statistically realistic\ndistributions, and phantoms are afflicted with either hemorrhagic or ischemic\nstrokes of various shapes and sizes. Simulated noisy EIT electrode data,\ngenerated using the realistic Complete Electrode Model (CEM) as opposed to the\nmathematically ideal continuum model, is processed to obtain VHED functions. We\ncompare the use of VHED functions as inputs against the alternative paradigm of\nusing raw EIT voltages. Our results show that (i) stroke classification can be\nperformed with high accuracy using 2D EIT data from physically detailed and\nmathematically realistic models, and (ii) in the presence of noise, VHED\nfunctions outperform raw data as network inputs.\n","authors":["Juan Pablo Agnelli","Fernando S. Moura","Siiri Rautio","Melody Alsaker","Rashmi Murthy","Matti Lassas","Samuli Siltanen"],"pdf_url":"https://arxiv.org/pdf/2501.14704v2.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.16679v2","updated":"2025-01-29T16:04:56Z","published":"2025-01-28T03:25:37Z","title":"Polyp-Gen: Realistic and Diverse Polyp Image Generation for Endoscopic\n  Dataset Expansion","summary":"  Automated diagnostic systems (ADS) have shown significant potential in the\nearly detection of polyps during endoscopic examinations, thereby reducing the\nincidence of colorectal cancer. However, due to high annotation costs and\nstrict privacy concerns, acquiring high-quality endoscopic images poses a\nconsiderable challenge in the development of ADS. Despite recent advancements\nin generating synthetic images for dataset expansion, existing endoscopic image\ngeneration algorithms failed to accurately generate the details of polyp\nboundary regions and typically required medical priors to specify plausible\nlocations and shapes of polyps, which limited the realism and diversity of the\ngenerated images. To address these limitations, we present Polyp-Gen, the first\nfull-automatic diffusion-based endoscopic image generation framework.\nSpecifically, we devise a spatial-aware diffusion training scheme with a\nlesion-guided loss to enhance the structural context of polyp boundary regions.\nMoreover, to capture medical priors for the localization of potential polyp\nareas, we introduce a hierarchical retrieval-based sampling strategy to match\nsimilar fine-grained spatial features. In this way, our Polyp-Gen can generate\nrealistic and diverse endoscopic images for building reliable ADS. Extensive\nexperiments demonstrate the state-of-the-art generation quality, and the\nsynthetic images can improve the downstream polyp detection task. Additionally,\nour Polyp-Gen has shown remarkable zero-shot generalizability on other\ndatasets. The source code is available at\nhttps://github.com/CUHK-AIM-Group/Polyp-Gen.\n","authors":["Shengyuan Liu","Zhen Chen","Qiushi Yang","Weihao Yu","Di Dong","Jiancong Hu","Yixuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2501.16679v2.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2501.17726v1","updated":"2025-01-29T16:02:16Z","published":"2025-01-29T16:02:16Z","title":"VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies\n  in Generated Report Without Human Feedback","summary":"  As artificial intelligence (AI) becomes increasingly central to healthcare,\nthe demand for explainable and trustworthy models is paramount. Current report\ngeneration systems for chest X-rays (CXR) often lack mechanisms for validating\noutputs without expert oversight, raising concerns about reliability and\ninterpretability. To address these challenges, we propose a novel multimodal\nframework designed to enhance the semantic alignment and localization accuracy\nof AI-generated medical reports. Our framework integrates two key modules: a\nPhrase Grounding Model, which identifies and localizes pathologies in CXR\nimages based on textual prompts, and a Text-to-Image Diffusion Module, which\ngenerates synthetic CXR images from prompts while preserving anatomical\nfidelity. By comparing features between the original and generated images, we\nintroduce a dual-scoring system: one score quantifies localization accuracy,\nwhile the other evaluates semantic consistency. This approach significantly\noutperforms existing methods, achieving state-of-the-art results in pathology\nlocalization and text-to-image alignment. The integration of phrase grounding\nwith diffusion models, coupled with the dual-scoring evaluation system,\nprovides a robust mechanism for validating report quality, paving the way for\nmore trustworthy and transparent AI in medical imaging.\n","authors":["Sayeh Gholipour Picha","Dawood Al Chanti","Alice Caplier"],"pdf_url":"https://arxiv.org/pdf/2501.17726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12588v2","updated":"2025-01-29T16:02:14Z","published":"2024-08-22T17:54:21Z","title":"Real-Time Video Generation with Pyramid Attention Broadcast","summary":"  We present Pyramid Attention Broadcast (PAB), a real-time, high quality and\ntraining-free approach for DiT-based video generation. Our method is founded on\nthe observation that attention difference in the diffusion process exhibits a\nU-shaped pattern, indicating significant redundancy. We mitigate this by\nbroadcasting attention outputs to subsequent steps in a pyramid style. It\napplies different broadcast strategies to each attention based on their\nvariance for best efficiency. We further introduce broadcast sequence parallel\nfor more efficient distributed inference. PAB demonstrates up to 10.5x speedup\nacross three models compared to baselines, achieving real-time generation for\nup to 720p videos. We anticipate that our simple yet effective method will\nserve as a robust baseline and facilitate future research and application for\nvideo generation.\n","authors":["Xuanlei Zhao","Xiaolong Jin","Kai Wang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2408.12588v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2406.17109v3","updated":"2025-01-29T15:59:04Z","published":"2024-06-24T19:52:27Z","title":"GMT: Guided Mask Transformer for Leaf Instance Segmentation","summary":"  Leaf instance segmentation is a challenging multi-instance segmentation task,\naiming to separate and delineate each leaf in an image of a plant. Accurate\nsegmentation of each leaf is crucial for plant-related applications such as the\nfine-grained monitoring of plant growth and crop yield estimation. This task is\nchallenging because of the high similarity (in shape and colour), great size\nvariation, and heavy occlusions among leaf instances. Furthermore, the\ntypically small size of annotated leaf datasets makes it more difficult to\nlearn the distinctive features needed for precise segmentation. We hypothesise\nthat the key to overcoming the these challenges lies in the specific spatial\npatterns of leaf distribution. In this paper, we propose the Guided Mask\nTransformer (GMT), which leverages and integrates leaf spatial distribution\npriors into a Transformer-based segmentor. These spatial priors are embedded in\na set of guide functions that map leaves at different positions into a more\nseparable embedding space. Our GMT consistently outperforms the\nstate-of-the-art on three public plant datasets. Our code is available at\nhttps://github.com/vios-s/gmt-leaf-ins-seg.\n","authors":["Feng Chen","Sotirios A. Tsaftaris","Mario Valerio Giuffrida"],"pdf_url":"https://arxiv.org/pdf/2406.17109v3.pdf","comment":"Accepted at IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2501.17718v1","updated":"2025-01-29T15:40:42Z","published":"2025-01-29T15:40:42Z","title":"Learning Semantic Facial Descriptors for Accurate Face Animation","summary":"  Face animation is a challenging task. Existing model-based methods (utilizing\n3DMMs or landmarks) often result in a model-like reconstruction effect, which\ndoesn't effectively preserve identity. Conversely, model-free approaches face\nchallenges in attaining a decoupled and semantically rich feature space,\nthereby making accurate motion transfer difficult to achieve. We introduce the\nsemantic facial descriptors in learnable disentangled vector space to address\nthe dilemma. The approach involves decoupling the facial space into identity\nand motion subspaces while endowing each of them with semantics by learning\ncomplete orthogonal basis vectors. We obtain basis vector coefficients by\nemploying an encoder on the source and driving faces, leading to effective\nfacial descriptors in the identity and motion subspaces. Ultimately, these\ndescriptors can be recombined as latent codes to animate faces. Our approach\nsuccessfully addresses the issue of model-based methods' limitations in\nhigh-fidelity identity and the challenges faced by model-free methods in\naccurate motion transfer. Extensive experiments are conducted on three\nchallenging benchmarks (i.e. VoxCeleb, HDTF, CelebV). Comprehensive\nquantitative and qualitative results demonstrate that our model outperforms\nSOTA methods with superior identity preservation and motion transfer.\n","authors":["Lei Zhu","Yuanqi Chen","Xiaohang Liu","Thomas H. Li","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2501.17718v1.pdf","comment":"6 pages,6 figures"},{"id":"http://arxiv.org/abs/2501.18412v1","updated":"2025-01-29T15:16:46Z","published":"2025-01-29T15:16:46Z","title":"Real Time Scheduling Framework for Multi Object Detection via Spiking\n  Neural Networks","summary":"  Given the energy constraints in autonomous mobile agents (AMAs), such as\nunmanned vehicles, spiking neural networks (SNNs) are increasingly favored as a\nmore efficient alternative to traditional artificial neural networks. AMAs\nemploy multi-object detection (MOD) from multiple cameras to identify nearby\nobjects while ensuring two essential objectives, (R1) timing guarantee and (R2)\nhigh accuracy for safety. In this paper, we propose RT-SNN, the first system\ndesign, aiming at achieving R1 and R2 in SNN-based MOD systems on AMAs.\nLeveraging the characteristic that SNNs gather feature data of input image\ntermed as membrane potential, through iterative computation over multiple\ntimesteps, RT-SNN provides multiple execution options with adjustable timesteps\nand a novel method for reusing membrane potential to support R1. Then, it\ncaptures how these execution strategies influence R2 by introducing a novel\nnotion of mean absolute error and membrane confidence. Further, RT-SNN develops\na new scheduling framework consisting of offline schedulability analysis for R1\nand a run-time scheduling algorithm for R2 using the notion of membrane\nconfidence. We deployed RT-SNN to Spiking-YOLO, the SNN-based MOD model derived\nfrom ANN-to-SNN conversion, and our experimental evaluation confirms its\neffectiveness in meeting the R1 and R2 requirements while providing significant\nenergy efficiency.\n","authors":["Donghwa Kang","Woojin Shin","Cheol-Ho Hong","Minsuk Koo","Brent ByungHoon Kang","Jinkyu Lee","Hyeongboo Baek"],"pdf_url":"https://arxiv.org/pdf/2501.18412v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2501.17699v1","updated":"2025-01-29T15:10:09Z","published":"2025-01-29T15:10:09Z","title":"PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal\n  Fusion","summary":"  Traditional remote spirometry lacks the precision required for effective\npulmonary monitoring. We present a novel, non-invasive approach using\nmultimodal predictive models that integrate RGB or thermal video data with\npatient metadata. Our method leverages energy-efficient Spiking Neural Networks\n(SNNs) for the regression of Peak Expiratory Flow (PEF) and classification of\nForced Expiratory Volume (FEV1) and Forced Vital Capacity (FVC), using\nlightweight CNNs to overcome SNN limitations in regression tasks. Multimodal\ndata integration is improved with a Multi-Head Attention Layer, and we employ\nK-Fold validation and ensemble learning to boost robustness. Using thermal\ndata, our SNN models achieve 92% accuracy on a breathing-cycle basis and 99.5%\npatient-wise. PEF regression models attain Relative RMSEs of 0.11 (thermal) and\n0.26 (RGB), with an MAE of 4.52% for FEV1/FVC predictions, establishing\nstate-of-the-art performance. Code and dataset can be found on\nhttps://github.com/ahmed-sharshar/RespiroDynamics.git\n","authors":["Ahmed Sharshar","Yasser Attia","Mohammad Yaqub","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2501.17699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17690v1","updated":"2025-01-29T14:58:48Z","published":"2025-01-29T14:58:48Z","title":"Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue\n  Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP)\n  Assessment","summary":"  We introduce a novel segmentation-aware joint training framework called\ngenerative reinforcement network (GRN) that integrates segmentation loss\nfeedback to optimize both image generation and segmentation performance in a\nsingle stage. An image enhancement technique called segmentation-guided\nenhancement (SGE) is also developed, where the generator produces images\ntailored specifically for the segmentation model. Two variants of GRN were also\ndeveloped, including GRN for sample-efficient learning (GRN-SEL) and GRN for\nsemi-supervised learning (GRN-SSL). GRN's performance was evaluated using a\ndataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The\nannotations included six anatomical structures: dermis, superficial fat,\nsuperficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and\nmuscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up\nto 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient\n(DSC) compared to models trained on fully labeled datasets. GRN-SEL alone\nreduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling\nrequirements by 70%, and GRN-SSL alone by 60%, all while maintaining\nperformance comparable to fully supervised models. These findings suggest the\neffectiveness of the GRN framework in optimizing segmentation performance with\nsignificantly less labeled data, offering a scalable and efficient solution for\nultrasound image analysis and reducing the burdens associated with data\nannotation.\n","authors":["Zixue Zeng","Xiaoyan Zhao","Matthew Cartier","Tong Yu","Jing Wang","Xin Meng","Zhiyu Sheng","Maryam Satarpour","John M Cormack","Allison Bean","Ryan Nussbaum","Maya Maurer","Emily Landis-Walkenhorst","Dinesh Kumbhare","Kang Kim","Ajay Wasan","Jiantao Pu"],"pdf_url":"https://arxiv.org/pdf/2501.17690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17906v1","updated":"2025-01-29T14:32:22Z","published":"2025-01-29T14:32:22Z","title":"Unsupervised Patch-GAN with Targeted Patch Ranking for Fine-Grained\n  Novelty Detection in Medical Imaging","summary":"  Detecting novel anomalies in medical imaging is challenging due to the\nlimited availability of labeled data for rare abnormalities, which often\ndisplay high variability and subtlety. This challenge is further compounded\nwhen small abnormal regions are embedded within larger normal areas, as\nwhole-image predictions frequently overlook these subtle deviations. To address\nthese issues, we propose an unsupervised Patch-GAN framework designed to detect\nand localize anomalies by capturing both local detail and global structure. Our\nframework first reconstructs masked images to learn fine-grained,\nnormal-specific features, allowing for enhanced sensitivity to minor deviations\nfrom normality. By dividing these reconstructed images into patches and\nassessing the authenticity of each patch, our approach identifies anomalies at\na more granular level, overcoming the limitations of whole-image evaluation.\nAdditionally, a patch-ranking mechanism prioritizes regions with higher\nabnormal scores, reinforcing the alignment between local patch discrepancies\nand the global image context. Experimental results on the ISIC 2016 skin lesion\nand BraTS 2019 brain tumor datasets validate our framework's effectiveness,\nachieving AUCs of 95.79% and 96.05%, respectively, and outperforming three\nstate-of-the-art baselines.\n","authors":["Jingkun Chen","Guang Yang","Xiao Zhang","Jingchao Peng","Tianlu Zhang","Jianguo Zhang","Jungong Han","Vicente Grau"],"pdf_url":"https://arxiv.org/pdf/2501.17906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09997v6","updated":"2025-01-29T14:10:19Z","published":"2023-07-19T14:10:55Z","title":"TUNeS: A Temporal U-Net with Self-Attention for Video-based Surgical\n  Phase Recognition","summary":"  Objective: To enable context-aware computer assistance in the operating room\nof the future, cognitive systems need to understand automatically which\nsurgical phase is being performed by the medical team. The primary source of\ninformation for surgical phase recognition is typically video, which presents\ntwo challenges: extracting meaningful features from the video stream and\neffectively modeling temporal information in the sequence of visual features.\nMethods: For temporal modeling, attention mechanisms have gained popularity due\nto their ability to capture long-range dependencies. In this paper, we explore\ndesign choices for attention in existing temporal models for surgical phase\nrecognition and propose a novel approach that uses attention more effectively\nand does not require hand-crafted constraints: TUNeS, an efficient and simple\ntemporal model that incorporates self-attention at the core of a convolutional\nU-Net structure. In addition, we propose to train the feature extractor, a\nstandard CNN, together with an LSTM on preferably long video segments, i.e.,\nwith long temporal context. Results: In our experiments, almost all temporal\nmodels performed better on top of feature extractors that were trained with\nlonger temporal context. On these contextualized features, TUNeS achieves\nstate-of-the-art results on the Cholec80 dataset. Conclusion: This study offers\nnew insights on how to use attention mechanisms to build accurate and efficient\ntemporal models for surgical phase recognition. Significance: Implementing\nautomatic surgical phase recognition is essential to automate the analysis and\noptimization of surgical workflows and to enable context-aware computer\nassistance during surgery, thus ultimately improving patient care.\n","authors":["Isabel Funke","Dominik Rivoir","Stefanie Krell","Stefanie Speidel"],"pdf_url":"https://arxiv.org/pdf/2307.09997v6.pdf","comment":"Accepted for publication in IEEE Transactions on Biomedical\n  Engineering"},{"id":"http://arxiv.org/abs/2501.17655v1","updated":"2025-01-29T13:40:25Z","published":"2025-01-29T13:40:25Z","title":"FeatureGS: Eigenvalue-Feature Optimization in 3D Gaussian Splatting for\n  Geometrically Accurate and Artifact-Reduced Reconstruction","summary":"  3D Gaussian Splatting (3DGS) has emerged as a powerful approach for 3D scene\nreconstruction using 3D Gaussians. However, neither the centers nor surfaces of\nthe Gaussians are accurately aligned to the object surface, complicating their\ndirect use in point cloud and mesh reconstruction. Additionally, 3DGS typically\nproduces floater artifacts, increasing the number of Gaussians and storage\nrequirements. To address these issues, we present FeatureGS, which incorporates\nan additional geometric loss term based on an eigenvalue-derived 3D shape\nfeature into the optimization process of 3DGS. The goal is to improve geometric\naccuracy and enhance properties of planar surfaces with reduced structural\nentropy in local 3D neighborhoods.We present four alternative formulations for\nthe geometric loss term based on 'planarity' of Gaussians, as well as\n'planarity', 'omnivariance', and 'eigenentropy' of Gaussian neighborhoods. We\nprovide quantitative and qualitative evaluations on 15 scenes of the DTU\nbenchmark dataset focusing on following key aspects: Geometric accuracy and\nartifact-reduction, measured by the Chamfer distance, and memory efficiency,\nevaluated by the total number of Gaussians. Additionally, rendering quality is\nmonitored by Peak Signal-to-Noise Ratio. FeatureGS achieves a 30 % improvement\nin geometric accuracy, reduces the number of Gaussians by 90 %, and suppresses\nfloater artifacts, while maintaining comparable photometric rendering quality.\nThe geometric loss with 'planarity' from Gaussians provides the highest\ngeometric accuracy, while 'omnivariance' in Gaussian neighborhoods reduces\nfloater artifacts and number of Gaussians the most. This makes FeatureGS a\nstrong method for geometrically accurate, artifact-reduced and memory-efficient\n3D scene reconstruction, enabling the direct use of Gaussian centers for\ngeometric representation.\n","authors":["Miriam Jäger","Markus Hillemann","Boris Jutzi"],"pdf_url":"https://arxiv.org/pdf/2501.17655v1.pdf","comment":"16 pages, 9 figures, 7 tables"},{"id":"http://arxiv.org/abs/2408.02301v2","updated":"2025-01-29T13:27:37Z","published":"2024-08-05T08:23:59Z","title":"Network Fission Ensembles for Low-Cost Self-Ensembles","summary":"  Recent ensemble learning methods for image classification have been shown to\nimprove classification accuracy with low extra cost. However, they still\nrequire multiple trained models for ensemble inference, which eventually\nbecomes a significant burden when the model size increases. In this paper, we\npropose a low-cost ensemble learning and inference, called Network Fission\nEnsembles (NFE), by converting a conventional network itself into a multi-exit\nstructure. Starting from a given initial network, we first prune some of the\nweights to reduce the training burden. We then group the remaining weights into\nseveral sets and create multiple auxiliary paths using each set to construct\nmulti-exits. We call this process Network Fission. Through this, multiple\noutputs can be obtained from a single network, which enables ensemble learning.\nSince this process simply changes the existing network structure to multi-exits\nwithout using additional networks, there is no extra computational burden for\nensemble learning and inference. Moreover, by learning from multiple losses of\nall exits, the multi-exits improve performance via regularization, and high\nperformance can be achieved even with increased network sparsity. With our\nsimple yet effective method, we achieve significant improvement compared to\nexisting ensemble methods. The code is available at\nhttps://github.com/hjdw2/NFE.\n","authors":["Hojung Lee","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2408.02301v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17642v1","updated":"2025-01-29T13:24:53Z","published":"2025-01-29T13:24:53Z","title":"Efficient Redundancy Reduction for Open-Vocabulary Semantic Segmentation","summary":"  Open-vocabulary semantic segmentation (OVSS) is an open-world task that aims\nto assign each pixel within an image to a specific class defined by arbitrary\ntext descriptions. Recent advancements in large-scale vision-language models\nhave demonstrated their open-vocabulary understanding capabilities,\nsignificantly facilitating the development of OVSS. However, most existing\nmethods suffer from either suboptimal performance or long latency. This study\nintroduces ERR-Seg, a novel framework that effectively reduces redundancy to\nbalance accuracy and efficiency. ERR-Seg incorporates a training-free Channel\nReduction Module (CRM) that leverages prior knowledge from vision-language\nmodels like CLIP to identify the most relevant classes while discarding others.\nMoreover, it incorporates Efficient Semantic Context Fusion (ESCF) with\nspatial-level and class-level sequence reduction strategies. CRM and ESCF\nresult in substantial memory and computational savings without compromising\naccuracy. Additionally, recognizing the significance of hierarchical semantics\nextracted from middle-layer features for closed-set semantic segmentation,\nERR-Seg introduces the Hierarchical Semantic Module (HSM) to exploit\nhierarchical semantics in the context of OVSS. Compared to previous\nstate-of-the-art methods under the ADE20K-847 setting, ERR-Seg achieves\n+$5.6\\%$ mIoU improvement and reduces latency by $67.3\\%$.\n","authors":["Lin Chen","Qi Yang","Kun Ding","Zhihao Li","Gang Shen","Fei Li","Qiyuan Cao","Shiming Xiang"],"pdf_url":"https://arxiv.org/pdf/2501.17642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04116v2","updated":"2025-01-29T13:16:04Z","published":"2024-09-06T08:33:26Z","title":"Segmentation and Smoothing Affect Explanation Quality More Than the\n  Choice of Perturbation-based XAI Method for Image Explanations","summary":"  Perturbation-based post-hoc image explanation methods are commonly used to\nexplain image prediction models. These methods perturb parts of the input to\nmeasure how those parts affect the output. Since the methods only require the\ninput and output they can be applied to any model, making them a popular choice\nto explain black-box models. While many different models exist and have been\ncompared with one another, it remains poorly understood which parameters of the\ndifferent methods are responsible for their varying performance.\n  This work uses the Randomized Input Sampling for Explanations (RISE) method\nas a baseline to evaluate many combinations of mask sampling, segmentation\ntechniques, smoothing, attribution calculation, and per-segment or per-pixel\nattribution, using a proxy metric. The results show that attribution\ncalculation, which is frequently the focus of other works, has little impact on\nthe results. Conversely, segmentation and per-pixel attribution, rarely\nexamined parameters, have a significant impact.\n  The implementation of and data gathered in this work are available online:\nhttps://github.com/guspih/post-hoc-image-perturbation and\nhttps://bit.ly/smooth-mask-perturbation\n","authors":["Gustav Grund Pihlgren","Kary Främling"],"pdf_url":"https://arxiv.org/pdf/2409.04116v2.pdf","comment":"This manuscript have been submitted to IJCNN 2025"},{"id":"http://arxiv.org/abs/2501.17634v1","updated":"2025-01-29T13:11:21Z","published":"2025-01-29T13:11:21Z","title":"Federated Learning With Individualized Privacy Through Client Sampling","summary":"  With growing concerns about user data collection, individualized privacy has\nemerged as a promising solution to balance protection and utility by accounting\nfor diverse user privacy preferences. Instead of enforcing a uniform level of\nanonymization for all users, this approach allows individuals to choose privacy\nsettings that align with their comfort levels. Building on this idea, we\npropose an adapted method for enabling Individualized Differential Privacy\n(IDP) in Federated Learning (FL) by handling clients according to their\npersonal privacy preferences. By extending the SAMPLE algorithm from\ncentralized settings to FL, we calculate client-specific sampling rates based\non their heterogeneous privacy budgets and integrate them into a modified\nIDP-FedAvg algorithm. We test this method under realistic privacy distributions\nand multiple datasets. The experimental results demonstrate that our approach\nachieves clear improvements over uniform DP baselines, reducing the trade-off\nbetween privacy and utility. Compared to the alternative SCALE method in\nrelated work, which assigns differing noise scales to clients, our method\nperforms notably better. However, challenges remain for complex tasks with\nnon-i.i.d. data, primarily stemming from the constraints of the decentralized\nsetting.\n","authors":["Lucas Lange","Ole Borchardt","Erhard Rahm"],"pdf_url":"https://arxiv.org/pdf/2501.17634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17628v1","updated":"2025-01-29T13:07:56Z","published":"2025-01-29T13:07:56Z","title":"Dual Invariance Self-training for Reliable Semi-supervised Surgical\n  Phase Recognition","summary":"  Accurate surgical phase recognition is crucial for advancing\ncomputer-assisted interventions, yet the scarcity of labeled data hinders\ntraining reliable deep learning models. Semi-supervised learning (SSL),\nparticularly with pseudo-labeling, shows promise over fully supervised methods\nbut often lacks reliable pseudo-label assessment mechanisms. To address this\ngap, we propose a novel SSL framework, Dual Invariance Self-Training (DIST),\nthat incorporates both Temporal and Transformation Invariance to enhance\nsurgical phase recognition. Our two-step self-training process dynamically\nselects reliable pseudo-labels, ensuring robust pseudo-supervision. Our\napproach mitigates the risk of noisy pseudo-labels, steering decision\nboundaries toward true data distribution and improving generalization to unseen\ndata. Evaluations on Cataract and Cholec80 datasets show our method outperforms\nstate-of-the-art SSL approaches, consistently surpassing both supervised and\nSSL baselines across various network architectures.\n","authors":["Sahar Nasirihaghighi","Negin Ghamsarian","Raphael Sznitman","Klaus Schoeffmann"],"pdf_url":"https://arxiv.org/pdf/2501.17628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.13792v2","updated":"2025-01-29T12:45:29Z","published":"2023-08-26T07:35:16Z","title":"Out-of-distribution detection using normalizing flows on the data\n  manifold","summary":"  Using the intuition that out-of-distribution data have lower likelihoods, a\ncommon approach for out-of-distribution detection involves estimating the\nunderlying data distribution. Normalizing flows are likelihood-based generative\nmodels providing a tractable density estimation via dimension-preserving\ninvertible transformations. Conventional normalizing flows are prone to fail in\nout-of-distribution detection, because of the well-known curse of\ndimensionality problem of the likelihood-based models. To solve the problem of\nlikelihood-based models, some works try to modify likelihood for example by\nincorporating a data complexity measure. We observed that these modifications\nare still insufficient. According to the manifold hypothesis, real-world data\noften lie on a low-dimensional manifold. Therefore, we proceed by estimating\nthe density on a low-dimensional manifold and calculating a distance from the\nmanifold as a measure for out-of-distribution detection. We propose a powerful\ncriterion that combines this measure with the modified likelihood measure based\non data complexity. Extensive experimental results show that incorporating\nmanifold learning while accounting for the estimation of data complexity\nimproves the out-of-distribution detection ability of normalizing flows. This\nimprovement is achieved without modifying the model structure or using\nauxiliary out-of-distribution data during training.\n","authors":["Seyedeh Fatemeh Razavi","Mohammad Mahdi Mehmanchi","Reshad Hosseini","Mostafa Tavassolipour"],"pdf_url":"https://arxiv.org/pdf/2308.13792v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11692v3","updated":"2025-01-29T12:21:55Z","published":"2024-09-18T04:21:04Z","title":"ORB-SfMLearner: ORB-Guided Self-supervised Visual Odometry with\n  Selective Online Adaptation","summary":"  Deep visual odometry, despite extensive research, still faces limitations in\naccuracy and generalizability that prevent its broader application. To address\nthese challenges, we propose an Oriented FAST and Rotated BRIEF (ORB)-guided\nvisual odometry with selective online adaptation named ORB-SfMLearner. We\npresent a novel use of ORB features for learning-based ego-motion estimation,\nleading to more robust and accurate results. We also introduce the\ncross-attention mechanism to enhance the explainability of PoseNet and have\nrevealed that driving direction of the vehicle can be explained through the\nattention weights. To improve generalizability, our selective online adaptation\nallows the network to rapidly and selectively adjust to the optimal parameters\nacross different domains. Experimental results on KITTI and vKITTI datasets\nshow that our method outperforms previous state-of-the-art deep visual odometry\nmethods in terms of ego-motion accuracy and generalizability.\n","authors":["Yanlin Jin","Rui-Yang Ju","Haojun Liu","Yuzhong Zhong"],"pdf_url":"https://arxiv.org/pdf/2409.11692v3.pdf","comment":"Accepted to ICRA 2025; Project page:\n  https://www.neiljin.site/projects/orbsfm/"},{"id":"http://arxiv.org/abs/2501.17594v1","updated":"2025-01-29T11:53:58Z","published":"2025-01-29T11:53:58Z","title":"Watch Your STEPP: Semantic Traversability Estimation using Pose\n  Projected Features","summary":"  Understanding the traversability of terrain is essential for autonomous robot\nnavigation, particularly in unstructured environments such as natural\nlandscapes. Although traditional methods, such as occupancy mapping, provide a\nbasic framework, they often fail to account for the complex mobility\ncapabilities of some platforms such as legged robots. In this work, we propose\na method for estimating terrain traversability by learning from demonstrations\nof human walking. Our approach leverages dense, pixel-wise feature embeddings\ngenerated using the DINOv2 vision Transformer model, which are processed\nthrough an encoder-decoder MLP architecture to analyze terrain segments. The\naveraged feature vectors, extracted from the masked regions of interest, are\nused to train the model in a reconstruction-based framework. By minimizing\nreconstruction loss, the network distinguishes between familiar terrain with a\nlow reconstruction error and unfamiliar or hazardous terrain with a higher\nreconstruction error. This approach facilitates the detection of anomalies,\nallowing a legged robot to navigate more effectively through challenging\nterrain. We run real-world experiments on the ANYmal legged robot both indoor\nand outdoor to prove our proposed method. The code is open-source, while video\ndemonstrations can be found on our website: https://rpl-cs-ucl.github.io/STEPP\n","authors":["Sebastian Ægidius","Dennis Hadjivelichkov","Jianhao Jiao","Jonathan Embley-Riches","Dimitrios Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2501.17594v1.pdf","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2412.15499v2","updated":"2025-01-29T11:46:08Z","published":"2024-12-20T02:25:31Z","title":"A Robust Prototype-Based Network with Interpretable RBF Classifier\n  Foundations","summary":"  Prototype-based classification learning methods are known to be inherently\ninterpretable. However, this paradigm suffers from major limitations compared\nto deep models, such as lower performance. This led to the development of the\nso-called deep Prototype-Based Networks (PBNs), also known as prototypical\nparts models. In this work, we analyze these models with respect to different\nproperties, including interpretability. In particular, we focus on the\nClassification-by-Components (CBC) approach, which uses a probabilistic model\nto ensure interpretability and can be used as a shallow or deep architecture.\nWe show that this model has several shortcomings, like creating contradicting\nexplanations. Based on these findings, we propose an extension of CBC that\nsolves these issues. Moreover, we prove that this extension has robustness\nguarantees and derive a loss that optimizes robustness. Additionally, our\nanalysis shows that most (deep) PBNs are related to (deep) RBF classifiers,\nwhich implies that our robustness guarantees generalize to shallow RBF\nclassifiers. The empirical evaluation demonstrates that our deep PBN yields\nstate-of-the-art classification accuracy on different benchmarks while\nresolving the interpretability shortcomings of other approaches. Further, our\nshallow PBN variant outperforms other shallow PBNs while being inherently\ninterpretable and exhibiting provable robustness guarantees.\n","authors":["Sascha Saralajew","Ashish Rana","Thomas Villmann","Ammar Shaker"],"pdf_url":"https://arxiv.org/pdf/2412.15499v2.pdf","comment":"To appear at AAAI 2025. Includes the Appendix of the AAAI submission.\n  In v2 the font size has been increased in some figures"},{"id":"http://arxiv.org/abs/2405.15661v2","updated":"2025-01-29T11:33:40Z","published":"2024-05-24T15:58:02Z","title":"Exposing Image Classifier Shortcuts with Counterfactual Frequency (CoF)\n  Tables","summary":"  The rise of deep learning in image classification has brought unprecedented\naccuracy but also highlighted a key issue: the use of 'shortcuts' by models.\nSuch shortcuts are easy-to-learn patterns from the training data that fail to\ngeneralise to new data. Examples include the use of a copyright watermark to\nrecognise horses, snowy background to recognise huskies, or ink markings to\ndetect malignant skin lesions. The explainable AI (XAI) community has suggested\nusing instance-level explanations to detect shortcuts without external data,\nbut this requires the examination of many explanations to confirm the presence\nof such shortcuts, making it a labour-intensive process. To address these\nchallenges, we introduce Counterfactual Frequency (CoF) tables, a novel\napproach that aggregates instance-based explanations into global insights, and\nexposes shortcuts. The aggregation implies the need for some semantic concepts\nto be used in the explanations, which we solve by labelling the segments of an\nimage. We demonstrate the utility of CoF tables across several datasets,\nrevealing the shortcuts learned from them.\n","authors":["James Hinns","David Martens"],"pdf_url":"https://arxiv.org/pdf/2405.15661v2.pdf","comment":"10 pages, 18 figures"},{"id":"http://arxiv.org/abs/2501.17570v1","updated":"2025-01-29T11:09:50Z","published":"2025-01-29T11:09:50Z","title":"Trustworthy image-to-image translation: evaluating uncertainty\n  calibration in unpaired training scenarios","summary":"  Mammographic screening is an effective method for detecting breast cancer,\nfacilitating early diagnosis. However, the current need to manually inspect\nimages places a heavy burden on healthcare systems, spurring a desire for\nautomated diagnostic protocols. Techniques based on deep neural networks have\nbeen shown effective in some studies, but their tendency to overfit leaves\nconsiderable risk for poor generalisation and misdiagnosis, preventing their\nwidespread adoption in clinical settings. Data augmentation schemes based on\nunpaired neural style transfer models have been proposed that improve\ngeneralisability by diversifying the representations of training image features\nin the absence of paired training data (images of the same tissue in either\nimage style). But these models are similarly prone to various pathologies, and\nevaluating their performance is challenging without ground truths/large\ndatasets (as is often the case in medical imaging). Here, we consider two\nframeworks/architectures: a GAN-based cycleGAN, and the more recently developed\ndiffusion-based SynDiff. We evaluate their performance when trained on image\npatches parsed from three open access mammography datasets and one non-medical\nimage dataset. We consider the use of uncertainty quantification to assess\nmodel trustworthiness, and propose a scheme to evaluate calibration quality in\nunpaired training scenarios. This ultimately helps facilitate the trustworthy\nuse of image-to-image translation models in domains where ground truths are not\ntypically available.\n","authors":["Ciaran Bench","Emir Ahmed","Spencer A. Thomas"],"pdf_url":"https://arxiv.org/pdf/2501.17570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17044v2","updated":"2025-01-29T11:06:57Z","published":"2025-01-28T16:09:34Z","title":"Synthesizing 3D Abstractions by Inverting Procedural Buildings with\n  Transformers","summary":"  We generate abstractions of buildings, reflecting the essential aspects of\ntheir geometry and structure, by learning to invert procedural models. We first\nbuild a dataset of abstract procedural building models paired with simulated\npoint clouds and then learn the inverse mapping through a transformer. Given a\npoint cloud, the trained transformer then infers the corresponding abstracted\nbuilding in terms of a programmatic language description. This approach\nleverages expressive procedural models developed for gaming and animation, and\nthereby retains desirable properties such as efficient rendering of the\ninferred abstractions and strong priors for regularity and symmetry. Our\napproach achieves good reconstruction accuracy in terms of geometry and\nstructure, as well as structurally consistent inpainting.\n","authors":["Maximilian Dax","Jordi Berbel","Jan Stria","Leonidas Guibas","Urs Bergmann"],"pdf_url":"https://arxiv.org/pdf/2501.17044v2.pdf","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2412.02198v2","updated":"2025-01-29T10:59:30Z","published":"2024-12-03T06:23:35Z","title":"Transformer-Based Auxiliary Loss for Face Recognition Across Age\n  Variations","summary":"  Aging presents a significant challenge in face recognition, as changes in\nskin texture and tone can alter facial features over time, making it\nparticularly difficult to compare images of the same individual taken years\napart, such as in long-term identification scenarios. Transformer networks have\nthe strength to preserve sequential spatial relationships caused by aging\neffect. This paper presents a technique for loss evaluation that uses a\ntransformer network as an additive loss in the face recognition domain. The\nstandard metric loss function typically takes the final embedding of the main\nCNN backbone as its input. Here, we employ a transformer-metric loss, a\ncombined approach that integrates both transformer-loss and metric-loss. This\nresearch intends to analyze the transformer behavior on the convolution output\nwhen the CNN outcome is arranged in a sequential vector. These sequential\nvectors have the potential to overcome the texture or regional structure\nreferred to as wrinkles or sagging skin affected by aging. The transformer\nencoder takes input from the contextual vectors obtained from the final\nconvolution layer of the network. The learned features can be more\nage-invariant, complementing the discriminative power of the standard metric\nloss embedding. With this technique, we use transformer loss with various base\nmetric-loss functions to evaluate the effect of the combined loss functions. We\nobserve that such a configuration allows the network to achieve SoTA results in\nLFW and age-variant datasets (CA-LFW and AgeDB). This research expands the role\nof transformers in the machine vision domain and opens new possibilities for\nexploring transformers as a loss function.\n","authors":["Pritesh Prakash","Ashish Jacob Sam","S Umamaheswaran"],"pdf_url":"https://arxiv.org/pdf/2412.02198v2.pdf","comment":"Face Recognition for Age-variant Datasets"},{"id":"http://arxiv.org/abs/2501.17555v1","updated":"2025-01-29T10:43:07Z","published":"2025-01-29T10:43:07Z","title":"An Exceptional Dataset For Rare Pancreatic Tumor Segmentation","summary":"  Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms\nthat account for less than 5% of all pancreatic malignancies, with an incidence\nof only 1-1.5 cases per 100,000. Early detection of pNETs is critical for\nimproving patient survival, but the rarity of pNETs makes segmenting them from\nCT a very challenging problem. So far, there has not been a dataset\nspecifically for pNETs available to researchers. To address this issue, we\npropose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography\n(CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors,\ncontaining data from 469 patients. This is the first dataset solely dedicated\nto pNETs, distinguishing it from previous collections. Additionally, we provide\nthe baseline detection networks with a new slice-wise weight loss function\ndesigned for the UNet-based model, improving the overall pNET segmentation\nperformance. We hope that our dataset can enhance the understanding and\ndiagnosis of pNET Tumors within the medical community, facilitate the\ndevelopment of more accurate diagnostic tools, and ultimately improve patient\noutcomes and advance the field of oncology.\n","authors":["Wenqi Li","Yingli Chen","Keyang Zhou","Xiaoxiao Hu","Zilu Zheng","Yue Yan","Xinpeng Zhang","Wei Tang","Zhenxing Qian"],"pdf_url":"https://arxiv.org/pdf/2501.17555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17550v1","updated":"2025-01-29T10:36:55Z","published":"2025-01-29T10:36:55Z","title":"Action Recognition Using Temporal Shift Module and Ensemble Learning","summary":"  This paper presents the first-rank solution for the Multi-Modal Action\nRecognition Challenge, part of the Multi-Modal Visual Pattern Recognition\nWorkshop at the \\acl{ICPR} 2024. The competition aimed to recognize human\nactions using a diverse dataset of 20 action classes, collected from\nmulti-modal sources. The proposed approach is built upon the \\acl{TSM}, a\ntechnique aimed at efficiently capturing temporal dynamics in video data,\nincorporating multiple data input types. Our strategy included transfer\nlearning to leverage pre-trained models, followed by meticulous fine-tuning on\nthe challenge's specific dataset to optimize performance for the 20 action\nclasses. We carefully selected a backbone network to balance computational\nefficiency and recognition accuracy and further refined the model using an\nensemble technique that integrates outputs from different modalities. This\nensemble approach proved crucial in boosting the overall performance. Our\nsolution achieved a perfect top-1 accuracy on the test set, demonstrating the\neffectiveness of the proposed approach in recognizing human actions across 20\nclasses. Our code is available online https://github.com/ffyyytt/TSM-MMVPR.\n","authors":["Anh-Kiet Duong","Petra Gomez-Krämer"],"pdf_url":"https://arxiv.org/pdf/2501.17550v1.pdf","comment":"12 pages, MMVPR @ ICPR2024"},{"id":"http://arxiv.org/abs/2501.17547v1","updated":"2025-01-29T10:32:08Z","published":"2025-01-29T10:32:08Z","title":"Towards Training-Free Open-World Classification with 3D Generative\n  Models","summary":"  3D open-world classification is a challenging yet essential task in dynamic\nand unstructured real-world scenarios, requiring both open-category and\nopen-pose recognition. To address these challenges, recent wisdom often takes\nsophisticated 2D pre-trained models to provide enriched and stable\nrepresentations. However, these methods largely rely on how 3D objects can be\nprojected into 2D space, which is unfortunately not well solved, and thus\nsignificantly limits their performance. Unlike these present efforts, in this\npaper we make a pioneering exploration of 3D generative models for 3D\nopen-world classification. Drawing on abundant prior knowledge from 3D\ngenerative models, we additionally craft a rotation-invariant feature\nextractor. This innovative synergy endows our pipeline with the advantages of\nbeing training-free, open-category, and pose-invariant, thus well suited to 3D\nopen-world classification. Extensive experiments on benchmark datasets\ndemonstrate the potential of generative models in 3D open-world classification,\nachieving state-of-the-art performance on ModelNet10 and McGill with 32.0% and\n8.7% overall accuracy improvement, respectively.\n","authors":["Xinzhe Xia","Weiguang Zhao","Yuyao Yan","Guanyu Yang","Rui Zhang","Kaizhu Huang","Xi Yang"],"pdf_url":"https://arxiv.org/pdf/2501.17547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17534v1","updated":"2025-01-29T10:09:32Z","published":"2025-01-29T10:09:32Z","title":"3DSES: an indoor Lidar point cloud segmentation dataset with real and\n  pseudo-labels from a 3D model","summary":"  Semantic segmentation of indoor point clouds has found various applications\nin the creation of digital twins for robotics, navigation and building\ninformation modeling (BIM). However, most existing datasets of labeled indoor\npoint clouds have been acquired by photogrammetry. In contrast, Terrestrial\nLaser Scanning (TLS) can acquire dense sub-centimeter point clouds and has\nbecome the standard for surveyors. We present 3DSES (3D Segmentation of ESGT\npoint clouds), a new dataset of indoor dense TLS colorized point clouds\ncovering 427 m 2 of an engineering school. 3DSES has a unique double annotation\nformat: semantic labels annotated at the point level alongside a full 3D CAD\nmodel of the building. We introduce a model-to-cloud algorithm for automated\nlabeling of indoor point clouds using an existing 3D CAD model. 3DSES has 3\nvariants of various semantic and geometrical complexities. We show that our\nmodel-to-cloud alignment can produce pseudo-labels on our point clouds with a\n\\&gt; 95% accuracy, allowing us to train deep models with significant time\nsavings compared to manual labeling. First baselines on 3DSES show the\ndifficulties encountered by existing models when segmenting objects relevant to\nBIM, such as light and safety utilities. We show that segmentation accuracy can\nbe improved by leveraging pseudo-labels and Lidar intensity, an information\nrarely considered in current datasets. Code and data will be open sourced.\n","authors":["Maxime Mérizette","Nicolas Audebert","Pierre Kervella","Jérôme Verdun"],"pdf_url":"https://arxiv.org/pdf/2501.17534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11821v5","updated":"2025-01-29T08:48:10Z","published":"2024-03-18T14:24:20Z","title":"A Survey on Quality Metrics for Text-to-Image Generation","summary":"  AI-based text-to-image models do not only excel at generating realistic\nimages, they also give designers more and more fine-grained control over the\nimage content. Consequently, these approaches have gathered increased attention\nwithin the computer graphics research community, which has been historically\ndevoted towards traditional rendering techniques, that offer precise control\nover scene parameters (e.g., objects, materials, and lighting). While the\nquality of conventionally rendered images is assessed through well established\nimage quality metrics, such as SSIM or PSNR, the unique challenges of\ntext-to-image generation require other, dedicated quality metrics. These\nmetrics must be able to not only measure overall image quality, but also how\nwell images reflect given text prompts, whereby the control of scene and\nrendering parameters is interweaved. Within this survey, we provide a\ncomprehensive overview of such text-to-image quality metrics, and propose a\ntaxonomy to categorize these metrics. Our taxonomy is grounded in the\nassumption, that there are two main quality criteria, namely compositional\nquality and general quality, that contribute to the overall image quality.\nBesides the metrics, this survey covers dedicated text-to-image benchmark\ndatasets, over which the metrics are frequently computed. Finally, we identify\nlimitations and open challenges in the field of text-to-image generation, and\nderive guidelines for practitioners conducting text-to-image evaluation.\n","authors":["Sebastian Hartwig","Dominik Engel","Leon Sick","Hannah Kniesel","Tristan Payer","Poonam Poonam","Michael Glöckler","Alex Bäuerle","Timo Ropinski"],"pdf_url":"https://arxiv.org/pdf/2403.11821v5.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2501.17468v1","updated":"2025-01-29T08:20:05Z","published":"2025-01-29T08:20:05Z","title":"Solving Inverse Problems using Diffusion with Fast Iterative Renoising","summary":"  Imaging inverse problems can be solved in an unsupervised manner using\npre-trained diffusion models. In most cases, that involves approximating the\ngradient of the measurement-conditional score function in the reverse process.\nSince the approximations produced by existing methods are quite poor,\nespecially early in the reverse process, we propose a new approach that\nre-estimates and renoises the image several times per diffusion step. Renoising\nadds carefully shaped colored noise that ensures the pre-trained diffusion\nmodel sees white-Gaussian error, in accordance with how it was trained. We\ndemonstrate the effectiveness of our \"DDfire\" method at 20, 100, and 1000\nneural function evaluations on linear inverse problems and phase retrieval.\n","authors":["Matt C. Bendel","Saurav K. Shastri","Rizwan Ahmad","Philip Schniter"],"pdf_url":"https://arxiv.org/pdf/2501.17468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17441v1","updated":"2025-01-29T06:43:38Z","published":"2025-01-29T06:43:38Z","title":"Towards Making Flowchart Images Machine Interpretable","summary":"  Computer programming textbooks and software documentations often contain\nflowcharts to illustrate the flow of an algorithm or procedure. Modern OCR\nengines often tag these flowcharts as graphics and ignore them in further\nprocessing. In this paper, we work towards making flowchart images\nmachine-interpretable by converting them to executable Python codes. To this\nend, inspired by the recent success in natural language to code generation\nliterature, we present a novel transformer-based framework, namely FloCo-T5.\nOur model is well-suited for this task,as it can effectively learn semantics,\nstructure, and patterns of programming languages, which it leverages to\ngenerate syntactically correct code. We also used a task-specific pre-training\nobjective to pre-train FloCo-T5 using a large number of logic-preserving\naugmented code samples. Further, to perform a rigorous study of this problem,\nwe introduce theFloCo dataset that contains 11,884 flowchart images and their\ncorresponding Python codes. Our experiments show promising results, and\nFloCo-T5 clearly outperforms related competitive baselines on code generation\nmetrics. We make our dataset and implementation publicly available.\n","authors":["Shreya Shukla","Prajwal Gatti","Yogesh Kumar","Vikash Yadav","Anand Mishra"],"pdf_url":"https://arxiv.org/pdf/2501.17441v1.pdf","comment":"Published at: ICDAR 2023, Project Page:\n  https://vl2g.github.io/projects/floco/"},{"id":"http://arxiv.org/abs/2407.15719v3","updated":"2025-01-29T06:35:34Z","published":"2024-07-22T15:22:33Z","title":"GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via\n  Generative Feature Extraction from MCI","summary":"  Alzheimer's Disease (AD) is a progressive, irreversible neurodegenerative\ndisorder that often originates from Mild Cognitive Impairment (MCI). This\nprogression results in significant memory loss and severely affects patients'\nquality of life. Clinical trials have consistently shown that early and\ntargeted interventions for individuals with MCI may slow or even prevent the\nadvancement of AD. Research indicates that accurate medical classification\nrequires diverse multimodal data, including detailed assessment scales and\nneuroimaging techniques like Magnetic Resonance Imaging (MRI) and Positron\nEmission Tomography (PET). However, simultaneously collecting the\naforementioned three modalities for training presents substantial challenges.\nTo tackle these difficulties, we propose GFE-Mamba, a multimodal classifier\nfounded on Generative Feature Extractor. The intermediate features provided by\nthis Extractor can compensate for the shortcomings of PET and achieve profound\nmultimodal fusion in the classifier. The Mamba block, as the backbone of the\nclassifier, enables it to efficiently extract information from long-sequence\nscale information. Pixel-level Bi-cross Attention supplements pixel-level\ninformation from MRI and PET. We provide our rationale for developing this\ncross-temporal progression prediction dataset and the pre-trained Extractor\nweights. Our experimental findings reveal that the GFE-Mamba model effectively\npredicts the progression from MCI to AD and surpasses several leading methods\nin the field. Our source code is available at\nhttps://github.com/Tinysqua/GFE-Mamba.\n","authors":["Zhaojie Fang","Shenghao Zhu","Yifei Chen","Binfeng Zou","Fan Jia","Chang Liu","Xiang Feng","Linwei Qiu","Feiwei Qin","Jin Fan","Changbiao Chu","Changmiao Wang"],"pdf_url":"https://arxiv.org/pdf/2407.15719v3.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.17422v1","updated":"2025-01-29T05:27:23Z","published":"2025-01-29T05:27:23Z","title":"SIGN: A Statistically-Informed Gaze Network for Gaze Time Prediction","summary":"  We propose a first version of SIGN, a Statistically-Informed Gaze Network, to\npredict aggregate gaze times on images. We develop a foundational statistical\nmodel for which we derive a deep learning implementation involving CNNs and\nVisual Transformers, which enables the prediction of overall gaze times. The\nmodel enables us to derive from the aggregate gaze times the underlying gaze\npattern as a probability map over all regions in the image, where each region's\nprobability represents the likelihood of being gazed at across all possible\nscan-paths. We test SIGN's performance on AdGaze3500, a dataset of images of\nads with aggregate gaze times, and on COCO-Search18, a dataset with\nindividual-level fixation patterns collected during search. We demonstrate that\nSIGN (1) improves gaze duration prediction significantly over state-of-the-art\ndeep learning benchmarks on both datasets, and (2) can deliver plausible gaze\npatterns that correspond to empirical fixation patterns in COCO-Search18. These\nresults suggest that the first version of SIGN holds promise for gaze-time\npredictions and deserves further development.\n","authors":["Jianping Ye","Michel Wedel"],"pdf_url":"https://arxiv.org/pdf/2501.17422v1.pdf","comment":"4 pages, 2 figures"},{"id":"http://arxiv.org/abs/2408.08093v2","updated":"2025-01-29T05:19:41Z","published":"2024-08-15T11:36:18Z","title":"When Video Coding Meets Multimodal Large Language Models: A Unified\n  Paradigm for Video Coding","summary":"  Existing codecs are designed to eliminate intrinsic redundancies to create a\ncompact representation for compression. However, strong external priors from\nMultimodal Large Language Models (MLLMs) have not been explicitly explored in\nvideo compression. Herein, we introduce a unified paradigm for Cross-Modality\nVideo Coding (CMVC), which is a pioneering approach to explore multimodality\nrepresentation and video generative models in video coding. Specifically, on\nthe encoder side, we disentangle a video into spatial content and motion\ncomponents, which are subsequently transformed into distinct modalities to\nachieve very compact representation by leveraging MLLMs. During decoding,\npreviously encoded components and video generation models are leveraged to\ncreate multiple encoding-decoding modes that optimize video reconstruction\nquality for specific decoding requirements, including Text-Text-to-Video (TT2V)\nmode to ensure high-quality semantic information and Image-Text-to-Video (IT2V)\nmode to achieve superb perceptual consistency. In addition, we propose an\nefficient frame interpolation model for IT2V mode via Low-Rank Adaption (LoRA)\ntuning to guarantee perceptual quality, which allows the generated motion cues\nto behave smoothly. Experiments on benchmarks indicate that TT2V achieves\neffective semantic reconstruction, while IT2V exhibits competitive perceptual\nconsistency. These results highlight potential directions for future research\nin video coding.\n","authors":["Pingping Zhang","Jinlong Li","Kecheng Chen","Meng Wang","Long Xu","Haoliang Li","Nicu Sebe","Sam Kwong","Shiqi Wang"],"pdf_url":"https://arxiv.org/pdf/2408.08093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15104v5","updated":"2025-01-29T04:48:16Z","published":"2024-06-21T12:45:07Z","title":"Deciphering the Definition of Adversarial Robustness for post-hoc OOD\n  Detectors","summary":"  Detecting out-of-distribution (OOD) inputs is critical for safely deploying\ndeep learning models in real-world scenarios. In recent years, many OOD\ndetectors have been developed, and even the benchmarking has been standardized,\ni.e. OpenOOD. The number of post-hoc detectors is growing fast. They are\nshowing an option to protect a pre-trained classifier against natural\ndistribution shifts and claim to be ready for real-world scenarios. However,\nits effectiveness in dealing with adversarial examples (AdEx) has been\nneglected in most studies. In cases where an OOD detector includes AdEx in its\nexperiments, the lack of uniform parameters for AdEx makes it difficult to\naccurately evaluate the performance of the OOD detector. This paper\ninvestigates the adversarial robustness of 16 post-hoc detectors against\nvarious evasion attacks. It also discusses a roadmap for adversarial defense in\nOOD detectors that would help adversarial robustness. We believe that level 1\n(AdEx on a unified dataset) should be added to any OOD detector to see the\nlimitations. The last level in the roadmap (defense against adaptive attacks)\nwe added for integrity from an adversarial machine learning (AML) point of\nview, which we do not believe is the ultimate goal for OOD detectors.\n","authors":["Peter Lorenz","Mario Fernandez","Jens Müller","Ullrich Köthe"],"pdf_url":"https://arxiv.org/pdf/2406.15104v5.pdf","comment":"accepted at ICML workshop 2024"},{"id":"http://arxiv.org/abs/2501.16769v2","updated":"2025-01-29T04:34:42Z","published":"2025-01-28T07:49:52Z","title":"Beyond-Labels: Advancing Open-Vocabulary Segmentation With\n  Vision-Language Models","summary":"  Self-supervised learning can resolve numerous image or linguistic processing\nproblems when effectively trained. This study investigated simple yet efficient\nmethods for adaping previously learned foundation models for open-vocabulary\nsemantic segmentation tasks. Our research proposed \"Beyond-Labels,\" a\nlightweight transformer-based fusion module that uses a handful of image\nsegmentation data to fuse frozen image representations with language concepts.\nFurthermore, we efficiently captured positional information in images using\nFourier embeddings, thus improving the generalization across various image\nsizes. Extensive ablation tests were performed to investigate the important\ncomponents of our proposed method; when tested against the common benchmark\nPASCAL-5i, it demonstrated superior performance despite being trained on frozen\nimage and language characteristics.\n","authors":["Muhammad Atta ur Rahman"],"pdf_url":"https://arxiv.org/pdf/2501.16769v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17403v1","updated":"2025-01-29T03:57:56Z","published":"2025-01-29T03:57:56Z","title":"General Scene Adaptation for Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on\none-time execution of individual instructions across multiple environments,\naiming to develop agents capable of functioning in any environment in a\nzero-shot manner. However, real-world navigation robots often operate in\npersistent environments with relatively consistent physical layouts, visual\nobservations, and language styles from instructors. Such a gap in the task\nsetting presents an opportunity to improve VLN agents by incorporating\ncontinuous adaptation to specific environments. To better reflect these\nreal-world conditions, we introduce GSA-VLN, a novel task requiring agents to\nexecute navigation instructions within a specific scene and simultaneously\nadapt to it for improved performance over time. To evaluate the proposed task,\none has to address two challenges in existing VLN datasets: the lack of OOD\ndata, and the limited number and style diversity of instructions for each\nscene. Therefore, we propose a new dataset, GSA-R2R, which significantly\nexpands the diversity and quantity of environments and instructions for the R2R\ndataset to evaluate agent adaptability in both ID and OOD contexts.\nFurthermore, we design a three-stage instruction orchestration pipeline that\nleverages LLMs to refine speaker-generated instructions and apply role-playing\ntechniques to rephrase instructions into different speaking styles. This is\nmotivated by the observation that each individual user often has consistent\nsignatures or preferences in their instructions. We conducted extensive\nexperiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various\nmethods. Based on our findings, we propose a novel method, GR-DUET, which\nincorporates memory-based navigation graphs with an environment-specific\ntraining strategy, achieving state-of-the-art results on all GSA-R2R splits.\n","authors":["Haodong Hong","Yanyuan Qiao","Sen Wang","Jiajun Liu","Qi Wu"],"pdf_url":"https://arxiv.org/pdf/2501.17403v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.16411v2","updated":"2025-01-29T03:52:39Z","published":"2025-01-27T18:59:58Z","title":"PhysBench: Benchmarking and Enhancing Vision-Language Models for\n  Physical World Understanding","summary":"  Understanding the physical world is a fundamental challenge in embodied AI,\ncritical for enabling agents to perform complex tasks and operate safely in\nreal-world environments. While Vision-Language Models (VLMs) have shown great\npromise in reasoning and task planning for embodied agents, their ability to\ncomprehend physical phenomena remains extremely limited. To close this gap, we\nintroduce PhysBench, a comprehensive benchmark designed to evaluate VLMs'\nphysical world understanding capability across a diverse set of tasks.\nPhysBench contains 10,002 entries of interleaved video-image-text data,\ncategorized into four major domains: physical object properties, physical\nobject relationships, physical scene understanding, and physics-based dynamics,\nfurther divided into 19 subclasses and 8 distinct capability dimensions. Our\nextensive experiments, conducted on 75 representative VLMs, reveal that while\nthese models excel in common-sense reasoning, they struggle with understanding\nthe physical world -- likely due to the absence of physical knowledge in their\ntraining data and the lack of embedded physical priors. To tackle the\nshortfall, we introduce PhysAgent, a novel framework that combines the\ngeneralization strengths of VLMs with the specialized expertise of vision\nmodels, significantly enhancing VLMs' physical understanding across a variety\nof tasks, including an 18.4\\% improvement on GPT-4o. Furthermore, our results\ndemonstrate that enhancing VLMs' physical world understanding capabilities can\nhelp embodied agents such as MOKA. We believe that PhysBench and PhysAgent\noffer valuable insights and contribute to bridging the gap between VLMs and\nphysical world understanding.\n","authors":["Wei Chow","Jiageng Mao","Boyi Li","Daniel Seita","Vitor Guizilini","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2501.16411v2.pdf","comment":"ICLR 2025. Project page: https://physbench.github.io/ Dataset:\n  https://huggingface.co/datasets/USC-GVL/PhysBench"},{"id":"http://arxiv.org/abs/2501.15045v2","updated":"2025-01-29T03:43:00Z","published":"2025-01-25T03:01:26Z","title":"Towards Robust Unsupervised Attention Prediction in Autonomous Driving","summary":"  Robustly predicting attention regions of interest for self-driving systems is\ncrucial for driving safety but presents significant challenges due to the\nlabor-intensive nature of obtaining large-scale attention labels and the domain\ngap between self-driving scenarios and natural scenes. These challenges are\nfurther exacerbated by complex traffic environments, including camera\ncorruption under adverse weather, noise interferences, and central bias from\nlong-tail distributions. To address these issues, we propose a robust\nunsupervised attention prediction method. An Uncertainty Mining Branch refines\npredictions by analyzing commonalities and differences across multiple\npre-trained models on natural scenes, while a Knowledge Embedding Block bridges\nthe domain gap by incorporating driving knowledge to adaptively enhance\npseudo-labels. Additionally, we introduce RoboMixup, a novel data augmentation\nmethod that improves robustness against corruption through soft attention and\ndynamic augmentation, and mitigates central bias by integrating random cropping\ninto Mixup as a regularizer. To systematically evaluate robustness in\nself-driving attention prediction, we introduce the DriverAttention-C\nbenchmark, comprising over 100k frames across three subsets: BDD-A-C,\nDR(eye)VE-C, and DADA-2000-C. Our method achieves performance equivalent to or\nsurpassing fully supervised state-of-the-art approaches on three public\ndatasets and the proposed robustness benchmark, reducing relative corruption\ndegradation by 58.8% and 52.8%, and improving central bias robustness by 12.4%\nand 11.4% in KLD and CC metrics, respectively. Code and data are available at\nhttps://github.com/zaplm/DriverAttention.\n","authors":["Mengshi Qi","Xiaoyang Bi","Pengfei Zhu","Huadong Ma"],"pdf_url":"https://arxiv.org/pdf/2501.15045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23413v2","updated":"2025-01-29T03:39:50Z","published":"2024-10-30T19:32:02Z","title":"EchoFM: Foundation Model for Generalizable Echocardiogram Analysis","summary":"  Foundation models have recently gained significant attention because of their\ngeneralizability and adaptability across multiple tasks and data distributions.\nAlthough medical foundation models have emerged, solutions for cardiac imaging,\nespecially echocardiography videos, are still unexplored. In this paper, we\nintroduce EchoFM, a foundation model specifically designed to represent and\nanalyze echocardiography videos. In EchoFM, we propose a self-supervised\nlearning framework that captures both spatial and temporal variability patterns\nthrough a spatio-temporal consistent masking strategy and periodic-driven\ncontrastive learning. This framework can effectively capture the\nspatio-temporal dynamics of echocardiography and learn the representative video\nfeatures without any labels. We pre-train our model on an extensive dataset\ncomprising over 290,000 echocardiography videos covering 26 scan views across\ndifferent imaging modes, with up to 20 million frames of images. The\npre-trained EchoFM can then be easily adapted and fine-tuned for a variety of\ndownstream tasks, serving as a robust backbone model. Our evaluation was\nsystemically designed for four downstream tasks after the echocardiography\nexamination routine. Experiment results show that EchoFM surpasses\nstate-of-the-art methods, including specialized echocardiography methods,\nself-supervised pre-training models, and general-purposed pre-trained\nfoundation models, across all downstream tasks.\n","authors":["Sekeun Kim","Pengfei Jin","Sifan Song","Cheng Chen","Yiwei Li","Hui Ren","Xiang Li","Tianming Liu","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2410.23413v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17391v1","updated":"2025-01-29T02:52:32Z","published":"2025-01-29T02:52:32Z","title":"Learning Free Token Reduction for Multi-Modal LLM","summary":"  Vision-Language Models (VLMs) have achieved remarkable success across a range\nof multimodal tasks; however, their practical deployment is often constrained\nby high computational costs and prolonged inference times. Since the vision\nmodality typically carries more information than the text modality, compressing\nvisual prompts offers a promising solution to alleviate these challenges.\nExisting approaches predominantly focus on refining model architectures or\ndirectly reducing the number of visual tokens. However, these methods often\ncompromise inference performance due to a lack of consideration for the unique\nspatial and temporal characteristics of visual data. In this work, we propose a\ntoken compression paradigm that operates on both spatial and temporal\ndimensions. Our approach includes a learning-free, plug-and-play compression\npipeline that can be seamlessly integrated into most Multimodal Large Language\nModel (MLLM) frameworks. By leveraging this method, we enhance the model\ninference capability while simultaneously reducing its computational cost.\nExperimental results on the Video-QA task demonstrate the effectiveness of the\nproposed approach, showcasing significant improvements in efficiency without\nsacrificing performance.\n","authors":["Zihui Zhao","Yingxin Li","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2501.17391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17897v1","updated":"2025-01-29T01:54:45Z","published":"2025-01-29T01:54:45Z","title":"Visualization of Organ Movements Using Automatic Region Segmentation of\n  Swallowing CT","summary":"  This study presents the first report on the development of an artificial\nintelligence (AI) for automatic region segmentation of four-dimensional\ncomputer tomography (4D-CT) images during swallowing. The material consists of\n4D-CT images taken during swallowing. Additionally, data for verifying the\npracticality of the AI were obtained from 4D-CT images during mastication and\nswallowing. The ground truth data for the region segmentation for the AI were\ncreated from five 4D-CT datasets of swallowing. A 3D convolutional model of\nnnU-Net was used for the AI. The learning and evaluation method for the AI was\nleave-one-out cross-validation. The number of epochs for training the nnU-Net\nwas 100. The Dice coefficient was used as a metric to assess the AI's region\nsegmentation accuracy. Regions with a median Dice coefficient of 0.7 or higher\nincluded the bolus, bones, tongue, and soft palate. Regions with a Dice\ncoefficient below 0.7 included the thyroid cartilage and epiglottis. Factors\nthat reduced the Dice coefficient included metal artifacts caused by dental\ncrowns in the bolus and the speed of movement for the thyroid cartilage and\nepiglottis. In practical verification of the AI, no significant misrecognition\nwas observed for facial bones, jaw bones, or the tongue. However, regions such\nas the hyoid bone, thyroid cartilage, and epiglottis were not fully delineated\nduring fast movement. It is expected that future research will improve the\naccuracy of the AI's region segmentation, though the risk of misrecognition\nwill always exist. Therefore, the development of tools for efficiently\ncorrecting the AI's segmentation results is necessary. AI-based visualization\nis expected to contribute not only to the deepening of motion analysis of\norgans during swallowing but also to improving the accuracy of swallowing CT by\nclearly showing the current state of its precision.\n","authors":["Yukihiro Michiwaki","Takahiro Kikuchi","Takashi Ijiri","Yoko Inamoto","Hiroshi Moriya","Takumi Ogawa","Ryota Nakatani","Yuto Masaki","Yoshito Otake","Yoshinobu Sato"],"pdf_url":"https://arxiv.org/pdf/2501.17897v1.pdf","comment":"8 pages, 5 figures, 1 table"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2501.18056v1","updated":"2025-01-29T23:41:12Z","published":"2025-01-29T23:41:12Z","title":"RL-based Query Rewriting with Distilled LLM for online E-Commerce\n  Systems","summary":"  Query rewriting (QR) is a critical technique in e-commerce search, addressing\nthe lexical gap between user queries and product descriptions to enhance search\nperformance. Existing QR approaches typically fall into two categories:\ndiscriminative models and generative methods leveraging large language models\n(LLMs). Discriminative models often struggle with natural language\nunderstanding and offer limited flexibility in rewriting, while generative\nLLMs, despite producing high-quality rewrites, face high inference latency and\ncost in online settings. These limitations force offline deployment, making\nthem vulnerable to issues like information staleness and semantic drift. To\novercome these challenges, we propose a novel hybrid pipeline for QR that\nbalances efficiency and effectiveness. Our approach combines offline knowledge\ndistillation to create a lightweight but efficient student model with online\nreinforcement learning (RL) to refine query rewriting dynamically using\nreal-time feedback. A key innovation is the use of LLMs as simulated human\nfeedback, enabling scalable reward signals and cost-effective evaluation\nwithout manual annotations. Experimental results on Amazon ESCI dataset\ndemonstrate significant improvements in query relevance, diversity, and\nadaptability, as well as positive feedback from the LLM simulation. This work\ncontributes to advancing LLM capabilities for domain-specific applications,\noffering a robust solution for dynamic and complex e-commerce search\nenvironments.\n","authors":["Duy A. Nguyen","Rishi Kesav Mohan","Van Yang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2501.18056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17981v1","updated":"2025-01-29T20:36:29Z","published":"2025-01-29T20:36:29Z","title":"Can Generative LLMs Create Query Variants for Test Collections? An\n  Exploratory Study","summary":"  This paper explores the utility of a Large Language Model (LLM) to\nautomatically generate queries and query variants from a description of an\ninformation need. Given a set of information needs described as backstories, we\nexplore how similar the queries generated by the LLM are to those generated by\nhumans. We quantify the similarity using different metrics and examine how the\nuse of each set would contribute to document pooling when building test\ncollections. Our results show potential in using LLMs to generate query\nvariants. While they may not fully capture the wide variety of human-generated\nvariants, they generate similar sets of relevant documents, reaching up to\n71.1% overlap at a pool depth of 100.\n","authors":["Marwah Alaofi","Luke Gallagher","Mark Sanderson","Falk Scholer","Paul Thomas"],"pdf_url":"https://arxiv.org/pdf/2501.17981v1.pdf","comment":"Published in the proceedings of SIGIR'23"},{"id":"http://arxiv.org/abs/2501.17969v1","updated":"2025-01-29T20:11:35Z","published":"2025-01-29T20:11:35Z","title":"LLMs can be Fooled into Labelling a Document as Relevant (best café\n  near me; this paper is perfectly relevant)","summary":"  LLMs are increasingly being used to assess the relevance of information\nobjects. This work reports on experiments to study the labelling of short texts\n(i.e., passages) for relevance, using multiple open-source and proprietary\nLLMs. While the overall agreement of some LLMs with human judgements is\ncomparable to human-to-human agreement measured in previous research, LLMs are\nmore likely to label passages as relevant compared to human judges, indicating\nthat LLM labels denoting non-relevance are more reliable than those indicating\nrelevance.\n  This observation prompts us to further examine cases where human judges and\nLLMs disagree, particularly when the human judge labels the passage as\nnon-relevant and the LLM labels it as relevant. Results show a tendency for\nmany LLMs to label passages that include the original query terms as relevant.\nWe, therefore, conduct experiments to inject query words into random and\nirrelevant passages, not unlike the way we inserted the query \"best caf\\'e near\nme\" into this paper. The results show that LLMs are highly influenced by the\npresence of query words in the passages under assessment, even if the wider\npassage has no relevance to the query. This tendency of LLMs to be fooled by\nthe mere presence of query words demonstrates a weakness in our current\nmeasures of LLM labelling: relying on overall agreement misses important\npatterns of failures. There is a real risk of bias in LLM-generated relevance\nlabels and, therefore, a risk of bias in rankers trained on those labels.\n  We also investigate the effects of deliberately manipulating LLMs by\ninstructing them to label passages as relevant, similar to the instruction\n\"this paper is perfectly relevant\" inserted above. We find that such\nmanipulation influences the performance of some LLMs, highlighting the critical\nneed to consider potential vulnerabilities when deploying LLMs in real-world\napplications.\n","authors":["Marwah Alaofi","Paul Thomas","Falk Scholer","Mark Sanderson"],"pdf_url":"https://arxiv.org/pdf/2501.17969v1.pdf","comment":"Published in the proceedings of SIGIR-AP'24"},{"id":"http://arxiv.org/abs/2501.17822v1","updated":"2025-01-29T18:14:51Z","published":"2025-01-29T18:14:51Z","title":"Aggregation Schemes for Single-Vector WSI Representation Learning in\n  Digital Pathology","summary":"  A crucial step to efficiently integrate Whole Slide Images (WSIs) in\ncomputational pathology is assigning a single high-quality feature vector,\ni.e., one embedding, to each WSI. With the existence of many pre-trained deep\nneural networks and the emergence of foundation models, extracting embeddings\nfor sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,\ngiven their high resolution and gigapixel nature, inputting them into existing\nGPUs as a single image is not feasible. As a result, WSIs are usually split\ninto many patches. Feeding each patch to a pre-trained model, each WSI can then\nbe represented by a set of patches, hence, a set of embeddings. Hence, in such\na setup, WSI representation learning reduces to set representation learning\nwhere for each WSI we have access to a set of patch embeddings. To obtain a\nsingle embedding from a set of patch embeddings for each WSI, multiple\nset-based learning schemes have been proposed in the literature. In this paper,\nwe evaluate the WSI search performance of multiple recently developed\naggregation techniques (mainly set representation learning techniques)\nincluding simple average or max pooling operations, Deep Sets, Memory networks,\nFocal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse\nand binary Fisher Vector on four different primary sites including bladder,\nbreast, kidney, and Colon from TCGA. Further, we benchmark the search\nperformance of these methods against the median of minimum distances of patch\nembeddings, a non-aggregating approach used for WSI retrieval.\n","authors":["Sobhan Hemati","Ghazal Alabtah","Saghir Alfasly","H. R. Tizhoosh"],"pdf_url":"https://arxiv.org/pdf/2501.17822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17788v1","updated":"2025-01-29T17:26:47Z","published":"2025-01-29T17:26:47Z","title":"WARP: An Efficient Engine for Multi-Vector Retrieval","summary":"  We study the efficiency of multi-vector retrieval methods like ColBERT and\nits recent variant XTR. We introduce WARP, a retrieval engine that drastically\nimproves the efficiency of XTR-based ColBERT retrievers through three key\ninnovations: (1) WARP$_\\text{SELECT}$ for dynamic similarity imputation, (2)\nimplicit decompression to bypass costly vector reconstruction, and (3) a\ntwo-stage reduction process for efficient scoring. Combined with optimized C++\nkernels and specialized inference runtimes, WARP reduces end-to-end latency by\n41x compared to XTR's reference implementation and thereby achieves a 3x\nspeedup over PLAID from the the official ColBERT implementation.\n  We study the efficiency of multi-vector retrieval methods like ColBERT and\nits recent variant XTR. We introduce WARP, a retrieval engine that drastically\nimproves the efficiency of XTR-based ColBERT retrievers through three key\ninnovations: (1) WARP$_\\text{SELECT}$ for dynamic similarity imputation, (2)\nimplicit decompression during retrieval, and (3) a two-stage reduction process\nfor efficient scoring. Thanks also to highly-optimized C++ kernels and to the\nadoption of specialized inference runtimes, WARP can reduce end-to-end query\nlatency relative to XTR's reference implementation by 41x. And it thereby\nachieves a 3x speedup over the official ColBERTv2 PLAID engine, while\npreserving retrieval quality.\n","authors":["Jan Luca Scheerer","Matei Zaharia","Christopher Potts","Gustavo Alonso","Omar Khattab"],"pdf_url":"https://arxiv.org/pdf/2501.17788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.17998v2","updated":"2025-01-29T17:17:56Z","published":"2024-12-23T21:42:31Z","title":"WavePulse: Real-time Content Analytics of Radio Livestreams","summary":"  Radio remains a pervasive medium for mass information dissemination, with\nAM/FM stations reaching more Americans than either smartphone-based social\nnetworking or live television. Increasingly, radio broadcasts are also streamed\nonline and accessed over the Internet. We present WavePulse, a framework that\nrecords, documents, and analyzes radio content in real-time. While our\nframework is generally applicable, we showcase the efficacy of WavePulse in a\ncollaborative project with a team of political scientists focusing on the 2024\nPresidential Elections. We use WavePulse to monitor livestreams of 396 news\nradio stations over a period of three months, processing close to 500,000 hours\nof audio streams. These streams were converted into time-stamped, diarized\ntranscripts and analyzed to track answer key political science questions at\nboth the national and state levels. Our analysis revealed how local issues\ninteracted with national trends, providing insights into information flow. Our\nresults demonstrate WavePulse's efficacy in capturing and analyzing content\nfrom radio livestreams sourced from the Web. Code and dataset can be accessed\nat \\url{https://wave-pulse.io}.\n","authors":["Govind Mittal","Sarthak Gupta","Shruti Wagle","Chirag Chopra","Anthony J DeMattee","Nasir Memon","Mustaque Ahamad","Chinmay Hegde"],"pdf_url":"https://arxiv.org/pdf/2412.17998v2.pdf","comment":"To appear at The Web Conference (WWW) 2025. 20 Pages, 24 figures.\n  Access code and dataset at https://wave-pulse.io"},{"id":"http://arxiv.org/abs/2405.11517v3","updated":"2025-01-29T16:26:36Z","published":"2024-05-19T11:12:10Z","title":"On the Convergence of No-Regret Dynamics in Information Retrieval Games\n  with Proportional Ranking Functions","summary":"  Publishers who publish their content on the web act strategically, in a\nbehavior that can be modeled within the online learning framework. Regret, a\ncentral concept in machine learning, serves as a canonical measure for\nassessing the performance of learning agents within this framework. We prove\nthat any proportional content ranking function with a concave activation\nfunction induces games in which no-regret learning dynamics converge. Moreover,\nfor proportional ranking functions, we prove the equivalence of the concavity\nof the activation function, the social concavity of the induced games and the\nconcavity of the induced games. We also study the empirical trade-offs between\npublishers' and users' welfare, under different choices of the activation\nfunction, using a state-of-the-art no-regret dynamics algorithm. Furthermore,\nwe demonstrate how the choice of the ranking function and changes in the\necosystem structure affect these welfare measures, as well as the dynamics'\nconvergence rate.\n","authors":["Omer Madmon","Idan Pipano","Itamar Reinman","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2405.11517v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17670v1","updated":"2025-01-29T14:20:42Z","published":"2025-01-29T14:20:42Z","title":"Distinguished Quantized Guidance for Diffusion-based Sequence\n  Recommendation","summary":"  Diffusion models (DMs) have emerged as promising approaches for sequential\nrecommendation due to their strong ability to model data distributions and\ngenerate high-quality items. Existing work typically adds noise to the next\nitem and progressively denoises it guided by the user's interaction sequence,\ngenerating items that closely align with user interests. However, we identify\ntwo key issues in this paradigm. First, the sequences are often heterogeneous\nin length and content, exhibiting noise due to stochastic user behaviors. Using\nsuch sequences as guidance may hinder DMs from accurately understanding user\ninterests. Second, DMs are prone to data bias and tend to generate only the\npopular items that dominate the training dataset, thus failing to meet the\npersonalized needs of different users. To address these issues, we propose\nDistinguished Quantized Guidance for Diffusion-based Sequence Recommendation\n(DiQDiff), which aims to extract robust guidance to understand user interests\nand generate distinguished items for personalized user interests within DMs. To\nextract robust guidance, DiQDiff introduces Semantic Vector Quantization (SVQ)\nto quantize sequences into semantic vectors (e.g., collaborative signals and\ncategory interests) using a codebook, which can enrich the guidance to better\nunderstand user interests. To generate distinguished items, DiQDiff\npersonalizes the generation through Contrastive Discrepancy Maximization (CDM),\nwhich maximizes the distance between denoising trajectories using contrastive\nloss to prevent biased generation for different users. Extensive experiments\nare conducted to compare DiQDiff with multiple baseline models across four\nwidely-used datasets. The superior recommendation performance of DiQDiff\nagainst leading approaches demonstrates its effectiveness in sequential\nrecommendation tasks.\n","authors":["Wenyu Mao","Shuchang Liu","Haoyang Liu","Haozhe Liu","Xiang Li","Lanatao Hu"],"pdf_url":"https://arxiv.org/pdf/2501.17670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17630v1","updated":"2025-01-29T13:08:17Z","published":"2025-01-29T13:08:17Z","title":"Uncertainty Quantification and Decomposition for LLM-based\n  Recommendation","summary":"  Despite the widespread adoption of large language models (LLMs) for\nrecommendation, we demonstrate that LLMs often exhibit uncertainty in their\nrecommendations. To ensure the trustworthy use of LLMs in generating\nrecommendations, we emphasize the importance of assessing the reliability of\nrecommendations generated by LLMs. We start by introducing a novel framework\nfor estimating the predictive uncertainty to quantitatively measure the\nreliability of LLM-based recommendations. We further propose to decompose the\npredictive uncertainty into recommendation uncertainty and prompt uncertainty,\nenabling in-depth analyses of the primary source of uncertainty. Through\nextensive experiments, we (1) demonstrate predictive uncertainty effectively\nindicates the reliability of LLM-based recommendations, (2) investigate the\norigins of uncertainty with decomposed uncertainty measures, and (3) propose\nuncertainty-aware prompting for a lower predictive uncertainty and enhanced\nrecommendation. Our source code and model weights are available at\nhttps://github.com/WonbinKweon/UNC_LLM_REC_WWW2025\n","authors":["Wonbin Kweon","Sanghwan Jang","SeongKu Kang","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2501.17630v1.pdf","comment":"WWW 2025"},{"id":"http://arxiv.org/abs/2405.05576v2","updated":"2025-01-29T10:59:47Z","published":"2024-05-09T06:52:24Z","title":"LayerPlexRank: Exploring Node Centrality and Layer Influence through\n  Algebraic Connectivity in Multiplex Networks","summary":"  As the calculation of centrality in complex networks becomes increasingly\nvital across technological, biological, and social systems, precise and\nscalable ranking methods are essential for understanding these networks. This\npaper introduces LayerPlexRank, an algorithm that simultaneously assesses node\ncentrality and layer influence in multiplex networks using algebraic\nconnectivity metrics. This method enhances the robustness of the ranking\nalgorithm by effectively assessing structural changes across layers using\nrandom walk, considering the overall connectivity of the graph. We substantiate\nthe utility of LayerPlexRank with theoretical analyses and empirical\nvalidations on varied real-world datasets, contrasting it with established\ncentrality measures.\n","authors":["Hao Ren","Jiaojiao Jiang"],"pdf_url":"https://arxiv.org/pdf/2405.05576v2.pdf","comment":"Published in Proceedings of the 33rd ACM International Conference on\n  Information and Knowledge Management (CIKM '24)"},{"id":"http://arxiv.org/abs/2501.17449v1","updated":"2025-01-29T07:13:27Z","published":"2025-01-29T07:13:27Z","title":"Cross-Language Approach for Quranic QA","summary":"  Question answering systems face critical limitations in languages with\nlimited resources and scarce data, making the development of robust models\nespecially challenging. The Quranic QA system holds significant importance as\nit facilitates a deeper understanding of the Quran, a Holy text for over a\nbillion people worldwide. However, these systems face unique challenges,\nincluding the linguistic disparity between questions written in Modern Standard\nArabic and answers found in Quranic verses written in Classical Arabic, and the\nsmall size of existing datasets, which further restricts model performance. To\naddress these challenges, we adopt a cross-language approach by (1) Dataset\nAugmentation: expanding and enriching the dataset through machine translation\nto convert Arabic questions into English, paraphrasing questions to create\nlinguistic diversity, and retrieving answers from an English translation of the\nQuran to align with multilingual training requirements; and (2) Language Model\nFine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base,\nDeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the\nspecific requirements of Quranic QA. Experimental results demonstrate that this\ncross-language approach significantly improves model performance, with\nRoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while\nDeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These\nfindings underscore the effectiveness of cross-language strategies in\novercoming linguistic barriers and advancing Quranic QA systems\n","authors":["Islam Oshallah","Mohamed Basem","Ali Hamdi","Ammar Mohammed"],"pdf_url":"https://arxiv.org/pdf/2501.17449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04276v2","updated":"2025-01-29T06:51:35Z","published":"2024-12-05T15:59:05Z","title":"Graph-Sequential Alignment and Uniformity: Toward Enhanced\n  Recommendation Systems","summary":"  Graph-based and sequential methods are two popular recommendation paradigms,\neach excelling in its domain but lacking the ability to leverage signals from\nthe other. To address this, we propose a novel method that integrates both\napproaches for enhanced performance. Our framework uses Graph Neural Network\n(GNN)-based and sequential recommenders as separate submodules while sharing a\nunified embedding space optimized jointly. To enable positive knowledge\ntransfer, we design a loss function that enforces alignment and uniformity both\nwithin and across submodules. Experiments on three real-world datasets\ndemonstrate that the proposed method significantly outperforms using either\napproach alone and achieves state-of-the-art results. Our implementations are\npublicly available at https://github.com/YuweiCao-UIC/GSAU.git.\n","authors":["Yuwei Cao","Liangwei Yang","Zhiwei Liu","Yuqing Liu","Chen Wang","Yueqing Liang","Hao Peng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2412.04276v2.pdf","comment":"Accepted to The Web Conference 2025"},{"id":"http://arxiv.org/abs/2501.17409v1","updated":"2025-01-29T04:22:29Z","published":"2025-01-29T04:22:29Z","title":"Value Function Decomposition in Markov Recommendation Process","summary":"  Recent advances in recommender systems have shown that user-system\ninteraction essentially formulates long-term optimization problems, and online\nreinforcement learning can be adopted to improve recommendation performance.\nThe general solution framework incorporates a value function that estimates the\nuser's expected cumulative rewards in the future and guides the training of the\nrecommendation policy. To avoid local maxima, the policy may explore potential\nhigh-quality actions during inference to increase the chance of finding better\nfuture rewards. To accommodate the stepwise recommendation process, one widely\nadopted approach to learning the value function is learning from the difference\nbetween the values of two consecutive states of a user. However, we argue that\nthis paradigm involves an incorrect approximation in the stochastic process.\nSpecifically, between the current state and the next state in each training\nsample, there exist two separate random factors from the stochastic policy and\nthe uncertain user environment. Original temporal difference (TD) learning\nunder these mixed random factors may result in a suboptimal estimation of the\nlong-term rewards. As a solution, we show that these two factors can be\nseparately approximated by decomposing the original temporal difference loss.\nThe disentangled learning framework can achieve a more accurate estimation with\nfaster learning and improved robustness against action exploration. As\nempirical verification of our proposed method, we conduct offline experiments\nwith online simulated environments built based on public datasets.\n","authors":["Xiaobei Wang","Shuchang Liu","Qingpeng Cai","Xiang Li","Lantao Hu","Han li","Guangming Xie"],"pdf_url":"https://arxiv.org/pdf/2501.17409v1.pdf","comment":"14 pages, 9 figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2408.08093v2","updated":"2025-01-29T05:19:41Z","published":"2024-08-15T11:36:18Z","title":"When Video Coding Meets Multimodal Large Language Models: A Unified\n  Paradigm for Video Coding","summary":"  Existing codecs are designed to eliminate intrinsic redundancies to create a\ncompact representation for compression. However, strong external priors from\nMultimodal Large Language Models (MLLMs) have not been explicitly explored in\nvideo compression. Herein, we introduce a unified paradigm for Cross-Modality\nVideo Coding (CMVC), which is a pioneering approach to explore multimodality\nrepresentation and video generative models in video coding. Specifically, on\nthe encoder side, we disentangle a video into spatial content and motion\ncomponents, which are subsequently transformed into distinct modalities to\nachieve very compact representation by leveraging MLLMs. During decoding,\npreviously encoded components and video generation models are leveraged to\ncreate multiple encoding-decoding modes that optimize video reconstruction\nquality for specific decoding requirements, including Text-Text-to-Video (TT2V)\nmode to ensure high-quality semantic information and Image-Text-to-Video (IT2V)\nmode to achieve superb perceptual consistency. In addition, we propose an\nefficient frame interpolation model for IT2V mode via Low-Rank Adaption (LoRA)\ntuning to guarantee perceptual quality, which allows the generated motion cues\nto behave smoothly. Experiments on benchmarks indicate that TT2V achieves\neffective semantic reconstruction, while IT2V exhibits competitive perceptual\nconsistency. These results highlight potential directions for future research\nin video coding.\n","authors":["Pingping Zhang","Jinlong Li","Kecheng Chen","Meng Wang","Long Xu","Haoliang Li","Nicu Sebe","Sam Kwong","Shiqi Wang"],"pdf_url":"https://arxiv.org/pdf/2408.08093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17375v1","updated":"2025-01-29T02:04:03Z","published":"2025-01-29T02:04:03Z","title":"Self-Guided Virtual Reality Therapy for Anxiety: A Systematic Review","summary":"  Virtual reality (VR) technology can be used to treat anxiety symptoms and\ndisorders. However, most VR interventions for anxiety have been therapist\nguided rather than self-guided. This systematic review aimed to examine the\neffectiveness and user experience (i.e., usability, acceptability, safety, and\nattrition rates) of self-guided VR therapy interventions in people with any\nanxiety condition as well as provide future research directions. Peer-reviewed\njournal articles reporting on self-guided VR interventions for anxiety were\nsought from the Cochrane Library, IEEE Explore Digital Library, PsycINFO,\nPubMED, Scopus, and Web of Science databases. Study data from the eligible\narticles were extracted, tabulated, and addressed with a narrative synthesis. A\ntotal of 21 articles met the inclusion criteria. The findings revealed that\nself-guided VR interventions for anxiety can provide an effective treatment of\nsocial anxiety disorder, public speaking anxiety, and specific phobias. User\nexperiences outcomes of safety, usability, and acceptability were generally\npositive and the average attrition rate was low. However, there was a lack of\nstandardised assessments to measure user experiences. Self-guided VR for\nanxiety can provide an engaging approach for effectively and safely treating\ncommon anxiety conditions. Nevertheless, more experimental studies are required\nto examine their use in underrepresented anxiety populations, their long-term\ntreatment effects beyond 12 months, and compare their effectiveness against\nother self-help interventions for anxiety (e.g., internet interventions and\nbibliotherapy).\n","authors":["Winona Graham","Russell Drinkwater","Joshua Kelson","Muhammad Ashad Kabir"],"pdf_url":"https://arxiv.org/pdf/2501.17375v1.pdf","comment":"40 pages, 1 figure, 4 tables"}]},"2025-01-28T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2501.17348v1","updated":"2025-01-28T23:50:02Z","published":"2025-01-28T23:50:02Z","title":"Better Slow than Sorry: Introducing Positive Friction for Reliable\n  Dialogue Systems","summary":"  While theories of discourse and cognitive science have long recognized the\nvalue of unhurried pacing, recent dialogue research tends to minimize friction\nin conversational systems. Yet, frictionless dialogue risks fostering\nuncritical reliance on AI outputs, which can obscure implicit assumptions and\nlead to unintended consequences. To meet this challenge, we propose integrating\npositive friction into conversational AI, which promotes user reflection on\ngoals, critical thinking on system response, and subsequent re-conditioning of\nAI systems. We hypothesize systems can improve goal alignment, modeling of user\nmental states, and task success by deliberately slowing down conversations in\nstrategic moments to ask questions, reveal assumptions, or pause. We present an\nontology of positive friction and collect expert human annotations on\nmulti-domain and embodied goal-oriented corpora. Experiments on these corpora,\nalong with simulated interactions using state-of-the-art systems, suggest\nincorporating friction not only fosters accountable decision-making, but also\nenhances machine understanding of user beliefs and goals, and increases task\nsuccess rates.\n","authors":["Mert İnan","Anthony Sicilia","Suvodip Dey","Vardhan Dongre","Tejas Srinivasan","Jesse Thomason","Gökhan Tür","Dilek Hakkani-Tür","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2501.17348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17338v1","updated":"2025-01-28T23:21:28Z","published":"2025-01-28T23:21:28Z","title":"Inferring from Logits: Exploring Best Practices for Decoding-Free\n  Generative Candidate Selection","summary":"  Generative Language Models rely on autoregressive decoding to produce the\noutput sequence token by token. Many tasks such as preference optimization,\nrequire the model to produce task-level output consisting of multiple tokens\ndirectly by selecting candidates from a pool as predictions. Determining a\ntask-level prediction from candidates using the ordinary token-level decoding\nmechanism is constrained by time-consuming decoding and interrupted gradients\nby discrete token selection. Existing works have been using decoding-free\ncandidate selection methods to obtain candidate probability from initial output\nlogits over vocabulary. Though these estimation methods are widely used, they\nare not systematically evaluated, especially on end tasks. We introduce an\nevaluation of a comprehensive collection of decoding-free candidate selection\napproaches on a comprehensive set of tasks, including five multiple-choice QA\ntasks with a small candidate pool and four clinical decision tasks with a\nmassive amount of candidates, some with 10k+ options. We evaluate the\nestimation methods paired with a wide spectrum of foundation LMs covering\ndifferent architectures, sizes and training paradigms. The results and insights\nfrom our analysis inform the future model design.\n","authors":["Mingyu Derek Ma","Yanna Ding","Zijie Huang","Jianxi Gao","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2501.17338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12026v2","updated":"2025-01-28T23:14:21Z","published":"2024-03-18T17:57:02Z","title":"FlexCap: Describe Anything in Images in Controllable Detail","summary":"  We introduce FlexCap, a vision-language model that generates region-specific\ndescriptions of varying lengths. FlexCap is trained to produce\nlength-conditioned captions for input boxes, enabling control over information\ndensity, with descriptions ranging from concise object labels to detailed\ncaptions. To achieve this, we create large-scale training datasets of image\nregion descriptions with varying lengths from captioned web images. We\ndemonstrate FlexCap's effectiveness in several applications: first, it achieves\nstrong performance in dense captioning tasks on the Visual Genome dataset.\nSecond, we show how FlexCap's localized descriptions can serve as input to a\nlarge language model to create a visual question answering (VQA) system,\nachieving state-of-the-art zero-shot performance on multiple VQA benchmarks.\nOur experiments illustrate FlexCap's utility for tasks including image\nlabeling, object attribute recognition, and visual dialog. Project webpage:\nhttps://flex-cap.github.io .\n","authors":["Debidatta Dwibedi","Vidhi Jain","Jonathan Tompson","Andrew Zisserman","Yusuf Aytar"],"pdf_url":"https://arxiv.org/pdf/2403.12026v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.17330v1","updated":"2025-01-28T22:48:29Z","published":"2025-01-28T22:48:29Z","title":"Attribution analysis of legal language as used by LLM","summary":"  Three publicly-available LLM specifically designed for legal tasks have been\nimplemented and shown that classification accuracy can benefit from training\nover legal corpora, but why and how? Here we use two publicly-available legal\ndatasets, a simpler binary classification task of ``overruling'' texts, and a\nmore elaborate multiple choice task identifying ``holding'' judicial decisions.\nWe report on experiments contrasting the legal LLM and a generic BERT model for\ncomparison, against both datasets. We use integrated gradient attribution\ntechniques to impute ``causes'' of variation in the models' perfomance, and\ncharacterize them in terms of the tokenizations each use. We find that while\nall models can correctly classify some test examples from the casehold task,\nother examples can only be identified by only one, model, and attribution can\nbe used to highlight the reasons for this. We find that differential behavior\nof the models' tokenizers accounts for most of the difference and analyze these\ndifferences in terms of the legal language they process. Frequency analysis of\ntokens generated by dataset texts, combined with use of known ``stop word''\nlists, allow identification of tokens that are clear signifiers of legal\ntopics.\n","authors":["Richard K. Belew"],"pdf_url":"https://arxiv.org/pdf/2501.17330v1.pdf","comment":"9 pages, 17 figures"},{"id":"http://arxiv.org/abs/2501.17326v1","updated":"2025-01-28T22:38:45Z","published":"2025-01-28T22:38:45Z","title":"Memorize and Rank: Elevating Large Language Models for Clinical\n  Diagnosis Prediction","summary":"  Clinical diagnosis prediction models, when provided with a patient's medical\nhistory, aim to detect potential diseases early, facilitating timely\nintervention and improving prognostic outcomes. However, the inherent scarcity\nof patient data and large disease candidate space often pose challenges in\ndeveloping satisfactory models for this intricate task. The exploration of\nleveraging Large Language Models (LLMs) for encapsulating clinical decision\nprocesses has been limited. We introduce MERA, a clinical diagnosis prediction\nmodel that bridges pertaining natural language knowledge with medical practice.\nWe apply hierarchical contrastive learning on a disease candidate ranking list\nto alleviate the large decision space issue. With concept memorization through\nfine-tuning, we bridge the natural language clinical knowledge with medical\ncodes. Experimental results on MIMIC-III and IV datasets show that MERA\nachieves the state-of-the-art diagnosis prediction performance and dramatically\nelevates the diagnosis prediction capabilities of generative LMs.\n","authors":["Mingyu Derek Ma","Xiaoxuan Wang","Yijia Xiao","Anthony Cuturrufo","Vijay S Nori","Eran Halperin","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2501.17326v1.pdf","comment":"To appear at AAAI 2025"},{"id":"http://arxiv.org/abs/2410.02159v2","updated":"2025-01-28T21:19:25Z","published":"2024-10-03T02:53:51Z","title":"Mitigating Memorization In Language Models","summary":"  Language models (LMs) can \"memorize\" information, i.e., encode training data\nin their weights in such a way that inference-time queries can lead to verbatim\nregurgitation of that data. This ability to extract training data can be\nproblematic, for example, when data are private or sensitive. In this work, we\ninvestigate methods to mitigate memorization: three regularizer-based, three\nfinetuning-based, and eleven machine unlearning-based methods, with five of the\nlatter being new methods that we introduce. We also introduce TinyMem, a suite\nof small, computationally-efficient LMs for the rapid development and\nevaluation of memorization-mitigation methods. We demonstrate that the\nmitigation methods that we develop using TinyMem can successfully be applied to\nproduction-grade LMs, and we determine via experiment that: regularizer-based\nmitigation methods are slow and ineffective at curbing memorization;\nfine-tuning-based methods are effective at curbing memorization, but overly\nexpensive, especially for retaining higher accuracies; and unlearning-based\nmethods are faster and more effective, allowing for the precise localization\nand removal of memorized information from LM weights prior to inference. We\nshow, in particular, that our proposed unlearning method BalancedSubnet\noutperforms other mitigation methods at removing memorized information while\npreserving performance on target tasks.\n","authors":["Mansi Sakarvadia","Aswathy Ajith","Arham Khan","Nathaniel Hudson","Caleb Geniesse","Kyle Chard","Yaoqing Yang","Ian Foster","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2410.02159v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17299v1","updated":"2025-01-28T21:06:52Z","published":"2025-01-28T21:06:52Z","title":"\"Ownership, Not Just Happy Talk\": Co-Designing a Participatory Large\n  Language Model for Journalism","summary":"  Journalism has emerged as an essential domain for understanding the uses,\nlimitations, and impacts of large language models (LLMs) in the workplace. News\norganizations face divergent financial incentives: LLMs already permeate\nnewswork processes within financially constrained organizations, even as\nongoing legal challenges assert that AI companies violate their copyright. At\nstake are key questions about what LLMs are created to do, and by whom: How\nmight a journalist-led LLM work, and what can participatory design illuminate\nabout the present-day challenges about adapting ``one-size-fits-all''\nfoundation models to a given context of use? In this paper, we undertake a\nco-design exploration to understand how a participatory approach to LLMs might\naddress opportunities and challenges around AI in journalism. Our 20 interviews\nwith reporters, data journalists, editors, labor organizers, product leads, and\nexecutives highlight macro, meso, and micro tensions that designing for this\nopportunity space must address. From these desiderata, we describe the result\nof our co-design work: organizational structures and functionality for a\njournalist-controlled LLM. In closing, we discuss the limitations of commercial\nfoundation models for workplace use, and the methodological implications of\napplying participatory methods to LLM co-design.\n","authors":["Emily Tseng","Meg Young","Marianne Aubin Le Quéré","Aimee Rinehart","Harini Suresh"],"pdf_url":"https://arxiv.org/pdf/2501.17299v1.pdf","comment":"Under review for an ACM conference"},{"id":"http://arxiv.org/abs/2501.17295v1","updated":"2025-01-28T20:58:43Z","published":"2025-01-28T20:58:43Z","title":"Mitigating Hallucinated Translations in Large Language Models with\n  Hallucination-focused Preference Optimization","summary":"  Machine Translation (MT) is undergoing a paradigm shift, with systems based\non fine-tuned large language models (LLM) becoming increasingly competitive\nwith traditional encoder-decoder models trained specifically for translation\ntasks. However, LLM-based systems are at a higher risk of generating\nhallucinations, which can severely undermine user's trust and safety. Most\nprior research on hallucination mitigation focuses on traditional MT models,\nwith solutions that involve post-hoc mitigation - detecting hallucinated\ntranslations and re-translating them. While effective, this approach introduces\nadditional complexity in deploying extra tools in production and also increases\nlatency. To address these limitations, we propose a method that intrinsically\nlearns to mitigate hallucinations during the model training phase.\nSpecifically, we introduce a data creation framework to generate hallucination\nfocused preference datasets. Fine-tuning LLMs on these preference datasets\nreduces the hallucination rate by an average of 96% across five language pairs,\nwhile preserving overall translation quality. In a zero-shot setting our\napproach reduces hallucinations by 89% on an average across three unseen target\nlanguages.\n","authors":["Zilu Tang","Rajen Chatterjee","Sarthak Garg"],"pdf_url":"https://arxiv.org/pdf/2501.17295v1.pdf","comment":"NAACL 2025 Main Conference Long paper (9 pages)"},{"id":"http://arxiv.org/abs/2501.17286v1","updated":"2025-01-28T20:37:32Z","published":"2025-01-28T20:37:32Z","title":"Fine-Tuning Open-Source Large Language Models to Improve Their\n  Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate\n  Their Potential Clinical Applications in Radiation Oncology","summary":"  Background: The radiation oncology clinical practice involves many steps\nrelying on the dynamic interplay of abundant text data. Large language models\nhave displayed remarkable capabilities in processing complex text information.\nBut their direct applications in specific fields like radiation oncology remain\nunderexplored.\n  Purpose: This study aims to investigate whether fine-tuning LLMs with domain\nknowledge can improve the performance on Task (1) treatment regimen generation,\nTask (2) treatment modality selection (photon, proton, electron, or\nbrachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.\n  Methods: Data for 15,724 patient cases were extracted. Cases where patients\nhad a single diagnostic record, and a clearly identifiable primary treatment\nplan were selected for preprocessing and manual annotation to have 7,903 cases\nof the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.\nEach case was used to construct a pair consisting of patient diagnostics\ndetails and an answer (treatment regimen, treatment modality, or ICD-10 code\nrespectively) for the supervised fine-tuning of these three tasks. Open source\nLLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the\nLow-Rank Approximations method. Accuracy and ROUGE-1 score were reported for\nthe fine-tuned models and original models. Clinical evaluation was performed on\nTask (1) by radiation oncologists, while precision, recall, and F-1 score were\nevaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used\nto statistically analyze the results.\n  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with\np-value <= 0.001. Clinical evaluation demonstrated that over 60% of the\nfine-tuned LLMs-generated treatment regimens were clinically acceptable.\nPrecision, recall, and F1-score showed improved performance of fine-tuned LLMs.\n","authors":["Peilong Wang","Zhengliang Liu","Yiwei Li","Jason Holmes","Peng Shu","Lian Zhang","Xiang Li","Quanzheng Li","Brady S. Laughlin","Diego Santos Toesca","Sujay A. Vora","Samir H. Patel","Terence T. Sio","Tianming Liu","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2501.17286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14184v2","updated":"2025-01-28T20:06:22Z","published":"2024-02-22T00:04:21Z","title":"Beyond Simple Averaging: Improving NLP Ensemble Performance with\n  Topological-Data-Analysis-Based Weighting","summary":"  In machine learning, ensembles are important tools for improving the model\nperformance. In natural language processing specifically, ensembles boost the\nperformance of a method due to multiple large models available in open source.\nHowever, existing approaches mostly rely on simple averaging of predictions by\nensembles with equal weights for each model, ignoring differences in the\nquality and conformity of models. We propose to estimate weights for ensembles\nof NLP models using not only knowledge of their individual performance but also\ntheir similarity to each other. By adopting distance measures based on\nTopological Data Analysis (TDA), we improve our ensemble. The quality improves\nfor both text classification accuracy and relevant uncertainty estimation.\n","authors":["Polina Proskura","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2402.14184v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17273v1","updated":"2025-01-28T20:06:09Z","published":"2025-01-28T20:06:09Z","title":"Tailored Truths: Optimizing LLM Persuasion with Personalization and\n  Fabricated Statistics","summary":"  Large Language Models (LLMs) are becoming increasingly persuasive,\ndemonstrating the ability to personalize arguments in conversation with humans\nby leveraging their personal data. This may have serious impacts on the scale\nand effectiveness of disinformation campaigns. We studied the persuasiveness of\nLLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated\narguments intended to change the human's opinion. We quantified the LLM's\neffect by measuring human agreement with the debate's hypothesis pre- and\npost-debate and analyzing both the magnitude of opinion change, as well as the\nlikelihood of an update in the LLM's direction. We compare persuasiveness\nacross established persuasion strategies, including personalized arguments\ninformed by user demographics and personality, appeal to fabricated statistics,\nand a mixed strategy utilizing both personalized arguments and fabricated\nstatistics. We found that static arguments generated by humans and GPT-4o-mini\nhave comparable persuasive power. However, the LLM outperformed static\nhuman-written arguments when leveraging the mixed strategy in an interactive\ndebate setting. This approach had a $\\mathbf{51\\%}$ chance of persuading\nparticipants to modify their initial position, compared to $\\mathbf{32\\%}$ for\nthe static human-written arguments. Our results highlight the concerning\npotential for LLMs to enable inexpensive and persuasive large-scale\ndisinformation campaigns.\n","authors":["Jasper Timm","Chetan Talele","Jacob Haimes"],"pdf_url":"https://arxiv.org/pdf/2501.17273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17270v1","updated":"2025-01-28T20:02:10Z","published":"2025-01-28T20:02:10Z","title":"Comprehensive Evaluation for a Large Scale Knowledge Graph Question\n  Answering Service","summary":"  Question answering systems for knowledge graph (KGQA), answer factoid\nquestions based on the data in the knowledge graph. KGQA systems are complex\nbecause the system has to understand the relations and entities in the\nknowledge-seeking natural language queries and map them to structured queries\nagainst the KG to answer them. In this paper, we introduce Chronos, a\ncomprehensive evaluation framework for KGQA at industry scale. It is designed\nto evaluate such a multi-component system comprehensively, focusing on (1)\nend-to-end and component-level metrics, (2) scalable to diverse datasets and\n(3) a scalable approach to measure the performance of the system prior to\nrelease. In this paper, we discuss the unique challenges associated with\nevaluating KGQA systems at industry scale, review the design of Chronos, and\nhow it addresses these challenges. We will demonstrate how it provides a base\nfor data-driven decisions and discuss the challenges of using it to measure and\nimprove a real-world KGQA system.\n","authors":["Saloni Potdar","Daniel Lee","Omar Attia","Varun Embar","De Meng","Ramesh Balaji","Chloe Seivwright","Eric Choi","Mina H. Farid","Yiwen Sun","Yunyao Li"],"pdf_url":"https://arxiv.org/pdf/2501.17270v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17265v1","updated":"2025-01-28T19:46:18Z","published":"2025-01-28T19:46:18Z","title":"Giving the Old a Fresh Spin: Quality Estimation-Assisted Constrained\n  Decoding for Automatic Post-Editing","summary":"  Automatic Post-Editing (APE) systems often struggle with over-correction,\nwhere unnecessary modifications are made to a translation, diverging from the\nprinciple of minimal editing. In this paper, we propose a novel technique to\nmitigate over-correction by incorporating word-level Quality Estimation (QE)\ninformation during the decoding process. This method is architecture-agnostic,\nmaking it adaptable to any APE system, regardless of the underlying model or\ntraining approach. Our experiments on English-German, English-Hindi, and\nEnglish-Marathi language pairs show the proposed approach yields significant\nimprovements over their corresponding baseline APE systems, with TER gains of\n$0.65$, $1.86$, and $1.44$ points, respectively. These results underscore the\ncomplementary relationship between QE and APE tasks and highlight the\neffectiveness of integrating QE information to reduce over-correction in APE\nsystems.\n","authors":["Sourabh Deoghare","Diptesh Kanojia","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2501.17265v1.pdf","comment":"Accepted to NAACL 2025 Main Conference: Short Papers"},{"id":"http://arxiv.org/abs/2409.06131v2","updated":"2025-01-28T19:18:51Z","published":"2024-09-10T00:59:18Z","title":"Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn,\n  Focus, and Review","summary":"  Traditional Large Language Model (LLM) pretraining relies on autoregressive\nlanguage modeling with randomly sampled data from web-scale datasets. Inspired\nby human learning techniques like spaced repetition, we hypothesize that random\nsampling leads to high training costs, lower-quality models, and significant\ndata forgetting. To address these inefficiencies, we propose the\nLearn-Focus-Review (LFR) paradigm -- a dynamic training approach that adapts to\nthe model's learning progress. LFR tracks the model's learning performance\nacross data blocks (sequences of tokens) and prioritizes revisiting challenging\nregions of the dataset that are more prone to being forgotten, enabling better\nretention and more efficient learning. Using the LFR paradigm, we pretrained\nLlama and GPT models on the SlimPajama and OpenWebText datasets, respectively.\nThese models were evaluated on downstream tasks across various domains,\nincluding question answering, problem-solving, commonsense reasoning, language\nmodeling, and translation. Compared to baseline models trained on the full\ndatasets, LFR consistently achieved lower perplexity and higher accuracy, while\nusing only 5%--19% of the training tokens. Furthermore, LFR matched the\nperformance of industry-standard Pythia models with up to 2$\\times$ the\nparameter count, using just 3.2% of the training tokens, demonstrating its\neffectiveness and efficiency.\n","authors":["Neha Prakriya","Jui-Nan Yen","Cho-Jui Hsieh","Jason Cong"],"pdf_url":"https://arxiv.org/pdf/2409.06131v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17144v1","updated":"2025-01-28T18:45:07Z","published":"2025-01-28T18:45:07Z","title":"FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data","summary":"  Prior research on training grounded factuality classification models to\ndetect hallucinations in large language models (LLMs) has relied on public\nnatural language inference (NLI) data and synthetic data. However, conventional\nNLI datasets are not well-suited for document-level reasoning, which is\ncritical for detecting LLM hallucinations. Recent approaches to document-level\nsynthetic data generation involve iteratively removing sentences from documents\nand annotating factuality using LLM-based prompts. While effective, this method\nis computationally expensive for long documents and limited by the LLM's\ncapabilities. In this work, we analyze the differences between existing\nsynthetic training data used in state-of-the-art models and real LLM output\nclaims. Based on our findings, we propose a novel approach for synthetic data\ngeneration, CG2C, that leverages multi-hop reasoning on context graphs\nextracted from documents. Our fact checker model, FactCG, demonstrates improved\nperformance with more connected reasoning, using the same backbone models.\nExperiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark\nwith much smaller model size.\n","authors":["Deren Lei","Yaxi Li","Siyao Li","Mengya Hu","Rui Xu","Ken Archer","Mingyu Wang","Emily Ching","Alex Deng"],"pdf_url":"https://arxiv.org/pdf/2501.17144v1.pdf","comment":"NAACL 2025"},{"id":"http://arxiv.org/abs/2501.17132v1","updated":"2025-01-28T18:25:11Z","published":"2025-01-28T18:25:11Z","title":"ASTRAL: Automated Safety Testing of Large Language Models","summary":"  Large Language Models (LLMs) have recently gained attention due to their\nability to understand and generate sophisticated human-like content. However,\nensuring their safety is paramount as they might provide harmful and unsafe\nresponses. Existing LLM testing frameworks address various safety-related\nconcerns (e.g., drugs, terrorism, animal abuse) but often face challenges due\nto unbalanced and obsolete datasets. In this paper, we present ASTRAL, a tool\nthat automates the generation and execution of test cases (i.e., prompts) for\ntesting the safety of LLMs. First, we introduce a novel black-box coverage\ncriterion to generate balanced and diverse unsafe test inputs across a diverse\nset of safety categories as well as linguistic writing characteristics (i.e.,\ndifferent style and persuasive writing techniques). Second, we propose an\nLLM-based approach that leverages Retrieval Augmented Generation (RAG),\nfew-shot prompting strategies and web browsing to generate up-to-date test\ninputs. Lastly, similar to current LLM test automation techniques, we leverage\nLLMs as test oracles to distinguish between safe and unsafe test outputs,\nallowing a fully automated testing approach. We conduct an extensive evaluation\non well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms\nother LLMs when acting as the test oracle, accurately detecting unsafe\nresponses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs\nthat are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard);\nii) the results confirm that our approach can uncover nearly twice as many\nunsafe LLM behaviors with the same number of test inputs compared to currently\nused static datasets; and iii) our black-box coverage criterion combined with\nweb browsing can effectively guide the LLM on generating up-to-date unsafe test\ninputs, significantly increasing the number of unsafe LLM behaviors.\n","authors":["Miriam Ugarte","Pablo Valle","José Antonio Parejo","Sergio Segura","Aitor Arrieta"],"pdf_url":"https://arxiv.org/pdf/2501.17132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07978v3","updated":"2025-01-28T18:23:59Z","published":"2024-08-15T06:52:24Z","title":"Coupling without Communication and Drafter-Invariant Speculative\n  Decoding","summary":"  Suppose Alice has a distribution $P$ and Bob has a distribution $Q$. Alice\nwants to draw a sample $a\\sim P$ and Bob a sample $b \\sim Q$ such that $a = b$\nwith as high of probability as possible. It is well-known that, by sampling\nfrom an optimal coupling between the distributions, Alice and Bob can achieve\n$\\Pr[a = b] = 1 - D_{TV}(P,Q)$, where $D_{TV}(P,Q)$ is the total variation\ndistance between $P$ and $Q$. What if Alice and Bob must solve this same\nproblem \\emph{without communicating at all?} Perhaps surprisingly, with access\nto public randomness, they can still achieve $\\Pr[a = b] \\geq \\frac{1 -\nD_{TV}(P,Q)}{1 + D_{TV}(P,Q)} \\geq 1-2D_{TV}(P,Q)$ using a simple protocol\nbased on the Weighted MinHash algorithm. This bound was shown to be optimal in\nthe worst-case by [Bavarian et al., 2020]. In this work, we revisit the\ncommunication-free coupling problem. We provide a simpler proof of the\noptimality result from [Bavarian et al., 2020]. We show that, while the\nworst-case success probability of Weighted MinHash cannot be improved, an\nequally simple protocol based on Gumbel sampling offers a Pareto improvement:\nfor every pair of distributions $P, Q$, Gumbel sampling achieves an equal or\nhigher value of $\\Pr[a = b]$ than Weighted MinHash. Importantly, this\nimprovement translates to practice. We demonstrate an application of\ncommunication-free coupling to \\emph{speculative decoding}, a recent method for\naccelerating autoregressive large language models [Leviathan, Kalman, Matias,\nICML 2023]. We show that communication-free protocols can be used to contruct\n\\emph{\\CSD{}} schemes, which have the desirable property that their output is\nfixed given a fixed random seed, regardless of what drafter is used for\nspeculation. In experiments on a language generation task, Gumbel sampling\noutperforms Weighted MinHash. Code is available at\nhttps://github.com/majid-daliri/DISD.\n","authors":["Majid Daliri","Christopher Musco","Ananda Theertha Suresh"],"pdf_url":"https://arxiv.org/pdf/2408.07978v3.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2501.17117v1","updated":"2025-01-28T18:07:30Z","published":"2025-01-28T18:07:30Z","title":"Histoires Morales: A French Dataset for Assessing Moral Alignment","summary":"  Aligning language models with human values is crucial, especially as they\nbecome more integrated into everyday life. While models are often adapted to\nuser preferences, it is equally important to ensure they align with moral norms\nand behaviours in real-world social situations. Despite significant progress in\nlanguages like English and Chinese, French has seen little attention in this\narea, leaving a gap in understanding how LLMs handle moral reasoning in this\nlanguage. To address this gap, we introduce Histoires Morales, a French dataset\nderived from Moral Stories, created through translation and subsequently\nrefined with the assistance of native speakers to guarantee grammatical\naccuracy and adaptation to the French cultural context. We also rely on\nannotations of the moral values within the dataset to ensure their alignment\nwith French norms. Histoires Morales covers a wide range of social situations,\nincluding differences in tipping practices, expressions of honesty in\nrelationships, and responsibilities toward animals. To foster future research,\nwe also conduct preliminary experiments on the alignment of multilingual models\non French and English data and the robustness of the alignment. We find that\nwhile LLMs are generally aligned with human moral norms by default, they can be\neasily influenced with user-preference optimization for both moral and immoral\ndata.\n","authors":["Thibaud Leteno","Irina Proskurina","Antoine Gourru","Julien Velcin","Charlotte Laclau","Guillaume Metzler","Christophe Gravier"],"pdf_url":"https://arxiv.org/pdf/2501.17117v1.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2501.17116v1","updated":"2025-01-28T18:04:50Z","published":"2025-01-28T18:04:50Z","title":"Optimizing Large Language Model Training Using FP4 Quantization","summary":"  The growing computational demands of training large language models (LLMs)\nnecessitate more efficient methods. Quantized training presents a promising\nsolution by enabling low-bit arithmetic operations to reduce these costs. While\nFP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge\ndue to significant quantization errors and limited representational capacity.\nThis work introduces the first FP4 training framework for LLMs, addressing\nthese challenges with two key innovations: a differentiable quantization\nestimator for precise weight updates and an outlier clamping and compensation\nstrategy to prevent activation collapse. To ensure stability, the framework\nintegrates a mixed-precision training scheme and vector-wise quantization.\nExperimental results demonstrate that our FP4 framework achieves accuracy\ncomparable to BF16 and FP8, with minimal degradation, scaling effectively to\n13B-parameter LLMs trained on up to 100B tokens. With the emergence of\nnext-generation hardware supporting FP4, our framework sets a foundation for\nefficient ultra-low precision training.\n","authors":["Ruizhe Wang","Yeyun Gong","Xiao Liu","Guoshuai Zhao","Ziyue Yang","Baining Guo","Zhengjun Zha","Peng Cheng"],"pdf_url":"https://arxiv.org/pdf/2501.17116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14917v2","updated":"2025-01-28T18:00:22Z","published":"2025-01-24T20:54:29Z","title":"Self-reflecting Large Language Models: A Hegelian Dialectical Approach","summary":"  Investigating NLP through a philosophical lens has recently caught\nresearcher's eyes as it connects computational methods with classical schools\nof philosophy. This paper introduces a philosophical approach inspired by the\nHegelian Dialectic for LLMs' self-reflection, utilizing a self-dialectical\napproach to emulate internal critiques and then synthesize new ideas by\nresolving the contradicting points. Moreover, this paper investigates the\neffect of LLMs' temperature for generation by establishing a dynamic annealing\napproach, which promotes the creativity in the early stages and gradually\nrefines it by focusing on the nuances, as well as a fixed temperature strategy\nfor generation. Our proposed approach is examined to determine its ability to\ngenerate novel ideas from an initial proposition. Additionally, a Multi Agent\nMajority Voting (MAMV) strategy is leveraged to assess the validity and novelty\nof the generated ideas, which proves beneficial in the absence of domain\nexperts. Our experiments show promise in generating new ideas and provide a\nstepping stone for future research.\n","authors":["Sara Abdali","Can Goksen","Saeed Amizadeh","Kazuhito Koishida"],"pdf_url":"https://arxiv.org/pdf/2501.14917v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17104v1","updated":"2025-01-28T17:44:04Z","published":"2025-01-28T17:44:04Z","title":"COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via\n  Language Models","summary":"  We present COS(M+O)S, a System 2-inspired framework for open-ended plot\ndevelopment that systematically explores the vast space of possible story\nexpansions, enabling a 3B-parameter language model to approach the plot quality\nof a 70B model on select short-story tasks. The method accomplishes this by\ncombining Monte Carlo Tree Search (MCTS), guided by a step-level value model\nthat rewards moderate surprisal (curiosity) while penalizing incoherence, and\nOdds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value\nplot expansions. This iterative reinforcement learning loop systematically\nexplores multiple candidate plot branches, backpropagates quality signals, and\nadapts the policy for faster convergence, notably shifting the policy from\npuzzle-based Chain-of-Thought to more character-driven storytelling. In\nsmall-scale tests with short-story prompts, 67%-77% of participants favored\nCOS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our\nlearned value function aligns. GPT-4o ratings further show that COS(M+O)S\nsurpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming\nwithin 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise\ncomparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no\nstatistically significant gap from 70B. Nevertheless, absolute story quality\nremains modest, constrained by the small model's capacity and limited training\ndata.\n","authors":["Tobias Materzok"],"pdf_url":"https://arxiv.org/pdf/2501.17104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08099v3","updated":"2025-01-28T17:33:40Z","published":"2024-12-11T04:53:15Z","title":"Adversarial Vulnerabilities in Large Language Models for Time Series\n  Forecasting","summary":"  Large Language Models (LLMs) have recently demonstrated significant potential\nin the field of time series forecasting, offering impressive capabilities in\nhandling complex temporal data. However, their robustness and reliability in\nreal-world applications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like TimeGPT and LLM-Time with GPT-3.5,\nGPT-4, LLaMa, and Mistral, show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications.\n","authors":["Fuqiang Liu","Sicong Jiang","Luis Miranda-Moreno","Seongjin Choi","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2412.08099v3.pdf","comment":"AISTATS 2025"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2501.17039v1","updated":"2025-01-28T16:03:52Z","published":"2025-01-28T16:03:52Z","title":"Enhanced Retrieval of Long Documents: Leveraging Fine-Grained Block\n  Representations with Large Language Models","summary":"  In recent years, large language models (LLMs) have demonstrated exceptional\npower in various domains, including information retrieval. Most of the previous\npractices involve leveraging these models to create a single embedding for each\nquery, each passage, or each document individually, a strategy exemplified and\nused by the Retrieval-Augmented Generation (RAG) framework. While this method\nhas proven effective, we argue that it falls short in fully capturing the\nnuanced intricacies of document-level texts due to its reliance on a relatively\ncoarse-grained representation. To address this limitation, we introduce a\nnovel, fine-grained approach aimed at enhancing the accuracy of relevance\nscoring for long documents. Our methodology firstly segments a long document\ninto blocks, each of which is embedded using an LLM, for matching with the\nquery representation. When calculating the relevance score, we aggregate the\nquery-block relevance scores through a weighted sum method, yielding a\ncomprehensive score for the query with the entire document. Despite its\napparent simplicity, our experimental findings reveal that this approach\noutperforms standard representation methods and achieves a significant\nreduction in embedding generation latency. Moreover, by carefully optimizing\npairwise loss functions, superior performances have been achieved.\n","authors":["Minghan Li","Eric Gaussier","Guodong Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.17039v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09560v2","updated":"2025-01-28T13:17:29Z","published":"2024-12-12T18:46:38Z","title":"Foundational Large Language Models for Materials Research","summary":"  Materials discovery and development are critical for addressing global\nchallenges. Yet, the exponential growth in materials science literature\ncomprising vast amounts of textual data has created significant bottlenecks in\nknowledge extraction, synthesis, and scientific reasoning. Large Language\nModels (LLMs) offer unprecedented opportunities to accelerate materials\nresearch through automated analysis and prediction. Still, their effective\ndeployment requires domain-specific adaptation for understanding and solving\ndomain-relevant tasks. Here, we present LLaMat, a family of foundational models\nfor materials science developed through continued pretraining of LLaMA models\non an extensive corpus of materials literature and crystallographic data.\nThrough systematic evaluation, we demonstrate that LLaMat excels in\nmaterials-specific NLP and structured information extraction while maintaining\ngeneral linguistic capabilities. The specialized LLaMat-CIF variant\ndemonstrates unprecedented capabilities in crystal structure generation,\npredicting stable crystals with high coverage across the periodic table.\nIntriguingly, despite LLaMA-3's superior performance in comparison to LLaMA-2,\nwe observe that LLaMat-2 demonstrates unexpectedly enhanced domain-specific\nperformance across diverse materials science tasks, including structured\ninformation extraction from text and tables, more particularly in crystal\nstructure generation, a potential adaptation rigidity in overtrained LLMs.\nAltogether, the present work demonstrates the effectiveness of domain\nadaptation towards developing practically deployable LLM copilots for materials\nresearch. Beyond materials science, our findings reveal important\nconsiderations for domain adaptation of LLMs, such as model selection, training\nmethodology, and domain-specific performance, which may influence the\ndevelopment of specialized scientific AI systems.\n","authors":["Vaibhav Mishra","Somaditya Singh","Dhruv Ahlawat","Mohd Zaki","Vaibhav Bihani","Hargun Singh Grover","Biswajit Mishra","Santiago Miret"," Mausam","N. M. Anoop Krishnan"],"pdf_url":"https://arxiv.org/pdf/2412.09560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16902v1","updated":"2025-01-28T12:40:37Z","published":"2025-01-28T12:40:37Z","title":"Document Screenshot Retrievers are Vulnerable to Pixel Poisoning Attacks","summary":"  Recent advancements in dense retrieval have introduced vision-language model\n(VLM)-based retrievers, such as DSE and ColPali, which leverage document\nscreenshots embedded as vectors to enable effective search and offer a\nsimplified pipeline over traditional text-only methods. In this study, we\npropose three pixel poisoning attack methods designed to compromise VLM-based\nretrievers and evaluate their effectiveness under various attack settings and\nparameter configurations. Our empirical results demonstrate that injecting even\na single adversarial screenshot into the retrieval corpus can significantly\ndisrupt search results, poisoning the top-10 retrieved documents for 41.9% of\nqueries in the case of DSE and 26.4% for ColPali. These vulnerability rates\nnotably exceed those observed with equivalent attacks on text-only retrievers.\nMoreover, when targeting a small set of known queries, the attack success rate\nraises, achieving complete success in certain cases. By exposing the\nvulnerabilities inherent in vision-language models, this work highlights the\npotential risks associated with their deployment.\n","authors":["Shengyao Zhuang","Ekaterina Khramtsova","Xueguang Ma","Bevan Koopman","Jimmy Lin","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2501.16902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16888v1","updated":"2025-01-28T12:18:09Z","published":"2025-01-28T12:18:09Z","title":"Secure Federated Graph-Filtering for Recommender Systems","summary":"  Recommender systems often rely on graph-based filters, such as normalized\nitem-item adjacency matrices and low-pass filters. While effective, the\ncentralized computation of these components raises concerns about privacy,\nsecurity, and the ethical use of user data. This work proposes two\ndecentralized frameworks for securely computing these critical graph components\nwithout centralizing sensitive information. The first approach leverages\nlightweight Multi-Party Computation and distributed singular vector\ncomputations to privately compute key graph filters. The second extends this\nframework by incorporating low-rank approximations, enabling a trade-off\nbetween communication efficiency and predictive performance. Empirical\nevaluations on benchmark datasets demonstrate that the proposed methods achieve\ncomparable accuracy to centralized state-of-the-art systems while ensuring data\nconfidentiality and maintaining low communication costs. Our results highlight\nthe potential for privacy-preserving decentralized architectures to bridge the\ngap between utility and user data protection in modern recommender systems.\n","authors":["Julien Nicolas","César Sabater","Mohamed Maouche","Sonia Ben Mokhtar","Mark Coates"],"pdf_url":"https://arxiv.org/pdf/2501.16888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14848v2","updated":"2025-01-28T06:00:44Z","published":"2024-06-21T03:33:51Z","title":"Leveraging Passage Embeddings for Efficient Listwise Reranking with\n  Large Language Models","summary":"  Recent studies have demonstrated the effectiveness of using large language\nlanguage models (LLMs) in passage ranking. The listwise approaches, such as\nRankGPT, have become new state-of-the-art in this task. However, the efficiency\nof RankGPT models is limited by the maximum context length and relatively high\nlatency of LLM inference. To address these issues, in this paper, we propose\nPE-Rank, leveraging the single passage embedding as a good context compression\nfor efficient listwise passage reranking. By treating each passage as a special\ntoken, we can directly input passage embeddings into LLMs, thereby reducing\ninput length. Additionally, we introduce an inference method that dynamically\nconstrains the decoding space to these special tokens, accelerating the\ndecoding process. For adapting the model to reranking, we employ listwise\nlearning to rank loss for training. Evaluation results on multiple benchmarks\ndemonstrate that PE-Rank significantly improves efficiency in both prefilling\nand decoding, while maintaining competitive ranking effectiveness. The Code is\navailable at https://github.com/liuqi6777/pe_rank.\n","authors":["Qi Liu","Bo Wang","Nan Wang","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2406.14848v2.pdf","comment":"Accepted by WWW 2025"},{"id":"http://arxiv.org/abs/2501.16722v1","updated":"2025-01-28T05:59:29Z","published":"2025-01-28T05:59:29Z","title":"Hypergraph Diffusion for High-Order Recommender Systems","summary":"  Recommender systems rely on Collaborative Filtering (CF) to predict user\npreferences by leveraging patterns in historical user-item interactions. While\ntraditional CF methods primarily focus on learning compact vector embeddings\nfor users and items, graph neural network (GNN)-based approaches have emerged\nas a powerful alternative, utilizing the structure of user-item interaction\ngraphs to enhance recommendation accuracy. However, existing GNN-based models,\nsuch as LightGCN and UltraGCN, often struggle with two major limitations: an\ninability to fully account for heterophilic interactions, where users engage\nwith diverse item categories, and the over-smoothing problem in multi-layer\nGNNs, which hinders their ability to model complex, high-order relationships.\nTo address these gaps, we introduce WaveHDNN, an innovative wavelet-enhanced\nhypergraph diffusion framework. WaveHDNN integrates a Heterophily-aware\nCollaborative Encoder, designed to capture user-item interactions across\ndiverse categories, with a Multi-scale Group-wise Structure Encoder, which\nleverages wavelet transforms to effectively model localized graph structures.\nAdditionally, cross-view contrastive learning is employed to maintain robust\nand consistent representations. Experiments on benchmark datasets validate the\nefficacy of WaveHDNN, demonstrating its superior ability to capture both\nheterophilic and localized structural information, leading to improved\nrecommendation performance.\n","authors":["Darnbi Sakong","Thanh Trung Huynh","Jun Jo"],"pdf_url":"https://arxiv.org/pdf/2501.16722v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2501.15183v2","updated":"2025-01-28T03:45:40Z","published":"2025-01-25T11:45:49Z","title":"Generating Negative Samples for Multi-Modal Recommendation","summary":"  Multi-modal recommender systems (MMRS) have gained significant attention due\nto their ability to leverage information from various modalities to enhance\nrecommendation quality. However, existing negative sampling techniques often\nstruggle to effectively utilize the multi-modal data, leading to suboptimal\nperformance. In this paper, we identify two key challenges in negative sampling\nfor MMRS: (1) producing cohesive negative samples contrasting with positive\nsamples and (2) maintaining a balanced influence across different modalities.\nTo address these challenges, we propose NegGen, a novel framework that utilizes\nmulti-modal large language models (MLLMs) to generate balanced and contrastive\nnegative samples. We design three different prompt templates to enable NegGen\nto analyze and manipulate item attributes across multiple modalities, and then\ngenerate negative samples that introduce better supervision signals and ensure\nmodality balance. Furthermore, NegGen employs a causal learning module to\ndisentangle the effect of intervened key features and irrelevant item\nattributes, enabling fine-grained learning of user preferences. Extensive\nexperiments on real-world datasets demonstrate the superior performance of\nNegGen compared to state-of-the-art methods in both negative sampling and\nmulti-modal recommendation.\n","authors":["Yanbiao Ji","Yue Ding","Dan Luo","Chang Liu","Jing Tong","Shaokai Wu","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2501.15183v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16672v1","updated":"2025-01-28T03:13:16Z","published":"2025-01-28T03:13:16Z","title":"VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic\n  Health Records","summary":"  Methods to ensure factual accuracy of text generated by large language models\n(LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence\nsystem that combines retrieval-augmented generation and LLM-as-a-Judge to\nverify whether LLM-generated text is factually supported by a patient's medical\nhistory based on their electronic health record (EHR). To evaluate this system,\nwe introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course\nnarratives from discharge summaries into a set of simple statements with\nclinician annotations for whether each statement is supported by the patient's\nEHR clinical notes. Whereas highest agreement between clinicians was 88.5%,\nVeriFact achieves up to 92.7% agreement when compared to a denoised and\nadjudicated average human clinican ground truth, suggesting that VeriFact\nexceeds the average clinician's ability to fact-check text against a patient's\nmedical record. VeriFact may accelerate the development of LLM-based EHR\napplications by removing current evaluation bottlenecks.\n","authors":["Philip Chung","Akshay Swaminathan","Alex J. Goodell","Yeasul Kim","S. Momsen Reincke","Lichy Han","Ben Deverett","Mohammad Amin Sadeghi","Abdel-Badih Ariss","Marc Ghanem","David Seong","Andrew A. Lee","Caitlin E. Coombes","Brad Bradshaw","Mahir A. Sufian","Hyo Jung Hong","Teresa P. Nguyen","Mohammad R. Rasouli","Komal Kamra","Mark A. Burbridge","James C. McAvoy","Roya Saffary","Stephen P. Ma","Dev Dash","James Xie","Ellen Y. Wang","Clifford A. Schmiesing","Nigam Shah","Nima Aghaeepour"],"pdf_url":"https://arxiv.org/pdf/2501.16672v1.pdf","comment":"62 pages, 5 figures, 1 table, pre-print manuscript"}],"Multimedia":[{"id":"http://arxiv.org/abs/2501.17011v1","updated":"2025-01-28T15:17:36Z","published":"2025-01-28T15:17:36Z","title":"MIDI-GPT: A Controllable Generative Model for Computer-Assisted\n  Multitrack Music Composition","summary":"  We present and release MIDI-GPT, a generative system based on the Transformer\narchitecture that is designed for computer-assisted music composition\nworkflows. MIDI-GPT supports the infilling of musical material at the track and\nbar level, and can condition generation on attributes including: instrument\ntype, musical style, note density, polyphony level, and note duration. In order\nto integrate these features, we employ an alternative representation for\nmusical material, creating a time-ordered sequence of musical events for each\ntrack and concatenating several tracks into a single sequence, rather than\nusing a single time-ordered sequence where the musical events corresponding to\ndifferent tracks are interleaved. We also propose a variation of our\nrepresentation allowing for expressiveness. We present experimental results\nthat demonstrate that MIDI-GPT is able to consistently avoid duplicating the\nmusical material it was trained on, generate music that is stylistically\nsimilar to the training dataset, and that attribute controls allow enforcing\nvarious constraints on the generated material. We also outline several\nreal-world applications of MIDI-GPT, including collaborations with industry\npartners that explore the integration and evaluation of MIDI-GPT into\ncommercial products, as well as several artistic works produced using it.\n","authors":["Philippe Pasquier","Jeff Ens","Nathan Fradet","Paul Triana","Davide Rizzotti","Jean-Baptiste Rolland","Maryam Safi"],"pdf_url":"https://arxiv.org/pdf/2501.17011v1.pdf","comment":"AAAI 25"},{"id":"http://arxiv.org/abs/2501.08137v2","updated":"2025-01-28T09:14:14Z","published":"2025-01-14T14:15:10Z","title":"Audio-Visual Deepfake Detection With Local Temporal Inconsistencies","summary":"  This paper proposes an audio-visual deepfake detection approach that aims to\ncapture fine-grained temporal inconsistencies between audio and visual\nmodalities. To achieve this, both architectural and data synthesis strategies\nare introduced. From an architectural perspective, a temporal distance map,\ncoupled with an attention mechanism, is designed to capture these\ninconsistencies while minimizing the impact of irrelevant temporal\nsubsequences. Moreover, we explore novel pseudo-fake generation techniques to\nsynthesize local inconsistencies. Our approach is evaluated against\nstate-of-the-art methods using the DFDC and FakeAVCeleb datasets, demonstrating\nits effectiveness in detecting audio-visual deepfakes.\n","authors":["Marcella Astrid","Enjie Ghorbel","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2501.08137v2.pdf","comment":"Accepted in ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.16780v1","updated":"2025-01-28T08:05:22Z","published":"2025-01-28T08:05:22Z","title":"AVE Speech Dataset: A Comprehensive Benchmark for Multi-Modal Speech\n  Recognition Integrating Audio, Visual, and Electromyographic Signals","summary":"  The global aging population faces considerable challenges, particularly in\ncommunication, due to the prevalence of hearing and speech impairments. To\naddress these, we introduce the AVE speech dataset, a comprehensive multi-modal\nbenchmark for speech recognition tasks. The dataset includes a 100-sentence\nMandarin Chinese corpus with audio signals, lip-region video recordings, and\nsix-channel electromyography (EMG) data, collected from 100 participants. Each\nsubject read the entire corpus ten times, with each sentence averaging\napproximately two seconds in duration, resulting in over 55 hours of\nmulti-modal speech data per modality. Experiments demonstrate that combining\nthese modalities significantly improves recognition performance, particularly\nin cross-subject and high-noise environments. To our knowledge, this is the\nfirst publicly available sentence-level dataset integrating these three\nmodalities for large-scale Mandarin speech recognition. We expect this dataset\nto drive advancements in both acoustic and non-acoustic speech recognition\nresearch, enhancing cross-modal learning and human-machine interaction.\n","authors":["Dongliang Zhou","Yakun Zhang","Jinghan Wu","Xingyu Zhang","Liang Xie","Erwei Yin"],"pdf_url":"https://arxiv.org/pdf/2501.16780v1.pdf","comment":null}]},"2025-01-27T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2501.16450v1","updated":"2025-01-27T19:14:52Z","published":"2025-01-27T19:14:52Z","title":"360Brew: A Decoder-only Foundation Model for Personalized Ranking and\n  Recommendation","summary":"  Ranking and recommendation systems are the foundation for numerous online\nexperiences, ranging from search results to personalized content delivery.\nThese systems have evolved into complex, multilayered architectures that\nleverage vast datasets and often incorporate thousands of predictive models.\nThe maintenance and enhancement of these models is a labor intensive process\nthat requires extensive feature engineering. This approach not only exacerbates\ntechnical debt but also hampers innovation in extending these systems to\nemerging problem domains. In this report, we present our research to address\nthese challenges by utilizing a large foundation model with a textual interface\nfor ranking and recommendation tasks. We illustrate several key advantages of\nour approach: (1) a single model can manage multiple predictive tasks involved\nin ranking and recommendation, (2) decoder models with textual interface due to\ntheir comprehension of reasoning capabilities, can generalize to new\nrecommendation surfaces and out-of-domain problems, and (3) by employing\nnatural language interfaces for task definitions and verbalizing member\nbehaviors and their social connections, we eliminate the need for feature\nengineering and the maintenance of complex directed acyclic graphs of model\ndependencies. We introduce our research pre-production model, 360Brew V1.0, a\n150B parameter, decoder-only model that has been trained and fine-tuned on\nLinkedIn's data and tasks. This model is capable of solving over 30 predictive\ntasks across various segments of the LinkedIn platform, achieving performance\nlevels comparable to or exceeding those of current production systems based on\noffline metrics, without task-specific fine-tuning. Notably, each of these\ntasks is conventionally addressed by dedicated models that have been developed\nand maintained over multiple years by teams of a similar or larger size than\nour own.\n","authors":["Hamed Firooz","Maziar Sanjabi","Adrian Englhardt","Aman Gupta","Ben Levine","Dre Olgiati","Gungor Polatkan","Iuliia Melnychuk","Karthik Ramgopal","Kirill Talanine","Kutta Srinivasan","Luke Simon","Natesh Sivasubramoniapillai","Necip Fazil Ayan","Qingquan Song","Samira Sriram","Souvik Ghosh","Tao Song","Vignesh Kothapalli","Xiaoling Zhai","Ya Xu","Yu Wang","Yun Dai"],"pdf_url":"https://arxiv.org/pdf/2501.16450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16303v1","updated":"2025-01-27T18:45:07Z","published":"2025-01-27T18:45:07Z","title":"RAPID: Retrieval-Augmented Parallel Inference Drafting for Text-Based\n  Video Event Retrieval","summary":"  Retrieving events from videos using text queries has become increasingly\nchallenging due to the rapid growth of multimedia content. Existing methods for\ntext-based video event retrieval often focus heavily on object-level\ndescriptions, overlooking the crucial role of contextual information. This\nlimitation is especially apparent when queries lack sufficient context, such as\nmissing location details or ambiguous background elements. To address these\nchallenges, we propose a novel system called RAPID (Retrieval-Augmented\nParallel Inference Drafting), which leverages advancements in Large Language\nModels (LLMs) and prompt-based learning to semantically correct and enrich user\nqueries with relevant contextual information. These enriched queries are then\nprocessed through parallel retrieval, followed by an evaluation step to select\nthe most relevant results based on their alignment with the original query.\nThrough extensive experiments on our custom-developed dataset, we demonstrate\nthat RAPID significantly outperforms traditional retrieval methods,\nparticularly for contextually incomplete queries. Our system was validated for\nboth speed and accuracy through participation in the Ho Chi Minh City AI\nChallenge 2024, where it successfully retrieved events from over 300 hours of\nvideo. Further evaluation comparing RAPID with the baseline proposed by the\ncompetition organizers demonstrated its superior effectiveness, highlighting\nthe strength and robustness of our approach.\n","authors":["Long Nguyen","Huy Nguyen","Bao Khuu","Huy Luu","Huy Le","Tuan Nguyen","Tho Quan"],"pdf_url":"https://arxiv.org/pdf/2501.16303v1.pdf","comment":"Under review at SoICT'24"},{"id":"http://arxiv.org/abs/2501.16276v1","updated":"2025-01-27T18:10:34Z","published":"2025-01-27T18:10:34Z","title":"URAG: Implementing a Unified Hybrid RAG for Precise Answers in\n  University Admission Chatbots -- A Case Study at HCMUT","summary":"  With the rapid advancement of Artificial Intelligence, particularly in\nNatural Language Processing, Large Language Models (LLMs) have become pivotal\nin educational question-answering systems, especially university admission\nchatbots. Concepts such as Retrieval-Augmented Generation (RAG) and other\nadvanced techniques have been developed to enhance these systems by integrating\nspecific university data, enabling LLMs to provide informed responses on\nadmissions and academic counseling. However, these enhanced RAG techniques\noften involve high operational costs and require the training of complex,\nspecialized modules, which poses challenges for practical deployment.\nAdditionally, in the educational context, it is crucial to provide accurate\nanswers to prevent misinformation, a task that LLM-based systems find\nchallenging without appropriate strategies and methods. In this paper, we\nintroduce the Unified RAG (URAG) Framework, a hybrid approach that\nsignificantly improves the accuracy of responses, particularly for critical\nqueries. Experimental results demonstrate that URAG enhances our in-house,\nlightweight model to perform comparably to state-of-the-art commercial models.\nMoreover, to validate its practical applicability, we conducted a case study at\nour educational institution, which received positive feedback and acclaim. This\nstudy not only proves the effectiveness of URAG but also highlights its\nfeasibility for real-world implementation in educational settings.\n","authors":["Long Nguyen","Tho Quan"],"pdf_url":"https://arxiv.org/pdf/2501.16276v1.pdf","comment":"Under review at SoICT'24"},{"id":"http://arxiv.org/abs/2409.04432v2","updated":"2025-01-27T18:03:08Z","published":"2024-09-06T17:54:43Z","title":"A Survey on Knowledge Organization Systems of Research Fields: Resources\n  and Challenges","summary":"  Knowledge Organization Systems (KOSs), such as term lists, thesauri,\ntaxonomies, and ontologies, play a fundamental role in categorising, managing,\nand retrieving information. In the academic domain, KOSs are often adopted for\nrepresenting research areas and their relationships, primarily aiming to\nclassify research articles, academic courses, patents, books, scientific\nvenues, domain experts, grants, software, experiment materials, and several\nother relevant products and agents. These structured representations of\nresearch areas, widely embraced by many academic fields, have proven effective\nin empowering AI-based systems to i) enhance retrievability of relevant\ndocuments, ii) enable advanced analytic solutions to quantify the impact of\nacademic research, and iii) analyse and forecast research dynamics. This paper\naims to present a comprehensive survey of the current KOS for academic\ndisciplines. We analysed and compared 45 KOSs according to five main\ndimensions: scope, structure, curation, usage, and links to other KOSs. Our\nresults reveal a very heterogeneous scenario in terms of scope, scale, quality,\nand usage, highlighting the need for more integrated solutions for representing\nresearch knowledge across academic fields. We conclude by discussing the main\nchallenges and the most promising future directions.\n","authors":["Angelo Salatino","Tanay Aggarwal","Andrea Mannocci","Francesco Osborne","Enrico Motta"],"pdf_url":"https://arxiv.org/pdf/2409.04432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16214v1","updated":"2025-01-27T17:06:56Z","published":"2025-01-27T17:06:56Z","title":"Provence: efficient and robust context pruning for retrieval-augmented\n  generation","summary":"  Retrieval-augmented generation improves various aspects of large language\nmodels (LLMs) generation, but suffers from computational overhead caused by\nlong contexts as well as the propagation of irrelevant retrieved information\ninto generated responses. Context pruning deals with both aspects, by removing\nirrelevant parts of retrieved contexts before LLM generation. Existing context\npruning approaches are however limited, and do not provide a universal model\nthat would be both efficient and robust in a wide range of scenarios, e.g.,\nwhen contexts contain a variable amount of relevant information or vary in\nlength, or when evaluated on various domains. In this work, we close this gap\nand introduce Provence (Pruning and Reranking Of retrieVEd relevaNt ContExts),\nan efficient and robust context pruner for Question Answering, which\ndynamically detects the needed amount of pruning for a given context and can be\nused out-of-the-box for various domains. The three key ingredients of Provence\nare formulating the context pruning task as sequence labeling, unifying context\npruning capabilities with context reranking, and training on diverse data. Our\nexperimental results show that Provence enables context pruning with negligible\nto no drop in performance, in various domains and settings, at almost no cost\nin a standard RAG pipeline. We also conduct a deeper analysis alongside various\nablations to provide insights into training context pruners for future work.\n","authors":["Nadezhda Chirkova","Thibault Formal","Vassilina Nikoulina","Stéphane Clinchant"],"pdf_url":"https://arxiv.org/pdf/2501.16214v1.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2501.16171v1","updated":"2025-01-27T16:13:50Z","published":"2025-01-27T16:13:50Z","title":"Separate This, and All of these Things Around It: Music Source\n  Separation via Hyperellipsoidal Queries","summary":"  Music source separation is an audio-to-audio retrieval task of extracting one\nor more constituent components, or composites thereof, from a musical audio\nmixture. Each of these constituent components is often referred to as a \"stem\"\nin literature. Historically, music source separation has been dominated by a\nstem-based paradigm, leading to most state-of-the-art systems being either a\ncollection of single-stem extraction models, or a tightly coupled system with a\nfixed, difficult-to-modify, set of supported stems. Combined with the limited\ndata availability, advances in music source separation have thus been mostly\nlimited to the \"VDBO\" set of stems: \\textit{vocals}, \\textit{drum},\n\\textit{bass}, and the catch-all \\textit{others}. Recent work in music source\nseparation has begun to challenge the fixed-stem paradigm, moving towards\nmodels able to extract any musical sound as long as this target type of sound\ncould be specified to the model as an additional query input. We generalize\nthis idea to a \\textit{query-by-region} source separation system, specifying\nthe target based on the query regardless of how many sound sources or which\nsound classes are contained within it. To do so, we propose the use of\nhyperellipsoidal regions as queries to allow for an intuitive yet easily\nparametrizable approach to specifying both the target (location) as well as its\nspread. Evaluation of the proposed system on the MoisesDB dataset demonstrated\nstate-of-the-art performance of the proposed system both in terms of\nsignal-to-noise ratios and retrieval metrics.\n","authors":["Karn N. Watcharasupat","Alexander Lerch"],"pdf_url":"https://arxiv.org/pdf/2501.16171v1.pdf","comment":"Submitted to the 2025 International Joint Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2501.16125v1","updated":"2025-01-27T15:12:27Z","published":"2025-01-27T15:12:27Z","title":"SampleLLM: Optimizing Tabular Data Synthesis in Recommendations","summary":"  Tabular data synthesis is crucial in machine learning, yet existing general\nmethods-primarily based on statistical or deep learning models-are highly\ndata-dependent and often fall short in recommender systems. This limitation\narises from their difficulty in capturing complex distributions and\nunderstanding feature relationships from sparse and limited data, along with\ntheir inability to grasp semantic feature relations. Recently, Large Language\nModels (LLMs) have shown potential in generating synthetic data samples through\nfew-shot learning and semantic understanding. However, they often suffer from\ninconsistent distribution and lack of diversity due to their inherent\ndistribution disparity with the target dataset. To address these challenges and\nenhance tabular data synthesis for recommendation tasks, we propose a novel\ntwo-stage framework named SampleLLM to improve the quality of LLM-based tabular\ndata synthesis for recommendations by ensuring better distribution alignment.\nIn the first stage, SampleLLM employs LLMs with Chain-of-Thought prompts and\ndiverse exemplars to generate data that closely aligns with the target dataset\ndistribution, even when input samples are limited. The second stage uses an\nadvanced feature attribution-based importance sampling method to refine feature\nrelationships within the synthesized data, reducing any distribution biases\nintroduced by the LLM. Experimental results on three recommendation datasets,\ntwo general datasets, and online deployment illustrate that SampleLLM\nsignificantly surpasses existing methods for recommendation tasks and holds\npromise for a broader range of tabular data scenarios.\n","authors":["Jingtong Gao","Zhaocheng Du","Xiaopeng Li","Xiangyu Zhao","Yichao Wang","Xiangyang Li","Huifeng Guo","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2501.16125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17890v3","updated":"2025-01-27T15:12:02Z","published":"2024-05-28T07:12:06Z","title":"SLMRec: Distilling Large Language Models into Small for Sequential\n  Recommendation","summary":"  Sequential Recommendation (SR) task involves predicting the next item a user\nis likely to interact with, given their past interactions. The SR models\nexamine the sequence of a user's actions to discern more complex behavioral\npatterns and temporal dynamics. Recent research demonstrates the great impact\nof LLMs on sequential recommendation systems, either viewing sequential\nrecommendation as language modeling or serving as the backbone for user\nrepresentation. Although these methods deliver outstanding performance, there\nis scant evidence of the necessity of a large language model and how large the\nlanguage model is needed, especially in the sequential recommendation scene.\nMeanwhile, due to the huge size of LLMs, it is inefficient and impractical to\napply a LLM-based model in real-world platforms that often need to process\nbillions of traffic logs daily. In this paper, we explore the influence of\nLLMs' depth by conducting extensive experiments on large-scale industry\ndatasets. Surprisingly, our motivational experiments reveal that most\nintermediate layers of LLMs are redundant, indicating that pruning the\nremaining layers can still maintain strong performance. Motivated by this\ninsight, we empower small language models for SR, namely SLMRec, which adopt a\nsimple yet effective knowledge distillation method. Moreover, SLMRec is\northogonal to other post-training efficiency techniques, such as quantization\nand pruning, so that they can be leveraged in combination. Comprehensive\nexperimental results illustrate that the proposed SLMRec model attains the best\nperformance using only 13% of the parameters found in LLM-based recommendation\nmodels while simultaneously achieving up to 6.6x and 8.0x speedups in training\nand inference time costs, respectively. Besides, we provide a theoretical\njustification for why small language models can perform comparably to large\nlanguage models in SR.\n","authors":["Wujiang Xu","Qitian Wu","Zujie Liang","Jiaojiao Han","Xuying Ning","Yunxiao Shi","Wenfang Lin","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.17890v3.pdf","comment":"International Conference on Learning Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2501.16112v1","updated":"2025-01-27T15:04:00Z","published":"2025-01-27T15:04:00Z","title":"Survey: Understand the challenges of MachineLearning Experts using Named\n  EntityRecognition Tools","summary":"  This paper presents a survey based on Kasunic's survey research methodology\nto identify the criteria used by Machine Learning (ML) experts to evaluate\nNamed Entity Recognition (NER) tools and frameworks. Comparison and selection\nof NER tools and frameworks is a critical step in leveraging NER for\nInformation Retrieval to support the development of Clinical Practice\nGuidelines. In addition, this study examines the main challenges faced by ML\nexperts when choosing suitable NER tools and frameworks. Using Nunamaker's\nmethodology, the article begins with an introduction to the topic,\ncontextualizes the research, reviews the state-of-the-art in science and\ntechnology, and identifies challenges for an expert survey on NER tools and\nframeworks. This is followed by a description of the survey's design and\nimplementation. The paper concludes with an evaluation of the survey results\nand the insights gained, ending with a summary and conclusions.\n","authors":["Florian Freund","Philippe Tamla","Matthias Hemmje"],"pdf_url":"https://arxiv.org/pdf/2501.16112v1.pdf","comment":"20 Pages, 13 Figures, 6th International Conference on Natural\n  Language Processing, Information Retrieval and AI (NIAI 2025) January 25 ~\n  26, 2025, Copenhagen, Denmark"},{"id":"http://arxiv.org/abs/2501.16111v1","updated":"2025-01-27T15:03:26Z","published":"2025-01-27T15:03:26Z","title":"Options-Aware Dense Retrieval for Multiple-Choice query Answering","summary":"  Long-context multiple-choice question answering tasks require robust\nreasoning over extensive text sources. Since most of the pre-trained\ntransformer models are restricted to processing only a few hundred words at a\ntime, successful completion of such tasks often relies on the identification of\nevidence spans, such as sentences, that provide supporting evidence for\nselecting the correct answer. Prior research in this domain has predominantly\nutilized pre-trained dense retrieval models, given the absence of supervision\nto fine-tune the retrieval process. This paper proposes a novel method called\nOptions Aware Dense Retrieval (OADR) to address these challenges. ORDA uses an\ninnovative approach to fine-tuning retrieval by leveraging query-options\nembeddings, which aim to mimic the embeddings of the oracle query (i.e., the\nquery paired with the correct answer) for enhanced identification of supporting\nevidence. Through experiments conducted on the QuALITY benchmark dataset, we\ndemonstrate that our proposed model surpasses existing baselines in terms of\nperformance and accuracy.\n","authors":["Manish Singh","Manish Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2501.16111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00080v4","updated":"2025-01-27T14:55:40Z","published":"2024-04-30T16:35:08Z","title":"Recommenadation aided Caching using Combinatorial Multi-armed Bandits","summary":"  We study content caching with recommendations in a wireless network where the\nusers are connected through a base station equipped with a finite-capacity\ncache. We assume a fixed set of contents with unknown user preferences and\ncontent popularities. The base station can cache a subset of the contents and\ncan also recommend subsets of the contents to different users in order to\nencourage them to request the recommended contents. Recommendations, depending\non their acceptability, can thus be used to increase cache hits. We first\nassume that the users' recommendation acceptabilities are known and formulate\nthe cache hit optimization problem as a combinatorial multi-armed bandit\n(CMAB). We propose a UCB-based algorithm to decide which contents to cache and\nrecommend and provide an upper bound on the regret of this algorithm.\nSubsequently, we consider a more general scenario where the users'\nrecommendation acceptabilities are also unknown and propose another UCB-based\nalgorithm that learns these as well. We numerically demonstrate the performance\nof our algorithms and compare these to state-of-the-art algorithms.\n","authors":["Pavamana K J","Chandramani Kishore Singh"],"pdf_url":"https://arxiv.org/pdf/2405.00080v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16075v1","updated":"2025-01-27T14:26:27Z","published":"2025-01-27T14:26:27Z","title":"PISCO: Pretty Simple Compression for Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) pipelines enhance Large Language Models\n(LLMs) by retrieving relevant documents, but they face scalability issues due\nto high inference costs and limited context size. Document compression is a\npractical solution, but current soft compression methods suffer from accuracy\nlosses and require extensive pretraining. In this paper, we introduce PISCO, a\nnovel method that achieves a 16x compression rate with minimal accuracy loss\n(0-3%) across diverse RAG-based question-answering (QA) tasks. Unlike existing\napproaches, PISCO requires no pretraining or annotated data, relying solely on\nsequence-level knowledge distillation from document-based questions. With the\nability to fine-tune a 7-10B LLM in 48 hours on a single A100 GPU, PISCO offers\na highly efficient and scalable solution. We present comprehensive experiments\nshowing that PISCO outperforms existing compression models by 8% in accuracy.\n","authors":["Maxime Louis","Hervé Déjean","Stéphane Clinchant"],"pdf_url":"https://arxiv.org/pdf/2501.16075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15953v1","updated":"2025-01-27T10:57:24Z","published":"2025-01-27T10:57:24Z","title":"Understanding Long Videos via LLM-Powered Entity Relation Graphs","summary":"  The analysis of extended video content poses unique challenges in artificial\nintelligence, particularly when dealing with the complexity of tracking and\nunderstanding visual elements across time. Current methodologies that process\nvideo frames sequentially struggle to maintain coherent tracking of objects,\nespecially when these objects temporarily vanish and later reappear in the\nfootage. A critical limitation of these approaches is their inability to\neffectively identify crucial moments in the video, largely due to their limited\ngrasp of temporal relationships. To overcome these obstacles, we present\nGraphVideoAgent, a cutting-edge system that leverages the power of graph-based\nobject tracking in conjunction with large language model capabilities. At its\ncore, our framework employs a dynamic graph structure that maps and monitors\nthe evolving relationships between visual entities throughout the video\nsequence. This innovative approach enables more nuanced understanding of how\nobjects interact and transform over time, facilitating improved frame selection\nthrough comprehensive contextual awareness. Our approach demonstrates\nremarkable effectiveness when tested against industry benchmarks. In\nevaluations on the EgoSchema dataset, GraphVideoAgent achieved a 2.2\nimprovement over existing methods while requiring analysis of only 8.2 frames\non average. Similarly, testing on the NExT-QA benchmark yielded a 2.0\nperformance increase with an average frame requirement of 8.1. These results\nunderscore the efficiency of our graph-guided methodology in enhancing both\naccuracy and computational performance in long-form video understanding tasks.\n","authors":["Meng Chu","Yicong Li","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2501.15953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15915v1","updated":"2025-01-27T10:04:49Z","published":"2025-01-27T10:04:49Z","title":"Parametric Retrieval Augmented Generation","summary":"  Retrieval-augmented generation (RAG) techniques have emerged as a promising\nsolution to enhance the reliability of large language models (LLMs) by\naddressing issues like hallucinations, outdated knowledge, and domain\nadaptation. In particular, existing RAG methods append relevant documents\nretrieved from external corpus or databases to the input of LLMs to guide their\ngeneration process, which we refer to as the in-context knowledge injection\nmethod. While this approach is simple and often effective, it has inherent\nlimitations. Firstly, increasing the context length and number of relevant\ndocuments can lead to higher computational overhead and degraded performance,\nespecially in complex reasoning tasks. More importantly, in-context knowledge\ninjection operates primarily at the input level, but LLMs store their internal\nknowledge in their parameters. This gap fundamentally limits the capacity of\nin-context methods. To this end, we introduce Parametric retrieval-augmented\ngeneration (Parametric RAG), a new RAG paradigm that integrates external\nknowledge directly into the parameters of feed-forward networks (FFN) of an LLM\nthrough document parameterization. This approach not only saves online\ncomputational costs by eliminating the need to inject multiple documents into\nthe LLMs' input context, but also deepens the integration of external knowledge\ninto the parametric knowledge space of the LLM. Experimental results\ndemonstrate that Parametric RAG substantially enhances both the effectiveness\nand efficiency of knowledge augmentation in LLMs. Also, it can be combined with\nin-context RAG methods to achieve even better performance.\n  We have open-sourced all the code, data, and models in the following\nanonymized GitHub link: https://github.com/oneal2000/PRAG\n","authors":["Weihang Su","Yichen Tang","Qingyao Ai","Junxi Yan","Changyue Wang","Hongning Wang","Ziyi Ye","Yujia Zhou","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2501.15915v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17191v1","updated":"2025-01-27T09:29:55Z","published":"2025-01-27T09:29:55Z","title":"Aspect-Aware Decomposition for Opinion Summarization","summary":"  Opinion summarization plays a key role in deriving meaningful insights from\nlarge-scale online reviews. To make this process more explainable and grounded,\nwe propose a modular approach guided by review aspects which separates the\ntasks of aspect identification, opinion consolidation, and meta-review\nsynthesis, enabling greater transparency and ease of inspection. We conduct\nextensive experiments across datasets representing scientific research,\nbusiness, and product domains. Results show that our method generates more\ngrounded summaries compared to strong baseline models, as verified through\nautomated and human evaluations. Additionally, our modular approach, which\nincorporates reasoning based on review aspects, produces more informative\nintermediate outputs than knowledge-agnostic decomposed prompting. These\nintermediate outputs can also effectively support humans in summarizing\nopinions from large volumes of reviews.\n","authors":["Miao Li","Jey Han Lau","Eduard Hovy","Mirella Lapata"],"pdf_url":"https://arxiv.org/pdf/2501.17191v1.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2501.15817v1","updated":"2025-01-27T06:52:50Z","published":"2025-01-27T06:52:50Z","title":"Long-Term Interest Clock: Fine-Grained Time Perception in Streaming\n  Recommendation System","summary":"  User interests manifest a dynamic pattern within the course of a day, e.g., a\nuser usually favors soft music at 8 a.m. but may turn to ambient music at 10\np.m. To model dynamic interests in a day, hour embedding is widely used in\ntraditional daily-trained industrial recommendation systems. However, its\ndiscreteness can cause periodical online patterns and instability in recent\nstreaming recommendation systems. Recently, Interest Clock has achieved\nremarkable performance in streaming recommendation systems. Nevertheless, it\nmodels users' dynamic interests in a coarse-grained manner, merely encoding\nusers' discrete interests of 24 hours from short-term behaviors. In this paper,\nwe propose a fine-grained method for perceiving time information for streaming\nrecommendation systems, named Long-term Interest Clock (LIC). The key idea of\nLIC is adaptively calculating current user interests by taking into\nconsideration the relevance of long-term behaviors around current time (e.g., 8\na.m.) given a candidate item. LIC consists of two modules: (1) Clock-GSU\nretrieves a sub-sequence by searching through long-term behaviors, using query\ninformation from a candidate item and current time, (2) Clock-ESU employs a\ntime-gap-aware attention mechanism to aggregate sub-sequence with the candidate\nitem. With Clock-GSU and Clock-ESU, LIC is capable of capturing users' dynamic\nfine-grained interests from long-term behaviors. We conduct online A/B tests,\nobtaining +0.122% improvements on user active days. Besides, the extended\noffline experiments show improvements as well. Long-term Interest Clock has\nbeen integrated into Douyin Music App's recommendation system.\n","authors":["Yongchun Zhu","Guanyu Jiang","Jingwu Chen","Feng Zhang","Xiao Yang","Zuotao Liu"],"pdf_url":"https://arxiv.org/pdf/2501.15817v1.pdf","comment":"Accepted by WWW2025"},{"id":"http://arxiv.org/abs/2501.15816v1","updated":"2025-01-27T06:49:27Z","published":"2025-01-27T06:49:27Z","title":"AdaF^2M^2: Comprehensive Learning and Responsive Leveraging Features in\n  Recommendation System","summary":"  Feature modeling, which involves feature representation learning and\nleveraging, plays an essential role in industrial recommendation systems.\nHowever, the data distribution in real-world applications usually follows a\nhighly skewed long-tail pattern due to the popularity bias, which easily leads\nto over-reliance on ID-based features, such as user/item IDs and ID sequences\nof interactions. Such over-reliance makes it hard for models to learn features\ncomprehensively, especially for those non-ID meta features, e.g., user/item\ncharacteristics. Further, it limits the feature leveraging ability in models,\ngetting less generalized and more susceptible to data noise. Previous studies\non feature modeling focus on feature extraction and interaction, hardly\nnoticing the problems brought about by the long-tail data distribution. To\nachieve better feature representation learning and leveraging on real-world\ndata, we propose a model-agnostic framework AdaF^2M^2, short for Adaptive\nFeature Modeling with Feature Mask. The feature-mask mechanism helps\ncomprehensive feature learning via multi-forward training with augmented\nsamples, while the adapter applies adaptive weights on features responsive to\ndifferent user/item states. By arming base models with AdaF^2M^2, we conduct\nonline A/B tests on multiple recommendation scenarios, obtaining +1.37% and\n+1.89% cumulative improvements on user active days and app duration\nrespectively. Besides, the extended offline experiments on different models\nshow improvements as well. AdaF$^2$M$^2$ has been widely deployed on both\nretrieval and ranking tasks in multiple applications of Douyin Group,\nindicating its superior effectiveness and universality.\n","authors":["Yongchun Zhu","Jingwu Chen","Ling Chen","Yitan Li","Feng Zhang","Xiao Yang","Zuotao Liu"],"pdf_url":"https://arxiv.org/pdf/2501.15816v1.pdf","comment":"Accepted by DASFAA2025"},{"id":"http://arxiv.org/abs/2402.02803v2","updated":"2025-01-27T04:30:43Z","published":"2024-02-05T08:25:22Z","title":"Large Language Model Distilling Medication Recommendation Model","summary":"  The recommendation of medication is a vital aspect of intelligent healthcare\nsystems, as it involves prescribing the most suitable drugs based on a\npatient's specific health needs. Unfortunately, many sophisticated models\ncurrently in use tend to overlook the nuanced semantics of medical data, while\nonly relying heavily on identities. Furthermore, these models face significant\nchallenges in handling cases involving patients who are visiting the hospital\nfor the first time, as they lack prior prescription histories to draw upon. To\ntackle these issues, we harness the powerful semantic comprehension and\ninput-agnostic characteristics of Large Language Models (LLMs). Our research\naims to transform existing medication recommendation methodologies using LLMs.\nIn this paper, we introduce a novel approach called Large Language Model\nDistilling Medication Recommendation (LEADER). We begin by creating appropriate\nprompt templates that enable LLMs to suggest medications effectively. However,\nthe straightforward integration of LLMs into recommender systems leads to an\nout-of-corpus issue specific to drugs. We handle it by adapting the LLMs with a\nnovel output layer and a refined tuning loss function. Although LLM-based\nmodels exhibit remarkable capabilities, they are plagued by high computational\ncosts during inference, which is impractical for the healthcare sector. To\nmitigate this, we have developed a feature-level knowledge distillation\ntechnique, which transfers the LLM's proficiency to a more compact model.\nExtensive experiments conducted on two real-world datasets, MIMIC-III and\nMIMIC-IV, demonstrate that our proposed model not only delivers effective\nresults but also is efficient. To ease the reproducibility of our experiments,\nwe release the implementation code online.\n","authors":["Qidong Liu","Xian Wu","Xiangyu Zhao","Yuanshao Zhu","Zijian Zhang","Feng Tian","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2402.02803v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2501.16326v1","updated":"2025-01-27T18:59:02Z","published":"2025-01-27T18:59:02Z","title":"Movement- and Traffic-based User Identification in Commercial Virtual\n  Reality Applications: Threats and Opportunities","summary":"  With the unprecedented diffusion of virtual reality, the number of\napplication scenarios is continuously growing. As commercial and gaming\napplications become pervasive, the need for the secure and convenient\nidentification of users, often overlooked by the research in immersive media,\nis becoming more and more pressing. Networked scenarios such as Cloud gaming or\ncooperative virtual training and teleoperation require both a user-friendly and\nstreamlined experience and user privacy and security. In this work, we\ninvestigate the possibility of identifying users from their movement patterns\nand data traffic traces while playing four commercial games, using a publicly\navailable dataset. If, on the one hand, this paves the way for easy\nidentification and automatic customization of the virtual reality content, it\nalso represents a serious threat to users' privacy due to network\nanalysis-based fingerprinting. Based on this, we analyze the threats and\nopportunities for virtual reality users' security and privacy.\n","authors":["Sara Baldoni","Salim Benhamadi","Federico Chiariotti","Michele Zorzi","Federica Battisti"],"pdf_url":"https://arxiv.org/pdf/2501.16326v1.pdf","comment":"Accepted for publication at IEEE VR 2025"},{"id":"http://arxiv.org/abs/2501.16164v1","updated":"2025-01-27T15:59:58Z","published":"2025-01-27T15:59:58Z","title":"MetaDecorator: Generating Immersive Virtual Tours through Multimodality","summary":"  MetaDecorator, is a framework that empowers users to personalize virtual\nspaces. By leveraging text-driven prompts and image synthesis techniques,\nMetaDecorator adorns static panoramas captured by 360{\\deg} imaging devices,\ntransforming them into uniquely styled and visually appealing environments.\nThis significantly enhances the realism and engagement of virtual tours\ncompared to traditional offerings. Beyond the core framework, we also discuss\nthe integration of Large Language Models (LLMs) and haptics in the VR\napplication to provide a more immersive experience.\n","authors":["Shuang Xie","Yang Liu","Jeannie S. A. Lee","Haiwei Dong"],"pdf_url":"https://arxiv.org/pdf/2501.16164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12791v2","updated":"2025-01-27T10:40:20Z","published":"2024-12-17T10:52:50Z","title":"Implicit Location-Caption Alignment via Complementary Masking for\n  Weakly-Supervised Dense Video Captioning","summary":"  Weakly-Supervised Dense Video Captioning (WSDVC) aims to localize and\ndescribe all events of interest in a video without requiring annotations of\nevent boundaries. This setting poses a great challenge in accurately locating\nthe temporal location of event, as the relevant supervision is unavailable.\nExisting methods rely on explicit alignment constraints between event locations\nand captions, which involve complex event proposal procedures during both\ntraining and inference. To tackle this problem, we propose a novel implicit\nlocation-caption alignment paradigm by complementary masking, which simplifies\nthe complex event proposal and localization process while maintaining\neffectiveness. Specifically, our model comprises two components: a dual-mode\nvideo captioning module and a mask generation module. The dual-mode video\ncaptioning module captures global event information and generates descriptive\ncaptions, while the mask generation module generates differentiable positive\nand negative masks for localizing the events. These masks enable the implicit\nalignment of event locations and captions by ensuring that captions generated\nfrom positively and negatively masked videos are complementary, thereby forming\na complete video description. In this way, even under weak supervision, the\nevent location and event caption can be aligned implicitly. Extensive\nexperiments on the public datasets demonstrate that our method outperforms\nexisting weakly-supervised methods and achieves competitive results compared to\nfully-supervised methods.\n","authors":["Shiping Ge","Qiang Chen","Zhiwei Jiang","Yafeng Yin","Liu Qin","Ziyao Chen","Qing Gu"],"pdf_url":"https://arxiv.org/pdf/2412.12791v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2501.15721v1","updated":"2025-01-27T01:22:11Z","published":"2025-01-27T01:22:11Z","title":"On Parallelism in Music and Language: A Perspective from Symbol\n  Emergence Systems based on Probabilistic Generative Models","summary":"  Music and language are structurally similar. Such structural similarity is\noften explained by generative processes. This paper describes the recent\ndevelopment of probabilistic generative models (PGMs) for language learning and\nsymbol emergence in robotics. Symbol emergence in robotics aims to develop a\nrobot that can adapt to real-world environments and human linguistic\ncommunications and acquire language from sensorimotor information alone (i.e.,\nin an unsupervised manner). This is regarded as a constructive approach to\nsymbol emergence systems. To this end, a series of PGMs have been developed,\nincluding those for simultaneous phoneme and word discovery, lexical\nacquisition, object and spatial concept formation, and the emergence of a\nsymbol system. By extending the models, a symbol emergence system comprising a\nmulti-agent system in which a symbol system emerges is revealed to be modeled\nusing PGMs. In this model, symbol emergence can be regarded as collective\npredictive coding. This paper expands on this idea by combining the theory that\n''emotion is based on the predictive coding of interoceptive signals'' and\n''symbol emergence systems,'' and describes the possible hypothesis of the\nemergence of meaning in music.\n","authors":["Tadahiro Taniguchi"],"pdf_url":"https://arxiv.org/pdf/2501.15721v1.pdf","comment":null}]},"2025-01-26T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2501.15587v1","updated":"2025-01-26T16:26:38Z","published":"2025-01-26T16:26:38Z","title":"SCP-116K: A High-Quality Problem-Solution Dataset and a Generalized\n  Pipeline for Automated Extraction in the Higher Education Science Domain","summary":"  Recent breakthroughs in large language models (LLMs) exemplified by the\nimpressive mathematical and scientific reasoning capabilities of the o1 model\nhave spotlighted the critical importance of high-quality training data in\nadvancing LLM performance across STEM disciplines. While the mathematics\ncommunity has benefited from a growing body of curated datasets, the scientific\ndomain at the higher education level has long suffered from a scarcity of\ncomparable resources. To address this gap, we present SCP-116K, a new\nlarge-scale dataset of 116,756 high-quality problem-solution pairs,\nautomatically extracted from heterogeneous sources using a streamlined and\nhighly generalizable pipeline. Our approach involves stringent filtering to\nensure the scientific rigor and educational level of the extracted materials,\nwhile maintaining adaptability for future expansions or domain transfers. By\nopenly releasing both the dataset and the extraction pipeline, we seek to\nfoster research on scientific reasoning, enable comprehensive performance\nevaluations of new LLMs, and lower the barrier to replicating the successes of\nadvanced models like o1 in the broader science community. We believe SCP-116K\nwill serve as a critical resource, catalyzing progress in high-level scientific\nreasoning tasks and promoting further innovations in LLM development. The\ndataset and code are publicly available at\nhttps://github.com/AQA6666/SCP-116K-open.\n","authors":["Dakuan Lu","Xiaoyu Tan","Rui Xu","Tianchu Yao","Chao Qu","Wei Chu","Yinghui Xu","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2501.15587v1.pdf","comment":"9 pages, 1 figures"},{"id":"http://arxiv.org/abs/2501.15470v1","updated":"2025-01-26T10:16:42Z","published":"2025-01-26T10:16:42Z","title":"Unveiling the Potential of Multimodal Retrieval Augmented Generation\n  with Planning","summary":"  Multimodal Retrieval Augmented Generation (MRAG) systems, while promising for\nenhancing Multimodal Large Language Models (MLLMs), often rely on rigid,\nsingle-step retrieval methods. This limitation hinders their ability to\neffectively address real-world scenarios that demand adaptive information\nacquisition and query refinement. To overcome this, we introduce the novel task\nof Multimodal Retrieval Augmented Generation Planning (MRAG Planning), focusing\non optimizing MLLM performance while minimizing computational overhead. We\npresent CogPlanner, a versatile framework inspired by human cognitive\nprocesses. CogPlanner iteratively refines queries and selects retrieval\nstrategies, enabling both parallel and sequential modeling approaches. To\nrigorously evaluate MRAG Planning, we introduce CogBench, a new benchmark\nspecifically designed for this task. CogBench facilitates the integration of\nlightweight CogPlanner with resource-efficient MLLMs. Our experimental findings\ndemonstrate that CogPlanner surpasses existing MRAG baselines, achieving\nsignificant improvements in both accuracy and efficiency with minimal\ncomputational overhead.\n","authors":["Xiaohan Yu","Zhihan Yang","Chong Chen"],"pdf_url":"https://arxiv.org/pdf/2501.15470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00490v2","updated":"2025-01-26T10:08:58Z","published":"2024-08-01T11:51:52Z","title":"Graph Representation Learning via Causal Diffusion for\n  Out-of-Distribution Recommendation","summary":"  Graph Neural Networks (GNNs)-based recommendation algorithms typically assume\nthat training and testing data are drawn from independent and identically\ndistributed (IID) spaces. However, this assumption often fails in the presence\nof out-of-distribution (OOD) data, resulting in significant performance\ndegradation. In this study, we construct a Structural Causal Model (SCM) to\nanalyze interaction data, revealing that environmental confounders (e.g., the\nCOVID-19 pandemic) lead to unstable correlations in GNN-based models, thus\nimpairing their generalization to OOD data. To address this issue, we propose a\nnovel approach, graph representation learning via causal diffusion\n(CausalDiffRec) for OOD recommendation. This method enhances the model's\ngeneralization on OOD data by eliminating environmental confounding factors and\nlearning invariant graph representations. Specifically, we use backdoor\nadjustment and variational inference to infer the real environmental\ndistribution, thereby eliminating the impact of environmental confounders. This\ninferred distribution is then used as prior knowledge to guide the\nrepresentation learning in the reverse phase of the diffusion process to learn\nthe invariant representation. In addition, we provide a theoretical derivation\nthat proves optimizing the objective function of CausalDiffRec can encourage\nthe model to learn environment-invariant graph representations, thereby\nachieving excellent generalization performance in recommendations under\ndistribution shifts. Our extensive experiments validate the effectiveness of\nCausalDiffRec in improving the generalization of OOD data, and the average\nimprovement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and\n11.65% on Douban datasets.\n","authors":["Chu Zhao","Enneng Yang","Yuliang Liang","Pengxiang Lan","Yuting Liu","Jianzhe Zhao","Guibing Guo","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2408.00490v2.pdf","comment":"14 pages, accepted by WWW2025"},{"id":"http://arxiv.org/abs/2501.15429v1","updated":"2025-01-26T07:10:22Z","published":"2025-01-26T07:10:22Z","title":"An Aspect Performance-aware Hypergraph Neural Network for Review-based\n  Recommendation","summary":"  Online reviews allow consumers to provide detailed feedback on various\naspects of items. Existing methods utilize these aspects to model users'\nfine-grained preferences for specific item features through graph neural\nnetworks. We argue that the performance of items on different aspects is\nimportant for making precise recommendations, which has not been taken into\naccount by existing approaches, due to lack of data. In this paper, we propose\nan aspect performance-aware hypergraph neural network (APH) for the\nreview-based recommendation, which learns the performance of items from the\nconflicting sentiment polarity of user reviews. Specifically, APH\ncomprehensively models the relationships among users, items, aspects, and\nsentiment polarity by systematically constructing an aspect hypergraph based on\nuser reviews. In addition, APH aggregates aspects representing users and items\nby employing an aspect performance-aware hypergraph aggregation method. It\naggregates the sentiment polarities from multiple users by jointly considering\nuser preferences and the semantics of their sentiments, determining the weights\nof sentiment polarities to infer the performance of items on various aspects.\nSuch performances are then used as weights to aggregate neighboring aspects.\nExperiments on six real-world datasets demonstrate that APH improves MSE,\nPrecision@5, and Recall@5 by an average of 2.30%, 4.89%, and 1.60% over the\nbest baseline. The source code and data are available at\nhttps://github.com/dianziliu/APH.\n","authors":["Junrui Liu","Tong Li","Di Wu","Zifang Tang","Yuan Fang","Zhen Yang"],"pdf_url":"https://arxiv.org/pdf/2501.15429v1.pdf","comment":"12 pages, accepted by WSDM'25"},{"id":"http://arxiv.org/abs/2501.15425v1","updated":"2025-01-26T07:04:57Z","published":"2025-01-26T07:04:57Z","title":"An Empirically-parametrized Spatio-Temporal Extended-SIR Model for\n  Combined Dilution and Vaccination Mitigation for Rabies Outbreaks in Wild\n  Jackals","summary":"  The transmission of zoonotic diseases between animals and humans poses an\nincreasing threat. Rabies is a prominent example with various instances\nglobally, facilitated by a surplus of meso-predators (commonly, facultative\nsynanthropic species e.g., golden jackals [Canis aureus, hereafter jackals])\nthanks to the abundance of anthropogenic resources leading to dense populations\nclose to human establishments. To mitigate rabies outbreaks and prevent human\ninfections, authorities target the jackal which is the main rabies vector in\nmany regions, through the dissemination of oral vaccines in known jackals'\nactivity centers, as well as opportunistic culling to reduce population\ndensity. Because dilution (i.e., culling) is not selective towards sick or\nun-vaccinated individuals, these two complementary epizootic intervention\npolicies (EIPs) can interfere with each other. Nonetheless, there is only\nlimited examination of the interactive effectiveness of these EIPs and their\npotential influence on rabies epizootic spread dynamics, highlighting the need\nto understand these measures and the spread of rabies in wild jackals. In this\nstudy, we introduce a novel spatio-temporal extended-SIR\n(susceptible-infected-recovered) model with a graph-based spatial framework for\nevaluating mitigation efficiency. We implement the model in a case study using\na jackal population in northern Israel, and using spatial and movement data\ncollected by Advanced Tracking and Localization of Animals in real-life Systems\n(ATLAS) telemetry. An agent-based simulation approach allows us to explore\nvarious biologically-realistic scenarios, and assess the impact of different\nEIPs configurations. Our model suggests that under biologically-realistic\nunderlying assumptions and scenarios, the effectiveness of both EIPs is not\ninfluenced much by the jackal population size but is sensitive to their\ndispersal between activity centers.\n","authors":["Teddy Lazebnik","Yehuda Samuel","Jonathan Tichon","Roi Lapid","Roni King","Tomer Nissimian","Orr Spiegel"],"pdf_url":"https://arxiv.org/pdf/2501.15425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00326v7","updated":"2025-01-26T06:16:39Z","published":"2023-12-01T03:44:54Z","title":"Agent-OM: Leveraging LLM Agents for Ontology Matching","summary":"  Ontology matching (OM) enables semantic interoperability between different\nontologies and resolves their conceptual heterogeneity by aligning related\nentities. OM systems currently have two prevailing design paradigms:\nconventional knowledge-based expert systems and newer machine learning-based\npredictive systems. While large language models (LLMs) and LLM agents have\nrevolutionised data engineering and have been applied creatively in many\ndomains, their potential for OM remains underexplored. This study introduces a\nnovel agent-powered LLM-based design paradigm for OM systems. With\nconsideration of several specific challenges in leveraging LLM agents for OM,\nwe propose a generic framework, namely Agent-OM (Agent for Ontology Matching),\nconsisting of two Siamese agents for retrieval and matching, with a set of OM\ntools. Our framework is implemented in a proof-of-concept system. Evaluations\nof three Ontology Alignment Evaluation Initiative (OAEI) tracks over\nstate-of-the-art OM systems show that our system can achieve results very close\nto the long-standing best performance on simple OM tasks and can significantly\nimprove the performance on complex and few-shot OM tasks.\n","authors":["Zhangcheng Qiang","Weiqing Wang","Kerry Taylor"],"pdf_url":"https://arxiv.org/pdf/2312.00326v7.pdf","comment":"19 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2501.15379v1","updated":"2025-01-26T03:29:18Z","published":"2025-01-26T03:29:18Z","title":"Zero-Shot Interactive Text-to-Image Retrieval via Diffusion-Augmented\n  Representations","summary":"  Interactive Text-to-Image Retrieval (I-TIR) has emerged as a transformative\nuser-interactive tool for applications in domains such as e-commerce and\neducation. Yet, current methodologies predominantly depend on finetuned\nMultimodal Large Language Models (MLLMs), which face two critical limitations:\n(1) Finetuning imposes prohibitive computational overhead and long-term\nmaintenance costs. (2) Finetuning narrows the pretrained knowledge distribution\nof MLLMs, reducing their adaptability to novel scenarios. These issues are\nexacerbated by the inherently dynamic nature of real-world I-TIR systems, where\nqueries and image databases evolve in complexity and diversity, often deviating\nfrom static training distributions. To overcome these constraints, we propose\nDiffusion Augmented Retrieval (DAR), a paradigm-shifting framework that\nbypasses MLLM finetuning entirely. DAR synergizes Large Language Model\n(LLM)-guided query refinement with Diffusion Model (DM)-based visual synthesis\nto create contextually enriched intermediate representations. This\ndual-modality approach deciphers nuanced user intent more holistically,\nenabling precise alignment between textual queries and visually relevant\nimages. Rigorous evaluations across four benchmarks reveal DAR's dual\nstrengths: (1) Matches state-of-the-art finetuned I-TIR models on\nstraightforward queries without task-specific training. (2) Scalable\nGeneralization: Surpasses finetuned baselines by 7.61% in Hits@10 (top-10\naccuracy) under multi-turn conversational complexity, demonstrating robustness\nto intricate, distributionally shifted interactions. By eliminating finetuning\ndependencies and leveraging generative-augmented representations, DAR\nestablishes a new trajectory for efficient, adaptive, and scalable cross-modal\nretrieval systems.\n","authors":["Zijun Long","Kangheng Liang","Gerardo Aragon-Camarasa","Richard Mccreadie","Paul Henderson"],"pdf_url":"https://arxiv.org/pdf/2501.15379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15378v1","updated":"2025-01-26T03:27:11Z","published":"2025-01-26T03:27:11Z","title":"How to Mitigate Information Loss in Knowledge Graphs for GraphRAG:\n  Leveraging Triple Context Restoration and Query-Driven Feedback","summary":"  Knowledge Graph (KG)-augmented Large Language Models (LLMs) have recently\npropelled significant advances in complex reasoning tasks, thanks to their\nbroad domain knowledge and contextual awareness. Unfortunately, current methods\noften assume KGs to be complete, which is impractical given the inherent\nlimitations of KG construction and the potential loss of contextual cues when\nconverting unstructured text into entity-relation triples. In response, this\npaper proposes the Triple Context Restoration and Query-driven Feedback\n(TCR-QF) framework, which reconstructs the textual context underlying each\ntriple to mitigate information loss, while dynamically refining the KG\nstructure by iteratively incorporating query-relevant missing knowledge.\nExperiments on five benchmark question-answering datasets substantiate the\neffectiveness of TCR-QF in KG and LLM integration, where itachieves a 29.1%\nimprovement in Exact Match and a 15.5% improvement in F1 over its\nstate-of-the-art GraphRAG competitors.\n","authors":["Manzong Huang","Chenyang Bu","Yi He","Xindong Wu"],"pdf_url":"https://arxiv.org/pdf/2501.15378v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2501.15508v1","updated":"2025-01-26T12:56:08Z","published":"2025-01-26T12:56:08Z","title":"Learning Complex Heterogeneous Multimodal Fake News via Social Latent\n  Network Inference","summary":"  With the diversification of online social platforms, news dissemination has\nbecome increasingly complex, heterogeneous, and multimodal, making the fake\nnews detection task more challenging and crucial. Previous works mainly focus\non obtaining social relationships of news via retweets, limiting the accurate\ndetection when real cascades are inaccessible. Given the proven assessment of\nthe spreading influence of events, this paper proposes a method called HML\n(Complex Heterogeneous Multimodal Fake News Detection method via Latent Network\nInference). Specifically, an improved social latent network inference strategy\nis designed to estimate the maximum likelihood of news influences under the\nsame event. Meanwhile, a novel heterogeneous graph is built based on social\nattributes for multimodal news under different events. Further, to better\naggregate the relationships among heterogeneous multimodal features, this paper\nproposes a self-supervised-based multimodal content learning strategy, to\nenhance, align, fuse and compare heterogeneous modal contents. Based above, a\npersonalized heterogeneous graph representation learning is designed to\nclassify fake news. Extensive experiments demonstrate that the proposed method\noutperforms the SOTA in real social media news datasets.\n","authors":["Mingxin Li","Yuchen Zhang","Haowei Xu","Xianghua Li","Chao Gao","Zhen Wang"],"pdf_url":"https://arxiv.org/pdf/2501.15508v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2501.15438v1","updated":"2025-01-26T07:50:14Z","published":"2025-01-26T07:50:14Z","title":"Cross-Modal Transfer from Memes to Videos: Addressing Data Scarcity in\n  Hateful Video Detection","summary":"  Detecting hate speech in online content is essential to ensuring safer\ndigital spaces. While significant progress has been made in text and meme\nmodalities, video-based hate speech detection remains under-explored, hindered\nby a lack of annotated datasets and the high cost of video annotation. This gap\nis particularly problematic given the growing reliance on large models, which\ndemand substantial amounts of training data. To address this challenge, we\nleverage meme datasets as both a substitution and an augmentation strategy for\ntraining hateful video detection models. Our approach introduces a\nhuman-assisted reannotation pipeline to align meme dataset labels with video\ndatasets, ensuring consistency with minimal labeling effort. Using two\nstate-of-the-art vision-language models, we demonstrate that meme data can\nsubstitute for video data in resource-scarce scenarios and augment video\ndatasets to achieve further performance gains. Our results consistently\noutperform state-of-the-art benchmarks, showcasing the potential of cross-modal\ntransfer learning for advancing hateful video detection. Dataset and code are\navailable at https://github.com/Social-AI-Studio/CrossModalTransferLearning.\n","authors":["Han Wang","Rui Yang Tan","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2501.15438v1.pdf","comment":"10 pages, 4 figures, THE WEB CONFERENCE 2025"}]},"2025-01-25T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2408.16312v3","updated":"2025-01-25T16:30:57Z","published":"2024-08-29T07:20:56Z","title":"SynDL: A Large-Scale Synthetic Test Collection for Passage Retrieval","summary":"  Large-scale test collections play a crucial role in Information Retrieval\n(IR) research. However, according to the Cranfield paradigm and the research\ninto publicly available datasets, the existing information retrieval research\nstudies are commonly developed on small-scale datasets that rely on human\nassessors for relevance judgments - a time-intensive and expensive process.\nRecent studies have shown the strong capability of Large Language Models (LLMs)\nin producing reliable relevance judgments with human accuracy but at a greatly\nreduced cost. In this paper, to address the missing large-scale ad-hoc document\nretrieval dataset, we extend the TREC Deep Learning Track (DL) test collection\nvia additional language model synthetic labels to enable researchers to test\nand evaluate their search systems at a large scale. Specifically, such a test\ncollection includes more than 1,900 test queries from the previous years of\ntracks. We compare system evaluation with past human labels from past years and\nfind that our synthetically created large-scale test collection can lead to\nhighly correlated system rankings.\n","authors":["Hossein A. Rahmani","Xi Wang","Emine Yilmaz","Nick Craswell","Bhaskar Mitra","Paul Thomas"],"pdf_url":"https://arxiv.org/pdf/2408.16312v3.pdf","comment":"9 pages, resource paper, WWW 2025"},{"id":"http://arxiv.org/abs/2501.15228v1","updated":"2025-01-25T14:24:50Z","published":"2025-01-25T14:24:50Z","title":"Improving Retrieval-Augmented Generation through Multi-Agent\n  Reinforcement Learning","summary":"  Retrieval-augmented generation (RAG) is extensively utilized to incorporate\nexternal, current knowledge into large language models, thereby minimizing\nhallucinations. A standard RAG pipeline may comprise several components, such\nas query rewriting, document retrieval, document filtering, and answer\ngeneration. However, these components are typically optimized separately\nthrough supervised fine-tuning, which can lead to misalignments between the\nobjectives of individual modules and the overarching aim of generating accurate\nanswers in question-answering (QA) tasks. Although recent efforts have explored\nreinforcement learning (RL) to optimize specific RAG components, these\napproaches often focus on overly simplistic pipelines with only two components\nor do not adequately address the complex interdependencies and collaborative\ninteractions among the modules. To overcome these challenges, we propose\ntreating the RAG pipeline as a multi-agent cooperative task, with each\ncomponent regarded as an RL agent. Specifically, we present MMOA-RAG, a\nMulti-Module joint Optimization Algorithm for RAG, which employs multi-agent\nreinforcement learning to harmonize all agents' goals towards a unified reward,\nsuch as the F1 score of the final answer. Experiments conducted on various QA\ndatasets demonstrate that MMOA-RAG improves the overall pipeline performance\nand outperforms existing baselines. Furthermore, comprehensive ablation studies\nvalidate the contributions of individual components and the adaptability of\nMMOA-RAG across different RAG components and datasets. The code of MMOA-RAG is\non https://github.com/chenyiqun/MMOA-RAG.\n","authors":["Yiqun Chen","Lingyong Yan","Weiwei Sun","Xinyu Ma","Yi Zhang","Shuaiqiang Wang","Dawei Yin","Yiming Yang","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2501.15228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21745v3","updated":"2025-01-25T13:37:50Z","published":"2024-10-29T05:18:34Z","title":"RDSA: A Robust Deep Graph Clustering Framework via Dual Soft Assignment","summary":"  Graph clustering is an essential aspect of network analysis that involves\ngrouping nodes into separate clusters. Recent developments in deep learning\nhave resulted in graph clustering, which has proven effective in many\napplications. Nonetheless, these methods often encounter difficulties when\ndealing with real-world graphs, particularly in the presence of noisy edges.\nAdditionally, many denoising graph clustering methods tend to suffer from lower\nperformance, training instability, and challenges in scaling to large datasets\ncompared to non-denoised models. To tackle these issues, we introduce a new\nframework called the Robust Deep Graph Clustering Framework via Dual Soft\nAssignment (RDSA). RDSA consists of three key components: (i) a node embedding\nmodule that effectively integrates the graph's topological features and node\nattributes; (ii) a structure-based soft assignment module that improves graph\nmodularity by utilizing an affinity matrix for node assignments; and (iii) a\nnode-based soft assignment module that identifies community landmarks and\nrefines node assignments to enhance the model's robustness. We assess RDSA on\nvarious real-world datasets, demonstrating its superior performance relative to\nexisting state-of-the-art methods. Our findings indicate that RDSA provides\nrobust clustering across different graph types, excelling in clustering\neffectiveness and robustness, including adaptability to noise, stability, and\nscalability.\n","authors":["Yang Xiang","Li Fan","Tulika Saha","Xiaoying Pang","Yushan Pan","Haiyang Zhang","Chengtao Ji"],"pdf_url":"https://arxiv.org/pdf/2410.21745v3.pdf","comment":"Accepted by DASFAA 2025; Complete version"},{"id":"http://arxiv.org/abs/2407.21033v3","updated":"2025-01-25T11:53:12Z","published":"2024-07-17T05:42:43Z","title":"Multi-Grained Query-Guided Set Prediction Network for Grounded\n  Multimodal Named Entity Recognition","summary":"  Grounded Multimodal Named Entity Recognition (GMNER) is an emerging\ninformation extraction (IE) task, aiming to simultaneously extract entity\nspans, types, and corresponding visual regions of entities from given\nsentence-image pairs data. Recent unified methods employing machine reading\ncomprehension or sequence generation-based frameworks show limitations in this\ndifficult task. The former, utilizing human-designed type queries, struggles to\ndifferentiate ambiguous entities, such as Jordan (Person) and off-White x\nJordan (Shoes). The latter, following the one-by-one decoding order, suffers\nfrom exposure bias issues. We maintain that these works misunderstand the\nrelationships of multimodal entities. To tackle these, we propose a novel\nunified framework named Multi-grained Query-guided Set Prediction Network\n(MQSPN) to learn appropriate relationships at intra-entity and inter-entity\nlevels. Specifically, MQSPN explicitly aligns textual entities with visual\nregions by employing a set of learnable queries to strengthen intra-entity\nconnections. Based on distinct intra-entity modeling, MQSPN reformulates GMNER\nas a set prediction, guiding models to establish appropriate inter-entity\nrelationships from a optimal global matching perspective. Additionally, we\nincorporate a query-guided Fusion Net (QFNet) as a glue network to boost better\nalignment of two-level relationships. Extensive experiments demonstrate that\nour approach achieves state-of-the-art performances in widely used benchmarks.\n","authors":["Jielong Tang","Zhenxing Wang","Ziyang Gong","Jianxing Yu","Xiangwei Zhu","Jian Yin"],"pdf_url":"https://arxiv.org/pdf/2407.21033v3.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.15462v4","updated":"2025-01-25T08:43:45Z","published":"2024-07-22T08:19:34Z","title":"Retrieval with Learned Similarities","summary":"  Retrieval plays a fundamental role in recommendation systems, search, and\nnatural language processing (NLP) by efficiently finding relevant items from a\nlarge corpus given a query. Dot products have been widely used as the\nsimilarity function in such tasks, enabled by Maximum Inner Product Search\n(MIPS) algorithms for efficient retrieval. However, state-of-the-art retrieval\nalgorithms have migrated to learned similarities. These advanced approaches\nencompass multiple query embeddings, complex neural networks, direct item ID\ndecoding via beam search, and hybrid solutions. Unfortunately, we lack\nefficient solutions for retrieval in these state-of-the-art setups. Our work\naddresses this gap by investigating efficient retrieval techniques with\nexpressive learned similarity functions. We establish Mixture-of-Logits (MoL)\nas a universal approximator of similarity functions, demonstrate that MoL's\nexpressiveness can be realized empirically to achieve superior performance on\ndiverse retrieval scenarios, and propose techniques to retrieve the approximate\ntop-k results using MoL with tight error bounds. Through extensive\nexperimentation, we show that MoL, enhanced by our proposed mutual\ninformation-based load balancing loss, sets new state-of-the-art results across\nheterogeneous scenarios, including sequential retrieval models in\nrecommendation systems and finetuning language models for question answering;\nand our approximate top-$k$ algorithms outperform baselines by up to 66x in\nlatency while achieving >.99 recall rate compared to exact algorithms.\n","authors":["Bailu Ding","Jiaqi Zhai"],"pdf_url":"https://arxiv.org/pdf/2407.15462v4.pdf","comment":"To appear in WWW 2025. Our code and model checkpoints are available\n  at https://github.com/bailuding/rails"},{"id":"http://arxiv.org/abs/2501.15120v1","updated":"2025-01-25T08:18:15Z","published":"2025-01-25T08:18:15Z","title":"Technology Mapping with Large Language Models","summary":"  In today's fast-evolving business landscape, having insight into the\ntechnology stacks that organizations use is crucial for forging partnerships,\nuncovering market openings, and informing strategic choices. However,\nconventional technology mapping, which typically hinges on keyword searches,\nstruggles with the sheer scale and variety of data available, often failing to\ncapture nascent technologies. To overcome these hurdles, we present STARS\n(Semantic Technology and Retrieval System), a novel framework that harnesses\nLarge Language Models (LLMs) and Sentence-BERT to pinpoint relevant\ntechnologies within unstructured content, build comprehensive company profiles,\nand rank each firm's technologies according to their operational importance. By\nintegrating entity extraction with Chain-of-Thought prompting and employing\nsemantic ranking, STARS provides a precise method for mapping corporate\ntechnology portfolios. Experimental results show that STARS markedly boosts\nretrieval accuracy, offering a versatile and high-performance solution for\ncross-industry technology mapping.\n","authors":["Minh Hieu Nguyen","Hien Thu Pham","Hiep Minh Ha","Ngoc Quang Hung Le","Jun Jo"],"pdf_url":"https://arxiv.org/pdf/2501.15120v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2501.15118v1","updated":"2025-01-25T08:09:37Z","published":"2025-01-25T08:09:37Z","title":"ABXI: Invariant Interest Adaptation for Task-Guided Cross-Domain\n  Sequential Recommendation","summary":"  Cross-Domain Sequential Recommendation (CDSR) has recently gained attention\nfor countering data sparsity by transferring knowledge across domains. A common\napproach merges domain-specific sequences into cross-domain sequences, serving\nas bridges to connect domains. One key challenge is to correctly extract the\nshared knowledge among these sequences and appropriately transfer it. Most\nexisting works directly transfer unfiltered cross-domain knowledge rather than\nextracting domain-invariant components and adaptively integrating them into\ndomain-specific modelings. Another challenge lies in aligning the\ndomain-specific and cross-domain sequences. Existing methods align these\nsequences based on timestamps, but this approach can cause prediction\nmismatches when the current tokens and their targets belong to different\ndomains. In such cases, the domain-specific knowledge carried by the current\ntokens may degrade performance. To address these challenges, we propose the\nA-B-Cross-to-Invariant Learning Recommender (ABXI). Specifically, leveraging\nLoRA's effectiveness for efficient adaptation, ABXI incorporates two types of\nLoRAs to facilitate knowledge adaptation. First, all sequences are processed\nthrough a shared encoder that employs a domain LoRA for each sequence, thereby\npreserving unique domain characteristics. Next, we introduce an invariant\nprojector that extracts domain-invariant interests from cross-domain\nrepresentations, utilizing an invariant LoRA to adapt these interests into\nmodeling each specific domain. Besides, to avoid prediction mismatches, all\ndomain-specific sequences are aligned to match the domains of the cross-domain\nground truths. Experimental results on three datasets demonstrate that our\napproach outperforms other CDSR counterparts by a large margin. The codes are\navailable in \\url{https://github.com/DiMarzioBian/ABXI}.\n","authors":["Qingtian Bian","Marcus Vinícius de Carvalho","Tieying Li","Jiaxing Xu","Hui Fang","Yiping Ke"],"pdf_url":"https://arxiv.org/pdf/2501.15118v1.pdf","comment":"Accepted by WebConf '25 (WWW '25)"},{"id":"http://arxiv.org/abs/2410.05763v3","updated":"2025-01-25T06:23:30Z","published":"2024-10-08T07:41:01Z","title":"Information Discovery in e-Commerce","summary":"  Electronic commerce, or e-commerce, is the buying and selling of goods and\nservices, or the transmitting of funds or data online. E-commerce platforms\ncome in many kinds, with global players such as Amazon, Airbnb, Alibaba, eBay\nand platforms targeting specific geographic regions. Information retrieval has\na natural role to play in e-commerce, especially in connecting people to goods\nand services. Information discovery in e-commerce concerns different types of\nsearch (e.g., exploratory search vs. lookup tasks), recommender systems, and\nnatural language processing in e-commerce portals. The rise in popularity of\ne-commerce sites has made research on information discovery in e-commerce an\nincreasingly active research area. This is witnessed by an increase in\npublications and dedicated workshops in this space. Methods for information\ndiscovery in e-commerce largely focus on improving the effectiveness of\ne-commerce search and recommender systems, on enriching and using knowledge\ngraphs to support e-commerce, and on developing innovative question answering\nand bot-based solutions that help to connect people to goods and services. In\nthis survey, an overview is given of the fundamental infrastructure,\nalgorithms, and technical solutions for information discovery in e-commerce.\nThe topics covered include user behavior and profiling, search, recommendation,\nand language technology in e-commerce.\n","authors":["Zhaochun Ren","Xiangnan He","Dawei Yin","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2410.05763v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15087v1","updated":"2025-01-25T05:30:58Z","published":"2025-01-25T05:30:58Z","title":"PatchRec: Multi-Grained Patching for Efficient LLM-based Sequential\n  Recommendation","summary":"  Large Language Models for sequential recommendation (LLM4SR), which transform\nuser-item interactions into language modeling, have shown promising results.\nHowever, due to the limitations of context window size and the computational\ncosts associated with Large Language Models (LLMs), current approaches\nprimarily truncate user history by only considering the textual information of\nitems from the most recent interactions in the input prompt. This truncation\nfails to fully capture the long-term behavioral patterns of users. To address\nthis, we propose a multi-grained patching framework -- PatchRec. It compresses\nthe textual tokens of an item title into a compact item patch, and further\ncompresses multiple item patches into a denser session patch, with earlier\ninteractions being compressed to a greater degree. The framework consists of\ntwo stages: (1) Patch Pre-training, which familiarizes LLMs with item-level\ncompression patterns, and (2) Patch Fine-tuning, which teaches LLMs to model\nsequences at multiple granularities. Through this simple yet effective\napproach, empirical results demonstrate that PatchRec outperforms existing\nmethods, achieving significant performance gains with fewer tokens fed to the\nLLM. Specifically, PatchRec shows up to a 32% improvement in HR@20 on the\nGoodreads dataset over uncompressed baseline, while using only 7% of the\ntokens. This multi-grained sequence modeling paradigm, with an adjustable\ncompression ratio, enables LLMs to be efficiently deployed in real-world\nrecommendation systems that handle extremely long user behavior sequences.\n","authors":["Jiayi Liao","Ruobing Xie","Sihang Li","Xiang Wang","Xingwu Sun","Zhanhui Kang","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2501.15087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15067v1","updated":"2025-01-25T04:18:08Z","published":"2025-01-25T04:18:08Z","title":"CG-RAG: Research Question Answering by Citation Graph\n  Retrieval-Augmented LLMs","summary":"  Research question answering requires accurate retrieval and contextual\nunderstanding of scientific literature. However, current Retrieval-Augmented\nGeneration (RAG) methods often struggle to balance complex document\nrelationships with precise information retrieval. In this paper, we introduce\nContextualized Graph Retrieval-Augmented Generation (CG-RAG), a novel framework\nthat integrates sparse and dense retrieval signals within graph structures to\nenhance retrieval efficiency and subsequently improve generation quality for\nresearch question answering. First, we propose a contextual graph\nrepresentation for citation graphs, effectively capturing both explicit and\nimplicit connections within and across documents. Next, we introduce\nLexical-Semantic Graph Retrieval (LeSeGR), which seamlessly integrates sparse\nand dense retrieval signals with graph encoding. It bridges the gap between\nlexical precision and semantic understanding in citation graph retrieval,\ndemonstrating generalizability to existing graph retrieval and hybrid retrieval\nmethods. Finally, we present a context-aware generation strategy that utilizes\nthe retrieved graph-structured information to generate precise and contextually\nenriched responses using large language models (LLMs). Extensive experiments on\nresearch question answering benchmarks across multiple domains demonstrate that\nour CG-RAG framework significantly outperforms RAG methods combined with\nvarious state-of-the-art retrieval approaches, delivering superior retrieval\naccuracy and generation quality.\n","authors":["Yuntong Hu","Zhihan Lei","Zhongjie Dai","Allen Zhang","Abhinav Angirekula","Zheng Zhang","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.15067v1.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2501.17181v1","updated":"2025-01-25T03:51:07Z","published":"2025-01-25T03:51:07Z","title":"An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome:\n  Minimizing Research Waste and Advancing Evidence Synthesis","summary":"  The Brain-Heart Interconnectome (BHI) combines neurology and cardiology but\nis hindered by inefficiencies in evidence synthesis, poor adherence to quality\nstandards, and research waste. To address these challenges, we developed an\nAI-driven system to enhance systematic reviews in the BHI domain. The system\nintegrates automated detection of Population, Intervention, Comparator,\nOutcome, and Study design (PICOS), semantic search using vector embeddings,\ngraph-based querying, and topic modeling to identify redundancies and\nunderexplored areas. Core components include a Bi-LSTM model achieving 87%\naccuracy for PICOS compliance, a study design classifier with 95.7% accuracy,\nand Retrieval-Augmented Generation (RAG) with GPT-3.5, which outperformed GPT-4\nfor graph-based and topic-driven queries. The system provides real-time\nupdates, reducing research waste through a living database and offering an\ninteractive interface with dashboards and conversational AI. While initially\ndeveloped for BHI, the system's adaptable architecture enables its application\nacross various biomedical fields, supporting rigorous evidence synthesis,\nefficient resource allocation, and informed clinical decision-making.\n","authors":["Arya Rahgozar","Pouria Mortezaagha","Jodi Edwards","Douglas Manuel","Jessie McGowen","Merrick Zwarenstein","Dean Fergusson","Andrea Tricco","Kelly Cobey","Margaret Sampson","Malcolm King","Dawn Richards","Alexandra Bodnaruc","David Moher"],"pdf_url":"https://arxiv.org/pdf/2501.17181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08713v4","updated":"2025-01-25T03:14:35Z","published":"2024-08-16T12:51:52Z","title":"CTR-KAN: KAN for Adaptive High-Order Feature Interaction Modeling","summary":"  Modeling high-order feature interactions is critical for click-through rate\n(CTR) prediction, yet traditional approaches often face challenges in balancing\npredictive accuracy and computational efficiency. These methods typically rely\non pre-defined interaction orders, which limit flexibility and require\nextensive prior knowledge. Moreover, explicitly modeling high-order\ninteractions can lead to significant computational overhead. To tackle these\nchallenges, we propose CTR-KAN, an adaptive framework for efficient high-order\nfeature interaction modeling. CTR-KAN builds upon the Kolmogorov-Arnold Network\n(KAN) paradigm, addressing its limitations in CTR prediction tasks.\nSpecifically, we introduce key enhancements, including a lightweight\narchitecture that reduces the computational complexity of KAN and supports\nembedding-based feature representations. Additionally, CTR-KAN integrates\nguided symbolic regression to effectively capture multiplicative relationships,\na known challenge in standard KAN implementations. Extensive experiments\ndemonstrate that CTR-KAN achieves state-of-the-art predictive accuracy with\nsignificantly lower computational costs. Its sparse network structure also\nfacilitates feature pruning and enhances global interpretability, making\nCTR-KAN a powerful tool for efficient inference in real-world CTR prediction\nscenarios.\n","authors":["Yunxiao Shi","Wujiang Xu","Haimin Zhang","Qiang Wu","Yongfeng Zhang","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2408.08713v4.pdf","comment":"draft paper"},{"id":"http://arxiv.org/abs/2409.03140v3","updated":"2025-01-25T01:47:28Z","published":"2024-09-05T00:25:37Z","title":"GraphEx: A Graph-based Extraction Method for Advertiser Keyphrase\n  Recommendation","summary":"  Online sellers and advertisers are recommended keyphrases for their listed\nproducts, which they bid on to enhance their sales. One popular paradigm that\ngenerates such recommendations is Extreme Multi-Label Classification (XMC),\nwhich involves tagging/mapping keyphrases to items. We outline the limitations\nof using traditional item-query based tagging or mapping techniques for\nkeyphrase recommendations on E-Commerce platforms. We introduce GraphEx, an\ninnovative graph-based approach that recommends keyphrases to sellers using\nextraction of token permutations from item titles. Additionally, we demonstrate\nthat relying on traditional metrics such as precision/recall can be misleading\nin practical applications, thereby necessitating a combination of metrics to\nevaluate performance in real-world scenarios. These metrics are designed to\nassess the relevance of keyphrases to items and the potential for buyer\noutreach. GraphEx outperforms production models at eBay, achieving the\nobjectives mentioned above. It supports near real-time inferencing in\nresource-constrained production environments and scales effectively for\nbillions of items.\n","authors":["Ashirbad Mishra","Soumik Dey","Marshall Wu","Jinyu Zhao","He Yu","Kaichen Ni","Binbin Li","Kamesh Madduri"],"pdf_url":"https://arxiv.org/pdf/2409.03140v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15000v1","updated":"2025-01-25T00:26:01Z","published":"2025-01-25T00:26:01Z","title":"MDEval: Evaluating and Enhancing Markdown Awareness in Large Language\n  Models","summary":"  Large language models (LLMs) are expected to offer structured Markdown\nresponses for the sake of readability in web chatbots (e.g., ChatGPT). Although\nthere are a myriad of metrics to evaluate LLMs, they fail to evaluate the\nreadability from the view of output content structure. To this end, we focus on\nan overlooked yet important metric -- Markdown Awareness, which directly\nimpacts the readability and structure of the content generated by these\nlanguage models. In this paper, we introduce MDEval, a comprehensive benchmark\nto assess Markdown Awareness for LLMs, by constructing a dataset with 20K\ninstances covering 10 subjects in English and Chinese. Unlike traditional\nmodel-based evaluations, MDEval provides excellent interpretability by\ncombining model-based generation tasks and statistical methods. Our results\ndemonstrate that MDEval achieves a Spearman correlation of 0.791 and an\naccuracy of 84.1% with human, outperforming existing methods by a large margin.\nExtensive experimental results also show that through fine-tuning over our\nproposed dataset, less performant open-source models are able to achieve\ncomparable performance to GPT-4o in terms of Markdown Awareness. To ensure\nreproducibility and transparency, MDEval is open sourced at\nhttps://github.com/SWUFE-DB-Group/MDEval-Benchmark.\n","authors":["Zhongpu Chen","Yinfeng Liu","Long Shi","Zhi-Jie Wang","Xingyan Chen","Yu Zhao","Fuji Ren"],"pdf_url":"https://arxiv.org/pdf/2501.15000v1.pdf","comment":"WWW 2025"}],"Multimedia":[{"id":"http://arxiv.org/abs/2501.15177v1","updated":"2025-01-25T11:15:06Z","published":"2025-01-25T11:15:06Z","title":"Audio-Language Models for Audio-Centric Tasks: A survey","summary":"  Audio-Language Models (ALMs), which are trained on audio-text data, focus on\nthe processing, understanding, and reasoning of sounds. Unlike traditional\nsupervised learning approaches learning from predefined labels, ALMs utilize\nnatural language as a supervision signal, which is more suitable for describing\ncomplex real-world audio recordings. ALMs demonstrate strong zero-shot\ncapabilities and can be flexibly adapted to diverse downstream tasks. These\nstrengths not only enhance the accuracy and generalization of audio processing\ntasks but also promote the development of models that more closely resemble\nhuman auditory perception and comprehension. Recent advances in ALMs have\npositioned them at the forefront of computer audition research, inspiring a\nsurge of efforts to advance ALM technologies. Despite rapid progress in the\nfield of ALMs, there is still a notable lack of systematic surveys that\ncomprehensively organize and analyze developments. In this paper, we present a\ncomprehensive review of ALMs with a focus on general audio tasks, aiming to\nfill this gap by providing a structured and holistic overview of ALMs.\nSpecifically, we cover: (1) the background of computer audition and\naudio-language models; (2) the foundational aspects of ALMs, including\nprevalent network architectures, training objectives, and evaluation methods;\n(3) foundational pre-training and audio-language pre-training approaches; (4)\ntask-specific fine-tuning, multi-task tuning and agent systems for downstream\napplications; (5) datasets and benchmarks; and (6) current challenges and\nfuture directions. Our review provides a clear technical roadmap for\nresearchers to understand the development and future trends of existing\ntechnologies, offering valuable references for implementation in real-world\nscenarios.\n","authors":["Yi Su","Jisheng Bai","Qisheng Xu","Kele Xu","Yong Dou"],"pdf_url":"https://arxiv.org/pdf/2501.15177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15052v1","updated":"2025-01-25T03:24:34Z","published":"2025-01-25T03:24:34Z","title":"Graph-Based Cross-Domain Knowledge Distillation for Cross-Dataset\n  Text-to-Image Person Retrieval","summary":"  Video surveillance systems are crucial components for ensuring public safety\nand management in smart city. As a fundamental task in video surveillance,\ntext-to-image person retrieval aims to retrieve the target person from an image\ngallery that best matches the given text description. Most existing\ntext-to-image person retrieval methods are trained in a supervised manner that\nrequires sufficient labeled data in the target domain. However, it is common in\npractice that only unlabeled data is available in the target domain due to the\ndifficulty and cost of data annotation, which limits the generalization of\nexisting methods in practical application scenarios. To address this issue, we\npropose a novel unsupervised domain adaptation method, termed Graph-Based\nCross-Domain Knowledge Distillation (GCKD), to learn the cross-modal feature\nrepresentation for text-to-image person retrieval in a cross-dataset scenario.\nThe proposed GCKD method consists of two main components. Firstly, a\ngraph-based multi-modal propagation module is designed to bridge the\ncross-domain correlation among the visual and textual samples. Secondly, a\ncontrastive momentum knowledge distillation module is proposed to learn the\ncross-modal feature representation using the online knowledge distillation\nstrategy. By jointly optimizing the two modules, the proposed method is able to\nachieve efficient performance for cross-dataset text-to-image person retrieval.\nacExtensive experiments on three publicly available text-to-image person\nretrieval datasets demonstrate the effectiveness of the proposed GCKD method,\nwhich consistently outperforms the state-of-the-art baselines.\n","authors":["Bingjun Luo","Jinpeng Wang","Wang Zewen","Junjie Zhu","Xibin Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.15052v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.15509v3","updated":"2025-01-25T02:06:55Z","published":"2024-12-20T02:45:37Z","title":"PolySmart @ TRECVid 2024 Video Captioning (VTT)","summary":"  In this paper, we present our methods and results for the Video-To-Text (VTT)\ntask at TRECVid 2024, exploring the capabilities of Vision-Language Models\n(VLMs) like LLaVA and LLaVA-NeXT-Video in generating natural language\ndescriptions for video content. We investigate the impact of fine-tuning VLMs\non VTT datasets to enhance description accuracy, contextual relevance, and\nlinguistic consistency. Our analysis reveals that fine-tuning substantially\nimproves the model's ability to produce more detailed and domain-aligned text,\nbridging the gap between generic VLM tasks and the specialized needs of VTT.\nExperimental results demonstrate that our fine-tuned model outperforms baseline\nVLMs across various evaluation metrics, underscoring the importance of\ndomain-specific tuning for complex VTT tasks.\n","authors":["Jiaxin Wu","Wengyu Zhang","Xiao-Yong Wei","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2412.15509v3.pdf","comment":null}]},"2025-01-24T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.17952v2","updated":"2025-01-24T23:45:11Z","published":"2024-10-23T15:24:16Z","title":"SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large\n  Language Models to Specialized Domains","summary":"  Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nself-generated synthetic examples, the LLM can improve their performance on\ndomain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone\nsizes and three domains, demonstrate that SimRAG outperforms baselines by\n1.2\\%--8.6\\%.\n","authors":["Ran Xu","Hui Liu","Sreyashi Nag","Zhenwei Dai","Yaochen Xie","Xianfeng Tang","Chen Luo","Yang Li","Joyce C. Ho","Carl Yang","Qi He"],"pdf_url":"https://arxiv.org/pdf/2410.17952v2.pdf","comment":"Accepted to NAACL 2025 main conference"},{"id":"http://arxiv.org/abs/2501.14956v1","updated":"2025-01-24T22:44:22Z","published":"2025-01-24T22:44:22Z","title":"ExPerT: Effective and Explainable Evaluation of Personalized Long-Form\n  Text Generation","summary":"  Evaluating personalized text generated by large language models (LLMs) is\nchallenging, as only the LLM user, i.e., prompt author, can reliably assess the\noutput, but re-engaging the same individuals across studies is infeasible. This\npaper addresses the challenge of evaluating personalized text generation by\nintroducing ExPerT, an explainable reference-based evaluation framework. ExPerT\nleverages an LLM to extract atomic aspects and their evidence from the\ngenerated and reference texts, match the aspects, and evaluate their alignment\nbased on content and writing style -- two key attributes in personalized text\ngeneration. Additionally, ExPerT generates detailed, fine-grained explanations\nfor every step of the evaluation process, enhancing transparency and\ninterpretability. Our experiments demonstrate that ExPerT achieves a 7.2%\nrelative improvement in alignment with human judgments compared to the\nstate-of-the-art text generation evaluation methods. Furthermore, human\nevaluators rated the usability of ExPerT's explanations at 4.7 out of 5,\nhighlighting its effectiveness in making evaluation decisions more\ninterpretable.\n","authors":["Alireza Salemi","Julian Killingback","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2501.14956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14954v1","updated":"2025-01-24T22:39:49Z","published":"2025-01-24T22:39:49Z","title":"MISCON: A Mission-Driven Conversational Consultant for Pre-Venture\n  Entrepreneurs in Food Deserts","summary":"  This work-in-progress report describes MISCON, a conversational consultant\nbeing developed for a public mission project called NOURISH. With MISCON,\naspiring small business owners in a food-insecure region and their advisors in\nCommunity-based organizations would be able to get information, recommendation\nand analysis regarding setting up food businesses. MISCON conversations are\nmodeled as state machine that uses a heterogeneous knowledge graph as well as\nseveral analytical tools and services including a variety of LLMs. In this\nshort report, we present the functional architecture and some design\nconsiderations behind MISCON.\n","authors":["Subhasis Dasgupta","Hans Taparia","Laura Schmidt","Amarnath Gupta"],"pdf_url":"https://arxiv.org/pdf/2501.14954v1.pdf","comment":"8 pages. Acccepted for AAAI 2025 Workshop on AI for Public Missions,\n  March 3rd, 2025"},{"id":"http://arxiv.org/abs/2501.14922v1","updated":"2025-01-24T21:13:45Z","published":"2025-01-24T21:13:45Z","title":"Search results diversification in competitive search","summary":"  In Web retrieval, there are many cases of competition between authors of Web\ndocuments: their incentive is to have their documents highly ranked for queries\nof interest. As such, the Web is a prominent example of a competitive search\nsetting. Past work on competitive search focused on ranking functions based\nsolely on relevance estimation. We study ranking functions that integrate a\nresults-diversification aspect. We show that the competitive search setting\nwith diversity-based ranking has an equilibrium. Furthermore, we theoretically\nand empirically show that the phenomenon of authors mimicking content in\ndocuments highly ranked in the past, which was demonstrated in previous work,\nis mitigated when search results diversification is applied.\n","authors":["Tommy Mordo","Itamar Reinman","Moshe Tennenholtz","Oren Kurland"],"pdf_url":"https://arxiv.org/pdf/2501.14922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19627v2","updated":"2025-01-24T20:49:16Z","published":"2024-10-25T15:25:36Z","title":"Knowledge Graph Enhanced Language Agents for Recommendation","summary":"  Language agents have recently been used to simulate human behavior and\nuser-item interactions for recommendation systems. However, current language\nagent simulations do not understand the relationships between users and items,\nleading to inaccurate user profiles and ineffective recommendations. In this\nwork, we explore the utility of Knowledge Graphs (KGs), which contain extensive\nand reliable relationships between users and items, for recommendation. Our key\ninsight is that the paths in a KG can capture complex relationships between\nusers and items, eliciting the underlying reasons for user preferences and\nenriching user profiles. Leveraging this insight, we propose Knowledge Graph\nEnhanced Language Agents(KGLA), a framework that unifies language agents and KG\nfor recommendation systems. In the simulated recommendation scenario, we\nposition the user and item within the KG and integrate KG paths as natural\nlanguage descriptions into the simulation. This allows language agents to\ninteract with each other and discover sufficient rationale behind their\ninteractions, making the simulation more accurate and aligned with real-world\ncases, thus improving recommendation performance. Our experimental results show\nthat KGLA significantly improves recommendation performance (with a 33%-95%\nboost in NDCG@1 among three widely used benchmarks) compared to the previous\nbest baseline method.\n","authors":["Taicheng Guo","Chaochun Liu","Hai Wang","Varun Mannam","Fang Wang","Xin Chen","Xiangliang Zhang","Chandan K. Reddy"],"pdf_url":"https://arxiv.org/pdf/2410.19627v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04973v2","updated":"2025-01-24T20:21:38Z","published":"2022-09-12T01:15:59Z","title":"Peer Recommendation Interventions for Health-related Social Support: a\n  Feasibility Assessment","summary":"  Online health communities (OHCs) offer the promise of connecting with\nsupportive peers. Forming these connections first requires finding relevant\npeers - a process that can be time-consuming. Peer recommendation systems are a\ncomputational approach to make finding peers easier during a health journey. By\nencouraging OHC users to alter their online social networks, peer\nrecommendations could increase available support. But these benefits are\nhypothetical and based on mixed, observational evidence. To experimentally\nevaluate the effect of peer recommendations, we conceptualize these systems as\nhealth interventions designed to increase specific beneficial connection\nbehaviors. In this paper, we designed a peer recommendation intervention to\nincrease two behaviors: reading about peer experiences and interacting with\npeers. We conducted an initial feasibility assessment of this intervention by\nconducting a 12-week field study in which 79 users of CaringBridge received\nweekly peer recommendations via email. Our results support the usefulness and\ndemand for peer recommendation and suggest benefits to evaluating larger peer\nrecommendation interventions. Our contributions include practical guidance on\nthe development and evaluation of peer recommendation interventions for OHCs.\n","authors":["Zachary Levonian","Matthew Zent","Ngan Nguyen","Matthew McNamara","Loren Terveen","Svetlana Yarosh"],"pdf_url":"https://arxiv.org/pdf/2209.04973v2.pdf","comment":"CSCW 2025, 24 article pages, 34 pages of references & appendices, 17\n  figures"},{"id":"http://arxiv.org/abs/2103.03223v4","updated":"2025-01-24T18:52:43Z","published":"2021-03-04T18:51:06Z","title":"A Comparative Evaluation of Quantification Methods","summary":"  Quantification represents the problem of estimating the distribution of class\nlabels on unseen data. It also represents a growing research field in\nsupervised machine learning, for which a large variety of different algorithms\nhas been proposed in recent years. However, a comprehensive empirical\ncomparison of quantification methods that supports algorithm selection is not\navailable yet. In this work, we close this research gap by conducting a\nthorough empirical performance comparison of 24 different quantification\nmethods on overall more than 40 data sets, considering binary as well as\nmulticlass quantification settings. We observe that no single algorithm\ngenerally outperforms all competitors, but identify a group of methods\nincluding the threshold selection-based Median Sweep and TSMax methods, the DyS\nframework including the HDy method, Forman's mixture model, and Friedman's\nmethod that performs best in the binary setting. For the multiclass setting, we\nobserve that a different, broad group of algorithms yields good performance,\nincluding the HDx method, the Generalized Probabilistic Adjusted Count, the\nreadme method, the energy distance minimization method, the EM algorithm for\nquantification, and Friedman's method. We also find that tuning the underlying\nclassifiers has in most cases only a limited impact on the quantification\nperformance. More generally, we find that the performance on multiclass\nquantification is inferior to the results obtained in the binary setting. Our\nresults can guide practitioners who intend to apply quantification algorithms\nand help researchers to identify opportunities for future research.\n","authors":["Tobias Schumacher","Markus Strohmaier","Florian Lemmerich"],"pdf_url":"https://arxiv.org/pdf/2103.03223v4.pdf","comment":"40 pages, 18 figures, 9 tables"},{"id":"http://arxiv.org/abs/2501.14719v1","updated":"2025-01-24T18:51:26Z","published":"2025-01-24T18:51:26Z","title":"Do LLMs Provide Consistent Answers to Health-Related Questions across\n  Languages?","summary":"  Equitable access to reliable health information is vital for public health,\nbut the quality of online health resources varies by language, raising concerns\nabout inconsistencies in Large Language Models (LLMs) for healthcare. In this\nstudy, we examine the consistency of responses provided by LLMs to\nhealth-related questions across English, German, Turkish, and Chinese. We\nlargely expand the HealthFC dataset by categorizing health-related questions by\ndisease type and broadening its multilingual scope with Turkish and Chinese\ntranslations. We reveal significant inconsistencies in responses that could\nspread healthcare misinformation. Our main contributions are 1) a multilingual\nhealth-related inquiry dataset with meta-information on disease categories, and\n2) a novel prompt-based evaluation workflow that enables sub-dimensional\ncomparisons between two languages through parsing. Our findings highlight key\nchallenges in deploying LLM-based tools in multilingual contexts and emphasize\nthe need for improved cross-lingual alignment to ensure accurate and equitable\nhealthcare information.\n","authors":["Ipek Baris Schlicht","Zhixue Zhao","Burcu Sayin","Lucie Flek","Paolo Rosso"],"pdf_url":"https://arxiv.org/pdf/2501.14719v1.pdf","comment":"9 pages. Short paper appeared at 47th European Conference on\n  Information Retrieval (ECIR 2025)"},{"id":"http://arxiv.org/abs/2406.14117v3","updated":"2025-01-24T15:50:47Z","published":"2024-06-20T09:03:18Z","title":"An Investigation of Prompt Variations for Zero-shot LLM-based Rankers","summary":"  We provide a systematic understanding of the impact of specific components\nand wordings used in prompts on the effectiveness of rankers based on zero-shot\nLarge Language Models (LLMs). Several zero-shot ranking methods based on LLMs\nhave recently been proposed. Among many aspects, methods differ across (1) the\nranking algorithm they implement, e.g., pointwise vs. listwise, (2) the\nbackbone LLMs used, e.g., GPT3.5 vs. FLAN-T5, (3) the components and wording\nused in prompts, e.g., the use or not of role-definition (role-playing) and the\nactual words used to express this. It is currently unclear whether performance\ndifferences are due to the underlying ranking algorithm, or because of spurious\nfactors such as better choice of words used in prompts. This confusion risks to\nundermine future research. Through our large-scale experimentation and\nanalysis, we find that ranking algorithms do contribute to differences between\nmethods for zero-shot LLM ranking. However, so do the LLM backbones -- but even\nmore importantly, the choice of prompt components and wordings affect the\nranking. In fact, in our experiments, we find that, at times, these latter\nelements have more impact on the ranker's effectiveness than the actual ranking\nalgorithms, and that differences among ranking methods become more blurred when\nprompt variations are considered.\n","authors":["Shuoqi Sun","Shengyao Zhuang","Shuai Wang","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2406.14117v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14579v1","updated":"2025-01-24T15:38:32Z","published":"2025-01-24T15:38:32Z","title":"Knowledge Graphs Construction from Criminal Court Appeals: Insights from\n  the French Cassation Court","summary":"  Despite growing interest, accurately and reliably representing unstructured\ndata, such as court decisions, in a structured form, remains a challenge.\nRecent advancements in generative AI applied to language modeling enabled the\ntransformation of text into knowledge graphs, unlocking new opportunities for\nanalysis and modeling. This paper presents a framework for constructing\nknowledge graphs from appeals to the French Cassation Court. The framework\nincludes a domain-specific ontology and a derived dataset, offering a\nfoundation for structured legal data representation and analysis.\n","authors":["Alexander V. Belikov","Sacha Raoult"],"pdf_url":"https://arxiv.org/pdf/2501.14579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06695v2","updated":"2025-01-24T15:37:53Z","published":"2024-12-09T17:41:25Z","title":"DEEPER: Dense Electroencephalography Passage Retrieval","summary":"  A fundamental challenge in Information Retrieval (IR) is the cognitive burden\nof translating internal information needs into explicit textual queries. This\ntranslation barrier particularly affects users with undefined information needs\nor those who face physical constraints in traditional text input methods. While\nBrain-Machine Interfaces (BMIs) have emerged as a potential solution for direct\nneural query interpretation, existing approaches that attempt to convert brain\nsignals into text queries have demonstrated limited success in capturing the\ncomplexity of neural semantic patterns. This paper introduces DEEPER Dense EEG\nPassage Retrieval, a novel framework that bypasses the need for explicit query\ntranslation by directly mapping electroencephalography (EEG) signals to\nrelevant text passages. Our approach employs dense retrieval architectures to\ncreate a unified semantic space where both EEG signals and text passages can be\neffectively compared. Experimental evaluation on the ZuCo dataset shows that\nDEEPER substantially outperforms current EEG-to-text baselines, achieving\nnearly 5x improvement in retrieval precision while demonstrating robust\nperformance across a diverse set of 30 participants. Through detailed ablation\nanalysis, we identify key architectural components, including specialized\nneural encoders and strategic negative sampling techniques, that enable\neffective cross-modal semantic alignment. Our findings demonstrate the\nfeasibility of direct EEG passage retrieval and suggest new possibilities for\ndeveloping IR systems that can more naturally interface with users' cognitive\nprocesses.\n","authors":["Niall McGuire","Yashar Moshfeghi"],"pdf_url":"https://arxiv.org/pdf/2412.06695v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14466v1","updated":"2025-01-24T12:55:42Z","published":"2025-01-24T12:55:42Z","title":"On Correlating Factors for Domain Adaptation Performance","summary":"  Dense retrievers have demonstrated significant potential for neural\ninformation retrieval; however, they lack robustness to domain shifts, limiting\ntheir efficacy in zero-shot settings across diverse domains. In this paper, we\nset out to analyze the possible factors that lead to successful domain\nadaptation of dense retrievers. We include domain similarity proxies between\ngenerated queries to test and source domains. Furthermore, we conduct a case\nstudy comparing two powerful domain adaptation techniques. We find that\ngenerated query type distribution is an important factor, and generating\nqueries that share a similar domain to the test documents improves the\nperformance of domain adaptation methods. This study further emphasizes the\nimportance of domain-tailored generated queries.\n","authors":["Goksenin Yuksel","Jaap Kamps"],"pdf_url":"https://arxiv.org/pdf/2501.14466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14459v1","updated":"2025-01-24T12:42:53Z","published":"2025-01-24T12:42:53Z","title":"Interpretability Analysis of Domain Adapted Dense Retrievers","summary":"  Dense retrievers have demonstrated significant potential for neural\ninformation retrieval; however, they exhibit a lack of robustness to domain\nshifts, thereby limiting their efficacy in zero-shot settings across diverse\ndomains. Previous research has investigated unsupervised domain adaptation\ntechniques to adapt dense retrievers to target domains. However, these studies\nhave not focused on explainability analysis to understand how such adaptations\nalter the model's behavior. In this paper, we propose utilizing the integrated\ngradients framework to develop an interpretability method that provides both\ninstance-based and ranking-based explanations for dense retrievers. To generate\nthese explanations, we introduce a novel baseline that reveals both query and\ndocument attributions. This method is used to analyze the effects of domain\nadaptation on input attributions for query and document tokens across two\ndatasets: the financial question answering dataset (FIQA) and the biomedical\ninformation retrieval dataset (TREC-COVID). Our visualizations reveal that\ndomain-adapted models focus more on in-domain terminology compared to\nnon-adapted models, exemplified by terms such as \"hedge,\" \"gold,\" \"corona,\" and\n\"disease.\" This research addresses how unsupervised domain adaptation\ntechniques influence the behavior of dense retrievers when adapted to new\ndomains. Additionally, we demonstrate that integrated gradients are a viable\nchoice for explaining and analyzing the internal mechanisms of these opaque\nneural models.\n","authors":["Goksenin Yuksel","Jaap Kamps"],"pdf_url":"https://arxiv.org/pdf/2501.14459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10381v3","updated":"2025-01-24T12:25:30Z","published":"2024-11-28T04:06:02Z","title":"Supervised Learning-enhanced Multi-Group Actor Critic for Live Stream\n  Allocation in Feed","summary":"  Reinforcement Learning (RL) has been widely applied in recommendation systems\nto capture long-term user engagement, thus improving dwelling time and\nimproving user retention. In the context of a short video & live stream mixed\nrecommendation scenario, the live stream recommendation system (RS) decides\nwhether to inject at most one live stream into the video feed for each user\nrequest. To maximize long-term user engagement, it is crucial to determine an\noptimal live stream injection policy for accurate live stream allocation.\nHowever, traditional RL algorithms often face divergence and instability\nproblems, and these issues may cause too many live stream allocation, which\ninterrupts user's short video interest and leads to a decrease in the user's\napp usage duration. To address these challenges, we propose a novel Supervised\nLearning-enhanced Multi-Group Actor Critic algorithm (SL-MGAC). Specifically,\nwe introduce a supervised learning-enhanced actor-critic framework that\nincorporates variance reduction techniques, where multi-task reward learning\nhelps restrict bootstrapping error accumulation during critic learning.\nAdditionally, we design a multi-group state decomposition module for both actor\nand critic networks to reduce prediction variance and improve model stability.\nWe also propose a novel reward function to prevent overly greedy live stream\nallocation. Empirically, we evaluate the SL-MGAC algorithm using offline policy\nevaluation (OPE) and online A/B testing. Experimental results demonstrate that\nthe proposed method not only outperforms baseline methods under the\nplatform-level constraints but also exhibits enhanced stability in online\nrecommendation scenarios.\n","authors":["Jingxin Liu","Xiang Gao","Yisha Li","Xin Li","Haiyang Lu","Ben Wang"],"pdf_url":"https://arxiv.org/pdf/2412.10381v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14434v1","updated":"2025-01-24T12:02:37Z","published":"2025-01-24T12:02:37Z","title":"Remining Hard Negatives for Generative Pseudo Labeled Domain Adaptation","summary":"  Dense retrievers have demonstrated significant potential for neural\ninformation retrieval; however, they exhibit a lack of robustness to domain\nshifts, thereby limiting their efficacy in zero-shot settings across diverse\ndomains. A state-of-the-art domain adaptation technique is Generative Pseudo\nLabeling (GPL). GPL uses synthetic query generation and initially mined hard\nnegatives to distill knowledge from cross-encoder to dense retrievers in the\ntarget domain. In this paper, we analyze the documents retrieved by the\ndomain-adapted model and discover that these are more relevant to the target\nqueries than those of the non-domain-adapted model. We then propose refreshing\nthe hard-negative index during the knowledge distillation phase to mine better\nhard negatives. Our remining R-GPL approach boosts ranking performance in 13/14\nBEIR datasets and 9/12 LoTTe datasets. Our contributions are (i) analyzing hard\nnegatives returned by domain-adapted and non-domain-adapted models and (ii)\napplying the GPL training with and without hard-negative re-mining in LoTTE and\nBEIR datasets.\n","authors":["Goksenin Yuksel","David Rau","Jaap Kamps"],"pdf_url":"https://arxiv.org/pdf/2501.14434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14432v1","updated":"2025-01-24T11:59:51Z","published":"2025-01-24T11:59:51Z","title":"CAMEO: Autocorrelation-Preserving Line Simplification for Lossy Time\n  Series Compression","summary":"  Time series data from a variety of sensors and IoT devices need effective\ncompression to reduce storage and I/O bandwidth requirements. While most time\nseries databases and systems rely on lossless compression, lossy techniques\noffer even greater space-saving with a small loss in precision. However, the\nunknown impact on downstream analytics applications requires a semi-manual\ntrial-and-error exploration. We initiate work on lossy compression that\nprovides guarantees on complex statistical features (which are strongly\ncorrelated with the accuracy of the downstream analytics). Specifically, we\npropose a new lossy compression method that provides guarantees on the\nautocorrelation and partial-autocorrelation functions (ACF/PACF) of a time\nseries. Our method leverages line simplification techniques as well as\nincremental maintenance of aggregates, blocking, and parallelization strategies\nfor effective and efficient compression. The results show that our method\nimproves compression ratios by 2x on average and up to 54x on selected\ndatasets, compared to previous lossy and lossless compression methods.\nMoreover, we maintain -- and sometimes even improve -- the forecasting accuracy\nby preserving the autocorrelation properties of the time series. Our framework\nis extensible to multivariate time series and other statistical features of the\ntime series.\n","authors":["Carlos Enrique Muñiz-Cuza","Matthias Boehm","Torben Bach Pedersen"],"pdf_url":"https://arxiv.org/pdf/2501.14432v1.pdf","comment":"14 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.20211v2","updated":"2025-01-24T11:18:26Z","published":"2024-12-28T16:48:55Z","title":"Sequence Generation Modeling for Continuous Value Prediction","summary":"  Continuous value prediction (CVP) plays a crucial role in short video\nrecommendation, capturing user preferences through precise numerical\nestimations. However, traditional regression-based methods often struggle with\nchallenges like wide value ranges and imbalanced data, leading to prediction\nbias. While ordinal classification approaches have been introduced to address\nthese issues, their reliance on discretization reduces accuracy and overlooks\ninherent relationships between intervals. To overcome these limitations, we\nintroduce a novel Generative Regression (GR) framework for CVP, inspired by\nsequence generation techniques in language modeling. Our method transforms\nnumerical values into token sequences through structural discretization,\npreserving original data fidelity while improving prediction precision.\nLeveraging a carefully crafted vocabulary and label encoding, GR employs\ncurriculum learning with an embedding mixup strategy to bridge\ntraining-inference gaps. Experimental evaluations on four public datasets and\none large-scale industrial dataset validate the superiority of GR over existing\nmethods. Real-world A/B tests on Kuaishou, a leading video platform, further\ndemonstrate its practical effectiveness. Additionally, GR proves adaptable to\nother regression tasks, such as Lifetime Value (LTV) prediction, showcasing its\npotential as a robust solution for diverse CVP challenges.\n","authors":["Hongxu Ma","Kai Tian","Tao Zhang","Xuefeng Zhang","Chunjie Chen","Han Li","Jihong Guan","Shuigeng Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.20211v2.pdf","comment":"10 pages, 5 figures, conference or other essential info"},{"id":"http://arxiv.org/abs/2501.14399v1","updated":"2025-01-24T11:08:29Z","published":"2025-01-24T11:08:29Z","title":"Handling Heterophily in Recommender Systems with Wavelet Hypergraph\n  Diffusion","summary":"  Recommender systems are pivotal in delivering personalised user experiences\nacross various domains. However, capturing the heterophily patterns and the\nmulti-dimensional nature of user-item interactions poses significant\nchallenges. To address this, we introduce FWHDNN (Fusion-based Wavelet\nHypergraph Diffusion Neural Networks), an innovative framework aimed at\nadvancing representation learning in hypergraph-based recommendation tasks. The\nmodel incorporates three key components: (1) a cross-difference relation\nencoder leveraging heterophily-aware hypergraph diffusion to adapt\nmessage-passing for diverse class labels, (2) a multi-level cluster-wise\nencoder employing wavelet transform-based hypergraph neural network layers to\ncapture multi-scale topological relationships, and (3) an integrated\nmulti-modal fusion mechanism that combines structural and textual information\nthrough intermediate and late-fusion strategies. Extensive experiments on\nreal-world datasets demonstrate that FWHDNN surpasses state-of-the-art methods\nin accuracy, robustness, and scalability in capturing high-order\ninterconnections between users and items.\n","authors":["Darnbi Sakong","Thanh Tam Nguyen"],"pdf_url":"https://arxiv.org/pdf/2501.14399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18434v2","updated":"2025-01-24T10:41:09Z","published":"2024-02-28T16:00:25Z","title":"Graph Regularized Encoder Training for Extreme Classification","summary":"  Deep extreme classification (XC) aims to train an encoder architecture and an\naccompanying classifier architecture to tag a data point with the most relevant\nsubset of labels from a very large universe of labels. XC applications in\nranking, recommendation and tagging routinely encounter tail labels for which\nthe amount of training data is exceedingly small. Graph convolutional networks\n(GCN) present a convenient but computationally expensive way to leverage task\nmetadata and enhance model accuracies in these settings. This paper formally\nestablishes that in several use cases, the steep computational cost of GCNs is\nentirely avoidable by replacing GCNs with non-GCN architectures. The paper\nnotices that in these settings, it is much more effective to use graph data to\nregularize encoder training than to implement a GCN. Based on these insights,\nan alternative paradigm RAMEN is presented to utilize graph metadata in XC\nsettings that offers significant performance boosts with zero increase in\ninference computational costs. RAMEN scales to datasets with up to 1M labels\nand offers prediction accuracy up to 15% higher on benchmark datasets than\nstate of the art methods, including those that use graph metadata to train\nGCNs. RAMEN also offers 10% higher accuracy over the best baseline on a\nproprietary recommendation dataset sourced from click logs of a popular search\nengine. Code for RAMEN will be released publicly.\n","authors":["Anshul Mittal","Shikhar Mohan","Deepak Saini","Siddarth Asokan","Suchith C. Prabhu","Lakshya Kumar","Pankaj Malhotra","Jain jiao","Amit Singh","Sumeet Agarwal","Soumen Chakrabarti","Purushottam Kar","Manik Varma"],"pdf_url":"https://arxiv.org/pdf/2402.18434v2.pdf","comment":"Accepted at TheWebConf"},{"id":"http://arxiv.org/abs/2410.10994v2","updated":"2025-01-24T10:40:05Z","published":"2024-10-14T18:20:09Z","title":"GraFPrint: A GNN-Based Approach for Audio Identification","summary":"  This paper introduces GraFPrint, an audio identification framework that\nleverages the structural learning capabilities of Graph Neural Networks (GNNs)\nto create robust audio fingerprints. Our method constructs a k-nearest neighbor\n(k-NN) graph from time-frequency representations and applies max-relative graph\nconvolutions to encode local and global information. The network is trained\nusing a self-supervised contrastive approach, which enhances resilience to\nambient distortions by optimizing feature representation. GraFPrint\ndemonstrates superior performance on large-scale datasets at various levels of\ngranularity, proving to be both lightweight and scalable, making it suitable\nfor real-world applications with extensive reference databases.\n","authors":["Aditya Bhattacharjee","Shubhr Singh","Emmanouil Benetos"],"pdf_url":"https://arxiv.org/pdf/2410.10994v2.pdf","comment":"Submitted to IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2025)"},{"id":"http://arxiv.org/abs/2501.14342v1","updated":"2025-01-24T09:12:52Z","published":"2025-01-24T09:12:52Z","title":"Chain-of-Retrieval Augmented Generation","summary":"  This paper introduces an approach for training o1-like RAG models that\nretrieve and reason over relevant information step by step before generating\nthe final answer. Conventional RAG methods usually perform a single retrieval\nstep before the generation process, which limits their effectiveness in\naddressing complex queries due to imperfect retrieval results. In contrast, our\nproposed method, CoRAG (Chain-of-Retrieval Augmented Generation), allows the\nmodel to dynamically reformulate the query based on the evolving state. To\ntrain CoRAG effectively, we utilize rejection sampling to automatically\ngenerate intermediate retrieval chains, thereby augmenting existing RAG\ndatasets that only provide the correct final answer. At test time, we propose\nvarious decoding strategies to scale the model's test-time compute by\ncontrolling the length and number of sampled retrieval chains. Experimental\nresults across multiple benchmarks validate the efficacy of CoRAG, particularly\nin multi-hop question answering tasks, where we observe more than 10 points\nimprovement in EM score compared to strong baselines. On the KILT benchmark,\nCoRAG establishes a new state-of-the-art performance across a diverse range of\nknowledge-intensive tasks. Furthermore, we offer comprehensive analyses to\nunderstand the scaling behavior of CoRAG, laying the groundwork for future\nresearch aimed at developing factual and grounded foundation models.\n","authors":["Liang Wang","Haonan Chen","Nan Yang","Xiaolong Huang","Zhicheng Dou","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2501.14342v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2501.14296v1","updated":"2025-01-24T07:33:39Z","published":"2025-01-24T07:33:39Z","title":"Multi-stage Large Language Model Pipelines Can Outperform GPT-4o in\n  Relevance Assessment","summary":"  The effectiveness of search systems is evaluated using relevance labels that\nindicate the usefulness of documents for specific queries and users. While\nobtaining these relevance labels from real users is ideal, scaling such data\ncollection is challenging. Consequently, third-party annotators are employed,\nbut their inconsistent accuracy demands costly auditing, training, and\nmonitoring. We propose an LLM-based modular classification pipeline that\ndivides the relevance assessment task into multiple stages, each utilising\ndifferent prompts and models of varying sizes and capabilities. Applied to TREC\nDeep Learning (TREC-DL), one of our approaches showed an 18.4% Krippendorff's\n$\\alpha$ accuracy increase over OpenAI's GPT-4o mini while maintaining a cost\nof about 0.2 USD per million input tokens, offering a more efficient and\nscalable solution for relevance assessment. This approach beats the baseline\nperformance of GPT-4o (5 USD). With a pipeline approach, even the accuracy of\nthe GPT-4o flagship model, measured in $\\alpha$, could be improved by 9.7%.\n","authors":["Julian A. Schnabel","Johanne R. Trippas","Falk Scholer","Danula Hettiachchi"],"pdf_url":"https://arxiv.org/pdf/2501.14296v1.pdf","comment":"WebConf'25, WWW'25"},{"id":"http://arxiv.org/abs/2501.14268v1","updated":"2025-01-24T06:18:12Z","published":"2025-01-24T06:18:12Z","title":"Pre-train and Fine-tune: Recommenders as Large Models","summary":"  In reality, users have different interests in different periods, regions,\nscenes, etc. Such changes in interest are so drastic that they are difficult to\nbe captured by recommenders. Existing multi-domain learning can alleviate this\nproblem. However, the structure of the industrial recommendation system is\ncomplex, the amount of data is huge, and the training cost is extremely high,\nso it is difficult to modify the structure of the industrial recommender and\nre-train it. To fill this gap, we consider recommenders as large pre-trained\nmodels and fine-tune them. We first propose the theory of the information\nbottleneck for fine-tuning and present an explanation for the fine-tuning\ntechnique in recommenders. To tailor for recommendation, we design an\ninformation-aware adaptive kernel (IAK) technique to fine-tune the pre-trained\nrecommender. Specifically, we define fine-tuning as two phases: knowledge\ncompression and knowledge matching and let the training stage of IAK explicitly\napproximate these two phases. Our proposed approach designed from the essence\nof fine-tuning is well interpretable. Extensive online and offline experiments\nshow the superiority of our proposed method. Besides, we also share unique and\nimportant lessons we learned when deploying the method in a large-scale online\nplatform. We also present the potential issues of fine-tuning techniques in\nrecommendation systems and the corresponding solutions. The recommender with\nIAK technique has been deployed on the homepage of a billion-scale online food\nplatform for several months and has yielded considerable profits in our\nbusiness.\n","authors":["Zhenhao Jiang","Chenghao Chen","Hao Feng","Yu Yang","Jin Liu","Jie Zhang","Jia Jia","Ning Hu"],"pdf_url":"https://arxiv.org/pdf/2501.14268v1.pdf","comment":"Accepted by WWW2025"},{"id":"http://arxiv.org/abs/2412.12612v2","updated":"2025-01-24T05:52:51Z","published":"2024-12-17T07:21:25Z","title":"Auto-Cypher: Improving LLMs on Cypher generation via LLM-supervised\n  generation-verification framework","summary":"  Graph databases like Neo4j are gaining popularity for handling complex,\ninterconnected data, over traditional relational databases in modeling and\nquerying relationships. While translating natural language into SQL queries is\nwell-researched, generating Cypher queries for Neo4j remains relatively\nunderexplored. In this work, we present an automated, LLM-Supervised, pipeline\nto generate high-quality synthetic data for Text2Cypher. Our Cypher data\ngeneration pipeline introduces LLM-As-Database-Filler, a novel strategy for\nensuring Cypher query correctness, thus resulting in high quality generations.\nUsing our pipeline, we generate high quality Text2Cypher data - SynthCypher\ncontaining 29.8k instances across various domains and queries with varying\ncomplexities. Training open-source LLMs like LLaMa-3.1-8B, Mistral-7B, and\nQWEN-7B on SynthCypher results in performance gains of up to 40% on the\nText2Cypher test split and 30% on the SPIDER benchmark, adapted for graph\ndatabases.\n","authors":["Aman Tiwari","Shiva Krishna Reddy Malay","Vikas Yadav","Masoud Hashemi","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2412.12612v2.pdf","comment":"Accepted at NAACL 2025 main conference"},{"id":"http://arxiv.org/abs/2501.14256v1","updated":"2025-01-24T05:44:04Z","published":"2025-01-24T05:44:04Z","title":"Revisiting Applicable and Comprehensive Knowledge Tracing in Large-Scale\n  Data","summary":"  Knowledge Tracing (KT) is a fundamental component of Intelligent Tutoring\nSystems (ITS), enabling the modeling of students' knowledge states to predict\nfuture performance. The introduction of Deep Knowledge Tracing (DKT), the first\ndeep learning-based KT (DLKT) model, has brought significant advantages in\nterms of applicability and comprehensiveness. However, recent DLKT models, such\nas Attentive Knowledge Tracing (AKT), have often prioritized predictive\nperformance at the expense of these benefits. While deep sequential models like\nDKT have shown potential, they face challenges related to parallel computing,\nstorage decision modification, and limited storage capacity. To address these\nlimitations, we propose DKT2, a novel KT model that leverages the recently\ndeveloped xLSTM architecture. DKT2 enhances input representation using the\nRasch model and incorporates Item Response Theory (IRT) for interpretability,\nallowing for the decomposition of learned knowledge into familiar and\nunfamiliar knowledge. By integrating this knowledge with predicted questions,\nDKT2 generates comprehensive knowledge states. Extensive experiments conducted\nacross three large-scale datasets demonstrate that DKT2 consistently\noutperforms 17 baseline models in various prediction tasks, underscoring its\npotential for real-world educational applications. This work bridges the gap\nbetween theoretical advancements and practical implementation in KT.Our code\nand datasets will be available at https://github.com/codebase-2025/DKT2.\n","authors":["Yiyun Zhou","Wenkang Han","Jingyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2501.14256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00430v5","updated":"2025-01-24T02:42:07Z","published":"2024-11-30T10:56:30Z","title":"Optimizing Sequential Recommendation Models with Scaling Laws and\n  Approximate Entropy","summary":"  Scaling Laws have emerged as a powerful framework for understanding how model\nperformance evolves as they increase in size, providing valuable insights for\noptimizing computational resources. In the realm of Sequential Recommendation\n(SR), which is pivotal for predicting users' sequential preferences, these laws\noffer a lens through which to address the challenges posed by the scalability\nof SR models. However, the presence of structural and collaborative issues in\nrecommender systems prevents the direct application of the Scaling Law (SL) in\nthese systems. In response, we introduce the Performance Law for SR models,\nwhich aims to theoretically investigate and model the relationship between\nmodel performance and data quality. Specifically, we first fit the HR and NDCG\nmetrics to transformer-based SR models. Subsequently, we propose Approximate\nEntropy (ApEn) to assess data quality, presenting a more nuanced approach\ncompared to traditional data quantity metrics. Our method enables accurate\npredictions across various dataset scales and model sizes, demonstrating a\nstrong correlation in large SR models and offering insights into achieving\noptimal performance for any given model configuration.\n","authors":["Tingjia Shen","Hao Wang","Chuhan Wu","Jin Yao Chin","Wei Guo","Yong Liu","Huifeng Guo","Defu Lian","Ruiming Tang","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.00430v5.pdf","comment":"12 pages, 5 figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2501.14728v1","updated":"2025-01-24T18:59:31Z","published":"2025-01-24T18:59:31Z","title":"Mitigating GenAI-powered Evidence Pollution for Out-of-Context\n  Multimodal Misinformation Detection","summary":"  While large generative artificial intelligence (GenAI) models have achieved\nsignificant success, they also raise growing concerns about online information\nsecurity due to their potential misuse for generating deceptive content.\nOut-of-context (OOC) multimodal misinformation detection, which often retrieves\nWeb evidence to identify the repurposing of images in false contexts, faces the\nissue of reasoning over GenAI-polluted evidence to derive accurate predictions.\nExisting works simulate GenAI-powered pollution at the claim level with\nstylistic rewriting to conceal linguistic cues, and ignore evidence-level\npollution for such information-seeking applications. In this work, we\ninvestigate how polluted evidence affects the performance of existing OOC\ndetectors, revealing a performance degradation of more than 9 percentage\npoints. We propose two strategies, cross-modal evidence reranking and\ncross-modal claim-evidence reasoning, to address the challenges posed by\npolluted evidence. Extensive experiments on two benchmark datasets show that\nthese strategies can effectively enhance the robustness of existing\nout-of-context detectors amidst polluted evidence.\n","authors":["Zehong Yan","Peng Qi","Wynne Hsu","Mong Li Lee"],"pdf_url":"https://arxiv.org/pdf/2501.14728v1.pdf","comment":"12 pages, 11 figures"}]}}